name,url,category,subcategory,instructors,description,enrollment,views,rating,raters
1. 基礎知識：データはあらゆるところにある,https://www.coursera.org/learn/foundations-data-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクス プロフェッショナル認定プログラムの最初のコースです。各コースでは、初歩的なデータ アナリスト業務に必要なスキルを習得します。あらゆる組織で、プロセスの改善、商機とトレンドの見極め、新製品のリリース、慎重な意思決定などに、データ アナリストが必要とされています。このコースでは、Google が開発した実践的なカリキュラムを通じてデータ アナリティクスの世界を紹介します。教材では、データ アナリティクスに関する多数の主要トピックに触れながら、Google データアナリティクス プロフェッショナル認定プログラムの概要がわかるよう工夫されています。現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
- ジュニア データ アナリストやアソシエート データ アナリストが日常的に関わる業務やプロセスを理解できるようになる。
- 専門的なツールボックスに追加できる、主要な分析スキル（データ クリーニング、データ分析、データの可視化）とツール（スプレッドシート、SQL、R プログラミング、Tableau）を習得する。
- データのライフサイクルやデータ分析プロセスなど、ジュニア データ アナリストの業務に関わる数多くの用語や概念を理解できるようになる。
- データ エコシステムにおけるアナリティクスの役割を評価できるようになる。
- 分析的思考について自己診断ができるようになる。
- コース修了後、求人情報を検索でき、求職活動のベストプラクティスを知る。",5406.0,119027.0,4.7,80.0
2. データに基づいた意思決定を行うための問いかけ,https://www.coursera.org/learn/ask-questions-make-decisions-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクス プロフェッショナル認定プログラムの 2 つめのコースです。各コースでは、初歩的なデータ アナリスト業務に必要なスキルを習得します。

このコースでは、1 つめのコースで紹介されたトピックの理解をさらに深めながら、データ主導の意思決定を行うための効果的な問いかけの方法を学び、ステークホルダーのニーズと結びつけられるようになることを目指します。また、現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
- 分析を行う際の、効果的な問いかけのテクニックを学ぶ。
- データ主導の意思決定とデータアナリストのプレゼンテーション方法について理解する。
- 問いかけと意思決定の理解を深めるために、ビジネスのさまざまなシナリオを検証する。
- データアナリストにとって、表計算ソフトが重要なツールであることを理解する。
- 構造化思考に関連するアイデアについて検証する。また、それらがデータアナリストが課題を理解し、ソリューションを生み出すためにどう役立つかを学ぶ。
- ビジネスにおける目標を達成するために、データアナリティクスチームと明確なコミュニケーションを取りながら、ステークホルダーの期待値を管理するための戦略について学ぶ。",1535.0,109144.0,4.6,20.0
3. 探索用データを準備する,https://www.coursera.org/learn/data-preparation-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクス プロフェッショナル認定プログラムの 3 つめのコースです。このコースでは、1～2 つめのコースで学んだトピックの理解を深めながら、表計算ソフトや SQL などのツールを使って目的に合ったデータを抽出し活用する方法、データの整理と保護の方法など、より実践的なデータアナリティクススキルを身につけるための新しいトピックについても学びます。

また、現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
- データアナリストが、分析のために収集するデータをどのように決定するかを知る。
 - 構造化データや非構造化データ、データ型、データ形式について学ぶ。
- データの信頼性を確保するために、データの中にあるさまざまな種類のバイアスを識別する方法を知る。
- データベースやデータセットに対して、データアナリストがどのように表計算ソフトや SQL を使用するかを学ぶ。
 - オープンデータや、データ倫理とデータプライバシーの関連性および重要性を理解する。
 - データベースにアクセスし、データを抽出、フィルタリング、並べ替えする方法について理解する。
 - データを整理し、安全に管理するためのベストプラクティスを学ぶ。",,74173.0,,
3D Data Visualization for Science Communication,https://www.coursera.org/learn/data-visualization-science-communication,Data Science,Data Analysis,"Kalina Borkiewicz, AJ Christensen","This course is an introduction to 3D scientific data visualization, with an emphasis on science communication and cinematic design for appealing to broad audiences. You will develop visualization literacy, through being able to interpret/analyze (read) visualizations and create (write) your own visualizations.

By the end of this course, you will:
-Develop visualization literacy.
-Learn the practicality of working with spatial data.
-Understand what makes a scientific visualization meaningful.
-Learn how to create educational visualizations that maintain scientific accuracy.
-Understand what makes a scientific visualization cinematic.
-Learn how to create visualizations that appeal to broad audiences.
-Learn how to work with image-making software. (for those completing the Honors track)",3471.0,4115.0,,
3D SARS-CoV-19 Protein Visualization With Biopython,https://www.coursera.org/learn/3d-sars-cov-19-protein-visualization-with-biopython,Data Science,Data Analysis,Bhagesh Hunakunti,"In this project you will create an interactive three-dimensional (3D) representation of SARS-CoV-19 (Coronavirus) protein structures & publication-quality pictures of the same, understand properties of SARS-CoV-19 genome, handle biological sequence data stored in FASTA & PDB (Protein Data Bank) and XML format, and get insights from this data using Biopython. This hands-on project will also give you a glimpse of tasks a Bioinformatician performs on a daily basis, along with the up-to-date concepts and database use cases in the field of Medical Research and Human genetics. 

In this project, we will also cover basics about important databases used by biologists and biotechnologists, along with the type of sequence data we can access and visualize from these databases using Biopython & Jupyter notebook.",,,4.5,70.0
4.「ダーティー」なデータを「クリーン」にする,https://www.coursera.org/learn/process-data-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクス プロフェッショナル認定プログラムの 4 つめのコースです。このコースでは、1～3 つめのコースで学んだトピックの理解を深めながら、表計算ソフトや SQL を使ったデータのチェックやクリーニングの方法、またデータクリーニング結果の検証やレポートの作成方法についても学びます。また、現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
 - データ完全性を確認する方法を学ぶ。
 - 表計算ソフトを使ったデータクリーニングの方法を学ぶ。
 - データベースで使用する、基本的な SQL クエリを作成できる。
 - データクリーニングと変換に基本的な SQL 関数を当てはめることができる。
 - データクリーニングの結果を検証する方法を理解する。
 - データクリーニングのレポートの要素と重要性を理解する。",,41569.0,,
5 .データを分析し、答えを導き出す,https://www.coursera.org/learn/analyze-data-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクス プロフェッショナル認定の 5 つめのコースです。このプログラムでは、エントリーレベルのデータアナリストの仕事に就くために必要なスキルを身につけることができます。このコースでは、データ分析プロセスの「分析」フェーズを探求します。ここまでに学んだことを分析に応用し、収集したデータの意味を理解していきます。表計算ソフトや SQL を使ってデータを整理し、フォーマットする方法を学び、データをさまざまな方法で見たり考えたりできるようにします。また、ビジネス上の目標を達成するために、データを使って複雑な計算を行う方法や、数式、関数、SQL クエリの使い方を学びながら、分析を進めていきます。現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
 - 分析のためにデータを整理する方法を学ぶ。
 - データをフォーマットし、調整するためのプロセスを理解する。
 - 表計算ソフトや SQL を使ったデータの集計方法を理解する。
 - 表計算ソフトの数式や関数を使用してデータを計算する。
 - SQL クエリを使用して計算する。",,34573.0,,
6. データ可視化（ビジュアライゼーション）による、データの共有,https://www.coursera.org/learn/visualize-data-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクスプロフェッショナル認定プログラムの 6 つめのコースです。このプログラムでは、エントリーレベルのデータアナリストの仕事に就くために必要なスキルを身につけることができます。このコースでは、データ分析プロセスを完了し、データから発見したことを視覚化、プレゼンテーションする方法を学びます。ビジュアル ダッシュボードなどのデータビジュアライゼーションの手法を活用して、データに命を吹き込んでいきます。また、プレゼンテーションに効果的なビジュアライゼーションを作成できるプラットフォーム Tableau についても学びます。現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
 - データ ビジュアライゼーションの重要性を理解する。
 - データのストーリーを通して説得力のあるナラティブを組み立てる方法を学ぶ。
 - Tableau を使用してダッシュボードとダッシュボード フィルタを作成する方法を理解する。
 - Tableau を使用して効果的なビジュアライゼーションを作成する方法を理解する。
 - 効果的なプレゼンテーションの原則と実践方法を学ぶ。
 - プレゼンテーション時に検討すべき考えうるデータの制限事項を学ぶ。
 - 聞き手との Q&A に関するベストプラクティスを理解する。",,26674.0,,
7. データ分析とR 言語（日本語版近日公開予定）,https://www.coursera.org/learn/data-analysis-r-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクスプロフェッショナル認定プログラムの 7 つめのコースです。このプログラムでは、エントリーレベルのデータアナリストの仕事に就くために必要なスキルを身につけることができます。このコースでは、R というプログラミング言語と、R で作業する環境としての RStudio の使い方を学びます。また、R パッケージなど、R 特有のソフトウェア アプリケーションやツールについても学びます。R を使ってより優れた新しい手法でデータのクリーニング、整理、分析、可視化、レポート作成が可能になることを体感していただきます。 現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
 - R プログラミング言語を使用することのメリットを理解する。
 - RStudio を使用して、R を分析に適用する方法を理解する。
 - R でのプログラミングに関連する基本的な概念を理解する。
 - Tidyverse パッケージを含む R パッケージの内容およびコンポーネントを探求する。
 - データフレームとその R での使用について理解する。
 - R でビジュアライゼーションを作成するためのオプションについて学ぶ。
 - R プログラミングを文書化するための R Markdown について学ぶ。",,2025.0,,
8. 学びの総仕上げとしての最終課題：ケーススタディ（日本語版近日公開予定）,https://www.coursera.org/learn/google-data-analytics-capstone-japanese,Data Science,Data Analysis,Google Career Certificates,"Google データアナリティクスプロフェッショナル認定プログラムの 8 つめのコースです。オプションでケーススタディを行い、データ分析に関連する職に就くための就職活動に備えます。ケーススタディは、候補者の分析能力を評価するために雇用主がよく活用するものです。ケーススタディでは、分析に基づくシナリオを選択します。そして、シナリオから得たデータをもとに、問いかけ、準備、処理、分析、共有、行動をしていただきます。その他にも、面接でよく聞かれる質問や回答、オンラインでポートフォリオを作成する際に役立つ資料などを動画で紹介し、就職活動で役立つスキルを身につけます。現職の Google データ アナリストが、最適なツールやリソースを使って、一般的なアナリスト業務を遂行する実践的な方法を指導します。

この認定プログラムを修了すると、エントリーレベルのデータ アナリスト職に応募できるようになります。過去の業務経験は不要です。

このコース修了後の目標は以下の通りです。
 - 就職活動におけるケーススタディとポートフォリオのメリットと活用方法を学ぶ。
 - 実際の面接のシナリオと一般的な面接での質問について学ぶ。
 - ケーススタディがどう面接プロセスの一部となり得るかを知る。
 - 様々なケーススタディのシナリオを検討し、考察する。
 - 自分のポートフォリオ用にケーススタディを完成させる。",,,,
A Complete Reinforcement Learning System (Capstone),https://www.coursera.org/learn/complete-reinforcement-learning-system,Data Science,Machine Learning,"Martha White, Adam White","In this final course, you will put together your knowledge from Courses 1, 2 and 3 to implement a complete RL solution to a problem. This capstone will let you see how each component---problem formulation, algorithm selection, parameter selection and representation design---fits together into a complete solution, and how to make appropriate choices when deploying RL in the real world. This project will require you to implement both the environment to stimulate your problem, and a control agent with Neural Network function approximation. In addition, you will conduct a scientific study of your learning system to develop your ability to assess the robustness of RL agents. To use RL in the real world, it is critical to (a) appropriately formalize the problem as an MDP, (b) select appropriate algorithms, (c ) identify what choices in your implementation will have large impacts on performance and (d) validate the expected behaviour of your algorithms. This capstone is valuable for anyone who is planning on using RL to solve real problems.

To be successful in this course, you will need to have completed Courses 1, 2, and 3 of this Specialization or the equivalent.

By the end of this course, you will be able to: 

Complete an RL solution to a problem, starting from problem formulation, appropriate algorithm selection and implementation and empirical study into the effectiveness of the solution.",16399.0,14391.0,4.7,580.0
A Crash Course in Causality:  Inferring Causal Effects from Observational Data,https://www.coursera.org/learn/crash-course-in-causality,Data Science,Probability and Statistics,"Jason A. Roy, Ph.D. ","We have all heard the phrase “correlation does not equal causation.”  What, then, does equal causation?  This course aims to answer that question and more!  

Over a period of 5 weeks, you will learn how causal effects are defined, what assumptions about your data and models are necessary, and how to implement and interpret some popular statistical methods.  Learners will have the opportunity to apply these methods to example data in R (free statistical software environment).

At the end of the course, learners should be able to:
1.  Define causal effects using potential outcomes
2.  Describe the difference between association and causation
3.  Express assumptions with causal graphs
4.  Implement several types of causal inference methods (e.g. matching, instrumental variables, inverse probability of treatment weighting)
5.  Identify which causal assumptions are necessary for each type of statistical method

So join us.... and discover for yourself why modern statistical methods for estimating causal effects are indispensable in so many fields of study!",34265.0,45342.0,4.7,474.0
A Crash Course in Data Science,https://www.coursera.org/learn/data-science-course,Data Science,Data Analysis,"Jeff Leek, PhD, Brian Caffo, PhD, Roger D. Peng, PhD","By now you have definitely heard about data science and big data. In this one-week class, we will provide a crash course in what these terms mean and how they play a role in successful organizations. This class is for anyone who wants to learn what all the data science action is about, including those who will eventually need to manage data scientists. The goal is to get you up to speed as quickly as possible on data science without all the fluff. We've designed this course to be as convenient as possible without sacrificing any of the essentials.

This is a focused course designed to rapidly get you up to speed on the field of data science. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward.

After completing this course you will know. 

1. How to describe the role data science plays in various contexts
2. How statistics, machine learning, and software engineering play a role in data science
3. How to describe the structure of a data science project
4. Know the key terms and tools used by data scientists
5. How to identify a successful and an unsuccessful data science project
3. The role of a data science manager


Course cover image by r2hox. Creative Commons BY-SA: https://flic.kr/p/gdMuhT",188396.0,35647.0,4.5,8012.0
A Geometrical Approach to Genome Analysis: Skew & Z-Curve,https://www.coursera.org/learn/genome-analysis-z-curve,Data Science,Data Analysis,Usama A. F. Khalil,"In this 1-hour long project-based course, you will learn how to analyze a complete viral genome using geometrical methods (skews and Z-curve), 2D- and 3D-plotting in Python, and how to use some important Python libraries (like Tkinter, Matplotlib, and NumPy) helping you accomplish this. You will also learn about the genomes of some viruses including, Corona, SARS, HIV, Zika, Nidovirous, and rubella viruses.",,,,
A Simple Scatter Plot using D3 js,https://www.coursera.org/learn/a-simple-scatter-plot-using-d3-js,Data Science,Data Analysis,Ahmad Varasteh,"During this guided project, you will create a simple scatter plot using D3 js. Starting from loading our dataset we are going to cover some steps in order to create a fully functional scatter plot. We will also cover some important topics in data visualization such as Linear and Ordinal scaling to best visualize our data. Having the knowledge of javascript programming language and the basics of d3 js are the two most important prerequisites to get the most out of this guided project.",,,,
AI Applications in People Management,https://www.coursera.org/learn/wharton-ai-applications-people-management,Data Science,Machine Learning,"Prasanna Tambe, Matthew Bidwell, Peter Cappelli","In this course, you will learn about Artificial Intelligence and Machine Learning as it applies to HR Management. You will explore concepts related to the role of data in machine learning, AI application, limitations of using data in HR decisions, and how bias can be mitigated using blockchain technology. Machine learning powers are becoming faster and more streamlined,  and you will gain firsthand knowledge of how to use current and emerging technology to manage the entire employee lifecycle. Through study and analysis, you will learn how to sift through tremendous volumes of data to identify patterns and make predictions that will be in the best interest of your business. By the end of this course, you'll be able to identify how you can incorporate AI to streamline all HR functions and how to work with data to take advantage of the power of machine learning.",,8065.0,4.7,23.0
AI Capstone Project with Deep Learning,https://www.coursera.org/learn/ai-deep-learning-capstone,Data Science,Machine Learning,"Alex Aklson, Joseph Santarcangelo","In this capstone, learners will apply their deep learning knowledge and expertise to a real world challenge.  They will use a library of their choice to develop and test a deep learning model. They will load and pre-process data for a real problem, build the model and validate it. Learners  will then present a project report to demonstrate the validity of their model and their proficiency in the field of Deep Learning.

Learning Outcomes:
•	determine what kind of deep learning method to use in which situation
•	know how to build a deep learning model to solve a real problem 
•	master the process of creating  a deep learning pipeline 
•	apply knowledge of deep learning to improve models using real data
•	demonstrate ability to present and communicate outcomes of deep learning projects",12825.0,25247.0,4.5,417.0
AI For Medical Treatment,https://www.coursera.org/learn/ai-for-medical-treatment,Data Science,Machine Learning,"Pranav Rajpurkar, Bora Uyumazturk, Amirhossein Kiani, Eddy Shyu","AI is transforming the practice of medicine. It’s helping doctors diagnose patients more accurately, make predictions about patients’ future health, and recommend better treatments. This Specialization will give you practical experience in applying machine learning to concrete problems in medicine.

Medical treatment may impact patients differently based on their existing health conditions. In this third course, you’ll recommend treatments more suited to individual patients using data from randomized control trials. In the second week, you’ll apply machine learning interpretation methods to explain the decision-making of complex machine learning models. Finally, you’ll use natural language entity extraction and question-answering methods to automate the task of labeling medical datasets.

These courses go beyond the foundations of deep learning to teach you the nuances in applying AI to medical use cases. If you are new to deep learning or want to get a deeper foundation of how neural networks work, we recommend that you take the Deep Learning Specialization.",18523.0,14899.0,4.7,476.0
AI Strategy and Governance,https://www.coursera.org/learn/wharton-ai-strategy-governance,Data Science,Machine Learning,"Kartik Hosanagar, Lynn Wu, Kevin Werbach, Prasanna Tambe","In this course, you will discover AI and the strategies that are used in transforming business in order to gain a competitive advantage. You will explore the multitude of uses for AI in an enterprise setting and the tools that are available to lower the barriers to AI use. You will get a closer look at the purpose, function, and use-cases for explainable AI. This course will also provide you with the tools to build responsible AI governance algorithms as faculty dive into the large datasets that you can expect to see in an enterprise setting and how that affects the business on a greater scale. Finally, you will examine AI in the organizational structure, how AI is playing a crucial role in change management, and the risks with AI processes. By the end of this course, you will learn different strategies to recognize biases that exist within data, how to ensure that you maintain and build trust with user data and privacy, and what it takes to construct a responsible governance strategy. For additional reading, Professor Hosanagar's book ""A Human’s Guide to Machine Intelligence"" can be used as an additional resource for more extensive information on topics covered in this module.",1556.0,7828.0,5.0,19.0
AI Workflow: AI in Production,https://www.coursera.org/learn/ibm-ai-workflow-ai-production,Data Science,Machine Learning,"Mark J Grover, Ray Lopez, Ph.D.","This is the sixth course in the IBM AI Enterprise Workflow Certification specialization.   You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.    

This course focuses on models in production at a hypothetical streaming media company.  There is an introduction to IBM Watson Machine Learning.  You will build your own API in a Docker container and learn how to manage containers with Kubernetes.  The course also introduces  several other tools in the IBM ecosystem designed to help deploy or maintain models in production.  The AI workflow is not a linear process so there is some time dedicated to the most important feedback loops in order to promote efficient iteration on the overall workflow.
 
By the end of this course you will be able to:
1.  Use Docker to deploy a flask application
2.  Deploy a simple UI to integrate the ML model, Watson NLU, and Watson Visual Recognition
3.  Discuss basic Kubernetes terminology
4.  Deploy a scalable web application on Kubernetes 
5.  Discuss the different feedback loops in AI workflow
6.  Discuss the use of unit testing in the context of model production
7.  Use IBM Watson OpenScale to assess bias and performance of production machine learning models.

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 through 5 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",2838.0,2787.0,4.5,41.0
AI Workflow: Business Priorities and Data Ingestion,https://www.coursera.org/learn/ibm-ai-workflow-business-priorities-data-ingestion,Data Science,Machine Learning,"Mark J Grover, Ray Lopez, Ph.D.","This is the first course of a six part specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.

This first course in the IBM AI Enterprise Workflow Certification specialization introduces you to the scope of the specialization and prerequisites.  Specifically, the courses in this specialization are meant for practicing data scientists who are knowledgeable about probability, statistics, linear algebra, and Python tooling for data science and machine learning.  A hypothetical streaming media company will be introduced as your new client.  You will be introduced to the concept of design thinking, IBMs framework for organizing large enterprise AI projects.  You will also be introduced to the basics of scientific thinking, because the quality that distinguishes a seasoned data scientist from a beginner is creative, scientific thinking.  Finally you will start your work for the hypothetical media company by understanding the data they have, and by building a data ingestion pipeline using Python and Jupyter notebooks.
 
By the end of this course you should be able to:
1.  Know the advantages of carrying out data science using a structured process
2.  Describe how the stages of design thinking correspond to the AI enterprise workflow
3.  Discuss several strategies used to prioritize business opportunities
4.  Explain where data science and data engineering have the most overlap in the AI workflow
5.  Explain the purpose of testing in data ingestion 
6.  Describe the use case for sparse matrices as a target destination for data ingestion 
7.  Know the initial steps that can be taken towards automation of data ingestion pipelines
 
Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",5277.0,3151.0,4.3,145.0
AI Workflow: Data Analysis and Hypothesis Testing,https://www.coursera.org/learn/ibm-ai-workflow-data-analysis-hypothesis-testing,Data Science,Machine Learning,"Mark J Grover, Ray Lopez, Ph.D.","This is the second course in the IBM AI Enterprise Workflow Certification specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.  

In this course you will begin your work for a hypothetical streaming media company by doing exploratory data analysis (EDA).  Best practices for data visualization, handling missing data, and hypothesis testing will be introduced to you as part of your work.  You will learn techniques of estimation with probability distributions and extending these estimates to apply null hypothesis significance tests. You will apply what you learn through two hands on case studies: data visualization and multiple testing using a simple pipeline.
 
By the end of this course you should be able to:
1.  List several best practices concerning EDA and data visualization
2.  Create a simple dashboard in Watson Studio
3.  Describe strategies for dealing with missing data
4.  Explain the difference between imputation and multiple imputation
5.  Employ common distributions to answer questions about event probabilities
6.  Explain the investigative role of hypothesis testing in EDA
7.  Apply several methods for dealing with multiple testing
 
Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.

What skills should you have?
It is assumed that you have completed Course 1 of the IBM AI Enterprise Workflow specialization and have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",3264.0,2189.0,4.2,96.0
AI Workflow: Enterprise Model Deployment,https://www.coursera.org/learn/ibm-ai-workflow-machine-learning-model-deployment,Data Science,Machine Learning,"Mark J Grover, Ray Lopez, Ph.D.","This is the fifth course in the IBM AI Enterprise Workflow Certification specialization.   You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.

This course introduces you to an area that few data scientists are able to experience: Deploying models for use in large enterprises.  Apache Spark is a very commonly used framework for running machine learning models.  Best practices for using Spark will be covered in this course.  Best practices for data manipulation, model training, and model tuning will also be covered.  The use case will call for the creation and deployment of a recommender system. The course wraps up with an introduction to model deployment technologies.
 
By the end of this course you will be able to:
1.  Use Apache Spark's RDDs, dataframes, and a pipeline
2.  Employ spark-submit scripts to interface with Spark environments
3.  Explain how collaborative filtering and content-based filtering work
4.  Build a data ingestion pipeline using Apache Spark and Apache Spark streaming
5.  Analyze hyperparameters in machine learning models on Apache Spark
6.  Deploy machine learning algorithms using the Apache Spark machine learning interface
7.  Deploy a machine learning model from Watson Studio to Watson Machine Learning

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.

What skills should you have?
It is assumed that you have completed Courses 1 through 4 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",2557.0,5287.0,4.1,46.0
AI Workflow: Feature Engineering and Bias Detection,https://www.coursera.org/learn/ibm-ai-workflow-feature-engineering-bias-detection,Data Science,Machine Learning,"Mark J Grover, Ray Lopez, Ph.D.","This is the third course in the IBM AI Enterprise Workflow Certification specialization.    You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.  

Course 3 introduces you to the next stage of the workflow for our hypothetical media company.  In this stage of work you will learn best practices for feature engineering, handling class imbalances and detecting bias in the data.  Class imbalances can seriously affect the validity of your machine learning models, and the mitigation of bias in data is essential to reducing the risk associated with biased models.  These topics will be followed by sections on best practices for dimension reduction, outlier detection, and unsupervised learning techniques for finding patterns in your data.  The case studies will focus on topic modeling and data visualization.
 
By the end of this course you will be able to:
1.  Employ the tools that help address class and class imbalance issues
2.  Explain the ethical considerations regarding bias in data
3.  Employ ai Fairness 360 open source libraries to detect bias in models
4.  Employ dimension reduction techniques for both EDA and transformations stages
5.  Describe topic modeling techniques in natural language processing
6.  Use topic modeling and visualization to explore text data
7.  Employ outlier handling best practices in high dimension data
8.  Employ outlier detection algorithms as a quality assurance tool and a modeling tool
9.  Employ unsupervised learning techniques using pipelines as part of the AI workflow
10.  Employ basic clustering algorithms
 
Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 and 2 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",3251.0,4292.0,4.4,64.0
"AI Workflow: Machine Learning, Visual Recognition and NLP",https://www.coursera.org/learn/ibm-ai-workflow-machine-learning-vr-nlp,Data Science,Machine Learning,"Mark J Grover, Ray Lopez, Ph.D.","This is the fourth course in the IBM AI Enterprise Workflow Certification specialization.    You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones. 

Course 4 covers the next stage of the workflow, setting up models and their associated data pipelines for a hypothetical streaming media company.  The first topic covers the complex topic of evaluation metrics, where you will learn best practices for a number of different metrics including regression metrics, classification metrics, and multi-class metrics, which you will use to select the best model for your business challenge.  The next topics cover best practices for different types of models including linear models, tree-based models, and neural networks.  Out-of-the-box Watson models for natural language understanding and visual recognition will be used.  There will be case studies focusing on natural language processing and on image analysis to provide realistic context for the model pipelines.
 
By the end of this course you will be able to:
Discuss common regression, classification, and multilabel classification metrics
Explain the use of linear and logistic regression in supervised learning applications
Describe common strategies for grid searching and cross-validation
Employ evaluation metrics to select models for production use
Explain the use of tree-based algorithms in supervised learning applications
Explain the use of Neural Networks in supervised learning applications
Discuss the major variants of neural networks and recent advances
Create a neural net model in Tensorflow
Create and test an instance of Watson Visual Recognition
Create and test an instance of Watson NLU

Who should take this course?
This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.
 
What skills should you have?
It is assumed that you have completed Courses 1 through 3 of the IBM AI Enterprise Workflow specialization and you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",3536.0,2977.0,4.4,65.0
AI for Medical Diagnosis,https://www.coursera.org/learn/ai-for-medical-diagnosis,Data Science,Machine Learning,"Pranav Rajpurkar, Bora Uyumazturk, Amirhossein Kiani, Eddy Shyu","AI is transforming the practice of medicine. It’s helping doctors diagnose patients more accurately, make predictions about patients’ future health, and recommend better treatments. As an AI practitioner, you have the opportunity to join in this transformation of modern medicine. If you're already familiar with some of the math and coding behind AI algorithms, and are eager to develop your skills further to tackle challenges in the healthcare industry, then this specialization is for you. No prior medical expertise is required! 

This program will give you practical experience in applying cutting-edge machine learning techniques to concrete problems in modern medicine:

- In Course 1, you will create convolutional neural network image classification and segmentation models to make diagnoses of lung and brain disorders. 
- In Course 2, you will build risk models and survival estimators for heart disease using statistical methods and a random forest predictor to determine patient prognosis. 
- In Course 3, you will build a treatment effect predictor, apply model interpretation techniques and use natural language processing to extract information from radiology reports.

These courses go beyond the foundations of deep learning to give you insight into the nuances of applying AI to medical use cases. As a learner, you will be set up for success in this program if you are already comfortable with some of the math and coding behind AI algorithms. You don't need to be an AI expert, but a working knowledge of deep neural networks, particularly convolutional networks, and proficiency in Python programming at an intermediate level will be essential. If you are relatively new to machine learning or neural networks, we recommend that you first take the Deep Learning Specialization, offered by deeplearning.ai and taught by Andrew Ng.

The demand for AI practitioners with the skills and knowledge to tackle the biggest issues in modern medicine is growing exponentially. Join us in this specialization and begin your journey toward building the future of healthcare.",55365.0,52267.0,4.7,1773.0
AI for Medical Prognosis,https://www.coursera.org/learn/ai-for-medical-prognosis,Data Science,Machine Learning,"Pranav Rajpurkar, Bora Uyumazturk, Eddy Shyu","AI is transforming the practice of medicine. It’s helping doctors diagnose patients more accurately, make predictions about patients’ future health, and recommend better treatments. This Specialization will give you practical experience in applying machine learning to concrete problems in medicine.

Machine learning is a powerful tool for prognosis, a branch of medicine that specializes in predicting the future health of patients. In this second course, you’ll walk through multiple examples of prognostic tasks. You’ll then use decision trees to model non-linear relationships, which are commonly observed in medical data, and apply them to predicting mortality rates more accurately. Finally, you’ll learn how to handle missing data, a key real-world challenge. 

These courses go beyond the foundations of deep learning to teach you the nuances in applying AI to medical use cases.  This course focuses on tree-based machine learning, so a foundation in deep learning is not required for this course.  However, a foundation in deep learning is highly recommended for course 1 and 3 of this specialization.  You can gain a foundation in deep learning by taking the Deep Learning Specialization offered by deeplearning.ai and taught by Andrew Ng.",21330.0,22131.0,4.7,713.0
AI-Powered Chest Disease Detection and Classification,https://www.coursera.org/learn/ai-powered-chest-disease-detection-and-classification,Data Science,Machine Learning,Ryan Ahmed,"Hello everyone and welcome to this hands-on guided project on Artificial intelligence (AI)-powered chest disease detection and classification. AI has been revolutionizing healthcare and medicine in many areas such as: (1) Medical imagery, (2) Drug research, and (3) Genome development. Deep learning has been proven to be superior in detecting and classifying disease using imagery data. 
In this case study, we will automate the process of detecting and classifying chest disease from X-Ray images to reduce the cost and time of detection. This guided project is practical and directly applicable to the healthcare industry. You can add this project to your portfolio of projects which is essential for your next job interview.",,,,
ANOVA and Experimental Design,https://www.coursera.org/learn/anova-and-experimental-design,Data Science,Probability and Statistics,Brian Zaharatos,"This second course in statistical modeling will introduce students to the study of the analysis of variance (ANOVA), analysis of covariance (ANCOVA), and experimental design. ANOVA and ANCOVA, presented as a type of linear regression model, will provide the mathematical basis for designing experiments for data science applications. Emphasis will be placed on important design-related concepts, such as randomization, blocking, factorial design, and causality. Some attention will also be given to ethical issues raised in experimentation.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Logo adapted from photo by Vincent Ledvina on Unsplash",1880.0,17421.0,,
AWS AutoGluon for Machine Learning Classification,https://www.coursera.org/learn/aws-autogluon-for-ml-classification,Data Science,Machine Learning,Ryan Ahmed,"Hello everyone and welcome to this new hands-on project on ML classification with AWS AutoGluon.
In this project, we will train several machine learning classifiers to detect and classify disease using a super powerful library known as AutoGluon.
AutoGluon is the library behind Amazon Web Services (AWS) autopilot and it allows for quick prototyping of several powerful models using a few lines of code.",,,,
Access Bioinformatics Databases with Biopython,https://www.coursera.org/learn/access-bioinformatics-databases-with-biopython,Data Science,Data Analysis,Bhagesh Hunakunti,"In this 1-hour long project-based course, you will learn how to access, parse, and visualize data from various bioinformatics sequence and structural online databases such as ENTREZ, PDB, KEGG and NCBI using Biopython.
You will also interact with various bioinformatics file formats such as FASTA, PDB, GENBANK and XML along with various parsers to read and modify these files using Biopython.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,18.0
Accounting Data Analytics with Python,https://www.coursera.org/learn/accounting-data-analytics-python,Data Science,Data Analysis,"Ronald Guymon, Linden Lu","This course focuses on developing Python skills for assembling business data. It will cover some of the same material from Introduction to Accounting Data Analytics and Visualization, but in a more general purpose programming environment (Jupyter Notebook for Python), rather than in Excel and the Visual Basic Editor. These concepts are taught within the context of one or more accounting data domains (e.g., financial statement data from EDGAR, stock data, loan data, point-of-sale data).

The first half of the course picks up where Introduction to Accounting Data Analytics and Visualization left off: using in an integrated development environment to automate data analytic tasks. We discuss how to manage code and share results within Jupyter Notebook, a popular development environment for data analytic software like Python and R. We then review some fundamental programming skills, such as mathematical operators, functions, conditional statements and loops using Python software. 
The second half of the course focuses on assembling data for machine learning purposes.  We introduce students to Pandas dataframes and Numpy for structuring and manipulating data. We then analyze the data using visualizations and linear regression. Finally, we explain how to use Python for interacting with SQL data.",9530.0,13207.0,4.2,71.0
"Activity Recognition using Python, Tensorflow and Keras",https://www.coursera.org/learn/activity-recognition-python-tensorflow-keras,Data Science,Machine Learning,Vinita Silaparasetty,"Note: The rhyme platform currently does not support webcams, so this is not a live project. 

This guided project is about human activity recognition using Python,TensorFlow2 and Keras. Human activity recognition comes under the computer vision domain. In this project you will learn how to customize the InceptionNet model using Tensorflow2 and Keras. 

While you are watching me code, you will get a cloud desktop with all the required software pre-installed. This will allow you to code along with me. After all, we learn best with active, hands-on learning.

Special Feature: 

1.Manually label images.
2. Learn how to use data augmentation normalization.
3. Learn about transfer learning  using training the pre-trained model InceptionNet V3 on the data.


Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Address Business Issues with Data Science,https://www.coursera.org/learn/address-business-issues-with-data-science,Data Science,Data Analysis,"Sarah Haq, Stacey McBrine, Megan Smith Branch","This course is designed for business professionals that want to learn how to determine if a business issue is appropriate for a data science project and apply the data science process.

The typical student in this course will have experience in a business setting and a high-level understanding of fundamental data science concepts, including, but not limited to: types of data, data science roles, the overall data science lifecycle, and the benefits and challenges of data science.",,3663.0,4.9,12.0
Advanced AI Techniques for the Supply Chain,https://www.coursera.org/learn/advanced-ai-techniques-for-the-supply-chain,Data Science,Machine Learning,"Rajvir Dua, Neelesh Tiruviluamala","In this course, we’ll learn about more advanced machine learning methods that are used to tackle problems in the supply chain. We’ll start with an overview of the different ML paradigms (regression/classification) and where the latest models fit into these breakdowns. Then, we’ll dive deeper into some of the specific techniques and use cases such as using neural networks to predict product demand and random forests to classify products. An important part to using these models is understanding their assumptions and required preprocessing steps. We’ll end with a project incorporating advanced techniques with an image classification problem to find faulty products coming out of a machine.",,3219.0,,
Advanced Business Analytics Capstone,https://www.coursera.org/learn/data-analytics-business-capstone,Data Science,Data Analysis,"Manuel Laguna, Dan Zhang, David Torgerson","The analytics process is a collection of interrelated activities that lead to better decisions and to a higher business performance. The capstone of this specialization is designed with the goal of allowing you to experience this process. The capstone project will take you from data to analysis and models, and ultimately to presentation of insights. 

In this capstone project, you will analyze the data on financial loans to help with the investment decisions of an investment company. You will go through all typical steps of a data analytics project, including data understanding and cleanup, data analysis, and presentation of analytical results. 
For the first week, the goal is to understand the data and prepare the data for analysis. As we discussed  in this specialization, data preprocessing and cleanup is often the first step in data analytics projects. Needless to say, this step is crucial for the success of this project.  

In the second week, you will perform some predictive analytics tasks, including classifying loans and predicting losses from defaulted loans. You will try a variety of tools and techniques  this week, as the predictive accuracy of different tools can vary quite a bit. It is rarely the case that the default model produced by ASP is the best model possible. Therefore, it is important for you to tune the different models in order to improve the performance.

Beginning in the third week, we turn our attention to prescriptive analytics, where you will provide some concrete suggestions on how to allocate investment funds using analytics tools, including clustering and simulation based optimization. You will see that allocating funds wisely is crucial for the financial return of the investment portfolio.

In the last week, you are expected to present your analytics results to your clients. Since you will obtain many results in your project, it is important for you to judiciously choose what to include in your presentation. You are also expected to follow the principles we covered in the courses in preparing your presentation.",7460.0,4788.0,4.3,62.0
Advanced Clinical Data Science,https://www.coursera.org/learn/advanced-clinical-data-science,Data Science,Data Analysis,"Michael G. Kahn, MD, PhD, Laura K. Wiley, PhD",This course prepares you to deal with advanced clinical data science topics and techniques including temporal and research quality analysis.,1960.0,3218.0,4.8,17.0
Advanced Computer Vision with TensorFlow,https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow,Data Science,Machine Learning,"Laurence Moroney, Eddy Shyu","In this course, you will:

a) Explore image classification, image segmentation, object localization, and object detection. Apply transfer learning to object localization and detection.
b) Apply object detection models such as regional-CNN and ResNet-50, customize existing models, and build your own models to detect, localize, and label your own rubber duck images.
c) Implement image segmentation using variations of the fully convolutional network (FCN) including U-Net and d) Mask-RCNN to identify and detect numbers, pets, zombies, and more.
d) Identify which parts of an image are being used by your model to make its predictions using class activation maps and saliency maps and apply these ML interpretation methods to inspect and improve the design of a famous network, AlexNet.


The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture and tools that help them create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",21325.0,54594.0,4.8,377.0
Advanced Data Science Capstone,https://www.coursera.org/learn/advanced-data-science-capstone,Data Science,Machine Learning,Romeo Kienzler,"This project completer has proven a deep understanding on massive parallel data processing, data exploration and visualization, advanced machine learning and deep learning and how to apply his knowledge in a real-world practical use case where he justifies architectural decisions, proves understanding the characteristics of different algorithms, frameworks and technologies and how they impact model performance and scalability. 

Please note: You are requested to create a short video presentation at the end of the course. This is mandatory to pass. You don't need to share the video in public.",14440.0,6180.0,4.6,374.0
Advanced Data Visualization with R,https://www.coursera.org/learn/jhu-advanced-data-visualization-r,Data Science,Data Analysis,Collin Paschall,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance.

This course is the third in the Specialization ""Data Visualization and Dashboarding in R.""  Learners come into this course with a foundation using R to make many basic kinds of visualization, primarily with the ggplot2 package. Accordingly, this course focuses on expanding the learners' inventory of data visualization options. Drawing on additional packages to supplement ggplot2, learners will made more variants of traditional figures, as well as venture into spatial data. The course ends make interactive and animated figures.

To fill that need, this course is intended for learners who have little or no experience with R but who are looking for an introduction to this tool. By the end of this course, students will be able to import data into R, manipulate that data using tools from the popular tidyverse package, and make simple reports using R Markdown. The course is designed for students with good basic computing skills, but limited if any experience with programming.",3494.0,7026.0,4.9,47.0
Advanced Deep Learning Methods for Healthcare,https://www.coursera.org/learn/advanced-deep-learning-methods-healthcare,Data Science,Machine Learning,Jimeng Sun,"This course covers deep learning (DL) methods, healthcare data and applications using DL methods. The courses include activities such as video lectures, self guided programming labs, homework assignments (both written and programming), and a large project.

The first phase of the course will include video lectures on different DL and health applications topics, self-guided labs and multiple homework assignments. In this phase, you will build up your knowledge and experience in developing practical deep learning models on healthcare data. The second phase of the course will be a large project that can lead to a technical report and functioning demo of the deep learning models for addressing some specific healthcare problems. We expect the best projects can potentially lead to scientific publications.",,5818.0,,
Advanced Learning Algorithms,https://www.coursera.org/learn/advanced-learning-algorithms,Data Science,Machine Learning,"Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig","In the second course of the Machine Learning Specialization, you will:

• Build and train a neural network with TensorFlow to perform multi-class classification
• Apply best practices for machine learning development so that your models generalize to data and tasks in the real world
• Build and use decision trees and tree ensemble methods, including random forests and boosted trees

The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. In this beginner-friendly program, you will learn the fundamentals of machine learning and how to use these techniques to build real-world AI applications. 

This Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.

This 3-course Specialization is an updated and expanded version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012. 

It provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)

By the end of this Specialization, you will have mastered key theoretical concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.",52052.0,1007824.0,4.9,1054.0
Advanced Linear Models for Data Science 1: Least Squares,https://www.coursera.org/learn/linear-models,Data Science,Probability and Statistics,"Brian Caffo, PhD","Welcome to the Advanced Linear Models for Data Science Class 1: Least Squares. This class is an introduction to least squares from a linear algebraic and mathematical perspective. Before beginning the class make sure that you have the following:

- A basic understanding of linear algebra and multivariate calculus.
- A basic understanding of statistics and regression models.
- At least a little familiarity with proof based mathematics.
- Basic knowledge of the R programming language.

After taking this course, students will have a firm foundation in a linear algebraic treatment of regression modeling. This will greatly augment applied data scientists' general understanding of regression models.",26587.0,5454.0,4.4,171.0
Advanced Linear Models for Data Science 2: Statistical Linear Models,https://www.coursera.org/learn/linear-models-2,Data Science,Probability and Statistics,"Brian Caffo, PhD","Welcome to the Advanced Linear Models for Data Science Class 2: Statistical Linear Models. This class is an introduction to least squares from a linear algebraic and mathematical perspective. Before beginning the class make sure that you have the following:

- A basic understanding of linear algebra and multivariate calculus.
- A basic understanding of statistics and regression models.
- At least a little familiarity with proof based mathematics.
- Basic knowledge of the R programming language.

After taking this course, students will have a firm foundation in a linear algebraic treatment of regression modeling. This will greatly augment applied data scientists' general understanding of regression models.",21165.0,3567.0,4.5,83.0
Advanced Machine Learning and Signal Processing,https://www.coursera.org/learn/advanced-machine-learning-signal-processing,Data Science,Machine Learning,"Romeo Kienzler, Nikolay Manchev",">>> By enrolling in this course you agree to the End User License Agreement as set out in the FAQ.  Once enrolled you can access the license in the Resources area <<<

This course, Advanced Machine Learning and Signal Processing, is part of the IBM Advanced Data Science Specialization which IBM is currently creating and gives you easy access to the invaluable insights into Supervised and Unsupervised Machine Learning Models used by experts in many field relevant disciplines. We’ll learn about the fundamentals of Linear Algebra to understand how machine learning modes work. Then we introduce the most popular Machine Learning Frameworks for python Scikit-Learn and SparkML. SparkML is making up the greatest portion of this course since scalability is key to address performance bottlenecks. We learn how to tune the models in parallel by evaluating hundreds of different parameter-combinations in parallel. We’ll continuously use a real-life example from IoT (Internet of Things), for exemplifying the different algorithms. For passing the course you are even required to create your own vibration sensor data using the accelerometer sensors in your smartphone. So you are actually working on a self-created, real dataset throughout the course.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.  To find out more about IBM digital badges follow the link ibm.biz/badging.",40842.0,18654.0,4.5,1194.0
Advanced Models for Decision Making,https://www.coursera.org/learn/advanced-models-for-decision-making,Data Science,Data Analysis,Soumya Sen,"Business analysts need to be able to prescribe optimal solution to problems. But analytics courses are often focused on training students in data analysis and visualization, not so much in helping them figure out how to take the available data and pair that with the right mathematical model to formulate a solution. This course is designed to connect data and models to real world decision-making scenarios in manufacturing, supply chain, finance, human resource management, etc. In particular, we understand how linear optimization - a prescriptive analytics method - can be used to formulate decision problems and provide data-based optimal solutions. Throughout this course we will work on applied problems in different industries, such as:

(a) Finance Decisions: How should an investment manager create an optimal portfolio that maximizes net returns while not taking too much risks across various investments?

(b) Production Decisions: Given projected demand, supply of raw materials, and transportation costs, what would be the optimal volume of products to manufacture at different plant locations?

(c) HR Decisions: How many workers need to be hired or terminated over a planning horizon to minimize cost while meeting operational needs of a company?

(c) Manufacturing: What would be the profit maximizing product mix that should be produced, given the raw material availability and customer demand?

We will learn how to formulate these problems as mathematical models and solve them using Excel spreadsheet.",2635.0,4500.0,4.8,36.0
Advanced Models in Smartpls,https://www.coursera.org/learn/advanced-models-smartpls,Data Science,Data Analysis,Shalini Gopalkrishnan ,"In this 1-hour long project-based course, you will learn how to  create path models using Smartpls. We will take a project on changing behavior and check if attitudes or subjective norms impact behavior the most.
 We will learn how to launch this new software, create the model and run it. We will then show you how to interpret the same. We will also learn how to create models for different groups such as males and females and if there is a difference between them.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Advanced R Programming,https://www.coursera.org/learn/advanced-r,Data Science,Data Analysis,"Roger D. Peng, PhD, Brooke Anderson","This course covers advanced topics in R programming that are necessary for developing powerful, robust, and reusable data science tools. Topics covered include functional programming in R, robust error handling, object oriented programming, profiling and benchmarking, debugging, and proper design of functions. Upon completing this course you will be able to identify and abstract common data analysis tasks and to encapsulate them in user-facing functions. Because every data science environment encounters unique data challenges, there is always a need to develop custom software specific to your organization’s mission. You will also be able to define new data types in R and to develop a universe of functionality specific to those data types to enable cleaner execution of data science tasks and stronger reusability within a team.",29743.0,9465.0,4.3,559.0
Advanced Recommender Systems,https://www.coursera.org/learn/advanced-recommender-systems,Data Science,Machine Learning,Paolo Cremonesi,"In this course, you will see how to use advanced machine learning techniques to build more sophisticated recommender systems. Machine Learning is able to provide recommendations and make better predictions, by taking advantage of historical opinions from users and building up the model automatically, without the need for you to think about all the details of the model.

At the end of this course, you will learn how to manage hybrid information and how to combine different filtering techniques, taking the best from each approach. You will know how to use factorization machines and represent the input data accordingly. You will be able to design more sophisticated recommender systems, which can solve the cross-domain recommendation problem. You will also learn how to identify new trends and challenges in providing recommendations in a range of innovative application contexts. 

This course leverages two important EIT Digital Overarching Learning Outcomes (OLOs), related to your creativity and innovation skills. In trying to design a new recommender system you need to think beyond boundaries and try to figure out how you can improve the quality of the outcomes. You should also be able to use knowledge, ideas and technology to create new or significantly improved recommendation tools to support choice-making processes and solve real-life problems in complex and innovative scenarios.",2228.0,4094.0,3.6,15.0
Advanced Reproducibility in Cancer Informatics,https://www.coursera.org/learn/adv-reproducibility-cancer-informatics,Data Science,Data Analysis,"Candace Savonen, MS","This course introduces tools that help enhance reproducibility and replicability in the context of cancer informatics. It uses hands-on exercises to demonstrate in practical terms how to get acquainted with these tools but is by no means meant to be a comprehensive dive into these tools.  The course introduces tools and their concepts such as git and GitHub, code review, Docker, and GitHub actions.

Target Audience  

The course is intended for students in the biomedical sciences and researchers who use informatics tools in their research. It is the follow up course to the Introduction to Reproducibility in Cancer Informatics course. Learners who take this course should: 

- Have some familiarity with R or Python
- Have take the Introductory Reproducibility in Cancer Informatics course
- Have some familiarity with GitHub

Motivation

Data analyses are generally not reproducible without direct contact with the original researchers and a substantial amount of time and effort (BeaulieuJones, 2017). Reproducibility in cancer informatics (as with other fields) is still not monitored or incentivized despite that it is fundamental to the scientific method. Despite the lack of incentive, many researchers strive for reproducibility in their own work but often lack the skills or training to do so effectively.

Equipping researchers with the skills to create reproducible data analyses increases the efficiency of everyone involved. Reproducible analyses are more likely to be understood, applied, and replicated by others. This helps expedite the scientific process by helping researchers avoid false positive dead ends. Open source clarity in reproducible methods also saves researchers' time so they don't have to reinvent the proverbial wheel for methods that everyone in the field is already performing.

Curriculum  

The course includes hands-on exercises for how to apply reproducible code concepts to their code. Individuals who take this course are encouraged to complete these activities as they follow along with the course material to help increase the reproducibility of their analyses.

**Goal of this course:**  
To equip learners with a deeper knowledge of the capabilities of reproducibility tools and how they can apply to their existing analyses scripts and projects.


**What is NOT the goal of this course:**  
To be a comprehensive dive into each of the tools discussed. . 

How to use the course

Each chapter has associated exercises that you are encourage to complete in order to get the full benefit of the course

This course is designed with busy professional learners in mind -- who may have to pick up and put down the course when their schedule allows. In general, you are able to skip to chapters you find a most useful to (One incidence where a prior chapter is required is noted). 

Each chapter has associated exercises that you are encourage to complete in order to get the full benefit of the course",,,,
Advanced SAS Programming Techniques,https://www.coursera.org/learn/advanced-sas-programming-techniques,Data Science,Data Analysis,Michele Ensor,"In this course, you learn advanced techniques within the DATA step and procedures to manipulate data.

“By the end of this course, a learner will be able to…”
●	Use additional functions (LAG, FINDC/FINDW, and COUNT/COUNTC/COUNTW).
●	Perform pattern matching using PRX functions.
●	Process repetitive code, rotate data, and perform table lookups using arrays.
●	Perform table lookups and sort data using hash and hash iterator objects.
●	Create numeric templates using the FORMAT procedure.
●	Create custom functions using the FCMP procedure.",2173.0,15030.0,4.9,73.0
Aerial Image Segmentation with PyTorch,https://www.coursera.org/learn/aerial-image-segmentation-with-pytorch,Data Science,Machine Learning,Parth Dhameliya,"In this 2-hour project-based course, you will be able to :

-  Understand the Massachusetts Roads Segmentation Dataset and you will write a custom dataset class for Image-mask dataset. Additionally,  you will apply segmentation domain augmentations to augment images as well as its masks. For image-mask augmentation you will use albumentation library. You will plot the image-Mask pair.

- Load a pretrained state of the art convolutional neural network for segmentation problem(for e.g, Unet) using segmentation model pytorch library. 

- Create train function and evaluator function which will helpful to write training loop. Moreover, you will use training loop to train the model.

- Finally, we will use best trained segementation model for inference.",,,,
Affectation de variable en Python,https://www.coursera.org/learn/affectation-de-variable-en-python,Data Science,Machine Learning,Fatima Youssef,"Dans ce cours d'une heure, basé sur un projet vous apprenez les principes de base de la création des variables en python, l'affectation des variables en python, et les types de variables en python.
A la fin de ce projet, vous aurez appris que l'affectation de variable est l'action de stocker une valeur dans une variable, et comment définir le nom d'une variable en Python en utilisant des lettres, minuscules ou majuscules, et des chiffres.",,,,
Agrégation de Données avec des Requêtes SQL,https://www.coursera.org/learn/agrgation-de-donnes-avec-des-requtes-sql,Data Science,Data Analysis,Yasmine Elfares,"À la fin de ce projet, vous serez capables d’appliquer les requêtes agrégées SQL. Une requête agrégée est une méthode de dérivation des données de groupe et de sous-groupe par l'analyse d'un ensemble d'entrées de données individuelles.
L'agrégation nous permet de combiner les résultats en regroupant les enregistrements en fonction de la valeur. Il est également utile pour calculer des valeurs combinées dans des groupes. Cela se fait à l'aide de fonctions d'agrégation: ""min"", ""max"", ""sum"", ""count"" et ""avg"" en plus de l'opération de jointure.
Étant programmeurs de bases de données débutants, vous serez capables d'utiliser les requêtes agrégées afin de regrouper les valeurs de plusieurs lignes de données selon certains critères pour former une valeur unique plus significative.
A travers ce projet, nous allons renforcer ces notions en manipulant la base de données de l'âge d'or de la musique française. Nous allons explorer les infos des artistes, chansons et albums les plus populaires dans cette période afin d'en extraire des aperçus pertinents, tout en utilisant SQL.
La compréhension de l'agrégation de données vous aidera à progresser dans une entreprise étant donné que les bases de données sont nécessaires pour toute organisation puisqu'elles servent à communiquer les informations facilement et efficacement.",,,,
Ajukan Pertanyaan untuk Mengambil Keputusan Berdasarkan Data,https://www.coursera.org/learn/ajukan-pertanyaan-untuk-mengambil-keputusan-berdasarkan-data,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi kedua dalam program Sertifikat Analitik Data Google (Google Data Analytics Certificate). Materi ini akan memberi Anda keterampilan yang dibutuhkan untuk melamar pekerjaan analis data tingkat pemula. Anda akan mengembangkan lebih lanjut pemahaman Anda mengenai topik yang diperkenalkan pada materi pertama program Sertifikat Analitik Data Google. Materi ini akan membantu Anda mempelajari cara mengajukan pertanyaan yang efektif untuk membuat keputusan berbasis data, namun tetap sesuai dengan kebutuhan pemangku kepentingan. Para analis data Google akan mengajarkan dan memberi tahu Anda berbagai cara praktis untuk menyelesaikan tugas umum analis data dengan menggunakan alat dan sumber daya terbaik.

Pembelajar yang menyelesaikan program sertifikat ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak diperlukan pengalaman apa pun sebelumnya.

Di akhir materi ini, Anda akan:
- Mempelajari teknik bertanya efektif yang dapat membantu mengarahkan analisis. 
- Memahami cara pengambilan keputusan berbasis data dan bagaimana analis data menyajikan temuannya.
- Mengeksplorasi berbagai skenario bisnis di dunia nyata agar lebih memahami tentang cara mengajukan pertanyaan dan pengambilan keputusan.
- Mengetahui mengapa dan bagaimana spreadsheet menjadi alat penting bagi analis data.
- Menguji berbagai ide penting yang berhubungan dengan pemikiran terstruktur dan bagaimana hal tersebut dapat membantu analis untuk memahami permasalahan dengan lebih baik serta mengembangkan berbagai solusinya.
- Mempelajari strategi untuk mengelola ekspektasi para pemangku kepentingan seraya membangun komunikasi yang jelas dengan tim analitik data untuk mencapai berbagai tujuan bisnis.",4646.0,428238.0,4.9,276.0
Algorithms for DNA Sequencing,https://www.coursera.org/learn/dna-sequencing,Data Science,Data Analysis,"Ben Langmead, PhD, Jacob Pritt","We will learn computational methods -- algorithms and data structures -- for analyzing DNA sequencing data. We will learn a little about DNA, genomics, and how DNA sequencing is used.  We will use Python to implement key algorithms and data structures and to analyze real genomes and DNA sequencing datasets.",34768.0,36651.0,4.7,812.0
Algoritmos de negociación basados en machine learning​,https://www.coursera.org/learn/algoritmos-de-negociacion-basados-en-machine-learning,Data Science,Machine Learning,Sergio Cabrales,"Este curso brinda una introducción a los mercados de capital, la formación de precios, el retorno, la volatilidad, los principios del análisis técnico de activos financieros, algoritmos de negociación basados en modelos de clasificación de machine learning, y sus aplicaciones a estrategias de inversión activas de corto plazo.

Este curso está dirigido a personas interesadas en soportar la toma de decisiones de inversión de activos financieros en el mercado de capitales basados en herramientas de analítica. Este curso no requiere de la instalación de ningún programa externo en un equipo local. Todas las herramientas digitales son provistas por la plataforma.",,2858.0,,
Amazon Echo Reviews Sentiment Analysis Using NLP,https://www.coursera.org/learn/amazon-echo-reviews-sentiment-nlp,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will predict customer sentiment using natural language processing techniques.
In this project, we will build a machine learning model to analyze thousands of amazon echo reviews to predict customers sentiment. Artificial Intelligence and Machine Learning (AI/ML)-based sentiment analysis is crucial for companies to automatically predict whether their customers are happy or not. This project is practical and directly applicable to any company with that has online presence. The algorithm could be used automatically detect customers sentiment.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Améliorez les réseaux neuronaux profonds,https://www.coursera.org/learn/deep-neural-network-fr,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Dans ce cours, vous apprendrez la ""magie"" qui permet l'efficacité de l’apprentissage profond.   Plutôt que de voir le processus d’apprentissage profond comme une boîte noire, vous comprendrez ce qui commande la performance et vous pourrez ainsi obtenir systématiquement de bons résultats plus souvent. Vous apprendrez également TensorFlow. 

Au bout de 3 semaines, vous: 
- Pourrez comprendre les meilleures pratiques dans le secteur de construction des applications d’apprentissage profond.
- Serez en mesure d’utiliser avec efficacité des ""astuces"", communes des réseaux neuronaux, qui incluent l’initialisation, la régularisation L2 et la régularisation du décrochage, la normalisation par lots, la vérification de gradients,
- Pourrez mettre en œuvre et employer une variété d’algorithmes d’optimisation, comme par exemple la descente de gradients par mini-lots, le momentum, RMSprop et Adam, et contrôler leur convergence. 
-  Comprendrez, à l’ère de l’apprentissage profond, les nouvelles meilleures pratiques sur la configuration des ensembles train/dev/test et comment analyser les biais/variances
-  Pourrez implémenter un réseau neuronal dans TensorFlow. 

Ceci est le deuxième cours de spécialisation en apprentissage profond.",,,,
An Intuitive Introduction to Probability,https://www.coursera.org/learn/introductiontoprobability,Data Science,Probability and Statistics,Karl Schmedders,"This course will provide you with a basic, intuitive and practical introduction into Probability Theory. You will be able to learn how to apply Probability Theory in different scenarios and you will earn a ""toolbox"" of methods to deal with uncertainty in your daily life. 

The course is split in 5 modules. In each module you will first have an easy introduction into the topic, which will serve as a basis to further develop your knowledge about the topic and acquire the ""tools"" to deal with uncertainty. Additionally, you will have the opportunity to complete 5 exercise sessions to reflect about the content learned in each module and start applying your earned knowledge right away. 

The topics covered are: ""Probability"", ""Conditional Probability"", ""Applications"", ""Random Variables"", and ""Normal Distribution"".

You will see how the modules are taught in a lively way, focusing on having an entertaining and useful learning experience! We are looking forward to see you online!",57237.0,56936.0,4.8,1439.0
Analisar os dados para responder às perguntas,https://www.coursera.org/learn/analisar-os-dados-para-responder-as-perguntas,Data Science,Data Analysis,Google Career Certificates,"Este é o quinto curso do Certificado de Data Analytics do Google. Estes cursos darão a você as habilidades necessárias para se candidatar a cargos empregos de analista de dados de nível inicial. Neste curso, você explorará a etapa de análise do processo de análise de dados. Você aplicará o que aprendeu até agora na análise para interpretar os dados coletados. Você aprenderá como organizar e formatar seus dados usando planilhas e SQL para ajudar você a observar e interpretar os dados de diferentes maneiras. Você também descobrirá como fazer cálculos complexos sobre seus dados para cumprir os objetivos de negócios. Você aprenderá a usar fórmulas, funções e consultas SQL conforme você realiza suas análises. Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível inicial para analista de dados. Nenhuma experiência anterior é necessária.

Ao final deste curso, você poderá:
 - Organizar dados para análise.
 - Dominar os processos para formatar e ajustar os dados. 
 - Compreender como agregar dados em planilhas e usando SQL.
 - Usar fórmulas e funções em planilhas para cálculos de dados.
 - Fazer cálculos completos usando consultas SQL.",,50469.0,4.7,24.0
Analisis Data dengan Pemrograman R,https://www.coursera.org/learn/analisis-data-dengan-pemrograman-r,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi ketujuh dalam program Google Data Analytics Certificate (Sertifikat Analisis Data Google). Materi ini akan membekali Anda dengan keterampilan yang dibutuhkan untuk melamar pekerjaan analis data tingkat pemula. Dalam materi ini, Anda akan belajar tentang bahasa pemrograman yang dikenal sebagai R. Anda akan mengetahui cara menggunakan RStudio, lingkungan yang memungkinkan Anda bekerja dengan R. Materi ini juga akan membahas aplikasi perangkat lunak dan alat yang unik untuk R, seperti beberapa paket R (R packages). Anda akan menemukan bagaimana R memungkinkan Anda membersihkan, mengatur, menganalisis, memvisualisasikan, dan melaporkan data dengan cara baru dan lebih ampuh.  Para analis data Google akan mengajarkan dan memberi tahu Anda berbagai cara untuk menyelesaikan tugas umum analis data dengan menggunakan peralatan dan sumber daya terbaik.

Pembelajar yang menyelesaikan program sertifikasi ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak membutuhkan pengalaman apa pun.

Di akhir materi ini, Anda akan:
 - Mengkaji manfaat menggunakan bahasa pemrograman R.
 - Menemukan cara menggunakan RStudio untuk menerapkan R ke analisis Anda. 
 - Mengeksplorasi konsep dasar yang terkait dengan pemrograman di R. 
 - Mengeksplorasi konten dan komponen paket R termasuk paket Tidyverse.
 - Mendapatkan pemahaman tentang dataframe dan penggunaannya di R.
 - Menemukan opsi untuk menghasilkan visualisasi di R.
 - Mempelajari tentang R Markdown untuk mendokumentasikan pemrograman R.",2382.0,459172.0,4.9,66.0
Analiza tu mercado con Python,https://www.coursera.org/learn/analiza--tu-mercado-con-python,Data Science,Machine Learning,Grissel Rodríguez Roldán,"En este curso aprenderás a realizar un análisis de reseñas de un restaurante utilizando la técnica de análisis de sentimientos en Python, trabajando en el entorno de Jupyter en la nube y utilizando técnicas de procesamiento de texto y algoritmos de machine learning que te permitirán clasificar la opinión de las personas.

Debido al impacto y popularidad que tiene Python entre la comunidad académica y profesional hemos realizado este proyecto guiado donde podrás aprender herramientas para brindar un mejor servicio a tu audiencia o mercado a través del análisis de sus comentarios.

La experiencia de este curso te permitirá procesar texto para realizar un análisis de sentimientos, mismo que puede ser utilizado para campañas políticas o de marketing, medir impactos en redes sociales o desarrollar programas para otras aplicaciones en tecnología,  matemática,  ingeniería y ciencia.

Python es un lenguaje fácil de aprender, sin embargo, para realizar este proyecto necesitas contar con un conocimiento básico de programación o experiencia en este lenguaje. Recuerda revisar todos los recursos disponibles para ti.",,,,
Analizando sentimientos y entidades en textos con Azure,https://www.coursera.org/learn/analisis-sentimientos-azure,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a desarrollar un motor de análisis de texto, sólo con Python y un servicio cognitivo de Azure

Además, entenderás qué tipo de análisis puedes hacer de manera muy sencilla y en varios idiomas.",,,,
Analizar datos para responder preguntas,https://www.coursera.org/learn/analizar-datos-para-responder-preguntas,Data Science,Data Analysis,Google Career Certificates,"Este es el quinto curso del certificado de Análisis computacional de datos de Google. En estos cursos obtendrás las habilidades necesarias para solicitar empleos de analista de datos de nivel introductorio. En este curso, explorarás la fase de “análisis” del proceso de análisis de datos. Aplicarás en tu análisis lo que aprendiste hasta el momento para darle sentido a los datos que recopilaste. Además, aprenderás cómo organizar y formatear tus datos por medio de hojas de cálculo y SQL para observarlos y analizarlos de diferentes maneras. También descubrirás cómo llevar a cabo cálculos complejos con respecto a los datos para lograr tus objetivos empresariales. Aprenderás a usar fórmulas, funciones y consultas de SQL a medida que lleves a cabo tu análisis. Los analistas de datos actuales de Google seguirán dándote instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, serás capaz de:
 - Aprender cómo organizar los datos para analizarlos.
 - Descubrir los procesos de formateo y ajuste de datos. 
 - Comprender cómo realizar la agregación de datos en hojas de cálculo y por medio de SQL.
 - Usar fórmulas y funciones en las hojas de cálculo para realizar cálculos en torno a los datos.
 - Aprender a realizar cálculos por medio de consultas de SQL.",3384.0,182713.0,4.7,54.0
Analyse Exploratoire des Données (AED) dans R,https://www.coursera.org/learn/analyse-exploratoire-des-donnees-dans-r,Data Science,Data Analysis,Emmanuel Segui,"Dans ce cours d'une heure, basé sur un projet, vous apprendrez comment faire des analyses de données exploratoires de base (EDA) dans R, automatiser vos rapports EDA et apprendre quelques astuces et techniques avancées d'EDA.

Remarque : ce cours fonctionne le mieux pour les étudiants basés en Amérique du Nord. Nous nous efforçons actuellement d'apporter la même expérience dans d'autres régions.",,,,
Analyse datasets with Java streams,https://www.coursera.org/learn/analyse-datasets-java-streams,Data Science,Data Analysis,Sherif A. Tawfik Abbas,"In this 1-hour long project-based course, you will learn how to create a Java Stream object based on a CSV data file, and engineer its data using Stream and Collector methods. You will explore the dataset using stream methods, and then apply a reduction operations on the data using a range of Collector methods. You will learn how to join and split strings in the data. You will apply the groupingBy method for grouping your data stream based on fields in your data object. 


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Analyse de données avec la programmation R,https://www.coursera.org/learn/analyse-de-donnees-avec-la-programmation-r,Data Science,Data Analysis,Google Career Certificates,"Ce cours est le septième du Google Data Analytics Certificate. Ces cours vous permettront d’acquérir les compétences dont vous avez besoin pour postuler les emplois d’analyste de données de niveau junior. Dans ce cours, vous découvrirez le langage de programmation R. Vous découvrirez comment utiliser RStudio, l'environnement qui vous permet de travailler avec R. Ce cours abordera également les applications logicielles et les outils spécifiques à R, tels que les packs R. Vous découvrirez comment R vous permet de nettoyer, d'organiser, d'analyser, de visualiser et d’élaborer des rapports de données de manière nouvelle et plus efficace.  Des analystes de données actuellement chez Google vous instruiront et vous fourniront des moyens pratiques d’accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler des emplois d’analyste de données de niveau junior. Aucune expérience préalable n’est nécessaire.

D’ici la fin de ce cours, vous :
 - Examinerez les avantages de l'utilisation du langage de programmation R.
 - Découvrirez comment utiliser RStudio afin d’appliquer R à votre analyse. 
 - Découvrirez les concepts fondamentaux associés à la programmation dans R. 
 - Examinerez le contenu et les composants des packs R, y compris le pack Tidyverse.
 - Comprendrez les trames de données et leur utilisation dans R.
 - Découvrirez les options de génération de visualisations dans R
 - Apprendrez R Markdown pour documenter la programmation R.",,3490.0,,
Analyser les données pour répondre aux questions,https://www.coursera.org/learn/analyser-les-donnees-pour-repondre-aux-questions,Data Science,Data Analysis,Google Career Certificates,"Il s'agit du cinquième cours du certificat Google Data Analytics. Ces cours vous permettront d’acquérir les compétences dont vous avez besoin pour postuler les emplois d’analyste de données de niveau junior. Dans ce cours, vous explorerez la phase d’« analyse » du processus d'analyse des données. Vous prendrez ce que vous avez appris jusqu'ici et l'appliquerez à votre analyse pour donner un sens aux données que vous avez collectées. Vous apprendrez à organiser et à formater vos données à l'aide de feuilles de calcul et de SQL pour vous aider à regarder et à penser à vos données de différentes manières. Vous découvrirez également comment effectuer des calculs complexes sur vos données pour atteindre des objectifs commerciaux. Vous apprendrez à utiliser des formules, des fonctions et des requêtes SQL pour mener à bien votre analyse. Des analystes de données actuellement chez Google vous instruiront et vous fourniront des moyens pratiques d’accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler à des emplois d’analyste de données de niveau junior. Aucune expérience préalable n’est nécessaire.

D’ici la fin de ce cours, vous :
 - apprendrez à organiser les données pour les analyser ;
 - découvrirez les processus de formatage et d'ajustement des données ; 
 - comprendrez comment agréger des données dans des feuilles de calcul et en utilisant SQL ;
 - utiliserez des formules et des fonctions dans des feuilles de calcul pour les calculs de données ;
 - apprendrez à effectuer des calculs à l'aide de requêtes SQL.",,,,
Analyser vos données avec Python,https://www.coursera.org/learn/analyser-donnees-python,Data Science,Data Analysis,Thierno Ibrahima Diop,"Dans ce projet guidé, vous allez charger et faire de l'analyse univariée de variables catégorielles et continues, tout comme l'analyse multivariée entre des variables catégorielles et continues. Pour réaliser cette analyse, vous allez utiliser JupyterLab avec des librairies de data science en python telles que Pandas, Matplotlib, SeaBorn et WordCloud.",,,,
Analysing Covid-19 Geospatial data with Python,https://www.coursera.org/learn/geospatial-covid19-python,Data Science,Data Analysis,Abdishakur Hassan,"In this one-hour guided project, you will learn how to process geospatial data using Python. We will go through different geoprocessing tasks including how to create Geodataframes from CSV files and perform a spatial join.",,,4.1,12.0
Analysis of Variance with ANOVA in Google Sheets,https://www.coursera.org/learn/analysis-of-variance-anova-in-google-sheets,Data Science,Data Analysis,Tricia Bagley,"In every domain it is critical to decision making to understand whether differences exist between two or more groups of things or outcomes. In this course you will test for differences with the One-Way ANOVA analysis of variance technique. You will also learn how to design the test and apply tactics so that you are able to confidently report statistical significance between and within groups if it exists. For this course, we will work side-by-side in the free-to-use software Google Sheets. 
By the end of this course, you will be able to apply ANOVA and post hoc tests using any spreadsheet software and you will be able to confidently report levels of statistical significance in groups.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.3,35.0
Analytics en las organizaciones,https://www.coursera.org/learn/analytics-analisis-datos,Data Science,Data Analysis,"Sánchez Sarmiento Germán Andrés, Felipe Montes Jiménez","El curso Analytics en las Organizaciones invita a adquirir conceptos y habilidades para el diagnóstico e implementación de una estrategia basada en analítica de datos tomando en cuenta las dimensiones humanas, organizacionales y tecnológicas de la organización. El curso tiene 5 módulos que te permitirán:

1.	Comprender el concepto de analítica de datos (analytics) y su relevancia en las organizaciones. 
2.	Conocer casos de éxito de implementación de estrategias basadas en analítica de datos
3.	Identificar cómo los diferentes niveles de madurez en analítica de datos pueden contribuir a mejorar la competitividad de una organización. 
4.	Aplicar herramientas para diagnosticar la competitividad analítica de una organización y trazar una hoja de ruta para que la organización se convierta en un competidor analítico.
5.	Identificar los recursos organizacionales, tecnológicos y humanos necesarios para alcanzar los distintos niveles de madurez analítica. 
6.	Reconocer aspectos básicos de gobernabilidad de datos y la estructuración de equipos de analítica.

Este curso está dirigido para profesionales de cualquier área con interés en aprender los conceptos básicos de analytics y cómo implementar una estrategia analítica en una organización. Este es un curso introductorio que no requiere habilidades técnicas, sólo motivación, entusiasmo e interés por conocer cómo la analítica de datos puede contribuir a generar competitividad en las organizaciones.",2364.0,7543.0,4.8,37.0
Analyze Box Office Data with Plotly and Python,https://www.coursera.org/learn/analyze-data-plotly-python,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Analyzing Box Office Data with Plotly and Python. In this course, you will be working with the The Movie Database (TMDB) Box Office Prediction data set. The motion picture industry is raking in more revenue than ever with its expansive growth the world over. Can we build models to accurately predict movie revenue? Could the results from these models be used to further increase revenue? We try to answer these questions by way of exploratory data analysis (EDA)  and feature engineering. We will primarily use Plotly for data visualization. Plotly Python which is Plotly's Python graphing library makes interactive, publication-quality graphs ready for both online and offline use.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",8643.0,,4.5,233.0
Analyze Box Office Data with Seaborn and Python,https://www.coursera.org/learn/analyze-data-seaborn-python,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Analyzing Box Office Data with Seaborn and Python. In this course, you will be working with the The Movie Database (TMDB) Box Office Prediction data set. The motion picture industry is raking in more revenue than ever with its expansive growth the world over. Can we build models to accurately predict movie revenue? Could the results from these models be used to further increase revenue? We try to answer these questions by way of exploratory data analysis (EDA) in this project and the next. The statistical data visualization libraries Seaborn and Plotly will be our workhorses to generate interactive, publication-quality graphs. By the end of this course, you will be able to produce data visualizations in Python with Seaborn, and apply graphical techniques used in exploratory data analysis (EDA).

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4200.0,,4.5,174.0
Analyze City Data Using R and Tableau,https://www.coursera.org/learn/analyze-city-data-r-tableau,Data Science,Data Analysis,Jose Luis Rodriguez,"By the end of this project, you will create, clean, explore and analyze San Francisco’s building permit public data. We will use OpenStreetMap API to find the geo-coordinates of buildings using R and RStudio and we will analyze the final results in Tableau. You will learn basic data cleaning techniques using R, create a function to make requests to the OpenStreeMaps API and  leverage Tableau to generate insights.

Note: This course works best for learners who are based in the North America region. We're currently working on providing the same experience in other regions.",,,3.6,15.0
Analyze Data,https://www.coursera.org/learn/analyze-data-cdsp,Data Science,Data Analysis,"Sarah Haq, Stacey McBrine, Megan Smith Branch","This course is designed for business professionals that want to learn how to analyze data to gain insight, use statistical analysis methods to explore the underlying distribution of data, use visualizations such as histograms, scatter plots, and maps to analyze data and preprocess data to produce a dataset ready for training.

The typical student in this course will have several years of experience with computing technology, including some aptitude in computer programming.",,2252.0,,
Analyze Data in Azure ML Studio,https://www.coursera.org/learn/analyze-data-azure-ml-studio,Data Science,Machine Learning,Laura Ramov,"Did you know that you can use Azure Machine Learning to help you analyze data?

In this 1-hour project-based course, you will learn how to display descriptive statistics of a dataset, measure relationships between variables and visualize relationships between variables. To achieve this, we will use one example diabetes data. We will calculate its descriptive statistics and correlations, train a machine learning model and calculate its feature importance to see how features affect the label and visualize categorical data, as well as relationships between variables, in Jupyter notebook.

In order to be successful in this project, you will need knowledge of Python language and experience with machine learning in Python. Also, Azure subscription is required (free trial is an option for those who don’t have it), as well as Azure Machine Learning resource and a compute instance within. Instructional links will be provided to guide you through creation, if needed, in the first task.

If you are ready to learn how to analyze data, this is a course for you! Let’s get started!",,,,
Analyze Data to Answer Questions,https://www.coursera.org/learn/analyze-data,Data Science,Data Analysis,Google Career Certificates,"This is the fifth course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. In this course, you’ll explore the “analyze” phase of the data analysis process. You’ll take what you’ve learned to this point and apply it to your analysis to make sense of the data you’ve collected. You’ll learn how to organize and format your data using spreadsheets and SQL to help you look at and think about your data in different ways. You’ll also find out how to perform complex calculations on your data to complete business objectives. You’ll learn how to use formulas, functions, and SQL queries as you conduct your analysis. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
 - Learn how to organize data for analysis.
 - Discover the processes for formatting and adjusting data. 
 - Gain an understanding of how to aggregate data in spreadsheets and by using SQL.
 - Use formulas and functions in spreadsheets for data calculations.
 - Learn how to complete calculations using SQL queries.",239777.0,3033810.0,4.6,6287.0
Analyze Datasets and Train ML Models using AutoML,https://www.coursera.org/learn/automl-datasets-ml-models,Data Science,Machine Learning,"Antje Barth, Shelbee Eigenbrode, Sireesha Muppala, Chris Fregly","In the first course of the Practical Data Science Specialization, you will learn foundational concepts for exploratory data analysis (EDA), automated machine learning (AutoML), and text classification algorithms. With Amazon SageMaker Clarify and Amazon SageMaker Data Wrangler, you will analyze a dataset for statistical bias, transform the dataset into machine-readable features, and select the most important features to train a multi-class text classifier. You will then perform automated machine learning (AutoML) to automatically train, tune, and deploy the best text-classification algorithm for the given dataset using Amazon SageMaker Autopilot. Next, you will work with Amazon SageMaker BlazingText, a highly optimized and scalable implementation of the popular FastText algorithm, to train a text classifier with very little code.

Practical data science is geared towards handling massive datasets that do not fit in your local hardware and could originate from multiple sources. One of the biggest benefits of developing and running data science projects in the cloud is the agility and elasticity that the cloud offers to scale up and out at a minimum cost.

The Practical Data Science Specialization helps you develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ML workflow using Amazon SageMaker. This Specialization is designed for data-focused developers, scientists, and analysts familiar with the Python and SQL programming languages and want to learn how to build, train, and deploy scalable, end-to-end ML pipelines - both automated and human-in-the-loop - in the AWS cloud.",20119.0,36225.0,4.6,322.0
Analyze Stock Data using R and Quantmod Package,https://www.coursera.org/learn/analyze-stock-data-using-r-quantmod,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to pull down Stock Data using the R quantmod package.   You will also learn how to perform analytics and pass financial risk functions to the data.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3605.0,,4.3,140.0
Analyze Survey Data with Tableau,https://www.coursera.org/learn/analyze-survey-data-tableau,Data Science,Data Analysis,Carmen Rojas,"Surveys are used in a variety of scenarios, both in businesses and in research. Companies are using them to better understand consumer insights and feedback, and researchers are going beyond the traditional uses to learn more about the world around us. Tableau can help visualize survey data of all kinds in a useful way—without needing advanced statistics, graphic design, or a statistics background. 

In this project, learners will learn how to create an account in Tableau and how to manipulate data with joins and pivots. Students will then learn how to create different kinds of visualizations, including tables, pie charts, and a stacked pie chart. 
This would be a great project for business and academic uses of survey data. 
This project is designed to be used by those somewhat familiar with Tableau and data visualizations. But the project can be accessible for those new to Tableau as well.",,,,
Analyze Text Data with Yellowbrick,https://www.coursera.org/learn/analyze-text-data-yellowbrick,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Analyzing Text Data with Yellowbrick. Tasks such as assessing document similarity, topic modelling and other text mining endeavors are predicated on the notion of ""closeness"" or ""similarity"" between documents. In this course, we define various distance metrics (e.g. Euclidean, Hamming, Cosine, Manhattan, etc) and understand their merits and shortcomings as they relate to document similarity. We will apply these metrics on documents within a specific corpus and visualize our results. By the end of this course, you will be able to confidently use visual diagnostic tools from Yellowbrick to steer your machine learning workflow, vectorize text data using TF-IDF, and cluster documents using embedding techniques and appropriate metrics.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, Yellowbrick, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4804.0,,4.4,82.0
Analyze Website Visitors with Google Analytics Segments,https://www.coursera.org/learn/analyze-visitors-google-analytics-segments,Data Science,Data Analysis,Carma Baughman,"In this project you will learn how to use segments in Google Analytics and how they provide a deeper analysis of your website visitors. You will learn how to set up and use segments. You will learn about system segments and custom segments. You will also learn how to import segments. You will understand how using segments helps you make better decisions when it comes to increasing and converting your website traffic.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6546.0,,4.6,98.0
Analyzing Big Data with SQL,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,Data Science,Data Analysis,Ian Cook,"In this course, you'll get an in-depth look at the SQL SELECT statement and its main clauses. The course focuses on big data SQL engines Apache Hive and Apache Impala, but most of the information is applicable to SQL with traditional RDBMs as well; the instructor explicitly addresses differences for MySQL and PostgreSQL.

By the end of the course, you will be able to
• explore and navigate databases and tables using different tools;
• understand the basics of SELECT statements;
• understand how and why to filter results;
• explore grouping and aggregation to answer analytic questions;
• work with sorting and limiting results; and 
• combine multiple tables in different ways.

To use the hands-on environment for this course, you need to download and install a virtual machine and the software on which to run it. Before continuing, be sure that you have access to a computer that meets the following hardware and software requirements:
• Windows, macOS, or Linux operating system (iPads and Android tablets will not work)
• 64-bit operating system (32-bit operating systems will not work)
• 8 GB RAM or more
• 25GB free disk space or more
• Intel VT-x or AMD-V virtualization support enabled (on Mac computers with Intel processors, this is always enabled;
on Windows and Linux computers, you might need to enable it in the BIOS)
• For Windows XP computers only: You must have an unzip utility such as 7-Zip or WinZip installed (Windows XP’s built-in unzip utility will not work)",23918.0,33893.0,4.9,497.0
Analyzing and Visualizing Data in Looker,https://www.coursera.org/learn/analyzing-and-visualizing-data-in-looker,Data Science,Data Analysis,Google Cloud Training,"In this course, you learn how to do the kind of data exploration and analysis in Looker that would formerly be done primarily by SQL developers or analysts. Upon completion of this course, you will be able to leverage Looker's modern analytics platform to find and explore relevant content in your organization’s Looker instance, ask questions of your data, create new metrics as needed, and build and share visualizations and dashboards to facilitate data-driven decision making.",12786.0,32242.0,4.7,261.0
Analyzing and Visualizing Data in Looker 日本語版,https://www.coursera.org/learn/analyzing-and-visualizing-data-in-looker-ja,Data Science,Data Analysis,Google Cloud Training,このコースでは、これまで主に SQL のデベロッパーやアナリストが行っていたようなデータの探索や分析を Looker で実施する方法について学びます。このコースを修了すると、Looker の最新の分析プラットフォームを活用して、組織の Looker インスタンスで関連するコンテンツの検索と探索、データに関する問い合わせ、必要に応じた新しい指標の作成、データドリブンな意思決定を促進するための可視化やダッシュボードの構築と共有が可能になります。,,1617.0,,
Analítica de Procesos: Optimización desde los Datos,https://www.coursera.org/learn/analitica-procesos-optimizacion-desde-datos,Data Science,Data Analysis,Oscar Fernando González Rojas,"El entorno empresarial y de innovación requiere y requerirá cada vez más profesionales capaces de conectar los datos con el análisis de procesos. Esta habilidad posibilita formas inteligentes de entender y mejorar continuamente la cambiante operación de las empresas: las mantiene vivas y competitivas. La analítica de procesos proporciona información acerca de la eficiencia de los procesos de negocio, lo cual cambia el enfoque a los líderes de proceso para tomar decisiones sobre cómo hacer evolucionar el comportamiento y métricas del proceso basados en datos y no solo intuición. 

El curso provee métodos y herramientas de fácil uso y apropiación, los cuales pueden ser aplicados para el entendimiento y mejoramiento de procesos en cualquier dominio de negocio y tecnología. Para ello, se explican diferentes técnicas de análisis de procesos soportadas en herramientas de minería y simulación de procesos. Estas herramientas presentan un crecimiento acelerado de apropiación empresarial por la proliferación de datos que se generan a través de nuevos canales digitales y entornos interconectados. El curso es introductorio ofreciendo variedad de ejemplos y ejercicios prácticos para ser analizados con un conjunto de datos de referencia. Los estudiantes podrán encontrar diferentes recursos como videos, lecturas, actividades y cuestionarios; los cuales buscan que el estudiante afiance y aplique los conocimientos que provee el curso. 

En los tutoriales y ejercicios prácticos del curso usaremos una herramienta de minería de procesos llamada Apromore, la cual se puede acceder desde cualquier navegador web. Si desea usar otra herramienta de minería de procesos, puede hacerlo libremente dado que en cualquiera de ellas se pueden implementar las diferentes capacidades de analítica de forma similar usando el mismo insumo de datos (un log de eventos de proceso).

Este curso está pensado para personas de diferentes disciplinas que quieren adentrarse en el mundo de la analítica de procesos, profesionales de negocio y tecnología que desean analizar el comportamiento de los procesos a partir de los datos e identificar posibilidades de cambio para el mejoramiento de los mismos. Este curso está pensado para personas con por lo menos un título de pregrado y es deseable que los estudiantes cuenten con conocimientos de modelamiento de procesos.",2352.0,6735.0,4.8,52.0
Analítica de ventas para la toma de decisiones con PowerBI,https://www.coursera.org/learn/analitica-ventas-toma-decisiones-powerbi,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a analizar los datos asociados a las ventas con la herramienta de Power BI Desktop. Se explicara paso a paso todo el proceso de desarrollo de los informes de ventas. Desde la importación de los datos y modelado, hasta el desarrollo de los KPIs y visuales de analítica avanzada con inteligencia artificial. 
Gracias a ello, al finalizar el curso sabremos generar nuestros propios análisis de los datos de ventas con Power BI y podremos tomar decisiones en base a los datos.",,,4.8,11.0
Analítica financiera​,https://www.coursera.org/learn/analitica-financiera,Data Science,Data Analysis,Adriana Abrego Pérez,"Conforme las organizaciones complejizan sus modelos de negocios, se requieren más personas con habilidades en el análisis de datos y la construcción de modelos estadísticos que faciliten la toma de decisiones financieras en escenarios con riesgo. En este curso, se presenta una visión general de los métodos de analítica en finanzas que se aplican en la actualidad. Se da primeramente, una introducción a la analítica financiera estableciendo la relación entre la transformación de datos y la generación de valor, entendiendo primeramente las diferencias entre los tipos de datos usuales para identificar modelos, técnicas y tipos de problemáticas que resuelven. Posteriormente, nos introduciremos en las series financieras, entenderás sus componentes, así como la relevancia de las diferentes métricas de error dentro de la muestra y los de pronóstico para la selección de modelos. Aprenderás los conceptos básicos del aprendizaje automático y los modelos usuales en finanzas; con ello en mente, estudiaremos y aplicaremos los principios de las redes neuronales para predecir comportamientos de las series financieras. Finalmente, entenderemos las principales métricas de riesgo financiero y su  relación con el rendimiento de activos.   Bajo este contexto, se realizarán aplicaciones a modelos descriptivos y predictivos contemplados en modelos econométricos y de aprendizaje automático. 

Este curso está pensado para personas de diferentes disciplinas que quieren adentrarse en el mundo de la analítica de datos aplicado a finanzas, quienes reconocen que el desarrollo de habilidades de análisis para el entendimiento y aplicación de los enfoques estadísticos descriptivos, de diagnóstico y de predicción en finanzas son relevantes hoy en día. Este curso está pensado para personas con por lo menos un título de pregrado con conocimientos intermedios en probabilidad y estadística. El aspirante a tomar este curso puede provenir de cualquier campo del conocimiento, desde el gobierno, la industria, la consultoría y la academia. 

Este curso requiere de la instalación de R y R-Studio, es recomendable que el equipo cuente con más de 8 GB de RAM y espacio en disco duro superior a 1 GB.",1903.0,8047.0,4.5,19.0
Análise de dados com Python,https://www.coursera.org/learn/data-analysis-with-python-pt,Data Science,Data Analysis,Joseph Santarcangelo,"Saiba como analisar dados usando Python. Este curso abrange desde o básico do Python até a exploração de diferentes tipos de dados. Você aprenderá como preparar dados para análise, executar análises estatísticas simples, criar visualizações de dados significativas, prever tendências futuras a partir de dados, e muito mais!

Tópicos abordados:

1) Importação de conjuntos de dados
2) Limpeza dos dados
3) Manipulação de estrutura de dados
4) Resumo dos dados
5) Construção de modelos de regressão de aprendizado de máquina
6) Construção de dados pipeline

A análise de dados com Python será realizada por meio de palestras, laboratórios e tarefas. Ele inclui as seguintes partes:

Bibliotecas de análise de dados:aprenderá a usar bibliotecas Pandas, Numpy e Scipy para trabalhar com uma amostra de conjunto de dados. Apresentaremos o pandas, uma biblioteca de código aberto, e a usaremos para carregar, manipular, analisar e visualizar conjuntos de dados. Em seguida, apresentaremos outra biblioteca de código aberto, a scikit-Learn, e usaremos alguns de seus algoritmos de aprendizado de máquina para criar modelos inteligentes e fazer previsões interessantes. Se você optar por fazer este curso e receber o certificado do curso Coursera, você também ganhará um selo digital da IBM. 

OFERTA LIMITADA: a assinatura custa apenas US$ 39,00 por mês para acesso a materiais classificados e a um certificado.",3552.0,8941.0,4.8,20.0
Análise de dados com programação em R,https://www.coursera.org/learn/analise-de-dados-com-programacao-em-r,Data Science,Data Analysis,Google Career Certificates,"Este é o sétimo curso do Certificado de Data Analytics do Google. Estes cursos darão a você as habilidades necessárias para se candidatar a cargos empregos de analista de dados de nível inicial. Neste curso, você aprenderá sobre a linguagem de programação conhecida como R. Você descobrirá como usar o RStudio, o ambiente que permite trabalhar em R. O curso também abarcará os aplicativos e ferramentas de software exclusivos de R, como os pacotes de R. Você descobrirá como é possível limpar, organizar, analisar, visualizar e gerar relatórios de dados usando R de maneiras novas e contundentes.  Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível inicial para analista de dados. Nenhuma experiência anterior é necessária.

Ao final deste curso, você poderá:
 - Examinar os benefícios de usar a linguagem de programação R.
 - Usar o RStudio para aplicar R em suas análises. 
 - Explorar os conceitos fundamentais da programação em R. 
 - Explorar o conteúdo e os componentes dos pacotes de R, inclusive o pacote Tidyverse.
 - Compreender os dataframes e seu uso em R.
 - Conhecer as opções para gerar visualizações em R.
 - Saber sobre R Markdown para documentar a programação em R.",,31395.0,4.4,15.0
Análisis Exploratorio de Datos con Python,https://www.coursera.org/learn/analisis-exploratorio-de-datos-con-python,Data Science,Data Analysis,Layla Scheli,"Python es un lenguaje fabuloso de programación, que nos ofrece muchas ventajas a la hora de utilizarlo como herramienta para el análisis exploratorio de datos. Realizar un EDA, es el primer paso que debemos de aplicar para tener un mayor entendimiento de nuestros datos y poder tener un contexto adecuado de la temática que estamos analizando. 

Resulta importante mencionar, que este proyecto guiado tiene una dificultad “intermedia” para su desarrollo. Como objetivo principal al finalizar todas las capsulas de conocimiento y entregas de prácticas asociadas, se busca que los estudiantes puedan aprender los conceptos más relevantes e importantes para el uso de Python como herramienta para el análisis exploratorio de datos.  También veremos cómo es el proceso de instalación de librerías utilizando el Anaconda Prompt.

Con los conocimientos adquiridos en este proyecto guiado, los estudiantes podrán ser capaces de realizar sus propios análisis de datos, utilizando Python como herramienta principal de análisis como así también, realizar visualizaciones graficas acordes e ilustrativas sobre nuestros datos.",,,,
Análisis de datos con Python,https://www.coursera.org/learn/analisis-de-datos-con-python,Data Science,Data Analysis,Joseph Santarcangelo,"Aprenda a analizar datos con Python. Este curso lo llevará desde los conceptos básicos de Python hasta la exploración de muchos tipos diferentes de datos. Aprenderá a preparar datos para el análisis, realizar análisis estadísticos simples, crear visualizaciones de datos significativas, predecir tendencias futuras a partir de datos, ¡y más!

Tópicos cubiertos:

1) Importación de conjuntos de datos
2) Limpiar los datos
3) manipulación del marco de datos
4) Resumen de los datos
5) Creación de modelos de regresión de aprendizaje automático
6) Construcción de canalizaciones de datos

 El análisis de datos con Python se entregará a través de conferencias, laboratorio y asignaciones. Incluye las siguientes partes:

Bibliotecas de análisis de datos: aprenderá a usar las bibliotecas Pandas, Numpy y Scipy para trabajar con un conjunto de datos de muestra. Le presentaremos pandas, una biblioteca de código abierto, y la usaremos para cargar, manipular, analizar y visualizar conjuntos de datos interesantes. Luego, le presentaremos otra biblioteca de código abierto, scikit-learn, y usaremos algunos de sus algoritmos de aprendizaje automático para construir modelos inteligentes y hacer predicciones interesantes.

Si elige tomar este curso y obtener el certificado del curso de Coursera, también obtendrá una insignia digital de IBM.

OFERTA POR TIEMPO LIMITADO: La suscripción cuesta solo $ 39 USD por mes para acceder a materiales calificados y un certificado.",2833.0,16245.0,4.7,39.0
Análisis de datos con programación en R,https://www.coursera.org/learn/analisis-de-datos-con-programacion-en-r,Data Science,Data Analysis,Google Career Certificates,"Este es el séptimo curso del Certificado de análisis computacional de datos de Google. En estos cursos obtendrás las habilidades necesarias para solicitar empleos de analista de datos de nivel introductorio. En este curso, aprenderás el lenguaje de programación conocido como R. Además, se profundizará en cómo usar RStudio, el entorno que te permite trabajar con R, y se cubrirán temas como las aplicaciones y las herramientas de software que son exclusivas para R, como los paquetes de R. Descubrirás cómo R te brinda más alternativas para limpiar, organizar, analizar, visualizar e informar los datos con mayor eficacia.  Los analistas de datos actuales de Google seguirán dándote instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, serás capaz de:
 - Analizar los beneficios de usar el lenguaje de programación en R.
 - Descubrir cómo usar RStudio para aplicar R en tus análisis. 
 - Explorar los conceptos básicos relacionados con la programación en R. 
 - Explorar el contenido y los componentes de los paquetes de R, incluido el paquete Tidyverse.
 - Comprender las tramas de datos y su uso en R.
 - Descubrir las opciones de generación de visualizaciones en R.
 - Aprender sobre R Markdown para documentar la programación en R.",3079.0,119489.0,4.7,46.0
Análisis de documentos con servicios cognitivos de Azure,https://www.coursera.org/learn/analisis-documentos-servicios-cognitivos-azure,Data Science,Data Analysis,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a desarrollar modelos no supervisados con uno de los servicios cognitivos de Azure (Form Recognizer) para analizar formularios en archivos PDF y extraer los datos en un formato clave valor. 
Podrás entrenar y validar el modelo mediante un orquestador construido con una aplicación lógica (Logic App) que se ejecutará al momento de subir un nuevo archivo a analizar.

Además, podrás analizar el resultado del servicio cognitivo y compararlo con el archivo PDF de pruebas que se utiliza para verificar el modelo generado.",,,4.8,22.0
Análisis exploratorio de datos con Python y Pandas,https://www.coursera.org/learn/analisis-exploratorio-de-datos-con-python-y-pandas,Data Science,Data Analysis,Juan Pablo Yepes,"En este proyecto guiado obtendrás experiencia práctica trabajando con la librería Pandas y creando tu propio cuaderno de Jupyter Lab.  Los conocimientos básicos que obtengas te permitirán trabajar con cualquier base de datos para analizar la información.  Al final de este proyecto serás capaz de crear tus propios cuadernos con análisis estadísticos de diferentes bases de datos.

Nota: Este curso está dirigido a personas que buscan iniciarse en el mundo de la ciencia de datos o el machine learning.",,,,
Apache Spark (TM) SQL for Data Analysts,https://www.coursera.org/learn/apache-spark-sql-for-data-analysts,Data Science,Data Analysis,Kate Sullivan,"Apache Spark is one of the most widely used technologies in big data analytics. In this course, you will learn how to leverage your existing SQL skills to start working with Spark immediately. You will also learn how to work with Delta Lake, a highly performant, open-source storage layer that brings reliability to data lakes. By the end of this course, you will be able to use Spark SQL and Delta Lake to ingest, transform, and query data to extract valuable insights that can be shared with your team.",16082.0,50258.0,4.5,393.0
Aplicando privacidad en modelos de Machine Learning,https://www.coursera.org/learn/privacidad-machine-learning,Data Science,Data Analysis,Nestor Nicolas Campos Rojas,"En este proyecto, vamos a entender la importancia de la privacidad en modelos de Machine Learning usando Azure.",,,,
App Dev: Storing Application Data in Cloud Datastore - Python,https://www.coursera.org/learn/googlecloud-app-dev-storing-application-data-in-cloud-datastore-python-zqyd5,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Application of Data Analysis in Business with R Programming,https://www.coursera.org/learn/application-of-data-analysis-in-business-with-r-programming,Data Science,Data Analysis,Nilosree Sengupta,"This Guided Project “Application of Data Analysis in Business with R Programming”  is for the data science learners and enthusiasts of 2 hours long. The learners will learn to discover the underlying patterns and analyse the trends in data with Data Science functions. 

They will explore a Real world application of Data Analysis in the field of business.They will gain insights that will assist in suggesting recommendations or strategic decision making for optimising business and efficient allocation of resources.

This Guided Project is unique because it is a research study and analysis of data of a pandemic affected period from the year 2020.Hence, learners will study customer purchasing trends of an uncertain period marked by covid-19 where the world economy has been suffering which will also prepare learners for analysing uncertain and uneven trends.

In order to be successful, learners will need prior fundamental knowledge of R programming,Statistics and familiarity with using RStudio.",3961.0,,4.5,69.0
Application using Amazon Rekognition,https://www.coursera.org/learn/aws-rekognition,Data Science,Machine Learning,Yara Yasser,"في اخر الكورس هتقدر تستخدم AWS Rekognition من الWesbite بتاع AWS . خلال المشروع هتقدر تستخدم AWS Rekognition APIs في Python code وهتقدر تعمل مشاريع Computer Vision, من غير ما تدخل في تفاصيل بناء Machine Learning Model,هتقدر كمان تستخدم AWS High Level Services وتخليها تعمل الوظيفة المطلوبة بسرعة ودقة 
المشروع  ده لاي شخص مبتدأ حابب يعمل مشروع او حلول بال Computer Vision باستخدام AWS  سواء في دراسته او شغله لتسهيل عملية بناء Machine Learning Model. وده هيفيد بان التركيز الاكبر يكون علي الهدف الاساسي للمشروع مش التركيز علي الComputer Vision, فالنجاح في المشروع هيكون احسن, اسرع, ادق وكمان يضمن استمرارية النتيجة. 
بيقدملك حلول لمشاكل كتير تقدر تتحل بال وفي الكورس ده هنبقي علي بداية طريق ال   cloud-based 
software ده Amazon Rekognition
 
بيقدملك حلول لمشاكل كتير تقدر تتحل بال وفي الكورس ده هتبقي علي بداية طريق الAutomation وبداية انك تقدر تعمل serverless pipeline تستخدمها في اي مشروع له علاقة بالComputer Vision فتبقي قادر اكتر تركز علي مشروعك واللفكرة الجديدة اللي عندك بدل ما تشغل نفسك في بناء Machine Learning Model جديد وانك تطور فيه كل شوية ودي واحدة من اهم مميزات AWS انها بتوفرلك خدمات مش بتخليك متضطر الي اعادة اختراع العجلة!",,,,
Applied AI with DeepLearning,https://www.coursera.org/learn/ai,Data Science,Machine Learning,"Romeo Kienzler, Niketan Pansare, Tom Hanlon, Max Pumperla, Ilja Rasin",">>> By enrolling in this course you agree to the End User License Agreement as set out in the FAQ.  Once enrolled you can access the license in the Resources area <<<

This course, Applied Artificial Intelligence with DeepLearning, is part of the IBM Advanced Data Science Certificate which IBM is currently creating and gives you easy access to the invaluable insights into Deep Learning models used by experts in Natural Language Processing, Computer Vision, Time Series Analysis, and many other disciplines. We’ll learn about the fundamentals of Linear Algebra and Neural Networks. Then we introduce the most popular DeepLearning Frameworks like Keras, TensorFlow, PyTorch, DeepLearning4J and Apache SystemML. Keras and TensorFlow are making up the greatest portion of this course. We learn about Anomaly Detection, Time Series Forecasting, Image Recognition and Natural Language Processing by building up models using Keras on real-life examples from IoT (Internet of Things), Financial Marked Data, Literature or Image Databases. Finally, we learn how to scale those artificial brains using Kubernetes, Apache Spark and GPUs.

IMPORTANT: THIS COURSE ALONE IS NOT SUFFICIENT TO OBTAIN THE ""IBM Watson IoT Certified Data Scientist certificate"". You need to take three other courses where two of them are currently built. The Specialization will be ready late spring, early summer 2018

Using these approaches, no matter what your skill levels in topics you would like to master, you can change your thinking and change your life. If you’re already an expert, this peep under the mental hood will give your ideas for turbocharging successful creation and deployment of DeepLearning models. If you’re struggling, you’ll see a structured treasure trove of practical techniques that walk you through what you need to do to get on track. If you’ve ever wanted to become better at anything, this course will help serve as your guide.

Prerequisites: Some coding skills are necessary. Preferably python, but any other programming language will do fine. Also some basic understanding of math (linear algebra) is a plus, but we will cover that part in the first week as well.

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.  To find out more about IBM digital badges follow the link ibm.biz/badging.",50274.0,18920.0,4.4,1078.0
Applied Calculus with Python,https://www.coursera.org/learn/applied-calculus-with-python,Data Science,Data Analysis,"Joseph W. Cutrone, PhD","This course is designed for the Python programmer who wants to develop the foundations of Calculus to help solve challenging problems as well as the student of mathematics looking to learn the theory and numerical techniques of applied calculus implemented in Python. By the end of this course, you will have learned how to apply essential calculus concepts to develop robust Python applications that solve a variety of real-world challenges.  Video lectures, readings, worked examples, assessments, and Python code are all provided in the course. These are used to illustrate techniques to solve equations, work with functions, and compute and apply derivatives and integrals. If you are interested in starting to develop concepts in fields such as applied math, data science, cybersecurity, or artificial intelligence, or just need a refresher of calculus or coding in Python, then this course is right for you.",,10259.0,4.5,10.0
Applied Data Science Capstone,https://www.coursera.org/learn/applied-data-science-capstone,Data Science,Data Analysis,"Yan Luo, Joseph Santarcangelo","This is the final course in the IBM Data Science Professional Certificate as well as the Applied Data Science with Python Specialization. This capstone project course will give you the chance to practice the work that data scientists do in real life when working with datasets.  

In this course you will assume the role of a Data Scientist working for a startup intending to compete with SpaceX, and in the process follow the Data Science methodology involving data collection, data wrangling, exploratory data analysis, data visualization, model development, model evaluation, and reporting your results to stakeholders.  

You will be tasked with predicting if the first stage of the SpaceX Falcon 9 rocket will land successfully. With the help of your Data Science findings and models, the competing startup you have been hired by can make more informed bids against SpaceX for a rocket launch.  

In this course, there will not be much new learning, instead you’ll focus on hands-on work to demonstrate and apply what you have learnt in previous courses.  By successfully completing this Capstone you will have added a project to your data science and machine learning portfolio to showcase to employers.",110724.0,240497.0,4.7,6314.0
Applied Data Science for Data Analysts,https://www.coursera.org/learn/applied-data-science-for-data-analysts,Data Science,Data Analysis,"Kevin Coyle, Mark Roepke, Emma Freeman","In this course, you will develop your data science skills while solving real-world problems. You'll work through the data science process to and use unsupervised learning to explore data, engineer and select meaningful features, and solve complex supervised learning problems using tree-based models. You will also learn to apply hyperparameter tuning and cross-validation strategies to improve model performance.

NOTE: This is the third and final course in the Data Science with Databricks for Data Analysts Coursera specialization. To be successful in this course we highly recommend taking the first two courses in that specialization prior to taking this course. These courses are: Apache Spark for Data Analysts and Data Science Fundamentals for Data Analysts.",3163.0,14530.0,4.3,31.0
Applied Machine Learning in Python,https://www.coursera.org/learn/python-machine-learning,Data Science,Data Analysis,Kevyn Collins-Thompson,"This course will introduce the learner to applied machine learning, focusing more on the techniques and methods than on the statistics behind these methods. The course will start with a discussion of how machine learning is different than descriptive statistics, and introduce the scikit learn toolkit through a tutorial. The issue of dimensionality of data will be discussed, and the task of clustering data, as well as evaluating those clusters, will be tackled. Supervised approaches for creating predictive models will be described, and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability (e.g. cross validation, overfitting). The course will end with a look at more advanced techniques, such as building ensembles, and practical limitations of predictive models. By the end of this course, students will be able to identify the difference between a supervised (classification) and unsupervised (clustering) technique, identify which technique they need to apply for a particular dataset and need, engineer features to meet that need, and write python code to carry out an analysis. 

This course should be taken after Introduction to Data Science in Python and Applied Plotting, Charting & Data Representation in Python and before Applied Text Mining in Python and Applied Social Analysis in Python.",266460.0,228406.0,4.6,8192.0
"Applied Plotting, Charting & Data Representation in Python",https://www.coursera.org/learn/python-plotting,Data Science,Data Analysis,Christopher Brooks,"This course will introduce the learner to information visualization basics, with a focus on reporting and charting using the matplotlib library. The course will start with a design and information literacy perspective, touching on what makes a good and bad visualization, and what statistical measures translate into in terms of visualizations. The second week will focus on the technology used to make visualizations in python, matplotlib, and introduce users to best practices when creating basic charts and how to realize design decisions in the framework. The third week will be a tutorial of functionality available in matplotlib, and demonstrate a variety of basic statistical charts helping learners to identify when a particular method is good for a particular problem. The course will end with a discussion of other forms of structuring and visualizing data. 

This course should be taken after Introduction to Data Science in Python and before the remainder of the Applied Data Science with Python courses: Applied Machine Learning in Python, Applied Text Mining in Python, and Applied Social Network Analysis in Python.",172668.0,130548.0,4.5,6094.0
Applied Social Network Analysis in Python,https://www.coursera.org/learn/python-social-network-analysis,Data Science,Data Analysis,Daniel Romero,"This course will introduce the learner to network analysis through tutorials using the NetworkX library. The course begins with an understanding of what network analysis is and motivations for why we might model phenomena as networks. The second week introduces the concept of connectivity and network robustness. The third week will explore ways of measuring the importance or centrality of a node in a network. The final week will explore the evolution of networks over time and cover models of network generation and the link prediction problem. 

This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.",90612.0,53514.0,4.6,2620.0
Applied Text Mining in Python,https://www.coursera.org/learn/python-text-mining,Data Science,Data Analysis,V. G. Vinod Vydiswaran,"This course will introduce the learner to text mining and text manipulation basics. The course begins with an understanding of how text is handled by python, the structure of text both to the machine and to humans, and an overview of the nltk framework for manipulating text. The second week focuses on common manipulation needs, including regular expressions (searching for text), cleaning text, and preparing text for use by machine learning processes. The third week will apply basic natural language processing methods to text, and demonstrate how text classification is accomplished. The final week will explore more advanced methods for detecting the topics in documents and grouping them by similarity (topic modelling). 

This course should be taken after: Introduction to Data Science in Python, Applied Plotting, Charting & Data Representation in Python, and Applied Machine Learning in Python.",128361.0,69158.0,4.2,3709.0
Apply Generative Adversarial Networks (GANs),https://www.coursera.org/learn/apply-generative-adversarial-networks-gans,Data Science,Machine Learning,"Sharon Zhou, Eda Zhou, Eric Zelikman","In this course, you will:

- Explore the applications of GANs and examine them wrt data augmentation, privacy, and anonymity
- Leverage the image-to-image translation framework and identify applications to modalities beyond images
- Implement Pix2Pix, a paired image-to-image translation GAN, to adapt satellite images into map routes (and vice versa)
- Compare paired image-to-image translation to unpaired image-to-image translation and identify how their key difference necessitates different GAN architectures
- Implement CycleGAN, an unpaired image-to-image translation model, to adapt horses to zebras (and vice versa) with two GANs in one

The DeepLearning.AI Generative Adversarial Networks (GANs) Specialization provides an exciting introduction to image generation with GANs, charting a path from foundational concepts to advanced techniques through an easy-to-understand approach. It also covers social implications, including bias in ML and the ways to detect it, privacy preservation, and more.

Build a comprehensive knowledge base and gain hands-on experience in GANs. Train your own model using PyTorch, use it to create images, and evaluate a variety of advanced GANs. 

This Specialization provides an accessible pathway for all levels of learners looking to break into the GANs space or apply GANs to their own projects, even without prior familiarity with advanced math and machine learning research.",16186.0,18729.0,4.8,449.0
Apprendre à une IA des jeux de stratégie avec easyAI,https://www.coursera.org/learn/intelligence-artificielle-pour-gamers,Data Science,Machine Learning,ELINGUI Pascal Uriel,"Dans ce projet guidé, vous découvrirez easyAI un Framework d’intelligence artificielle pouvant apprendre à la machine à jouer des jeux de stratégie dit à somme nulle. Vous allez découvrir ce Framework à travers la création de 5 jeux en console : le jeu des Allumettes, le jeu de Nim, le Morpion, Puissance 4 et Awalé.

easyAI embarque plusieurs simples algorithmes de Machine Learning  comme Negamax et les arbres de Monte-Carlo souvent utilisé pour le Reinforcement Learning.

Ce cours est destiné aux pratiquants du Machine Learning, ayant des sensibilités en Gaming.",,,,
Aprendizado de máquina com Python,https://www.coursera.org/learn/machine-learning-with-python-pt,Data Science,Machine Learning,Joseph Santarcangelo,"Este curso mergulha nos fundamentos básicos de aprendizado de máquina usando uma linguagem de programação acessível e bem conhecida, Python. 

Neste curso, revisaremos dois componentes principais:
Primeiro, você aprenderá sobre o propósito do aprendizado de máquina e onde ele se aplica no mundo real. 
Segundo, você terá uma visão geral dos tópicos de aprendizado de máquina, como um aprendizado supervisionado versus não supervisionado, avaliação de modelo e algoritmos de aprendizado de máquina. 

Neste curso, você praticará com exemplos de aprendizado de máquina da vida real e verá como ele a afeta a sociedade de maneiras que você nunca imaginou!

Veja o que você terá durante as próximas semanas dedicando algumas horas por semana.
1) Novas habilidades para acrescentar em seu currículo, tais como regressão, classificação, clusterização, aprendizado sci-kit e SciPy 
2) Novos projetos que você pode acrescentar ao seu portfólio, incluindo detecção de câncer, previsão de tendências econômicas, previsão de churn de cliente, máquinas de recomendação e muito mais.
3) E um certificado em aprendizado de máquina para comprovar a sua competência e compartilhar onde você quiser, online ou offline, como no perfil do LinkedIn e nas redes sociais.
Se você escolher fazer este curso e obter o certificado do curso do Coursera, você também receberá um selo digital IBM após a conclusão bem-sucedida do curso.",,2769.0,,
Aprendizaje Automático con Python,https://www.coursera.org/learn/aprendizaje-automatico-con-python,Data Science,Machine Learning,"SAEED AGHABOZORGI, Joseph Santarcangelo","Este curso se sumerge en los conceptos básicos del aprendizaje automático mediante un lenguaje de programación accesible y conocido, Python.

En este curso, repasaremos dos componentes principales:
Primero, aprenderá sobre el propósito del aprendizaje automático y dónde se aplica al mundo real.
En segundo lugar, obtendrá una descripción general de los temas del aprendizaje automático, como el aprendizaje supervisado o no supervisado, la evaluación de modelos y los algoritmos del aprendizaje automático.

En este curso, practicarás con ejemplos de la vida real de aprendizaje automático y verás cómo afecta a la sociedad de formas que quizás no hayas adivinado.

Con solo dedicar unas horas a la semana durante las próximas semanas, esto es lo que obtendrá.
1) Nuevas habilidades para agregar a su currículum, como regresión, clasificación, agrupamiento, aprendizaje de sci-kit y SciPy
2) Nuevos proyectos que puede agregar a su cartera, incluida la detección de cáncer, la predicción de tendencias económicas, la predicción de la rotación de clientes, los motores de recomendación y muchos más.
3) Y un certificado en aprendizaje automático para demostrar su competencia y compartirlo en cualquier lugar que desee en línea o fuera de línea, como perfiles de LinkedIn y redes sociales.

Si elige tomar este curso y obtener el certificado del curso de Coursera, también obtendrá una insignia digital de IBM al completar con éxito el curso.",1538.0,4443.0,4.5,11.0
Aprendizaje automático con Python y Azure Notebooks,https://www.coursera.org/learn/aprendizaje-automatico-python-azure-notebooks,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a crear modelos de Machine Learning  con Python y Azure Notebooks, Aprenderás no solo a crear los modelos, si no que también a ejecutarlos desde el servicio de Notebooks de Azure Machine Learning Service.
Gracias a un enfoque práctico y aplicado, al acabar este proyecto habrás desarrollados tus propios modelos de Machine Learning de regresión, clasificación binaria y multiclase. Y acabarás aprendiendo a crear tus propios modelos desde cero, a evaluarlos y a desplegarlos en el entorno de Azure Notebooks.",,,,
Aprendizaje automático sin código: Azure ML Designer,https://www.coursera.org/learn/aprendizaje-automatico-sin-codigo-azureml-designer,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a crear modelos de ML con Azure Machine Learning Designer. Aprenderás todos los pasos de desarrollo de un modelo y su despliegue en producción en Azure, desde su entrenamiento hasta su consumo desde un software-API de terceros.
Aprenderás desde cero Azure y los fundamentos de Azure Machine Learning. Y acabarás aprendiendo a crear tus propios modelos, evaluarlos y desplegarlos en producción.",,,,
Art and Science of Machine Learning em Português Brasileiro,https://www.coursera.org/learn/art-science-ml-br,Data Science,Machine Learning,Google Cloud Training,"Este é o curso Art and Science of Machine Learning. O curso tem seis módulos. Falaremos sobre as habilidades essenciais de intuição, bom senso e experimentação em ML para ajustar e otimizar modelos e ter melhor desempenho. Você aprenderá a generalizar os modelos usando técnicas de regularização e conhecerá os efeitos dos hiperparâmetros, como tamanho de lote e taxa de aprendizado, sobre o desempenho do modelo. Também abordaremos alguns algoritmos mais comuns de otimização de modelo e mostraremos como especificar um método de otimização no código do TensorFlow.",,,4.6,14.0
Art and Science of Machine Learning en Español,https://www.coursera.org/learn/art-science-ml-es,Data Science,Machine Learning,Google Cloud Training,"Le damos la bienvenida a The Art and Science of Machine Learning.  El curso consta de 6 módulos. En este curso, se abordan las habilidades básicas de intuición, buen criterio y experimentación del AA necesarias para ajustar mejor y optimizar modelos de AA a fin de lograr el mejor rendimiento.  Aprenderá a generalizar su modelo usando técnicas de regularización y descubrirá los efectos de los hiperparámetros, como el tamaño del lote y la tasa de aprendizaje, en el rendimiento del modelo.  Analizaremos algunos de los algoritmos de optimización de los modelos más comunes y le mostraremos cómo especificar un método de optimización en su código de TensorFlow.",2272.0,,4.6,26.0
Art and Science of Machine Learning en Français,https://www.coursera.org/learn/art-science-ml-fr,Data Science,Machine Learning,Google Cloud Training,"Bienvenue dans ""Art and Science of Machine Learning"". Ce cours se compose de 6 modules. Dans ce cours, nous allons voir les compétences essentielles que sont l'intuition, le bon sens et l'expérimentation, nécessaires pour ajuster vos modèles de ML et optimiser leurs performances. Nous verrons comment généraliser votre modèle à l'aide de techniques de régularisation, et nous évoquerons les effets des hyperparamètres tels que la taille de lot et le taux d'apprentissage sur les performances de votre modèle. Nous présenterons également certains des algorithmes d'optimisation les plus courants et vous montrerons comment spécifier une méthode d'optimisation dans votre code TensorFlow.",,,,
Art and Science of Machine Learning 日本語版,https://www.coursera.org/learn/art-science-ml-jp,Data Science,Machine Learning,Google Cloud Training,「Art and Science of machine learning」へようこそ。このコースは 6 つのモジュールで構成されています。このコースでは、機械学習モデルの詳細な調整や最適化によって最高のパフォーマンスを実現するために必要な、機械学習の知識、適切な判断、テストの基本的なスキルについて説明します。正則化の手法を使用してモデルを一般化する方法と、ハイパーパラメータの影響について学習します（モデルのパフォーマンスに対するバッチサイズや学習率の影響など）。一般的なモデル最適化アルゴリズムをいくつか説明し、TensorFlow コードで最適化メソッドを指定する方法を示します。,,,,
Artificial Intelligence Algorithms Models and Limitations,https://www.coursera.org/learn/ai-algorithm-limitations,Data Science,Data Analysis,Brent Summers,"We live in an age increasingly dominated by algorithms. As machine learning models begin making important decisions based on massive datasets, we need to be aware of their limitations in the real world. Whether it's making loan decisions or re-routing traffic, machine learning models need to accurately reflect our shared values. In this course, we will explore the rise of algorithms, from the most basic to the fully-autonomous, and discuss how to make them more ethically sound.",6444.0,9964.0,4.7,126.0
Artificial Intelligence Ethics in Action,https://www.coursera.org/learn/ai-ethics-analysis,Data Science,Data Analysis,Brent Summers,"AI Ethics research is an emerging field, and to prove our skills, we need to demonstrate our critical thinking and analytical ability. Since it's not reasonable to jump into a full research paper with our newly founded skills, we will instead work on 3 projects that will demonstrate your ability to analyze ethical AI across a variety of topics and situations. These projects include all the skills you've learned in this AI Ethics Specialization.",2862.0,4731.0,4.8,33.0
Artificial Intelligence Privacy and Convenience,https://www.coursera.org/learn/ai-privacy-and-convenience,Data Science,Data Analysis,Brent Summers,"In this course, we will explore fundamental concepts involved in security and privacy of machine learning projects. Diving into the ethics behind these decisions, we will explore how to protect users from privacy violations while creating useful predictive models. We will also ask big questions about how businesses implement algorithms and how that affects user privacy and transparency now and in the future.",2967.0,10055.0,4.7,48.0
Artificial Intelligence for Breast Cancer Detection,https://www.coursera.org/learn/artificial-intelligence-for-breast-cancer-detection,Data Science,Machine Learning,"Chung-Fu Chang, Emily Ambinder","The objective of this course is to provide students the knowledge of artificial intelligence processing approaches to breast cancer detection. Students will take quizzes and participate in discussion sessions to reinforce critical concepts conveyed in the modules. Reading assignments, including journal papers to understand the topics in the modules, will be provided. 

The course is designed for students who are interested in the career of product development using artificial intelligence and would like to know how AI can be applied to mammography.  The course content is focused on the AI processing paradigm along with the domain knowledge of breast imaging.  

This course approach is unique, providing students a broad perspective of AI, rather than homing in on a particular implementation method.  Students who complete this course will not only leverage the knowledge into an entry level job in the field of artificial intelligence but also perform well on projects because their thorough understanding of the AI processing paradigm.",,3882.0,4.5,41.0
Ask Questions to Make Data-Driven Decisions,https://www.coursera.org/learn/ask-questions-make-decisions,Data Science,Data Analysis,Google Career Certificates,"This is the second course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. You’ll build on your understanding of the topics that were introduced in the first Google Data Analytics Certificate course. The material will help you learn how to ask effective questions to make data-driven decisions, while connecting with stakeholders’ needs. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
- Learn about effective questioning techniques that can help guide analysis. 
- Gain an understanding of data-driven decision-making and how data analysts present findings.
- Explore a variety of real-world business scenarios to support an understanding of questioning and decision-making.
- Discover how and why spreadsheets are an important tool for data analysts.
- Examine the key ideas associated with structured thinking and how they can help analysts better understand problems and develop solutions.
- Learn strategies for managing the expectations of stakeholders while establishing clear communication with a data analytics team to achieve business objectives.",474561.0,5116016.0,4.7,19658.0
"Aspectos básicos: Datos, datos, en todas partes",https://www.coursera.org/learn/aspectos-basicos-datos-datos-en-todas-partes,Data Science,Data Analysis,Google Career Certificates,"Este es el primer curso del certificado de Google Data Analytics. En estos cursos obtendrás las habilidades que necesitas para aplicar a los trabajos de analista de datos de nivel introductorio. Organizaciones de todo tipo necesitan analistas de datos que las ayuden a mejorar sus procesos, identificar oportunidades y tendencias, lanzar nuevos productos y tomar decisiones reflexivas. En este curso, conocerás el mundo del análisis computacional de datos a través de un plan de estudios práctico desarrollado por Google. En el material compartido se incluyen muchos temas clave de análisis computacional de datos y una visión general de lo que aborda el Certificado de Google Data Analytics. Los analistas de datos actuales de Google te darán instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, serás capaz de:
- Comprender las prácticas y los procesos que utiliza un analista de datos junior o asociado en su trabajo diario. 
- Obtener información sobre las principales destrezas analíticas (limpieza de datos, análisis de datos, visualización de datos) y herramientas (hojas de cálculo, SQL, programación en R, Tableau) que puedes agregar a tu caja de herramientas profesional. 
- Descubrir una amplia variedad de términos y conceptos relevantes para el rol de analista de datos junior, como el ciclo de vida de los datos y el proceso de análisis de datos. 
- Evaluar el rol del análisis en el ecosistema de datos. 
- Llevar a cabo una autoevaluación del pensamiento analítico. 
- Explorar las oportunidades de trabajo disponibles al finalizar el programa y obtener información sobre las mejores prácticas en la búsqueda de empleo.",35797.0,802728.0,4.8,1942.0
Assessment for Data Analysis and Visualization Foundations,https://www.coursera.org/learn/data-analysis-visualization-foundations-assessment,Data Science,Data Analysis,Skills Network,"This is the final course in the Data Analysis and Visualization Foundations Specialization. It contains a graded final examination covering content from three courses: Introduction to Data Analytics, Excel Basics for Data Analysis, and Data Visualization and Dashboards with Excel and Cognos.  

From the Introduction to Data Analytics course, you will be assessed on your knowledge of topics such as the data ecosystem and the fundamentals of data analysis, including data gathering and data mining tools. From the Excel Basics for Data Analysis course, you should be prepared to answer test items on topics like how Excel spreadsheets are used in data analytics, cleansing and wrangling data, as well as pivot tables. Finally, from the Data Visualization and Dashboards with Excel and Cognos course, you will demonstrate your knowledge on topics such as the basics of IBM Cognos and using Excel for data visualization.",2701.0,13689.0,4.2,59.0
AutoML avec AutoKeras - Classification d'images,https://www.coursera.org/learn/automl-autokeras-classification,Data Science,Machine Learning,ELINGUI Pascal Uriel,"Dans ce projet guidé, vous créerez des modèles de Deep Learning (Apprentissage profond) automatisés  facilement en utilisant AutoKeras une bibliothèque basée sur Keras et Tensorflow.

L'optimisation des hyper-paramètres et l’une des tâches les plus chronophages lors de la création de modèles de Machine Learning. Avec AutoML cela est automatisé, ce qui résulte en un gain de temps considérable pour les ingénieurs en Machine Learning. Cela permet aussi à n'importe qui ayant des connaissances basiques de rapidement créer un modèle de Machine Learning

Cette compétence est déterminante pour accroître votre productivité et la qualité de vos modèles de machine learning. 

Ce cours est destiné aux ingénieurs en Machine Learning, au Data Scientists et tous les curieux désireux augmenter leur productivité.",,,,
AutoML con Pycaret y TPOT,https://www.coursera.org/learn/automl-pycaret-tpot,Data Science,Data Analysis,Leire Ahedo,Este proyecto es un curso práctico y efectivo para aprender todo lo que necesitas saber acerca de autoML. En este curso aprenderemos acerca de las librerías de autoML de Pycaret y TPOT. No solo eso si no que además entrenarás tus propios modelos de ML con autoML,,,,
AutoML for Computer Vision with Microsoft Custom Vision,https://www.coursera.org/learn/automl-computer-vision-microsoft-custom-vision,Data Science,Machine Learning,Snehan Kekre,"Welcome to this hands-on project on using Microsoft’s Custom Vision service for automated machine learning or AutoML as it’s popularly known. In this project, you are going to use Microsoft’s drag and drop tool to train your computer to recognize images of dogs and cats. We are going to do all of this without writing a single line of code! To take this guided-project, you do not need a background in computer science, machine learning or coding. 

The only prerequisite for this project is that you have a Microsoft Azure account. If you don’t already have one, you will have to sign up for it.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4250.0,,4.7,114.0
AutoML tools for data science,https://www.coursera.org/learn/automl,Data Science,Machine Learning,Muhammad Saad uddin,"By the end of this project, you will learn how to perform analysis on data using different python libraries and export reports and visualization without much hassle all this with minimal coding.",,,,
Autoencoders y eventos extremadamente infrecuentes,https://www.coursera.org/learn/autoencoders-y-eventos-extremadamente-infrecuentes,Data Science,Data Analysis,Leire Ahedo,"En muchos casos cuando queremos entrenar modelos de clasificación para predecir una clase minoritaria, no es fácil obtener datos de esta clase. En este curso aprenderás a entrenar modelos capaces de predecir estas clases minoritarias aún sin datos.

Por ello, en este curso te enseñaremos a entrenar y utilizar Autoencoders para procesar los datos existentes y que las clases sean más fácilmente distinguibles. También te enseñaremos a utilizar los propios Autoencoders para predecir la clase minoritaria en eventos extremadamente infrecuentes o cuando no tenemos datos de esta clase.",,,,
Automated Machine Learning en Microsoft Power BI,https://www.coursera.org/learn/automated-machine-learning-powerbi,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender todo lo que necesitas saber acerca de como crear e integrar modelos de autoML en Power BI. No solo aprenderás, de manera practica, a generar y evaluar los modelos. Sino que además aprenderás a integrar y utilizarlos dentro de tus dashboards de Power BI.",,,4.4,13.0
Automated Machine Learning en Power BI Clasificación,https://www.coursera.org/learn/automated-machine-learning-powerbi-clasificacion,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender todo lo que necesitas saber acerca de como crear e integrar modelos de clasificación de autoML en Power BI. No solo aprenderás, de manera practica, a generar y evaluar los modelos de clasificación de autoML. Sino que además aprenderás a integrarlos y a utilizarlos dentro de tus dashboards de Power BI.",,,,
Automatic Machine Learning with H2O AutoML and Python,https://www.coursera.org/learn/automatic-machine-learning-h2o-automl-python,Data Science,Machine Learning,Snehan Kekre,"This is a hands-on, guided project on Automatic Machine Learning with H2O AutoML and Python. By the end of this project, you will be able to describe what AutoML is and apply automatic machine learning to a business analytics problem with the H2O AutoML interface in Python. H2O's AutoML automates the process of training and tuning a large selection of models, allowing the user to focus on other aspects of the data science and machine learning pipeline such as data pre-processing, feature engineering and model deployment.

To successfully complete the project, we recommend that you have prior experience in Python programming, basic machine learning theory, and have trained ML models with a library such as scikit-learn. We will not be exploring how any particular model works nor dive into the math behind them. Instead, we assume you have this foundational knowledge and want to learn to use H2O's AutoML interface for automatic machine learning.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6417.0,,4.8,138.0
Avoid Overfitting Using Regularization in TensorFlow,https://www.coursera.org/learn/tensorflow-regularization-avoid-overfitting,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn the basics of using weight regularization and dropout regularization to reduce over-fitting in an image classification problem. By the end of this project, you will have created, trained, and evaluated a Neural Network model that, after the training and regularization, will predict image classes of input examples with similar accuracy for both training and validation sets.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4365.0,,4.8,75.0
Avoiding Data Science Pitfalls,https://www.coursera.org/learn/ds-pitfalls,Data Science,Data Analysis,Muhammad Saad uddin,"In this 2-hour long project-based course, you will learn some important statistical concepts with examples & visuals, concepts that are most commonly mistaken in data analysis and how to ensure you don’t fall for them.",,,,
Azure Data Engineer con Databricks y Azure Data Factory,https://www.coursera.org/learn/azure-data-engineer-databricks-data-factory,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a utilizar las herramientas de Azure Data Factory y Azure Databricks desde cero. Aprenderás, de manera practica y efectiva a generar pipelines en Data Factory, a utilizar Notebooks de Spark en Databricks y a integrar ambas herramientas.",,,,
Azure Data Lake Storage Gen2 and Data Streaming Solution,https://www.coursera.org/learn/azure-data-lake-storage-gen2-and-data-streaming-solution,Data Science,Data Analysis, Microsoft,"In this course, you will see how Azure Data Lake Storage can make processing Big Data analytical solutions more efficient and how easy it is to set up. You will also explore how it fits into common architectures, as well as the different methods of uploading the data to the data store. You will examine the myriad of security features that will ensure your data is secure. Learn the concepts of event processing and streaming data and how this applies to Azure Stream Analytics. You will then set up a stream analytics job to stream data, and learn how to manage and monitor a running job.

This course is part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services for anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). You will take a practice exam that covers key skills measured by the certification exam.

This is the ninth course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",1803.0,10744.0,4.2,13.0
Bancos de dados e SQL para Ciência de Dados,https://www.coursera.org/learn/sql-data-science-pt,Data Science,Data Analysis,"Hima Vasudevan, Rav Ahuja","Grande parte dos dados do mundo reside em bancos de dados. SQL (ou Structured Query Language) é uma linguagem poderosa usada para se comunicar e extrair dados de bancos de dados. Um conhecimento prático de bancos de dados e SQL é essencial se você deseja se tornar um cientista de dados.

O objetivo deste curso é apresentar os conceitos de banco de dados relacional e ajudá-lo a aprender e aplicar o conhecimento básico da linguagem SQL. Também se destina a ajudá-lo a começar a executar o acesso SQL em um ambiente de ciência de dados.

A ênfase neste curso está no aprendizado prático e participativo. Como tal, você trabalhará com bancos de dados reais, ferramentas de ciência de dados reais e conjuntos de dados do mundo real. Você criará uma instância de banco de dados na nuvem. Por meio de uma série de laboratórios práticos, você praticará a construção e a execução de consultas SQL. Você também aprenderá como acessar bancos de dados do notebook Jupyter usando SQL e Python.

Não é necessário conhecimento prévio de bancos de dados, SQL, Python ou programação.

Qualquer pessoa pode assistir a este curso gratuitamente. Se você optar por fazer este curso e obter o certificado do Coursera, também poderá obter um selo digital da IBM após a conclusão do curso.

OFERTA POR TEMPO LIMITADO: a assinatura custa apenas US$ 39 por mês para obter acesso a materiais avaliados e um certificado.",9927.0,25698.0,4.6,91.0
Bank Loan Approval Prediction With Artificial Neural Nets,https://www.coursera.org/learn/loan-approval-prediction-using-neural-networks,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will build and train a simple deep neural network model to predict the approval of personal loan for a person based on features like age, experience, income, locations, family, education, exiting mortgage, credit card etc.

By the end of this project, you will be able to: 

- Understand the applications of Artificial Intelligence and Machine Learning techniques in the banking industry
- Understand the theory and intuition behind Deep Neural Networks
- Import key Python libraries, dataset, and perform Exploratory Data Analysis.
- Perform data visualization using Seaborn.
- Standardize the data and split them into train and test datasets.   
- Build a deep learning model using Keras with Tensorflow 2.0 as a back-end.
- Assess the performance of the model and ensure its generalization using various Key Performance Indicators (KPIs).

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,22.0
"Bases : Des données, des données, partout",https://www.coursera.org/learn/bases-des-donnees-des-donnees-partout,Data Science,Data Analysis,Google Career Certificates,"Il s’agit du premier cours du Google Data Analytics Certificate. Ces cours vous permettront d’acquérir les compétences dont vous avez besoin pour postuler à des emplois d’analyste de données de niveau junior. Les entreprises de toutes sortes ont besoin d’analystes de données pour les aider à améliorer leurs processus, à identifier les opportunités et les tendances, à lancer de nouveaux produits et à prendre des décisions éclairées. Dans ce cours, vous serez initié au monde de l’analytique de données au travers d’un programme pratique développé par Google. Les supports couvrent de nombreux sujets clés de l’analytique de données, et ils sont conçus pour vous donner un aperçu de ce que contiendra le Google Data Analytics Certificate. Des analystes de données de chez Google vous instruiront et vous fourniront des moyens pratiques d’accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler à des emplois de niveau junior d’analystes de données. Aucune expérience préalable n’est nécessaire.

À la fin de ce cours vous aurez :
- Compris les pratiques et les processus utilisés par un analyste de données junior ou associé dans son travail quotidien. 
- Découvert les compétences (nettoyage des données, analyse des données, visualisation des données) et les outils (tableurs, SQL, programmation R, Tableau) analytiques clés, que vous pourrez ajouter à votre boîte à outils professionnelle. 
- Découvert une grande variété de termes et de concepts pertinents au rôle d’un analyste de données junior, tels que le cycle de vie des données et le processus d’analyse des données. 
- Évalué le rôle de l’analytique dans l’écosystème de données. 
- Effectué une auto-évaluation en mode de pensée analytique. 
- Exploré les possibilités d’emploi qui s’offrent à vous à la fin du programme et connaîtrez les meilleures pratiques en matière de recherche d’emploi.",,6324.0,,
Bases de datos y SQL para ciencia de datos,https://www.coursera.org/learn/sql-para-ciencia-de-datos,Data Science,Data Analysis,Rav Ahuja,"Gran parte de los datos del mundo residen en bases de datos. SQL (o lenguaje de consulta estructurado) es un lenguaje poderoso que se utiliza para comunicarse y extraer datos de bases de datos. Un conocimiento práctico de bases de datos y SQL es imprescindible si desea convertirse en un científico de datos.

El propósito de este curso es presentar los conceptos de bases de datos relacionales y ayudarlo a aprender y aplicar los conocimientos básicos del lenguaje SQL. También está destinado a ayudarle a empezar a realizar el acceso SQL en un entorno de ciencia de datos.

El énfasis en este curso está en el aprendizaje práctico y práctico. Como tal, trabajará con bases de datos reales, herramientas de ciencia de datos reales y conjuntos de datos del mundo real. Creará una instancia de base de datos en la nube. A través de una serie de prácticas de laboratorio, practicará la creación y ejecución de consultas SQL. También aprenderá cómo acceder a las bases de datos desde los cuadernos de Jupyter usando SQL y Python.

No se requieren conocimientos previos de bases de datos, SQL, Python o programación.

Cualquiera puede auditar este curso sin cargo. Si elige tomar este curso y obtener el certificado del curso de Coursera, también puede obtener una insignia digital de IBM al completar con éxito el curso.

OFERTA POR TIEMPO LIMITADO: La suscripción cuesta solo $39 USD por mes para acceder a materiales calificados y un certificado.",3527.0,17738.0,3.8,55.0
"Basic Data Descriptors, Statistical Distributions, and Application to Business Decisions",https://www.coursera.org/learn/descriptive-statistics-statistical-distributions-business-application,Data Science,Data Analysis,Sharad Borle,"The ability to understand and apply Business Statistics is becoming increasingly important in the industry. A good understanding of Business Statistics is a requirement to make correct and relevant interpretations of data. Lack of knowledge could lead to erroneous decisions which could potentially have negative consequences for a firm. This course is designed to introduce you to Business Statistics. We begin with the notion of descriptive statistics, which is summarizing data using a few numbers. Different categories of descriptive measures are introduced and discussed along with the Excel functions to calculate them. The notion of probability or uncertainty is introduced along with the concept of a sample and population data using relevant business examples. This leads us to various statistical distributions along with their Excel functions which are then used to model or approximate business processes. You get to apply these descriptive measures of data and various statistical distributions using easy-to-follow Excel based examples which are demonstrated throughout the course.

To successfully complete course assignments, students must have access to Microsoft Excel. 
________________________________________
WEEK 1
Module 1: Basic Data Descriptors
In this module you will get to understand, calculate and interpret various descriptive or summary measures of data. These descriptive measures summarize and present data using a few numbers. Appropriate Excel functions to do these calculations are introduced and demonstrated.

Topics covered include:
•	Categories of descriptive data
•	Measures of central tendency, the mean, median, mode, and their interpretations and calculations
•	Measures of spread-in-data, the range, interquartile-range, standard deviation and variance
•	Box plots
•	Interpreting the standard deviation measure using the rule-of-thumb and Chebyshev’s theorem
________________________________________
WEEK 2
Module 2: Descriptive Measures of Association, Probability, and Statistical Distributions
This module presents the covariance and correlation measures and their respective Excel functions. You get to understand the notion of causation versus correlation. The module then introduces the notion of probability and random variables and starts introducing statistical distributions.

Topics covered include:
•	Measures of association, the covariance and correlation measures; causation versus correlation
•	Probability and random variables; discrete versus continuous data
•	Introduction to statistical distributions
________________________________________
WEEK 3
Module 3: The Normal Distribution
This module introduces the Normal distribution and the Excel function to calculate probabilities and various outcomes from the distribution. 

Topics covered include:
•	Probability density function and area under the curve as a measure of probability
•	The Normal distribution (bell curve), NORM.DIST, NORM.INV functions in Excel
________________________________________
WEEK 4
Module 4: Working with Distributions, Normal, Binomial, Poisson
In this module, you'll see various applications of the Normal distribution. You will also get introduced to the Binomial and Poisson distributions. The Central Limit Theorem is introduced and explained in the context of understanding sample data versus population data and the link between the two.

Topics covered include:
•	Various applications of the Normal distribution
•	The Binomial and Poisson distributions
•	Sample versus population data; the Central Limit Theorem",51653.0,112251.0,4.7,2352.0
Basic Data Processing and Visualization,https://www.coursera.org/learn/basic-data-processing-visualization-python,Data Science,Data Analysis,"Julian McAuley, Ilkay Altintas","This is the first course in the four-course specialization Python Data Products for Predictive Analytics, introducing the basics of reading and manipulating datasets in Python. In this course, you will learn what a data product is and go through several Python libraries to perform data retrieval, processing, and visualization. 

This course will introduce you to the field of data science and prepare you for the next three courses in the Specialization: Design Thinking and Predictive Analytics for Data Products, Meaningful Predictive Modeling, and Deploying Machine Learning Models. At each step in the specialization, you will gain hands-on experience in data manipulation and building your skills, eventually culminating in a capstone project encompassing all the concepts taught in the specialization.",18655.0,9348.0,4.3,180.0
Basic Descriptives using R Cmdr,https://www.coursera.org/learn/basic-desc-r-cmdr,Data Science,Data Analysis,Shalini Gopalkrishnan ,"In this 1-hour long project-based course, we will show you how to do  basic descriptives using RCmdr .You will learn about measures of central tendency and dispersion. This project uses data about cereals that you eat and details about their sugar, fiber calorie content.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Basic Image Classification with TensorFlow,https://www.coursera.org/learn/tensorflow-beginner-basic-image-classification,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn the basics of using Keras with TensorFlow as its backend and use it to solve a basic image classification problem. By the end of this project, you will have created, trained, and evaluated a Neural Network model that will be able to predict digits from hand-written images with a high degree of accuracy. You also will have learned the fundamentals of neural networks, TensorFlow, and Keras.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",19900.0,,4.6,762.0
Basic Recommender Systems,https://www.coursera.org/learn/basic-recommender-systems,Data Science,Data Analysis,Paolo Cremonesi,"This course introduces you to the leading approaches in recommender systems. The techniques described touch both collaborative and content-based approaches and include the most important algorithms used to provide recommendations. You'll learn how they work, how to use and how to evaluate them, pointing out benefits and limits of different recommender system alternatives. 

After completing this course, you'll be able to describe the requirements and objectives of recommender systems based on different application domains. You'll know how to distinguish recommender systems according to their input data, their internal working mechanisms, and their goals. You’ll have the tools to measure the quality of a recommender system and to incrementally improve it with the design of new algorithms. You'll learn as well how to design recommender systems tailored for new application domains, also considering surrounding social and ethical issues such as identity, privacy, and manipulation.

Providing affordable, personalised and high-quality recommendations is always a challenge! This course also leverages two important EIT Overarching Learning Outcomes (OLOs), related to creativity and innovation skills. In trying to design a new recommender system you need to think beyond boundaries and try to figure out how you can improve the quality of the predictions. You should also be able to use knowledge, ideas and technology to create new or significantly improved recommendation tools to support choice-making processes and strategies in different and innovative scenarios, for a better quality of life.",2128.0,5142.0,4.4,31.0
Basic Sentiment Analysis with TensorFlow,https://www.coursera.org/learn/basic-sentiment-analysis-tensorflow,Data Science,Machine Learning,Amit Yadav,"Welcome to this project-based course on Basic Sentiment Analysis with TensorFlow. In this project, you will learn the basics of using Keras with TensorFlow as its backend and you will learn to use it to solve a basic sentiment analysis problem. By the end of this 2-hour long project, you will have created, trained, and evaluated a Neural Network model that, after the training, will be able to predict movie reviews as either positive or negative reviews - classifying the sentiment of the review text.

Notes:
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7150.0,,4.5,198.0
Basic Statistics,https://www.coursera.org/learn/basic-statistics,Data Science,Probability and Statistics,"Matthijs Rooduijn, Emiel van Loon","Understanding statistics is essential to understand research in the social and behavioral sciences. In this course you will learn the basics of statistics; not just how to calculate them, but also how to evaluate them. This course will also prepare you for the next course in the specialization - the course Inferential Statistics. 

In the first part of the course we will discuss methods of descriptive statistics. You will learn what cases and variables are and how you can compute measures of central tendency (mean, median and mode) and dispersion (standard deviation and variance). Next, we discuss how to assess relationships between variables, and we introduce the concepts correlation and regression. 

The second part of the course is concerned with the basics of probability: calculating probabilities, probability distributions and sampling distributions. You need to know about these things in order to understand how inferential statistics work. 

The third part of the course consists of an introduction to methods of inferential statistics - methods that help us decide whether the patterns we see in our data are strong enough to draw conclusions about the underlying population we are interested in. We will discuss confidence intervals and significance tests.

You will not only learn about all these statistical concepts, you will also be trained to calculate and generate these statistics yourself using freely available statistical software.",258298.0,165068.0,4.6,4240.0
Basic Statistics in Python (ANOVA),https://www.coursera.org/learn/basic-statistics-python-anova,Data Science,Data Analysis,Laura Gemmell,"In this 1-hour long project-based course, you will learn how to set up a Google Colab notebook, source data from the internet, load data into Python, merge two datasets, clean data, perform exploratory data analysis, carry out ANOVA and create boxplots. Throughout the course you will work on an Education dataset from World Bank. This will allow you to perform statistical analysis on your own datasets in Python. This project does not require any previous Python or coding experience, but it would be useful for learners to understand the statistical methods covered. The course includes data sourcing and cleaning which are invaluable real world skills, and focuses on visualizing your results which is needed as a large part of any analysis is the storytelling.",,,4.2,27.0
Basic Statistics in Python (Correlations and T-tests),https://www.coursera.org/learn/basic-statistics-python-ttest-corr,Data Science,Probability and Statistics,Laura Gemmell,"By the end of this project, you will learn how to use Python for basic statistics (including t-tests and correlations). We will learn all the important steps of analysis, including loading, sorting and cleaning data. In this course, we will use exploratory data analysis to understand our data and plot boxplots to visualize the data. Boxplots also allow us to investigate any outliers in our datasets. We will then learn how to examine relationships between the different data using correlations and scatter plots. Finally, we will compare data using t-tests. Throughout this course we will analyse a dataset on Science and Technology from World Bank. The measures in this dataset are numeric, therefore you will learn how to handle and compare numeric data. 

This guided project is for anyone with an interest in performing statistical analysis using Python. This could be someone from a social science background with statistics knowledge who wants to advance their analysis, or anyone interested in analysing data.",,,4.4,24.0
Bayesian Inference with MCMC,https://www.coursera.org/learn/mcmc,Data Science,Machine Learning,Dr. Srijith Rajamohan,"The objective of this course is to introduce Markov Chain Monte Carlo Methods for Bayesian modeling and inference,  The attendees will start off by learning the the basics of Monte Carlo methods. This will be augmented by hands-on examples in Python that will be used to illustrate how these algorithms work. This will be the second course in a specialization of three courses .Python and Jupyter notebooks will be used throughout this course to illustrate and perform Bayesian modeling with PyMC3. The course website is located at https://sjster.github.io/introduction_to_computational_statistics/docs/index.html. The course notebooks can be downloaded from this website by following the instructions on page https://sjster.github.io/introduction_to_computational_statistics/docs/getting_started.html.

The instructor for this course will be Dr. Srijith Rajamohan.",,2993.0,3.3,12.0
Bayesian Statistics,https://www.coursera.org/learn/bayesian,Data Science,Data Analysis,"Mine Çetinkaya-Rundel, David Banks, Colin Rundel , Merlise A Clyde","This course describes Bayesian statistics, in which one's inferences about parameters or hypotheses are updated as evidence accumulates. You will learn to use Bayes’ rule to transform prior probabilities into posterior probabilities, and be introduced to the underlying theory and perspective of the Bayesian paradigm. The course will apply Bayesian methods to several practical problems, to show end-to-end Bayesian analyses that move from framing the question to building models to eliciting prior probabilities to implementing in R (free statistical software) the final posterior distribution. Additionally, the course will introduce credible regions, Bayesian comparisons of means and proportions, Bayesian regression and inference using multiple models, and discussion of Bayesian prediction.

We assume learners in this course have background knowledge equivalent to what is covered in the earlier three courses in this specialization: ""Introduction to Probability and Data,"" ""Inferential Statistics,"" and ""Linear Regression and Modeling.""",71586.0,12954.0,3.8,782.0
Bayesian Statistics: Capstone Project,https://www.coursera.org/learn/bayesian-statistics-capstone,Data Science,Data Analysis,Jizhou Kang,"This is the capstone project for UC Santa Cruz's Bayesian Statistics Specialization. It is an opportunity for you to demonstrate a wide range of skills and knowledge in Bayesian statistics and to apply what you know to real-world data. You will review essential concepts in Bayesian statistics with lecture videos and quizzes, and you will perform a complex data analysis and compose a report on your methods and results.",,,,
Bayesian Statistics: From Concept to Data Analysis,https://www.coursera.org/learn/bayesian-statistics,Data Science,Probability and Statistics,Herbert Lee,"This course introduces the Bayesian approach to statistics, starting with the concept of probability and moving to the analysis of data. We will learn about the philosophy of the Bayesian approach as well as how to implement it for common types of data. We will compare the Bayesian approach to the more commonly-taught Frequentist approach, and see some of the benefits of the Bayesian approach. In particular, the Bayesian approach allows for better accounting of uncertainty, results that have more intuitive and interpretable meaning, and more explicit statements of assumptions. This course combines lecture videos, computer demonstrations, readings, exercises, and discussion boards to create an active learning experience. For computing, you have the choice of using Microsoft Excel or the open-source, freely available statistical package R, with equivalent content for both options. The lectures provide some of the basic mathematical development as well as explanations of philosophy and interpretation. Completion of this course will give you an understanding of the concepts of the Bayesian approach, understanding the key differences between Bayesian and Frequentist approaches, and the ability to do basic data analyses.",135290.0,63080.0,4.6,3009.0
Bayesian Statistics: Mixture Models,https://www.coursera.org/learn/mixture-models,Data Science,Data Analysis,Abel Rodriguez,"Bayesian Statistics: Mixture Models introduces you to an important class of statistical models. The course is organized in five modules, each of which contains lecture videos, short quizzes, background reading, discussion prompts, and one or more peer-reviewed assignments. Statistics is best learned by doing it, not just watching a video, so the course is structured to help you learn through application. 

Some exercises require the use of R, a freely-available statistical software package. A brief tutorial is provided, but we encourage you to take advantage of the many other resources online for learning R if you are interested.

This is an intermediate-level course, and it was designed to be the third in UC Santa Cruz's series on Bayesian statistics, after Herbie Lee's ""Bayesian Statistics: From Concept to Data Analysis"" and Matthew Heiner's ""Bayesian Statistics: Techniques and Models."" To succeed in the course, you should have some knowledge of and comfort with calculus-based probability, principles of maximum-likelihood estimation, and Bayesian estimation.",6763.0,9122.0,4.6,37.0
Bayesian Statistics: Techniques and Models,https://www.coursera.org/learn/mcmc-bayesian-statistics,Data Science,Probability and Statistics,Matthew Heiner,"This is the second of a two-course sequence introducing the fundamentals of Bayesian statistics. It builds on the course Bayesian Statistics: From Concept to Data Analysis, which introduces Bayesian methods through use of simple conjugate models. Real-world data often require more sophisticated models to reach realistic conclusions. This course aims to expand our “Bayesian toolbox” with more general models, and computational techniques to fit them. In particular, we will introduce Markov chain Monte Carlo (MCMC) methods, which allow sampling from posterior distributions that have no analytical solution. We will use the open-source, freely available software R (some experience is assumed, e.g., completing the previous course in R) and JAGS (no experience required). We will learn how to construct, fit, assess, and compare Bayesian statistical models to answer scientific questions involving continuous, binary, and count data. This course combines lecture videos, computer demonstrations, readings, exercises, and discussion boards to create an active learning experience. The lectures provide some of the basic mathematical development, explanations of the statistical modeling process, and a few basic modeling techniques commonly used by statisticians. Computer demonstrations provide concrete, practical walkthroughs. Completion of this course will give you access to a wide range of Bayesian analytical tools, customizable to your data.",50194.0,30314.0,4.8,449.0
Bayesian Statistics: Time Series Analysis,https://www.coursera.org/learn/bayesian-statistics-time-series-analysis,Data Science,Probability and Statistics,Raquel Prado,"This course for practicing and aspiring data scientists and statisticians. It is the fourth of a four-course sequence introducing the fundamentals of Bayesian statistics. It builds on the course Bayesian Statistics: From Concept to Data Analysis, Techniques and Models, and Mixture models. 

Time series analysis is concerned with modeling the dependency among elements of a sequence of temporally related variables. To succeed in this course, you should be familiar with calculus-based probability, the principles of maximum likelihood estimation, and Bayesian inference. You will learn how to build models that can describe temporal dependencies and how to perform Bayesian inference and forecasting for the models. You will apply what you've learned with the open-source, freely available software R with sample databases. Your instructor Raquel Prado will take you from basic concepts for modeling temporally dependent data to implementation of specific classes of models",1716.0,11257.0,,
Berbagi Data Melalui Seni Visualisasi,https://www.coursera.org/learn/berbagi-data-melalui-seni-visualisasi,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi keenam dalam program Google Data Analytics Certificate (Sertifikat Analitik Data Google). Materi ini akan membekali Anda dengan keterampilan yang Anda butuhkan untuk melamar pekerjaan analis data tingkat pemula. Anda akan belajar bagaimana memvisualisasikan dan menyajikan temuan data saat Anda menyelesaikan proses analisis data. Materi ini akan menunjukkan kepada Anda bagaimana visualisasi data, seperti dasbor visual, dapat membuat data Anda lebih hidup. Anda juga akan mengeksplorasi Tableau, platform visualisasi data yang akan membantu membuat visualisasi yang efektif untuk presentasi Anda. Para analis data Google akan mengajarkan dan memberi tahu Anda berbagai cara untuk menyelesaikan tugas umum analis data dengan menggunakan peralatan dan sumber daya terbaik.

Pembelajar yang menyelesaikan program sertifikasi ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak membutuhkan pengalaman apa pun.

Di akhir materi ini, Anda akan:
 - Mengkaji pentingnya visualisasi data.
 - Mempelajari cara menyusun narasi yang menarik melalui cerita tentang 
   data.
 - Mendapatkan pemahaman tentang cara menggunakan Tableau untuk 
   membuat dasbor dan filter dasbor.
 - Mempelajari cara menggunakan Tableau untuk membuat visualisasi 
    yang efektif. 
 - Mengeksplorasi prinsip dan praktik terkait presentasi yang efektif.
 - Mempelajari cara mempertimbangkan keterbatasan yang mungkin 
   terkait dengan data dalam presentasi Anda.
 - Memahami cara menerapkan praktik terbaik ketika melakukan Tanya 
   Jawab dengan audiens Anda.",2532.0,412850.0,4.9,79.0
Big Data - Capstone Project,https://www.coursera.org/learn/big-data-project,Data Science,Data Analysis,"Ilkay Altintas, Amarnath Gupta","Welcome to the Capstone Project for Big Data! In this culminating project, you will build a big data ecosystem using tools and methods form the earlier courses in this specialization. You will analyze a data set simulating big data generated from a large number of users who are playing our imaginary game ""Catch the Pink Flamingo"". During the five week Capstone Project, you will walk through the typical big data science steps for acquiring, exploring, preparing, analyzing, and reporting. In the first two weeks, we will introduce you to the data set and guide you through some exploratory analysis using tools such as Splunk and Open Office. Then we will move into more challenging big data problems requiring the more advanced tools you have learned including KNIME, Spark's MLLib and Gephi. Finally, during the fifth and final week, we will show you how to bring it all together to create engaging and compelling reports and slide presentations. As a result of our collaboration with Splunk, a software company focus on analyzing machine-generated big data, learners with the top projects will be eligible to present to Splunk and meet Splunk recruiters and engineering leadership.",14467.0,8293.0,4.4,389.0
Big Data Integration and Processing,https://www.coursera.org/learn/big-data-integration-processing,Data Science,Data Analysis,"Ilkay Altintas, Amarnath Gupta","At the end of the course, you will be able to:

*Retrieve data from example database and big data management systems 
*Describe the connections between data management operations and the big data processing patterns needed to utilize them in large-scale analytical applications
*Identify when a big data problem needs data integration
*Execute simple big data integration and processing on Hadoop and Spark platforms

This course is for those new to data science.  Completion of Intro to Big Data is recommended.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  Refer to the specialization technical requirements for complete hardware and software specifications.

Hardware Requirements: 
(A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size. 

Software Requirements: 
This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge (except for data charges from your internet provider). Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.",68834.0,34974.0,4.4,2359.0
Big Data Modeling and Management Systems,https://www.coursera.org/learn/big-data-management,Data Science,Data Analysis,"Ilkay Altintas, Amarnath Gupta","Once you’ve identified a big data issue to analyze, how do you collect, store and organize your data using Big Data solutions?  In this course, you will experience various data genres and management tools appropriate for each.  You will be able to describe the reasons behind the evolving plethora of new big data platforms from the perspective of big data management systems and analytical tools.  Through guided hands-on tutorials, you will become familiar with techniques using real-time and semi-structured data examples.  Systems and tools discussed include: AsterixDB, HP Vertica, Impala, Neo4j, Redis, SparkSQL. This course provides techniques to extract value from existing untapped data sources and discovering new data sources.

At the end of this course, you will be able to:
 * Recognize different data elements in your own work and in everyday life problems
 * Explain why your team needs to design a Big Data Infrastructure Plan and Information System Design
 * Identify the frequent data operations required for various types of data
 * Select a data model to suit the characteristics of your data 
 * Apply techniques to handle streaming data
 * Differentiate between a traditional Database Management System and a Big Data Management System
 * Appreciate why there are so many data management systems
 * Design a big data information system for an online game company

This course is for those new to data science.  Completion of Intro to Big Data is recommended.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  Refer to the specialization technical requirements for complete hardware and software specifications.

Hardware Requirements: 
(A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size. 

Software Requirements: 
This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge (except for data charges from your internet provider). Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.",88986.0,51612.0,4.4,2946.0
"Big Data, Artificial Intelligence, and Ethics",https://www.coursera.org/learn/big-data-ai-ethics,Data Science,Data Analysis,Martin Hilbert,"This course gives you context and first-hand experience with the two major catalyzers of the computational science revolution: big data and artificial intelligence. With more than 99% of all mediated information in digital format and with 98% of the world population using digital technology, humanity produces an impressive digital footprint. In theory, this provides unprecedented opportunities to understand and shape society. In practice, the only way this information deluge can be processed is through using the same digital technologies that produced it. Data is the fuel, but machine learning it the motor to extract remarkable new knowledge from vasts amounts of data. Since an important part of this data is about ourselves, using algorithms in order to learn more about ourselves naturally leads to ethical questions. Therefore, we cannot finish this course without also talking about research ethics and about some of the old and new lines computational social scientists have to keep in mind. As hands-on labs, you will use IBM Watson’s artificial intelligence to extract the personality of people from their digital text traces, and you will experience the power and limitations of machine learning by teaching two teachable machines from Google yourself.",21708.0,27456.0,4.6,393.0
Big Data: adquisición y almacenamiento de datos,https://www.coursera.org/learn/adquisicion-almacenamiento-de-datos,Data Science,Data Analysis,"Antonio Espinosa, Tomás Margalef, Andrés Cencerrado","¿Estás interesado en tener un conocimiento más detallado sobre las herramientas y aplicaciones Big Data?

En este curso aprenderás los principios para comprender la terminología, conceptos básicos y herramientas más importantes para resolver problemas de análisis de datos enfocándonos en los problemas y las aplicaciones. El objetivo es proporcionar una visión de sistema para entender los retos más importantes que nos encontramos cuando trabajamos en entornos con grandes volúmenes de datos.

En el curso se plantea una introducción a diversas herramientas utilizadas de forma común en la comunidad como Hadoop, Spark o Hive y tendrás que resolver diferentes retos de análisis de datos mediante su uso.

Al terminar el curso habrás adquirido conocimientos sobre el ecosistema de herramientas Big Data incluyendo ejemplos de uso con problemas industriales y científicos. Tendrás una serie de recursos sobre cómo un análisis a realizar se traduce en  una serie de operaciones de recolección de datos, monitorización, almacenamiento, análisis y creación de informes sobre los resultados obtenidos. También adquirirás un criterio para elegir cuál es la herramienta más adecuada para resolver un cierto problema de análisis de datos a partir de los requerimientos de uso de las herramientas. 

El curso está orientado tanto a estudiantes universitarios de primeros cursos de estudios universitarios relacionados con la informática, la ingeniería o las matemáticas, como a otros estudiantes con conocimientos de programación, interesados en aprender cómo utilizar de análisis de datos con herramientas de código abierto.  Para realizar los ejercicios es necesario utilizar una máquina virtual que deberá ser instalada en tu ordenador.",16324.0,12406.0,4.4,614.0
Big Data: capstone project,https://www.coursera.org/learn/big-data-proyecto,Data Science,Data Analysis,"Francesc Torradeflot, Nadia Tonello, Pau Tallada, Jorge Carretero","En este último curso de la Especialización Big Data el estudiante tendrá la oportunidad de aplicar algunas de las herramientas y métodos aprendidos en los cursos anteriores en un caso práctico.

El objetivo de este Capstone Project es mostrar un ejemplo del trabajo que se realiza diariamente en el departamento de Cosmología del Port d’Informació Científica, en Barcelona. Se trata de crear un clasificador para imágenes de galaxias, a partir de datos del proyecto GalaxyZoo e imágenes y datos del telescopio Sloan Digital Sky Survey. Los trabajos y ejercicios guiados llevarán al estudiante a la exploración y analisis de estos datos, hasta realizar una herramienta automática de Machine Learning.

El proceso seguido por los estudiantes en este curso se podría aplicar en cualquier otra disciplina, por ejemplo en las ciencias sociales, en un estudio de mercado o en cualquier ámbito que comporte toma de decisiones a partir de un gran volumen de datos.",4354.0,3394.0,4.7,53.0
Big Data: el impacto de los datos masivos en la sociedad actual,https://www.coursera.org/learn/impacto-datos-masivos,Data Science,Data Analysis,"Santiago González, Carme Artigas Brugal, Antonio Pita","La digitalización, la informática e Internet han producido lo que se puede denominar una revolución en la acumulación y utilización de datos. Podemos almacenar y conservar más datos que nunca antes en la historia. Podemos estudiarlos y analizarlos para tomar decisiones y mejorar procesos. Esta nueva capacidad tiene un enorme impacto en todos los ámbitos de la vida social.

A lo largo de este curso:

•	Conoceremos qué es el Big Data y cuáles son sus características fundamentales
•	Exploraremos el crecimiento continuo de datos, analizaremos el impacto potencial en muchos campos de la actividad humana y nos preguntaremos por los retos y desafíos que suponen en todos los órdenes de la vida social. 
•	Conoceremos las características de cada una de las fases del procesamiento Big Data, adquiriendo un lenguaje adecuado para la descripción de los procesos. Dispondremos así de una visión de conjunto sobre sistema de tratamiento de grandes datos en la actualidad.
•	Conoceremos las principales áreas de aplicación de los datos masivos. Qué tipos de transformaciones están imponiendo en la organización del trabajo y en la gestión. Qué desafíos imponen en la gobernanza, la economía y el trabajo. Qué mejoras introducen y qué riesgos representan.
•	Estudiaremos las principales tecnologías e infraestructuras para el almacenamiento y procesado de grandes volúmenes de datos.",34713.0,21055.0,4.7,2092.0
Big Data: procesamiento y análisis,https://www.coursera.org/learn/big-data-procesamiento-analisis,Data Science,Data Analysis,"Llorenç Badiella, Isabel Serra","El presente curso tiene como objetivo presentar los métodos y técnicas básicos para el procesamiento y análisis de datos en el contexto de Big Data. No prentende ser un curso exhaustivo sobre Machine Learning ni sobre métodos Estadísticos, simplemente se pretenden mostrar las características principales de estas técnicas para que el alumno pueda tener una visión general de las opciones que ofrece el análisis de datos para poder explorar, confirmar indicios y en definitiva, extraer conclusiones.

El curso está dirigido a estudiantes y profesionales que deseen aproximarse al procesamiento y análisis de datos en Big Data. Aunque no es un requisito indispensable tener experiencia en análisis de datos o en entornos Big Data, el curso puede resultar especialmente interesante  a estudiantes con ciertos conocimientos de análisis de datos que deseen introducirse en el entorno Big Data, por otro lado, también resultará interesante a aquellos estudiantes con cierta experiencia en entornos Big Data que deseen adquirir una mayor visión analítica. 

En este sentido el curso pretende ofrecer recursos realistas en el contexto Big Data y por este motivo se trabajará des de una máquina virtual con la aplicación Jupyter como enlace para desarrollar los modelos y técnicas con PySpark.

El curso está dividido en 4 módulos más o menos independientes aunque se recomienda realizarlos de forma secuencial. 

En el Módulo 1 se presentan los diferentes problemas y técnicas más habitules para analizar datos desde una perspectiva general. También se introduce el caso de estudio y las herramientas de trabajo que se emplearán. El resto de módulo está dedicado a la tarea de Exploración y Pre-Proceso de los datos, incluyendo consultas, tareas de gestión, resúmenes numéricos y gráficos. Los siguientes módulos se focalizan en las técnicas de análisis.

El Módulo 2 se centra en técnicas de modelización básicas, en particular regresión y regresión logística. Además de repasar las etapas de calibración del modelo, también se incluyen las etapas de validación y simplificación.

El módulo 3 está plenamente dedicado a la técnica de Árboles de Regresión y Clasificación. También se incluyen los bosques aleatorios.  

El módulo final contiene la técnica de Redes Neuronales para clasificación y también una introducción a las técnicas No Supervisadas, en particular, reducción de dimensión a través del análisis de componentes principales y la clasificación automática a través del análisis de clústers.",13655.0,16742.0,4.2,238.0
Big Data: visualización de datos,https://www.coursera.org/learn/big-data-visualizacion-datos,Data Science,Data Analysis,"Quelic Berga Carreras, Julià Minguillón Alfonso, Teresa Sancho Vinuesa, Josep Curto Díaz, Ignasi Alcalde","“Visualización de datos” es el cuarto curso de la especialización “Biga Data- Uso práctico de datos masivos. Organizado en cuatro semanas, tiene por objetivo motivar e introducir los conceptos clave de la visualización de datos así como mostrar ejemplos en diferentes contextos. Además, se proporcionan criterios para formular el problema y elegir las herramientas más adecuadas para obtener una correcta visualización. Este debe ser un curso introductorio, motivador e inspirador para la narración de historias a través de la visualización de sus datos.

Los cuatro módulos en los que se estructura el curso son los siguientes:
MÓDULO 1: Contexto para la visualización de datos hoy
MÓDULO 2: Herramientas de análisis y visualización de datos
MÓDULO 3: El proceso de creación de una visualización de datos
MÓDULO 4: Otros aspectos de la visualización de datos",11041.0,7622.0,4.6,158.0
BigQuery Machine Learning using Soccer Data,https://www.coursera.org/learn/googlecloud-bigquery-machine-learning-using-soccer-data-5olso,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
BigQuery Soccer Data Analysis,https://www.coursera.org/learn/googlecloud-bigquery-soccer-data-analysis-ai3rr,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
BigQuery Soccer Data Analytical Insight,https://www.coursera.org/learn/googlecloud-bigquery-soccer-data-analytical-insight-yrrml,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
BigQuery Soccer Data Ingestion,https://www.coursera.org/learn/googlecloud-bigquery-soccer-data-ingestion-i4kw4,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Bike Rental Sharing Demand Prediction with Machine Learning,https://www.coursera.org/learn/bike-rental-sharing-demand-prediction-with-machine-learning,Data Science,Machine Learning,Ryan Ahmed,"In this 1-hour long project-based course, you will learn how to predict bike sharing demand with machine learning. Bike sharing services enable people to rent a bike from one location and drop it off at another location on an as-needed basis. The objective of this guided project is to predict bike sharing rental usage based on inputs such as temperature, season, humidity, wind speed. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Bildklassifizierung mit Tensorflow,https://www.coursera.org/learn/bildklassifizierung-mit-tensorflow,Data Science,Machine Learning,Jousef Murad,Bildklassifizierung mit Tensorflow,,,,
Bioconductor for Genomic Data Science,https://www.coursera.org/learn/bioconductor,Data Science,Data Analysis,"Kasper Daniel Hansen, PhD",Learn to use tools from the Bioconductor project to perform analysis of genomic data. This is the fifth course in the Genomic Big Data Specialization from Johns Hopkins University.,19703.0,11511.0,3.9,333.0
Bitcoin Price Prediction using Facebook Prophet,https://www.coursera.org/learn/bitcoin-price-prediction-using-facebook-prophet,Data Science,Machine Learning,Abhishek Jha,"In this 1.5-hour long project-based course, you will learn how to create a Facebook Prophet Machine learning Model and use it to Forecast the Price of Bitcoin for the future 30 days. 

We will begin by importing all the necessary libraries including Facebook Prophet. Then we will import our dataset and analyze it. Then we will start creating visualizations in Plotly express in order to understand the historical performance of Bitcoin. We will then prepare our data for Facebook Prophet and create a Facebook Prophet Machine learning Model. We will then fit our prepared data to the Facebook Prophet Model and command it to make a Forecast for the future 30 days. We will then Visualize the Forecast using the Prophet’s internal visualization tools and then download the Forecast data.

In the final section, we will go to Google Sheets and learn to extract Financial data of Bitcoin using Google Finance. We will then import the Forecast data into Google Sheets and compare it against the actual data and evaluate the performance of the Model.

Please note that although this project deals with Bitcoin and teaches to make Price predictions, it is for educational purposes only and should not be taken for a piece of Financial advice since Cryptocurrencies like Bitcoin are extremely volatile and speculative.
 
Basic knowledge of Python programming language is recommended but even those with no prior programming experience will be able to complete this project. You will need a Google account to complete this project.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,50.0
Bracketology with Google Machine Learning,https://www.coursera.org/learn/googlecloud-bracketology-with-google-machine-learning-5ytsd,Data Science,Machine Learning,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Breast Cancer Prediction Using Machine Learning,https://www.coursera.org/learn/breast-cancer-prediction-using-machine-learning,Data Science,Machine Learning,Priya Jha,"In this 2 hours long project-based course, you will learn to build a Logistic regression model using Scikit-learn to classify breast cancer as either Malignant or Benign. We will use the Breast Cancer Wisconsin (Diagnostic) Data Set from Kaggle. Our goal is to use a simple logistic regression classifier for cancer classification. We will be carrying out the entire project on the Google Colab environment. You will need a free Gmail account to complete this project. Please be aware of the fact that the dataset and the model in this project, can not be used in real-life. We are only using this data for educational purposes.

By the end of this project, you will be able to build the logistic regression classifier to classify between cancerous and noncancerous patients. You will also be able to set up and work with the Google colab environment. Additionally, you will also be able to clean and prepare data for analysis.

You should be familiar with the Python Programming language and you should have a theoretical understanding of the Logistic Regression algorithm. You will need a free Gmail account to complete this project.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,21.0
Build Basic Generative Adversarial Networks (GANs),https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans,Data Science,Machine Learning,"Sharon Zhou, Eda Zhou, Eric Zelikman","In this course, you will:

- Learn about GANs and their applications
- Understand the intuition behind the fundamental components of GANs
- Explore and implement multiple GAN architectures
- Build conditional GANs capable of generating examples from determined categories

The DeepLearning.AI Generative Adversarial Networks (GANs) Specialization provides an exciting introduction to image generation with GANs, charting a path from foundational concepts to advanced techniques through an easy-to-understand approach. It also covers social implications, including bias in ML and the ways to detect it, privacy preservation, and more.

Build a comprehensive knowledge base and gain hands-on experience in GANs. Train your own model using PyTorch, use it to create images, and evaluate a variety of advanced GANs. 

This Specialization provides an accessible pathway for all levels of learners looking to break into the GANs space or apply GANs to their own projects, even without prior familiarity with advanced math and machine learning research.",44904.0,69524.0,4.7,1612.0
Build Better Generative Adversarial Networks (GANs),https://www.coursera.org/learn/build-better-generative-adversarial-networks-gans,Data Science,Machine Learning,"Sharon Zhou, Eda Zhou, Eric Zelikman","In this course, you will:

- Assess the challenges of evaluating GANs and compare different generative models
- Use the Fréchet Inception Distance (FID) method to evaluate the fidelity and diversity of GANs
- Identify sources of bias and the ways to detect it in GANs
- Learn and implement the techniques associated with the state-of-the-art StyleGANs

The DeepLearning.AI Generative Adversarial Networks (GANs) Specialization provides an exciting introduction to image generation with GANs, charting a path from foundational concepts to advanced techniques through an easy-to-understand approach. It also covers social implications, including bias in ML and the ways to detect it, privacy preservation, and more.

Build a comprehensive knowledge base and gain hands-on experience in GANs. Train your own model using PyTorch, use it to create images, and evaluate a variety of advanced GANs. 

This Specialization provides an accessible pathway for all levels of learners looking to break into the GANs space or apply GANs to their own projects, even without prior familiarity with advanced math and machine learning research.",19460.0,27852.0,4.6,562.0
Build Dashboards in Power BI,https://www.coursera.org/learn/build-dashboards-power-bi,Data Science,Data Analysis,Wendy S Barker,"In this project, you will create a Dashboard in Power BI. You will get data to bring into a model, build several reports, generate informative charts from each report, then choose powerful visuals to highlight on a Dashboard. Your new skills will help you efficiently summarize important information on a one-page dashboard with visual data.",5621.0,,4.3,83.0
Build Data Analysis and Transformation Skills in R using DPLYR,https://www.coursera.org/learn/dplyr,Data Science,Data Analysis,Chris Shockley,"Congratulations you've made it to Part 2 of the DPLYR series!  In a moment you will be taken to Rhyme where a Virtual Machine with R, R Studio and DPLYR awaits. Once there you will begin the Project where you will be introduced to the Rhyme Interface and subsequently learn how to use the DPLYR verbs in a more advanced way by building on the foundation learned in the previous course.  Come in,  get experience using R and learn new ways to use the dplyr functions.

By the end of this course, you will be able to:
To practice the basic dplyr functions and how they are used
To learn advanced features of the dplyr verb 'mutate'
To implement the verb mutate over a data set in place of a 'for loop'
To continue thinking in dplyr verb phrases (ex. filter, aggregate, and transform data)",3210.0,,4.7,87.0
Build Data Analysis tools using R and DPLYR,https://www.coursera.org/learn/introduction-to-dplyr,Data Science,Data Analysis,Chris Shockley,"In this 2-hour long project-based course, you will learn one of the most powerful data analysis tools of the experts: the DPLYR package.  By learning the six main verbs of the package (filter, select, group by, summarize, mutate, and arrange), you will have the knowledge and tools to complete your next data analysis project or data transformation.  
 
By the end of this project, you will be able to:
Use the six main dplyr verbs
Understand the dplyr package and its capabilities 
Get hands-on practice using R and dplyr functions 
 
This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, this means instant access to a cloud desktop with R and the appropriate packages installed.  
 
Notes:
- You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7405.0,,4.6,286.0
"Build Decision Trees, SVMs, and Artificial Neural Networks",https://www.coursera.org/learn/build-decision-trees-svms-neural-networks,Data Science,Machine Learning,Stacey McBrine,"There are numerous types of machine learning algorithms, each of which has certain characteristics that might make it more or less suitable for solving a particular problem. Decision trees and support-vector machines (SVMs) are two examples of algorithms that can both solve regression and classification problems, but which have different applications. Likewise, a more advanced approach to machine learning, called deep learning, uses artificial neural networks (ANNs) to solve these types of problems and more. Adding all of these algorithms to your skillset is crucial for selecting the best tool for the job.

This fourth and final course within the Certified Artificial Intelligence Practitioner (CAIP) professional certificate continues on from the previous course by introducing more, and in some cases, more advanced algorithms used in both machine learning and deep learning. As before, you'll build multiple models that can solve business problems, and you'll do so within a workflow.

Ultimately, this course concludes the technical exploration of the various machine learning algorithms and how they can be used to build problem-solving models.",1618.0,3285.0,,
Build Image Quality Inspection using AWS Lookout for Vision,https://www.coursera.org/learn/build-automated-image-quality-inspection-using-amazon-lookout-for-vision,Data Science,Machine Learning,Ranjan Relan,"In this guided project, you will learn how to build automated image quality inspection using Amazon Lookout for Vision.  Amazon Lookout for Vision is a Machine Learning as a Service from Amazon Web services which you could leverage to do Image Analytics and address interesting use cases such as drone detection, defect detection, object detection, smile detection, fall detection without writing a single line of code. 

Please note:  As part of this course, you would need your AWS Account to complete the course.  It would be charged as per your usage of AWS Lookout for Vision service.",,,4.7,17.0
Build Multilayer Perceptron Models with Keras,https://www.coursera.org/learn/multilayer-perceptron-model-keras,Data Science,Machine Learning,Snehan Kekre,"In this 45-minute long project-based course, you will build and train a multilayer perceptronl (MLP) model using Keras, with Tensorflow as its backend. We will be working with the Reuters dataset, a set of short newswires and their topics, published by Reuters in 1986. It's a very simple, widely used toy dataset for text classification. There are 46 different topics, some of which are more represented than others. But each topic has at least 10 examples in the training set. So in this project, you will build a MLP feed-forward neural network to classify Reuters newswires into 46 different mutually-exclusive topics.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Keras pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3709.0,,4.5,99.0
Build Random Forests in R with Azure ML Studio,https://www.coursera.org/learn/azure-machine-learning-studio-random-forests,Data Science,Machine Learning,Snehan Kekre,"In this project-based course you will learn to perform feature engineering and create custom R models on Azure ML Studio, all without writing a single line of code! You will build a Random Forests model in Azure ML Studio using the R programming language. The data to be used in this course is the Bike Sharing Dataset. The dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information. Using the information from the dataset, you can build a model to predict the number of bikes rented during certain weather conditions. You will leverage the Execute R Script and Create R Model modules to run R scripts from the Azure ML Studio experiment perform feature engineering.

This is the fourth course in this series on building machine learning applications using Azure Machine Learning Studio. I highly encourage you to take the first course before proceeding. It has instructions on how to set up your Azure ML account with $200 worth of free credit to get started with running your experiments! 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",5039.0,,4.8,63.0
"Build Regression, Classification, and Clustering Models",https://www.coursera.org/learn/build-regression-classification-clustering-models,Data Science,Machine Learning,Anastas Stoyanovsky,"In most cases, the ultimate goal of a machine learning project is to produce a model. Models make decisions, predictions—anything that can help the business understand itself, its customers, and its environment better than a human could. Models are constructed using algorithms, and in the world of machine learning, there are many different algorithms to choose from. You need to know how to select the best algorithm for a given job, and how to use that algorithm to produce a working model that provides value to the business.

This third course within the Certified Artificial Intelligence Practitioner (CAIP) professional certificate introduces you to some of the major machine learning algorithms that are used to solve the two most common supervised problems: regression and classification, and one of the most common unsupervised problems: clustering. You'll build multiple models to address each of these problems using the machine learning workflow you learned about in the previous course.

Ultimately, this course begins a technical exploration of the various machine learning algorithms and how they can be used to build problem-solving models.",,3140.0,,
Build a Classification Model using PyCaret,https://www.coursera.org/learn/build-classification-model-using-pycaret,Data Science,Machine Learning,Mohamed Jendoubi,"In this 1-hour long project-based course, you will create an end-to-end classification model using PyCaret a low-code Python open-source Machine Learning library.
The goal is to build a model that can accurately predict whether a teacher's project proposal was accepted, based on the data they provided in their application.
You will learn how to automate the major steps for building, evaluating, comparing and interpreting Machine Learning Models for classification. 
Here are the main steps you will go through: frame the problem, get and prepare the data, discover and visualize the data, create the transformation pipeline, build, evaluate, interpret and deploy the model.
This guided project is for seasoned Data Scientists who want to build a accelerate the efficiency in building POC and experiments by using a low-code library. It is also for Citizen data Scientists (professionals working with data) by using the low-code library PyCaret to add machine learning models to the analytics toolkit
In order to be successful in this project, you should be familiar with Python and the basic concepts on Machine Learning


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Build a Clustering Model using PyCaret,https://www.coursera.org/learn/build-clustering-model-using-pycaret,Data Science,Machine Learning,Mohamed Jendoubi,"In this 1-hour long project-based course, you will create an end-to-end clustering model using PyCaret a low-code Python open-source Machine Learning library.
The goal is to build a model that can segment a wholesale customers based on their historical purchases.
You will learn how to automate the major steps for building, evaluating, comparing and interpreting Machine Learning Models for clustering. 
Here are the main steps you will go through: frame the problem, get and prepare the data, discover and visualize the data, create the transformation pipeline, build, evaluate, interpret and deploy the model.
This guided project is for seasoned Data Scientists who want to build a accelerate the efficiency in building POC and experiments by using a low-code library. It is also for Citizen data Scientists (professionals working with data) by using the low-code library PyCaret to add machine learning models to the analytics toolkit.
To be successful in this project, you should be familiar with Python and the basic concepts on Machine Learning.",,,,
Build a Data Science Web App with Streamlit and Python,https://www.coursera.org/learn/data-science-streamlit-python,Data Science,Machine Learning,Snehan Kekre,"Welcome to this hands-on project on building your first data science web app with the Streamlit library in Python. By the end of this project, you are going to be comfortable with using Python and Streamlit to build beautiful and interactive web apps with zero web development experience! We are going to load, explore, visualize and interact with data, and generate dashboards in less than 100 lines of Python code!

Prior experience with writing simple Python scripts and using pandas for data manipulation is recommended.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",19307.0,,4.6,683.0
Build a Deep Learning Based Image Classifier with R,https://www.coursera.org/learn/deep-learning-image-classifier-r,Data Science,Machine Learning,Snehan Kekre,"In this 45-min guided project, you will learn the basics of using the Keras interface to R with Tensorflow as its backend to solve an image classification problem. By the time you complete this project, you will have used the R programming language to build, train, and evaluate a neural network model to classify images of clothing items into categories such as t-shirts, trousers, and sneakers. We will be training the deep learning based image classification model on the Fashion MNIST dataset which contains 70000 grayscale images of clothes across 10 categories. 

In order to be successful in this project, you should be familiar with R programming, and basics of neural networks. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6936.0,,4.6,175.0
Build a Machine Learning Image Classifier with Python,https://www.coursera.org/learn/build-machine-learning-image-classifier-with-python,Data Science,Machine Learning,Ikechukwu Nigel Ogbuchi,"In this 1-hour long project-based course, you will learn how to build your own Machine Learning Image Classifier using Python and Colab. You will be able to easily load the data, preview it, process and normalize it, then train and test your model! I hope you enjoy the experience!

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Build a Machine Learning Web App with Streamlit and Python,https://www.coursera.org/learn/machine-learning-streamlit-python,Data Science,Machine Learning,Snehan Kekre,"Welcome to this hands-on project on building your first machine learning web app with the Streamlit library in Python. By the end of this project, you are going to be comfortable with using Python and Streamlit to build beautiful and interactive ML web apps with zero web development experience! We are going to load, explore, visualize and interact with data, and generate dashboards in less than 100 lines of Python code! Our web application will allows users to choose what classification algorithm they want to use and let them interactively set hyper-parameter values, all without them knowing to code!

Prior experience with writing simple Python scripts and using pandas for data manipulation is recommended. It is required that you have an understanding of Logistic Regression, Support Vector Machines, and Random Forest Classifiers and how to use them in scikit-learn.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",10443.0,,4.7,364.0
Build a Regression Model using PyCaret,https://www.coursera.org/learn/build-a-regression-model-using-pycaret,Data Science,Machine Learning,Mohamed Jendoubi,"In this 1-hour long project-based course, you will create an end-to-end Regression model using PyCaret a low-code Python open-source Machine Learning library.
The goal is to build a model that can accurately predict the strength of concrete based on several fatures.
You will learn how to automate the major steps for building, evaluating, comparing and interpreting Machine Learning Models for regression. 
Here are the main steps you will go through: frame the problem, get and prepare the data, discover and visualize the data, create the transformation pipeline, build, evaluate, interpret and deploy the model.
This guided project is for seasoned Data Scientists who want to build a accelerate the efficiency in building POC and experiments by using a low-code library. It is also for Citizen data Scientists (professionals working with data) by using the low-code library PyCaret to add machine learning models to the analytics toolkit
In order to be successful in this project, you should be familiar with Python and the basic concepts on Machine Learning


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Build an Anomaly Detection Model using PyCaret,https://www.coursera.org/learn/build-an-anomaly-detection-model-using-pycaret,Data Science,Machine Learning,Mohamed Jendoubi,Build an Anomaly Detection Model using PyCaret,,,,
Build an Income Statement Dashboard in Power BI,https://www.coursera.org/learn/build-an-income-statement-dashboard-in-power-bi,Data Science,Data Analysis,Abhishek Jha,"In this 1.5 hours long project, we will be creating an income statement dashboard filled with relevant charts and data. Power BI dashboards are an amazing way to visualize data and make them interactive.  We will begin this guided project by importing the data and transforming it in the Power Query editor. We will then visualize the Income Statement using a table, visualize total revenue, operating income and net income using cards and in the final task visualize the year on year growth using clustered column charts. This project is for anyone who is interested in Power BI and data visualization and specially for those who work in accounts and finance departments. By the end of this course, you will be confident in creating financial statement dashboards with many different kinds of visualizations.",,,,
"Build and Execute MySQL, PostgreSQL, and SQLServer to Data Catalog Connectors",https://www.coursera.org/learn/googlecloud-build-and-execute-mysql-postgresql-and-sqlserver-to-data-catal-3jdjj,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Build and Operate Machine Learning Solutions with Azure,https://www.coursera.org/learn/build-and-operate-machine-learning-solutions-with-azure,Data Science,Machine Learning, Microsoft,"Azure Machine Learning is a cloud platform for training, deploying, managing, and monitoring machine learning models. In this course, you will learn how to use the Azure Machine Learning Python SDK to create and manage enterprise-ready ML solutions.

This is the third course in a five-course program that prepares you to take the DP-100: Designing and Implementing a Data Science Solution on Azurecertification exam.

The certification exam is an opportunity to prove knowledge and expertise operate machine learning solutions at a cloud-scale using Azure Machine Learning. This specialization teaches you to leverage your existing knowledge of Python and machine learning to manage data ingestion and preparation, model training and deployment, and machine learning solution monitoring in Microsoft Azure. Each course teaches you the concepts and skills that are measured by the exam. 

This Specialization is intended for data scientists with existing knowledge of Python and machine learning frameworks like Scikit-Learn, PyTorch, and Tensorflow, who want to build and operate machine learning solutions in the cloud. It teaches data scientists how to create end-to-end solutions in Microsoft Azure. Students will learn how to manage Azure resources for machine learning; run experiments and train models; deploy and operationalize machine learning solutions, and implement responsible machine learning. They will also learn to use Azure Databricks to explore, prepare, and model data; and integrate Databricks machine learning processes with Azure Machine Learning.",2125.0,30049.0,4.6,13.0
Build your first Machine Learning Pipeline using Dataiku,https://www.coursera.org/learn/build-your-first-machine-learning-pipeline-using-dataiku-tool,Data Science,Machine Learning,Ranjan Relan,"As part of this guided project, you shall build your first Machine Learning Pipeline using DataIku tool without writing a single line of code. You shall build a prediction model which inputs COVID daily count data across the world and predict COVID fatalities.DataIku tool is a low code no code platform which is gaining traction with citizen data scientist to quickly build and deploy their models.",2022.0,,4.6,37.0
Build your first Search Engine using AWS Kendra,https://www.coursera.org/learn/build-your-first-search-engine-using-aws-kendra,Data Science,Machine Learning,Ranjan Relan,"This project is focused on building your first search engine using Amazon Kendra without writing a single line of code. By the end of this guided project, you will be able to build your first enterprise search engine by leveraging Amazon’s Kendra.  Search as a capability is an important feature which is required by almost all medium and large enterprises as search helps filter relevant and required information in the world of big data. Search helps find relevant information quickly and saves time to go through vast information.  Google’s first product was search engine, Amazon leverages search capability to browse the millions of products listed on its marketplace, Facebook has search capability for its users to find friends based on name, location, etc. and Microsoft also has its own bing search engine. AWS Kendra provides search as a service capability and as part of this guided project we shall study how to build a search engine.",,,4.5,19.0
"Build, Train, and Deploy ML Pipelines using BERT",https://www.coursera.org/learn/ml-pipelines-bert,Data Science,Machine Learning,"Antje Barth, Shelbee Eigenbrode, Sireesha Muppala, Chris Fregly","In the second course of the Practical Data Science Specialization, you will learn to automate a natural language processing task by building an end-to-end machine learning pipeline using Hugging Face’s highly-optimized implementation of the state-of-the-art BERT algorithm with Amazon SageMaker Pipelines. Your pipeline will first transform the dataset into BERT-readable features and store the features in the Amazon SageMaker Feature Store. It will then fine-tune a text classification model to the dataset using a Hugging Face pre-trained model, which has learned to understand the human language from millions of Wikipedia documents. Finally, your pipeline will evaluate the model’s accuracy and only deploy the model if the accuracy exceeds a given threshold.

Practical data science is geared towards handling massive datasets that do not fit in your local hardware and could originate from multiple sources. One of the biggest benefits of developing and running data science projects in the cloud is the agility and elasticity that the cloud offers to scale up and out at a minimum cost.

The Practical Data Science Specialization helps you develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ML workflow using Amazon SageMaker. This Specialization is designed for data-focused developers, scientists, and analysts familiar with the Python and SQL programming languages and want to learn how to build, train, and deploy scalable, end-to-end ML pipelines - both automated and human-in-the-loop - in the AWS cloud.",9467.0,19195.0,4.6,113.0
Building AI Applications with Watson APIs,https://www.coursera.org/learn/building-ai-applications,Data Science,Machine Learning,"Antonio Cangiano, Tanmay Bakshi","A learner will be able to write an application that leverages multiple Watson AI services (Discovery, Speech to Text, Assistant, and Text to Speech). By the end of the course, they’ll learn best practices of combining Watson services, and how they can build interactive information retrieval systems with Discovery + Assistant.",14388.0,47091.0,4.3,645.0
Building Data Visualization Tools,https://www.coursera.org/learn/r-data-visualization,Data Science,Data Analysis,"Roger D. Peng, PhD, Brooke Anderson","The data science revolution has produced reams of new data from a wide variety of new sources. These new datasets are being used to answer new questions in way never before conceived. Visualization remains one of the most powerful ways draw conclusions from data, but the influx of new data types requires the development of new visualization techniques and building blocks. This course provides you with the skills for creating those new visualization building blocks. We focus on the ggplot2 framework and describe how to use and extend the system to suit the specific needs of your organization or team. Upon completing this course, learners will be able to build the tools needed to visualize a wide variety of data types and will have the fundamentals needed to address new data types as they come about.",11910.0,,3.9,154.0
Building Deep Learning Models with TensorFlow,https://www.coursera.org/learn/building-deep-learning-models-with-tensorflow,Data Science,Machine Learning,"Samaya Madhavan, JEREMY NILMEIER, Romeo Kienzler, Alex Aklson","The majority of data in the world is unlabeled and unstructured. Shallow neural networks cannot easily capture relevant structure in, for instance, images, sound, and textual data. Deep networks are capable of discovering hidden structures within this type of data. In this course you’ll use TensorFlow library to apply deep learning to different data types in order to solve real world problems.

Learning Outcomes:
After completing this course, learners will be able to:
•	explain foundational TensorFlow concepts such as the main functions, operations and the execution pipelines. 
•	describe how TensorFlow can be used in curve fitting, regression, classification and minimization of error functions. 
•	understand different types of Deep Architectures, such as Convolutional Networks, Recurrent Networks and Autoencoders.
•	apply TensorFlow for backpropagation to tune the weights and biases while the Neural Networks are being trained.",16421.0,17323.0,4.4,685.0
Building Machine Learning Pipelines in PySpark MLlib,https://www.coursera.org/learn/spark-machine-learning-pipeline-python,Data Science,Machine Learning,Dr. Nikunj Maheshwari,"By the end of this project, you will learn how to create machine learning pipelines using Python and Spark, free, open-source programs that you can download. You will learn how to load your dataset in Spark and learn how to perform basic cleaning techniques such as removing columns with high missing values and removing rows with missing values. You will then create a machine learning pipeline with a random forest regression model. You will use cross validation and parameter tuning to select the best model from the pipeline. Lastly, you will evaluate your model’s performance using various metrics.

A pipeline in Spark combines multiple execution steps in the order of their execution. So rather than executing the steps individually, one can put them in a pipeline to streamline the machine learning process. You can save this pipeline, share it with your colleagues, and load it back again effortlessly.

Note: You should have a Gmail account which you will use to sign into Google Colab.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2859.0,,4.3,53.0
Building R Packages,https://www.coursera.org/learn/r-packages,Data Science,Data Analysis,"Roger D. Peng, PhD, Brooke Anderson","Writing good code for data science is only part of the job. In order to maximizing the usefulness and reusability of data science software, code must be organized and distributed in a manner that adheres to community-based standards and provides a good user experience. This course covers the primary means by which R software is organized and distributed to others. We cover R package development, writing good documentation and vignettes, writing robust software, cross-platform development, continuous integration tools, and distributing packages via CRAN and GitHub. Learners will produce R packages that satisfy the criteria for submission to CRAN.",10164.0,2591.0,4.1,218.0
Building Recommendation System Using MXNET on AWS Sagemaker,https://www.coursera.org/learn/building-recommendation-system-using-mxnet-aws-sagemaker,Data Science,Machine Learning,Mohammed Murtuza Qureshi,"Please note: You will need an AWS account to complete this course. Your AWS account will be charged as per your usage. Please make sure that you are able to access Sagemaker within your AWS account. If your AWS account is new, you may need to ask AWS support for access to certain resources. You should be familiar with python programming, and AWS before starting this hands on project. We use a Sagemaker P type instance in this project for training the model, and if you don't have access to this instance type, please contact AWS support and request access.

In this 2-hour long project-based course, you will how to train and deploy a Recommendation System using AWS Sagemaker. We will go through the detailed step by step process of training a recommendation system on the Amazon's Electronics dataset. We will be using a Notebook Instance to build our training model.  You will learn how to use Apache's MXNET Deep Learning Model on the AWS Sagemaker platform. 

Since this is a practical, project-based course, we will not dive in the theory behind recommendation systems, but will focus purely on training and deploying a model with AWS Sagemaker. You will also need to have some experience with Amazon Web Services (AWS) and knowledge of how deep learning frameworks work.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Building Resilient Streaming Systems on GCP em Português Brasileiro,https://www.coursera.org/learn/building-resilient-streaming-systems-gcp-br,Data Science,Data Analysis,Google Cloud Training,"Este curso rápido sob demanda tem uma semana de duração e é baseado no Google Cloud Platform Big Data and Machine Learning Fundamentals. Por meio de videoaulas, demonstrações e laboratórios práticos, os participantes aprenderão a criar pipelines de dados de streaming usando o Google Cloud Pub/Sub e o Dataflow para a tomada de decisões em tempo real. Você também aprenderá a criar painéis para renderizar respostas personalizadas para vários tipos de público das partes interessadas.

Pré-requisitos:
 • Noções básicas de Big Data e Machine Learning do Google Cloud Platform (ou experiência equivalente)
 • Conhecimento de Java
 
 Objetivos:
 • Entender os casos de uso para análise de streaming em tempo real
 • Usar o serviço de mensagens assíncronas do Google Cloud Pub/Sub para gerenciar eventos de dados
 • Criar pipelines de streaming e executar transformações
 • Conhecer os dois lados de um pipeline de streaming: produção e consumo
 • Interoperar o Dataflow, o BigQuery e o Cloud Pub/Sub para streaming e análise em tempo real",,,4.1,15.0
Building Similarity Based Recommendation System,https://www.coursera.org/learn/building-similarity-based-recommendation-system,Data Science,Probability and Statistics,Bhaskarjit Sarmah,"Welcome to this 1-hour project-based course on Building Similarity Based Recommendation System. In this project, you will learn how similarity based collaborative filtering recommendation systems work, how you can collect data for building such systems. You will learn what are some different ways you to compute similarity between users and recommend items based on products interacted by other similar users. You will learn to create user item interactions matrix from the original dataset and also how to recommend items to a new user who does not have any historical interactions with the items.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",1548.0,,4.3,30.0
Building Statistical Models in R: Linear Regression,https://www.coursera.org/learn/building-statistical-models-in-r-linear-regression,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Building Statistical Models in R: Linear Regression. This is a hands-on project that introduces beginners to the world of statistical modeling. In this project, you will learn the basics of building statistical models in R. We will start this hands-on project by exploring the dataset and creating visualizations for the dataset.

By the end of this 2-hour long project, you will understand how to build and interpret the result of simple linear regression models in R. Also, you will learn how to perform model assessments and check for assumptions using diagnostic plots. By extension, you will learn how to build and interpret the result of a multiple linear regression model.

Note that you do not need to be a data scientist to be successful in this guided project; just a familiarity with basic statistics and R suffice for this project. If you are not familiar with R and want to learn the basics, start with my previous guided project titled “Getting Started with R”. So, taking this project will give the needed requisite to complete this project on Building Statistical Models in R: Linear Regression. However, if you are comfortable using R, please join me on this wonderful and exciting ride! Let’s get our hands dirty!",,,,
Building a Data Science Team,https://www.coursera.org/learn/build-data-science-team,Data Science,Data Analysis,"Jeff Leek, PhD, Brian Caffo, PhD, Roger D. Peng, PhD","Data science is a team sport. As a data science executive it is your job to recruit, organize, and manage the team to success. In this one-week course, we will cover how you can find the right people to fill out your data science team, how to organize them to give them the best chance to feel empowered and successful, and how to manage your team as it grows. 

This is a focused course designed to rapidly get you up to speed on the process of building and managing a data science team. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward.

After completing this course you will know.

1. The different roles in the data science team including data scientist and data engineer
2. How the data science team relates to other teams in an organization
3. What are the expected qualifications of different data science team members
4. Relevant questions for interviewing data scientists
5. How to manage the onboarding process for the team
6. How to guide data science teams to success
7. How to encourage and empower data science teams

Commitment: 1 week of study, 4-6 hours

Course cover image by JaredZammit. Creative Commons BY-SA. https://flic.kr/p/5vuWZz",44746.0,12153.0,4.5,3241.0
Building a Fraud Detection Model with Vertex AI AutoML,https://www.coursera.org/learn/googlecloud-building-a-fraud-detection-model-with-vertex-ai-automl-a68tp,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Building a Keras Horse Zebra CycleGAN Webapp with Streamlit,https://www.coursera.org/learn/building-a-keras-horse-zebra-cyclegan-webapp-with-streamlit,Data Science,Machine Learning,Emmanuel Acheampong,"Welcome to the “Building a Keras Horse Zebra CycleGAN Webapp with Streamlit” guided project. 

In this project, we will build a Streamlit web app of a keras trained computer vision CycleGAN for horse images to zebra and vice versa. This project will take a jpg image of a horse and transform it into a zebra and take a picture of a zebra and transform it to a horse.

This project is an intermediate python project for anyone interested in learning about how to productionize computer vision models or more specifically a beginner GAN model with Streamlit and Python. 

It requires preliminary knowledge on how to build and train GAN models (as we will not be building or training models) but we will be using a model that has already been trained and provided in the workspace.",,,,
"Building a Large-Scale, Automated Forecasting System",https://www.coursera.org/learn/large-scale-forecasting-sas-viya,Data Science,Data Analysis,"George Fernandez, Jay Laramore, Marc Huber","In this course you learn to develop and maintain a large-scale forecasting project using SAS Visual Forecasting tools. Emphasis is initially on selecting appropriate methods for data creation and variable transformations, model generation, and model selection. Then you learn how to improve overall baseline forecasting performance by modifying default processes in the system.

This course is appropriate for analysts interested in augmenting their machine learning skills with analysis tools that are appropriate for assaying, modifying, modeling, forecasting, and managing data that consist of variables that are collected over time. The courses is primarily syntax based, so analysts taking this course need some familiarity with coding. Experience with an object-oriented language is helpful, as is familiarity with manipulating large tables.",,,,
Building a unique NLP project: 1984 book vs 1984 album,https://www.coursera.org/learn/1984-versus-nlp,Data Science,Machine Learning,Emmanuel Acheampong,"Welcome to the “Building a unique NLP project: 1984 book vs 1984 album” guided project.

This project is for anyone interested in exploring fun and interactive Natural Language Processing (NLP) projects. Inspired by the cultural phenomenon, Versus, in this project we’re going to be leveraging the NLP to compare 1984, the dystopian social science fiction novel by the English novelist George Orwell and 1984, the sixth studio album by American rock band Van Halen.

In this project, we’ll explore the NLP techniques of:
1. summarizing text
2. sentiment analysis
3. word clouds.

At the end of this project, learners will be able to demonstrate a beginner's understanding of building NLP projects.",,,,
Building and analyzing linear regression model in R,https://www.coursera.org/learn/build-analyze-linear-regression-model-r,Data Science,Machine Learning,Dr. Nikunj Maheshwari,"By the end of this project, you will learn how to build and analyse linear regression model in R, a free, open-source program that you can download. You will learn how to load and clean a real world dataset. Next, you will learn how to build a linear regression model and various plots to analyze the model’s performance. Lastly, you will learn how to predict future values using the model. By the end of this project, you will become confident in building a linear regression model on real world dataset and the know-how of assessing the model’s performance using R programming language.

Linear regression models are useful in identifying critical relationships between predictors (or factors) and output variable. These relationships can impact a business in the future and can help business owners to make decisions.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,33.0
Business Analytics Capstone,https://www.coursera.org/learn/wharton-capstone-analytics,Data Science,Data Analysis,Wharton Teaching Staff,"The Business Analytics Capstone Project gives you the opportunity to apply what you've learned about how to make data-driven decisions to a real business challenge faced by global technology companies like Yahoo, Google, and Facebook. At the end of this Capstone, you'll be able to ask the right questions of the data, and know how to use data effectively to address business challenges of your own. You’ll understand how cutting-edge businesses use data to optimize marketing, maximize revenue, make operations efficient, and make hiring and management decisions so that you can apply these strategies to your own company or business. Designed with Yahoo to give you invaluable experience in evaluating and creating data-driven decisions, the Business Analytics Capstone Project provides the chance for you to devise a plan of action for optimizing data itself to provide key insights and analysis, and to describe the interaction between key financial and non-financial indicators. Once you complete your analysis, you'll be better prepared to make better data-driven business decisions of your own.",10228.0,22811.0,4.5,686.0
Business Analytics for Decision Making,https://www.coursera.org/learn/business-analytics-decision-making,Data Science,Data Analysis,Manuel Laguna,"In this course you will learn how to create models for decision making. We will start with cluster analysis, a technique for data reduction that is very useful in market segmentation. You will then learn the basics of Monte Carlo simulation that will help you model the uncertainty that is prevalent in many business decisions. A key element of decision making is to identify the best course of action. Since businesses problems often have too many alternative solutions, you will learn how optimization can help you identify the best option. What is really exciting about this course is that you won’t need to know a computer language or advanced statistics to learn about these predictive and prescriptive analytic models. The Analytic Solver Platform and basic knowledge of Excel is all you’ll need. Learners participating in assignments will be able to get free access to the Analytic Solver Platform.",78380.0,17258.0,4.6,1748.0
Business Applications of Hypothesis Testing and Confidence Interval Estimation,https://www.coursera.org/learn/hypothesis-testing-confidence-intervals,Data Science,Data Analysis,Sharad Borle,"Confidence intervals and Hypothesis tests are very important tools in the Business Statistics toolbox. A mastery over these topics will help enhance your business decision making and allow you to understand and measure the extent of ‘risk’ or ‘uncertainty’ in various business processes. 

This is the third course in the specialization ""Business Statistics and Analysis"" and the course  advances your knowledge about Business Statistics by introducing you to Confidence Intervals and Hypothesis Testing. We first conceptually understand these tools and their business application. We then introduce various calculations to constructing confidence intervals and to conduct different kinds of Hypothesis Tests. These are done by easy to understand applications.

To successfully complete course assignments, students must have access to a Windows version of Microsoft Excel 2010 or later. Please note that earlier versions of Microsoft Excel (2007 and earlier) will not be compatible to some Excel functions covered in this course. 


WEEK 1
Module 1: Confidence Interval - Introduction
In this module you will get to conceptually understand what a confidence interval is and how is its constructed. We will introduce the various building blocks for the confidence interval such as the t-distribution, the t-statistic, the z-statistic and their various excel formulas. We will then use these building blocks to construct confidence intervals.

Topics covered include:
•	Introducing the t-distribution, the T.DIST and T.INV excel functions
•	Conceptual understanding of a Confidence Interval
•	The z-statistic and the t-statistic
•	Constructing a Confidence Interval using z-statistic and t-statistic 


WEEK 2
Module 2: Confidence Interval - Applications
This module presents various business applications of the confidence interval including an application where we use the confidence interval to calculate an appropriate sample size. We also introduce with an application, the confidence interval for a population proportion. Towards the close of module we start introducing the concept of Hypothesis Testing.

Topics covered include:
•	Applications of Confidence Interval
•	Confidence Interval for a Population Proportion
•	Sample Size Calculation
•	Hypothesis Testing, An Introduction


WEEK 3
Module 3: Hypothesis Testing
This module introduces Hypothesis Testing. You get to understand the logic behind hypothesis tests. The four steps for conducting a hypothesis test are introduced and you get to apply them for hypothesis tests for a population mean as well as population proportion. You will understand the difference between single tail hypothesis tests and two tail hypothesis tests and also the Type I and Type II errors associated with hypothesis tests and ways to reduce such errors. 

Topics covered include:
•	The Logic of Hypothesis Testing
•	The Four Steps for conducting a Hypothesis Test
•	Single Tail and Two Tail Hypothesis Tests
•	Guidelines, Formulas and an Application of Hypothesis Test
•	Hypothesis Test for a Population Proportion
•	Type I and Type II Errors in a Hypothesis 


WEEK 4
Module 4: Hypothesis Test - Differences in Mean
In this module, you'll apply Hypothesis Tests to test the difference between two different data, such hypothesis tests are called difference in means tests. We will introduce the three kinds of difference in means test and apply them to various business applications. We will also introduce the Excel dialog box to conduct such hypothesis tests.

Topics covered include:
•	Introducing the Difference-In-Means Hypothesis Test
•	Applications of the Difference-In-Means Hypothesis Test
•	The Equal & Unequal Variance Assumption and the Paired t-test for difference in means.
•	Some more applications",29422.0,45039.0,4.8,1246.0
"Business Intelligence Concepts, Tools, and Applications",https://www.coursera.org/learn/business-intelligence-tools,Data Science,Data Analysis,Jahangir Karimi,"This is the fourth course in the Data Warehouse for Business Intelligence specialization. Ideally, the courses should be taken in sequence. Effectively and efficiently mining data is the very center of any modern business’s competitive strategy, and a data warehouse is a core component of this data mining. The ability to quickly look back at early trends and have the accurate data – properly formatted – is essential to good decision making. By enabling this historical overview, a data warehouse allows decision makers to learn from past trends and challenges. In essence, the benefit of a data warehouse is continuous improvement. 

By the end of the course, you will be able to enhance Conformity And Quality of Data by gaining the knowledge and skills for using data warehouses for business intelligence purposes and for working as a business intelligence developer. You’ll have the opportunity to work with large data sets in a data warehouse environment and will learn the use of MicroStrategy's Online Analytical Processing (OLAP) and Visualization capabilities to create visualizations and dashboards. 

The course gives an overview of how business intelligence technologies can support decision making across any number of business sectors. These technologies have had a profound impact on corporate strategy, performance, and competitiveness and broadly encompass  decision support systems, business intelligence systems, and visual analytics. Modules are organized around the business intelligence concepts, tools, and applications, and the use of data warehouse for business reporting and online analytical processing, for creating visualizations and dashboards, and for business performance management and descriptive analytics.

This course is intended for business and computer science university students, IT professionals, program managers, business analysts and anyone with career interests in business intelligence.

In order to be successful in this course, you should have either completed Course 3 of the Data Warehousing for Business Intelligence Specialization or have some prior experience with data visualization and document management.",41913.0,14470.0,4.5,607.0
Business Intelligence con la Product Suite di Tableau,https://www.coursera.org/learn/business-intelligence-con-tableau,Data Science,Data Analysis,Manuel Belgioioso,"Questo corso è rivolto a tutti coloro che hanno maturato una conoscenza solida di Tableau. Dopo aver imparato a analizzare dati e costruire visualizzazioni è arrivato il momento di approfondire la conoscenza della Business Intelligence (BI) e andare oltre Tableau. 

La week 1 è dedicata alle Dashboard e alle Story. Una volta create le visualizzazioni di dati, imparerai come combinarle in modo interattivo all’interno di questi due ambienti.
La week 2 si occuperà della rappresentazione dell’informazione non limitata ai soli aspetti puramente grafici ma a tutte le scelte che un analista deve fare per comunicare in modo efficace i propri risultati. Per questo il modulo mescola teoria e pratica dei principi della data visualization, fondamentali per la comunicazione dei dati in ambito BI. 
Nella week 3 imparerai a costruire visualizzazioni avanzate su Tableau. Combinando creatività e una conoscenza approfondita dello strumento potrai costruire visualizzazioni originali ed efficaci.
La week 4  introduce Tableau Server e Tableau Online, estensioni che consentono di condividere le proprie analisi. 
La week 5, infine, è indirizzata all’apprendimento di Tableau Prep, il prodotto della suite dedicato alla preparazione dei dati che permette agli utenti di disegnare una data source ottimizzata sulla base delle proprie necessità analitiche.",,1639.0,,
Business Metrics for Data-Driven Companies,https://www.coursera.org/learn/analytics-business-metrics,Data Science,Data Analysis,"Daniel Egger, Jana Schaich Borg","In this course, you will learn best practices for how to use data analytics to make any company more competitive and more profitable. You will be able to recognize the most critical business metrics and distinguish them from mere data.

You’ll get a clear picture of the vital but different roles business analysts, business data analysts, and data scientists each play in various types of companies. And you’ll know exactly what skills are required to be hired for, and succeed at, these high-demand jobs.
 
Finally, you will be able to use a checklist provided in the course to score any company on how effectively it is embracing big data culture. Digital companies like Amazon, Uber and Airbnb are transforming entire industries through their creative use of big data. You’ll understand why these companies are so disruptive and how they use data-analytics techniques to out-compete traditional companies.",266041.0,53345.0,4.6,8244.0
Business Statistics and Analysis Capstone,https://www.coursera.org/learn/business-statistics-analysis-capstone,Data Science,Data Analysis,Sharad Borle,"The Business Statistics and Analysis Capstone is an opportunity to apply various skills developed across the four courses in the specialization to a real life data. The Capstone, in collaboration with an industry partner uses publicly available ‘Housing Data’ to pose various questions typically a client would pose to a data analyst.

Your job is to do the relevant statistical analysis and report your findings in response to the questions in a way that anyone can understand.
Please remember that this is a Capstone, and has a degree of difficulty/ambiguity higher than the previous four courses. The aim being to mimic a real life application as close as possible.",16172.0,9024.0,4.8,396.0
Business intelligence and data warehousing,https://www.coursera.org/learn/business-intelligence-data-warehousing,Data Science,Data Analysis,María del Pilar Ángeles,"Welcome to the specialization course Business Intelligence and Data Warehousing. This course will be completed on six weeks, it will be supported with videos and various documents that will allow you to learn in a very simple way how to identify, design and develop analytical information systems, such as Business Intelligence with a descriptive analysis on data warehouses. You will be able to understand the problem of integration and predictive analysis of high volume of unstructured data (big data) with data mining and the Hadoop framework.

After completing this course, a learner will be able to
●	Create a Star o Snowflake data model Diagram through the Multidimensional Design from analytical business requirements and OLTP system
●	Create a physical database system 
●	Extract, Transform and load data to a data-warehouse.
●	Program analytical queries with SQL using MySQL
●	Predictive analysis with RapidMiner
●	Load relational or unstructured data to Hortonworks HDFS
●	Execute Map-Reduce jobs to query data on HDFS for analytical purposes


Programming languages:
For course 2 you will use the MYSQL language.

Software to download:
Rapidminer
MYSQL
Excel
Hortonworks Hadoop framework

In case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).",11470.0,9613.0,3.9,93.0
CASL Programming for Distributed Computing in SAS® Viya®,https://www.coursera.org/learn/casl-programming-sas-viya-distributed-computing,Data Science,Data Analysis,"Peter Styliadis, Stacey Syphus","Welcome to the CASL Programming for Distributed Computing in SAS Viya course. SAS Viya is an AI, analytic and data management platform running on a scalable, distributed, cloud-native architecture. 

In this course you will learn how how to use the native CAS programming language (CASL) to leverage SAS Cloud Analytics Services (CAS), the high-performance, in-memory analytics and distributed computing engine in SAS Viya . You will learn how to use CASL to access, explore, prepare, analyze, and summarize data in the CAS server's massively parallel processing environment.

This is an advanced course, intended for learners with at least one year of programming experience with a modern language: (SAS, R, Python, SQL, and so on), and at least one year of experience working with data.  To be successful in this course,  you should have a general understanding of fundamental computer programming concepts and the data analytics lifecycle.

By the end of the course, you will be able to:
- Understand and use various SAS Viya servers.
- Connect to the CAS server to access and manage data. 
- Use CASL to explore, prepare and analyze data.
- Create reports and visualizations using SAS Viya.",,1603.0,,
COVID-19 : Les séries temporelles avec Python et Pandas,https://www.coursera.org/learn/covid-19-series-temporelles-python,Data Science,Data Analysis,ELINGUI Pascal Uriel,"Dans ce projet guidé, vous manipulerez des séries temporelles avec Python et Pandas. Une série temporelle est une suite de valeurs numériques représentant l'évolution d'une quantité spécifique au cours du temps. Les données du COVID-19 en sont un parfait exemple que nous allons explorer dans ce projet guidé.

La grande majorité des données que nous exploitons sont des séries temporelles. Savoir les manipuler efficacement est un prérequis obligatoire pour tous professionnel des données. (Data Scientist, Data Analyst, Data Engineer, Ingénieur Big Data, etc)

Vous expérimentez plusieurs techniques pour indexer, filtrer, agréger, échantillonner et afficher des séries temporelles en python",1525.0,,4.5,24.0
COVID-19 mRNA Vaccine Degradation Prediction,https://www.coursera.org/learn/covid-19-mrna-vaccine-degradation-prediction,Data Science,Machine Learning,Mohammed Murtuza Qureshi,"In this 2-hour long project-based course, you will learn how to predict mRNA Vaccine Degradation Rates at various positions of the molecule. Our model will predict likely degradation rates at each base of an RNA molecule which will be useful to develop models and design rules for RNA degradation. 

We will look at how to build a Bidirectional Gated Recurrent Units Neural Network which can predict the degradation for multiple scenarios at each of the base.
We will cover how to train the model and evaluate on a test set. We will then finally make predictions using the trained model and compare it with the original degradation rates.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.2,14.0
COVID19 Data Analysis Using Python,https://www.coursera.org/learn/covid19-data-analysis-using-python,Data Science,Data Analysis,Ahmad Varasteh,"In this project, you will learn how to preprocess and merge datasets to calculate needed measures and prepare them for an Analysis. In this project, we are going to work with the COVID19 dataset, published by John Hopkins University, which consists of the data related to the cumulative number of confirmed cases, per day, in each Country. Also, we have another dataset consist of various life factors, scored by the people living in each country around the globe.  We are going to merge these two datasets to see if there is any relationship between the spread of the virus in a country and how happy people are, living in that country.

Notes: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",29481.0,,4.5,1926.0
COVID19 Data Visualization Using Python,https://www.coursera.org/learn/covid19-data-visualization-using-python,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project, you will learn How you can use data visualization techniques to answer to some analytical questions. in this project we are going to use COVID19 dataset we have consisting of the data related cumulative number of confirmed, recovered, and deaths cases. we are going to prepare this dataset to answer these questions: How does the Global Spread of the virus look like?, How intensive the spread of the virus has been in the countries? Does covid19 national lockdowns and self-isolations in different countries have actually impact on COVID19 transmission? we are going to use Plotly module, which is a great visualization tool in python, in order to plot some insightful and intuitive graphs to answer the questions.",3716.0,,4.6,80.0
Calcul de données en SQL,https://www.coursera.org/learn/calcul-de-donnees-en-sql,Data Science,Data Analysis,Hodroj Jamal,"Dans ce projet guidé d'une heure, vous apprendrez à faire une requête SQL pour calculer les données, et aussi à les grouper et calculer les données d’un groupe des enregistrements.
À la fin de ce projet, nous aurons appris à créer et exploiter les requêtes de recherche avec les fonctions d'agrégations et les clauses GROUP BY et HAVING dans SQL.",,,,
Calculating Descriptive Statistics in R,https://www.coursera.org/learn/calculating-descriptive-statistics-in-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this 2-hour long project-based course Calculating Descriptive Statistics in R. In this project, you will learn how to perform extensive descriptive statistics on both quantitative and qualitative variables in R. You will also learn how to calculate the frequency and percentage of categorical variables and check the distribution of quantitative variables. By extension, you will learn how to perform univariate and bivariate statistics for univariate and bivariate variables in R.

Note: You do not need to be a Data Scientist to be successful in this guided project, just a familiarity with basic statistics and using R suffice for this project. If you are not familiar with R and want to learn the basics, start with my previous guided project titled “Getting Started with R”.",1748.0,,4.8,37.0
Capstone Assignment - CDSS 5,https://www.coursera.org/learn/cdss5-capstoneassignment,Data Science,Machine Learning,Fani Deligianni,This course is a capstone assignment requiring you to apply the knowledge and skill you have learnt throughout the specialization. In this course you will choose one of the areas and complete the assignment to pass.,,,,
Capstone Project: Advanced AI for Drug Discovery,https://www.coursera.org/learn/ai-for-drug-discovery,Data Science,Machine Learning,"Rajvir Dua, Neelesh Tiruviluamala","In this capstone project course, we'll compare genome sequences of COVID-19 mutations to identify potential areas a drug therapy can look to target. The first step in drug discovery involves identifying target subsequences of theirs genome to target. We'll start by comparing the genomes of virus mutations to look for similarities. Then, we'll perform PCA to cut down our number of dimensions and identify the most common features. Next, we'll use K-means clustering in Python to find the optimal number of groups and trace the lineage of the virus. Finally, we'll predict similarity between the sequences and use this to pick a target subsequence. Throughout the course, each section will consist of a programming assignment coupled with a guide video and helpful hints. By the end, you'll be well on your way to discovering ways to combat disease with genome sequencing.",,2255.0,,
Capstone Project: Predicting Safety Stock,https://www.coursera.org/learn/ml-safety-stock,Data Science,Machine Learning,"Rajvir Dua, Neelesh Tiruviluamala","In this course, we'll make predictions on product usage and calculate optimal safety stock storage. We'll start with a time series of shoe sales across multiple stores on three different continents. To begin, we'll look for unique insights and other interesting things we can find in the data by performing groupings and comparing products within each store. Then, we'll use a seasonal autoregressive integrated moving average (SARIMA) model to make predictions on future sales. In addition to making predictions, we'll analyze the provided statistics (such as p-score) to judge the viability of using the SARIMA model to make predictions. Then, we'll tune the hyper-parameters of the model to garner better results and higher statistical significance. Finally, we'll make predictions on safety stock by looking to the data for monthly usage predictions and calculating safety stock from the formula involving lead times.",,,,
Capstone: Analyzing (Social) Network Data,https://www.coursera.org/learn/intermediate-programming-capstone,Data Science,Data Analysis,"Christine Alvarado, Mia Minnes, Leo Porter","In this capstone project we’ll combine  all of the skills from all four specialization courses to do something really fun: analyze social networks!  

The opportunities for learning are practically endless in a social network.  Who are the “influential” members of the network?  What are the sub-communities in the network?   Who is connected to whom, and by how many links?   These are just some of the questions you can explore in this project.

We will provide you with a real-world data set and some infrastructure for getting started, as well as some warm up tasks and basic project requirements, but then it’ll be up to you where you want to take the project.  If you’re running short on ideas, we’ll have several suggested directions that can help get your creativity and imagination going.  Finally, to integrate the skills you acquired in course 4 (and to show off your project!) you will be asked to create a video showcase of your final product.",5907.0,3525.0,4.7,97.0
"Capstone: Retrieving, Processing, and Visualizing Data with Python",https://www.coursera.org/learn/python-data-visualization,Data Science,Data Analysis,Charles Russell Severance,"In the capstone, students will build a series of applications to retrieve, process and visualize data using Python.   The projects will involve all the elements of the specialization.  In the first part of the capstone, students will do some visualizations to become familiar with the technologies in use and then will pursue their own project to visualize some other data that they have or can find.  Chapters 15 and 16 from the book “Python for Everybody” will serve as the backbone for the capstone. This course covers Python 3.",239831.0,121063.0,4.7,12691.0
Case studies in business analytics with ACCENTURE,https://www.coursera.org/learn/case-studies-business-analytics-accenture,Data Science,Data Analysis,Nicolas Glady ,"Who is this course for ?

This course is RESTRICTED TO LEARNERS ENROLLED IN  Strategic Business Analytics SPECIALIZATION as a preparation to the capstone project. During the first two MOOCs, we focused on specific techniques for specific applications. Instead, with this third MOOC, we provide you with different examples  to open your mind to different applications from different industries and sectors.
The objective is to give you an helicopter overview on what's happening in this field. You will see how the tools presented in the two previous courses of the Specialization are used in real life projects. 
We want to ignite your reflection process. Hence, you will best make use of the Accenture cases by watching first the MOOC and then investigate by yourself on the different concepts, industries, or challenges that are introduced during the videos.

At the end of this course learners will be able to: 
- identify the possible applications of business analytics,
- hence, reflect on the possible solutions and added-value applications that could be proposed for their capstone project.

The cases will be presented by senior practitioners from Accenture with different backgrounds in term of industry, function, and country.  Special attention will be paid to the ""value case"" of the issue raised to prepare you for the capstone project of the specialization.

About Accenture
Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions—underpinned by the world’s largest delivery network—Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With more than 358,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com.",25079.0,9083.0,3.7,200.0
Causal Inference,https://www.coursera.org/learn/causal-inference,Data Science,Probability and Statistics,Michael E. Sobel,"This course offers a rigorous mathematical survey of causal inference at the Master’s level.

Inferences about causation are of great importance in science, medicine, policy, and business.  This course provides an introduction to the statistical literature on causal inference that has emerged in the last 35-40 years and that has revolutionized the way in which statisticians and applied researchers in many disciplines use data to make inferences about causal relationships.  

We will study methods for collecting data to estimate causal relationships. Students will learn how to distinguish between relationships that are causal and non-causal; this is not always obvious. We shall then study and evaluate the various methods students can use — such as matching, sub-classification on the propensity score, inverse probability of treatment weighting, and machine learning — to estimate a variety of effects — such as the average treatment effect and the effect of treatment on the treated. At the end, we discuss methods for evaluating some of the assumptions we have made, and we offer a look forward to the extensions we take up in the sequel to this course.",14535.0,6451.0,3.3,68.0
Causal Inference  2,https://www.coursera.org/learn/causal-inference-2,Data Science,Probability and Statistics,Michael E. Sobel,"This course offers a rigorous mathematical survey of advanced topics in causal inference at the Master’s level.

Inferences about causation are of great importance in science, medicine, policy, and business.  This course provides an introduction to the statistical literature on causal inference that has emerged in the last 35-40 years and that has revolutionized the way in which statisticians and applied researchers in many disciplines use data to make inferences about causal relationships.  

We will study advanced topics in causal inference, including mediation, principal stratification, longitudinal causal inference, regression discontinuity, interference, and fixed effects models.",4788.0,2561.0,3.4,14.0
Cervical Cancer Risk Prediction Using Machine Learning,https://www.coursera.org/learn/cervical-cancer-risk-prediction-using-machine-learning,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will build and train an XG-Boost classifier to predict whether a person has a risk of having cervical cancer. Cervical cancer kills about 4,000 women in the U.S. and about 300,000 women worldwide. 
Data has been obtained from 858 patients and include features such as number of pregnancies, smoking habits, Sexually Transmitted Disease (STD), demographics, and historic medical records.",,,4.6,17.0
Choisir la Meilleure Méthode pour Illustrer les Données,https://www.coursera.org/learn/choisir-la-meilleure-methode-pour-illustrer-les-donnees,Data Science,Data Analysis,Eya Smati,"La visualisation reste une étape importante et primordial dans l'exploration et l'analyse des ensembles de données du monde réel. En tant que telle, la visualisation est une méthode est indispensable dans la boîte à outils de tout Scientifique de données. C'est aussi un outil puissant pour identifier les problèmes dans les analyses et pour illustrer les résultats.

Dans ce projet, vous serez en mesure de choisir la meilleure manière d'illustrer votre data à l'aide des Librairies de Visualisation de Python . Tout au long du projet, vous pourrez accéder et afficher l’ensemble de vos données, faire un prétraitement simple de vos données, visualiser l’ensemble de vos informations à travers plusieurs manières . Et enfin, tirer des conclusions constructives.
Ce projet guidé est destiné aux apprenants de niveau débutant qui ont des connaissances de base en Python (Manipulation des librairies Numpy Pandas ..)  et qui sont bien évidemment intéressés par le domaine de la data visualisation et de l'analyse de données.",,,,
Ciclo completo del desarrollo de un proyecto de Data Science,https://www.coursera.org/learn/ciclo-completo-del-desarrollo-de-un-proyecto-de-data-science,Data Science,Data Analysis,Leire Ahedo,"En este curso aprenderemos a desarrollar el ciclo completo de la ciencia de datos, desarrollando en profundidad la parte del despliegue del modelo. Para ello utilizaremos tecnologías como Python, Flask, Postman, heroku, Scikit-learn o anaconda.",,,,
Ciencia de Datos Aplicada - Curso Capstone,https://www.coursera.org/learn/ciencia-de-datos-aplicada-cuso-capstone,Data Science,Data Analysis,Alex Aklson,"Este curso de proyecto final le dará una idea de lo que atraviesan los científicos de datos en la vida real cuando trabajan con datos.

Aprenderá sobre datos de ubicación y diferentes proveedores de datos de ubicación, como Foursquare. Aprenderá cómo realizar llamadas de API RESTful a la API de Foursquare para recuperar datos sobre lugares en diferentes vecindarios de todo el mundo. También aprenderá a ser creativo en situaciones en las que los datos no están disponibles fácilmente al extraer datos web y analizar el código HTML. Utilizará Python y su biblioteca de pandas para manipular datos, lo que lo ayudará a refinar sus habilidades para explorar y analizar datos.

Finalmente, se le pedirá que utilice la biblioteca Folium para obtener excelentes mapas de datos geoespaciales y para comunicar sus resultados y hallazgos.

Si elige tomar este curso y obtener el certificado del curso de Coursera, también obtendrá una insignia digital de IBM al completar con éxito el curso.

OFERTA POR TIEMPO LIMITADO: La suscripción cuesta solo $ 39 USD por mes para acceder a materiales calificados y un certificado.",,4590.0,4.5,13.0
Cifar-10 Image Classification with Keras and Tensorflow 2.0,https://www.coursera.org/learn/cifar-10-image-classification,Data Science,Machine Learning,Ryan Ahmed,"In this guided project, we will build, train, and test a deep neural network model  to classify low-resolution images containing airplanes, cars, birds, cats, ships, and trucks in Keras and Tensorflow 2.0. We will use Cifar-10 which is a benchmark dataset that stands for the Canadian Institute For Advanced Research (CIFAR) and contains 60,000 32x32 color images. This project is practical and directly applicable to many industries.",,,,
Citation Analysis for Bibliometric Study,https://www.coursera.org/learn/citation-analysis-for-bibliometric-study,Data Science,Data Analysis,Barsha Saha,"In this 2 hour long project, you will learn to search and extract relevant research articles and their linked references efficiently from a journal database to conduct a bibliometric literature review. Then with these extracted data, you will learn to create a citation network. The visualization tool Gephi will be used in this project for citation network analysis. You will also learn, how to modify the network to present more information visually about the extracted citation data. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,18.0
Clasificación de datos de Satélites con autoML y Pycaret,https://www.coursera.org/learn/clasificacion-datos-satelites-automl-pycaret,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender todo lo que necesitas saber acerca de autoML y Pycaret. Aprenderemos a generar un modelo predictivo de clasificación multiclase capaz de predecir el tipo de suelo en base a datos de satélite. Para ello, aprenderemos, de manera práctica, a generar múltiples modelos de ML y metamodelos, a evaluar su eficiencia, a desplegarlos en producción y a guardarlos en MlFlow, etc.",,,,
Clasificación de imágenes con Tensorflow,https://www.coursera.org/learn/clasificacion-tensorflow,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a usar Tensorflow para desarrollar tu primera red neuronal, usango Google Colaboratory para ello.
Además, aprenderás a usar TensorflowJS para consumir el modelo desde la web, por parte de tus usuarios.",,,,
"Classification Trees in Python, From Start To Finish",https://www.coursera.org/learn/classification-trees-in-python,Data Science,Data Analysis,Josh Starmer,"In this 1-hour long project-based course, you will learn how to build Classification Trees in Python, using a real world dataset that has missing data and categorical data that must be transformed  with One-Hot Encoding. We then use Cost Complexity Pruning and Cross Validation to build a tree that is not overfit to the Training Dataset.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Prerequisites:
In order to be successful in this project, you should be familiar with Python and the theory behind Decision Trees, Cost Complexity Pruning, Cross Validation and Confusion Matrices.

Notes:
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9255.0,,4.6,226.0
Classification of COVID19 using Chest X-ray Images in Keras,https://www.coursera.org/learn/classification-of-covid19-using-chest-xray-images-in-keras,Data Science,Machine Learning,Priya Jha,"In this 1 hour long project-based course, you will learn to build and train a convolutional neural network in Keras with TensorFlow as backend from scratch to classify patients as infected with COVID or not using their chest x-ray images. Our goal is to create an image classifier with Tensorflow by implementing a CNN to differentiate between chest x rays images with a COVID 19 infections versus without.  The dataset contains the lungs X-ray images of both groups.We will be carrying out the entire project on the Google Colab environment.

Please be aware of the fact that the dataset and the model in this project, can not be used in the real-life. We are only using this data for educational purposes.

By the end of this project, you will be able to build and train the convolutional neural network using Keras with TensorFlow as a backend. You will also be able to perform data visualization. Additionally, you will also be able to use the model to make predictions  on new data.

You should be familiar with the Python Programming language and you should have a theoretical understanding of Convolutional Neural Networks. You will need a free Gmail account to complete this project. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,32.0
Classification with Transfer Learning in Keras,https://www.coursera.org/learn/image-classification-transfer-learning-keras,Data Science,Machine Learning,Amit Yadav,"In this 1.5 hour long project-based course, you will learn to create and train a Convolutional Neural Network (CNN) with an existing CNN model architecture, and its pre-trained weights. We will use the MobileNet model architecture along with its weights trained on the popular ImageNet dataset. By using a model with pre-trained weights, and then training just the last layers on a new dataset, we can drastically reduce the training time required to fit the model to the new data . The pre-trained model has already learned to recognize thousands on simple and complex image features, and we are using its output as the input to the last layers that we are training.

In order to be successful in this project, you should be familiar with Python, Neural Networks, and CNNs. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",5496.0,,4.5,154.0
Classify Radio Signals from Space using Keras,https://www.coursera.org/learn/classify-radio-signals-space-keras-cnn,Data Science,Machine Learning,Snehan Kekre,"In this 1-hour long project-based course, you will learn the basics of using Keras with TensorFlow as its backend and use it to solve an image classification problem. The data we are going to use consists of 2D spectrograms of deep space radio signals collected by the Allen Telescope Array at the SETI Institute. We will treat the spectrograms as images to train an image classification model to classify the signals into one of four classes. By the end of the project, you will have built and trained a convolutional neural network from scratch using Keras to classify signals from space.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Tensorflow pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7303.0,,4.5,251.0
Classify Radio Signals with PyTorch,https://www.coursera.org/learn/classify-radio-signals-with-pytorch,Data Science,Machine Learning,Parth Dhameliya,"In this 2-hour long guided-project course, you will load a pretrained state of the art model CNN and you will train in PyTorch to classify radio signals with input as spectogram images. The data that you will use, consists of spectogram images (spectogram is a representation of audio signals) and there are targets such as ( Squiggle, Noises, Narrowband, etc). Furthermore, you will apply spectogram augmentation for classification task to augment spectogram images. Moreover, you are going to create train and evaluator function which will be helpful to write training loop. Lastly, you will use best trained model to classify radio signals given any 2D Spectogram of radio signal input images.",,,,
Cleaning and Exploring Big Data using PySpark,https://www.coursera.org/learn/clean-explore-visualize-big-data-python-spark,Data Science,Data Analysis,Dr. Nikunj Maheshwari,"By the end of this project, you will learn how to clean, explore and visualize big data using PySpark. You will be using an open source dataset containing information on all the water wells in Tanzania. I will teach you various ways to clean and explore your big data in PySpark such as changing column’s data type, renaming categories with low frequency in character columns and imputing missing values in numerical columns. I will also teach you ways to visualize your data by intelligently converting Spark dataframe to Pandas dataframe. 

Cleaning and exploring big data in PySpark is quite different from Python due to the distributed nature of Spark dataframes. This guided project will dive deep into various ways to clean and explore your data loaded in PySpark. Data preprocessing in big data analysis is a crucial step and one should learn about it before building any big data machine learning model. 

Note: You should have a Gmail account which you will use to sign into Google Colab.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3977.0,,4.2,57.0
Climate Geospatial Analysis on Python with Xarray,https://www.coursera.org/learn/xarray,Data Science,Data Analysis,Danilo Lessa Bernardineli,"By the end of this project, you will be able to load, visualize, manipulate and perform both simple and grouped operations over geospatial multidimensional data through Xarray and Python.  

We'll explore an dataset containing temperature, vegetation density and total precipitation over the Brazilian Amazon for the 1979-2019 period while the concepts are developed. 

This will enable the learner to handle and extract knowledge from complex datasets such as the ones from satellite and climate re-analysis observations.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,28.0
Clinical Data Models and Data Quality Assessments,https://www.coursera.org/learn/clinical-data-models-and-data-quality-assessments,Data Science,Data Analysis,"Laura K. Wiley, PhD, Michael G. Kahn, MD, PhD","This course aims to teach the concepts of clinical data models and common data models. Upon completion of this course, learners will be able to interpret and evaluate data model designs using Entity-Relationship Diagrams (ERDs), differentiate between data models and articulate how each are used to support clinical care and data science, and create SQL statements in Google BigQuery to query the MIMIC3 clinical data model and the OMOP common data model.",6070.0,6882.0,4.2,54.0
Clinical Decision Support Systems - CDSS 4,https://www.coursera.org/learn/cdss4,Data Science,Machine Learning,Fani Deligianni,"Machine learning systems used in Clinical Decision Support Systems (CDSS) require further external validation, calibration analysis, assessment of bias and fairness. In this course, the main concepts of machine learning evaluation adopted in CDSS will be explained. Furthermore, decision curve analysis along with human-centred CDSS that need to be explainable will be discussed. Finally, privacy concerns of deep learning models and potential adversarial attacks will be presented along with the vision for a new generation of explainable and privacy-preserved CDSS.",,,,
Clinical Natural Language Processing,https://www.coursera.org/learn/clinical-natural-language-processing,Data Science,Data Analysis,"Laura K. Wiley, PhD","This course teaches you the fundamentals of clinical natural language processing (NLP). In this course you will learn the basic linguistic principals underlying NLP, as well as how to write regular expressions and handle text data in R. You will also learn practical techniques for text processing to be able to extract information from clinical notes.  Finally, you will have a chance to put your skills to the test with a real-world practical application where you develop text processing algorithms to identify diabetic complications from clinical notes. You will complete this work using a free, online computational environment for data science hosted by our Industry Partner Google Cloud.",4399.0,4073.0,3.5,20.0
Cloud DNS: Traffic Steering using Geolocation Policy,https://www.coursera.org/learn/googlecloud-cloud-dns-traffic-steering-using-geolocation-policy-447v0,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Cloud Life Sciences: Variant Transforms Tool,https://www.coursera.org/learn/googlecloud-cloud-life-sciences-variant-transforms-tool-qosgc,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Cloud SQL for MySQL: Qwik Start,https://www.coursera.org/learn/googlecloud-cloud-sql-for-mysql-qwik-start-etqlf,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Cluster Analysis in Data Mining,https://www.coursera.org/learn/cluster-analysis,Data Science,Data Analysis,Jiawei Han,"Discover the basic concepts of cluster analysis, and then study a set of typical clustering methodologies, algorithms, and applications. This includes partitioning methods such as k-means, hierarchical methods such as BIRCH, and density-based methods such as DBSCAN/OPTICS. Moreover, learn methods for clustering validation and evaluation of clustering quality. Finally, see examples of cluster analysis in applications.",39546.0,17377.0,4.5,396.0
Cluster Analysis using RCmdr,https://www.coursera.org/learn/cluster-analysis-rcmdr,Data Science,Data Analysis,Shalini Gopalkrishnan ,"In this 1-hour long project-based course, we will show you how to do cluster analysis using RCmdr  using the k means method and Hierarchical method. This project uses data about 29 cars and has 22 dimensions such as price , acceleration and we will use these methods to cluster groups .

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
"Cluster Analysis, Association Mining, and Model Evaluation",https://www.coursera.org/learn/cluster-analysis-association-mining-and-model-evaluation,Data Science,Data Analysis,"Dursun Delen, Julie Pai","Welcome to Cluster Analysis, Association Mining, and Model Evaluation. In this course we will begin with an exploration of cluster analysis and segmentation, and discuss how techniques such as collaborative filtering and association rules mining can be applied. We will also explain how a model can be evaluated for performance, and review the differences in analysis types and when to apply them.",1827.0,3609.0,4.6,27.0
Clustering Geolocation Data Intelligently in Python,https://www.coursera.org/learn/clustering-geolocation-data-intelligently-python,Data Science,Machine Learning,Ari Anastassiou,"In this 1.5-hour long project, you will learn how to clean and preprocess geolocation data for clustering. You will learn how to export this data into an interactive file that can be better understood for the data. You will learn how to cluster initially with a K-Means approach, before using a more complicated density-based algorithm, DBSCAN. We will discuss how to evaluate these models, and offer improvements to DBSCAN with the introduction of HDBSCAN.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",10650.0,,4.5,399.0
Clustering analysis and techniques,https://www.coursera.org/learn/cluster-analysis-techniques,Data Science,Machine Learning,Muhammad Saad uddin,"In this 2-hour long project-based course, you will learn how to perform clustering (one of the core pillar of unsupervised learning) and its importance in machine learning, set up PyCaret Clustering module, create, visualize & compare Clustering algorithms all this with just a few lines of code.",,,,
Code Free Data Science,https://www.coursera.org/learn/code-free-data-science,Data Science,Machine Learning,"Natasha Balac, Ph.D.","The Code Free Data Science class is designed for learners seeking to gain or expand their knowledge in the area of Data Science.  Participants will receive the basic training in effective predictive analytic approaches accompanying the growing discipline of Data Science without any programming requirements.  Machine Learning methods will be presented by utilizing the KNIME Analytics Platform to discover patterns and relationships in data. Predicting future trends and behaviors allows for proactive, data-driven decisions.  During the class learners will acquire new skills to apply predictive algorithms to real data, evaluate, validate and interpret the results without any pre requisites for any kind of programming.  Participants will gain the essential skills to design, build, verify and test predictive models.  

You Will Learn
•	How to design Data Science workflows without any programming involved
•	Essential Data Science skills to design, build, test and evaluate predictive models
•	Data Manipulation, preparation and Classification and clustering methods
•	Ways to apply Data Science algorithms to real data and evaluate and interpret the results",21235.0,9976.0,4.3,180.0
Combiner des données de plusieurs tables SQL,https://www.coursera.org/learn/combiner-des-donnes-de-plusieurs-tables-sql,Data Science,Data Analysis,Mohamed Jendoubi,"Dans ce projet vous allez apprendre les différentes techniques pour combiner des données de plusieurs tables SQL.
Vous apprendrez comment tirer parti de la puissance de SQL pour extraire des informations de bases de données relationnelles.
Vous allez apprendre à utiliser les clauses join (inner, left, right et full)
Vous allez aussi pratiquer l'utilisation de la clause union et l'utilisation des requêtes imbriquées.
Vous serez équipé pour savoir quand utiliser SQL pour fournir des informations étayées par des données sur des stratégies d’affaires complexes.",,,,
Combining and Analyzing Complex Data,https://www.coursera.org/learn/data-collection-analytics-project,Data Science,Data Analysis,"Richard Valliant, Ph.D.","In this course you will learn how to use survey weights to estimate descriptive statistics, like means and totals, and more complicated quantities like model parameters for linear and logistic regressions.  Software capabilities will be covered with R® receiving particular emphasis.  The course will also cover the basics of record linkage and statistical matching—both of which are becoming more important as ways of combining data from different sources.  Combining of datasets raises ethical issues which the course reviews.  Informed consent may have to be obtained from persons to allow their data to be linked. You will learn about differences in the legal requirements in different countries.",7622.0,4917.0,4.2,56.0
Command Line Tools for Genomic Data Science,https://www.coursera.org/learn/genomic-tools,Data Science,Data Analysis,"Liliana Florea, PhD","Introduces to the commands that you need to manage and analyze directories, files, and large sets of genomic data. This is the fourth course in the Genomic Big Data Science Specialization from Johns Hopkins University.",23956.0,22009.0,4.0,512.0
Comment créer une connexion à une base de données SQL Server,https://www.coursera.org/learn/comment-creer-une-connexion-a-une-base-de-donnees-sql-server,Data Science,Data Analysis,Hadeel Sleem,"Dans ce projet guidé d'une heure, vous apprendrez à comment créer une connexion à une base de données SQL Server. Cette vidéo vous aide à apprendre les sujets suivants: SQL Server Management Studio, Détails sur la connexion Microsoft SQL Serve, Démarrer avec la base de données SQL Server, Créer une connexion à une base de données SQL Server, Créer une base de données SQL Server.
À la fin de ce projet, vous allez être capable à créer une connexion à une base de données SQL Server, démarrer avec la base de données SQL Server et créer une base de données SQL Server.",,,,
Communicate Effectively about Ethical Challenges in Data-Driven Technologies,https://www.coursera.org/learn/ethical-communication-data-driven-technologies,Data Science,Machine Learning,"Renée Cummings, Jennifer Fischer, Megan Smith Branch","Leading a data-driven organization necessitates effective communication to create a culture of ethical practice. Communication to stakeholders will guide an organization's strategy and potentially impact the future of work for that organization or entity. It is not enough to talk about ethical practices, you need to to relate their value to stakeholders. Building out strategies that are inclusive and relatable can build public trust and loyalty, and knowing how to plan for a crisis will reduce the harm to such trust and loyalty. 

In this fourth course of the CertNexus Certified Ethical Emerging Technologist (CEET) professional certificate, learners will develop inclusive strategies to communicate business impacts to stakeholders, design communication strategies that mirror ethical principles and policies, and in case of an ethical crisis, be prepared to manage the crisis and the media to reduce business impact.

This course is the fourth of five courses within the Certified Ethical Emerging Technologist (CEET) professional certificate. The preceding courses are titled Promote the Ethical Use of Data-Driven Technologies, Turn Ethical Frameworks into Actionable Steps, and Detect and Mitigate Ethical Risks.",7048.0,31913.0,4.4,59.0
Communicating Business Analytics Results,https://www.coursera.org/learn/communicating-business-analytics-results,Data Science,Data Analysis,"Manuel Laguna, Dan Zhang, David Torgerson","The analytical process does not end with models than can predict with accuracy or prescribe the best solution to business problems. Developing these models and gaining insights from data do not necessarily lead to successful implementations. This depends on the ability to communicate results to those who make decisions. Presenting findings to decision makers who are not familiar with the language of analytics presents a challenge. In this course you will learn how to communicate analytics results to  stakeholders who do not understand the details of analytics but want evidence of analysis and data. You will be able to choose the right vehicles to present quantitative information, including those based on principles of data visualization. You will also learn how to develop and deliver data-analytics stories that provide context, insight, and interpretation.",22784.0,10404.0,4.5,489.0
Communicating Data Science Results,https://www.coursera.org/learn/data-results,Data Science,Data Analysis,Bill Howe,"Important note: The second assignment in this course covers the topic of Graph Analysis in the Cloud, in which you will use Elastic MapReduce and the Pig language to perform graph analysis over a moderately large dataset, about 600GB. In order to complete this assignment, you will need to make use of Amazon Web Services (AWS). Amazon has generously offered to provide up to $50 in free AWS credit to each learner in this course to allow you to complete the assignment. Further details regarding the process of receiving this credit are available in the welcome message for the course, as well as in the assignment itself. Please note that Amazon, University of Washington, and Coursera cannot reimburse you for any charges if you exhaust your credit.

While we believe that this assignment contributes an excellent learning experience in this course, we understand that some learners may be unable or unwilling to use AWS. We are unable to issue Course Certificates for learners who do not complete the assignment that requires use of AWS. As such, you should not pay for a Course Certificate in Communicating Data Results if you are unable or unwilling to use AWS, as you will not be able to successfully complete the course without doing so.

Making predictions is not enough!  Effective data scientists know how to explain and interpret their results, and communicate findings accurately to stakeholders to inform business decisions.  Visualization is the field of research in computer science that studies effective communication of quantitative results by linking perception, cognition, and algorithms to exploit the enormous bandwidth of the human visual cortex.  In this course you will learn to recognize, design, and use effective visualizations.

Just because you can make a prediction and convince others to act on it doesn’t mean you should.  In this course you will explore the ethical considerations around big data and how these considerations are beginning to influence policy and practice.   You will learn the foundational limitations of using technology to protect privacy and the codes of conduct emerging to guide the behavior of data scientists.  You will also learn the importance of reproducibility in data science and how the commercial cloud can help support reproducible research even for experiments involving massive datasets, complex computational infrastructures, or both.

Learning Goals: After completing this course, you will be able to:
1. Design and critique visualizations
2. Explain the state-of-the-art in privacy, ethics, governance around big data and data science
3. Use cloud computing to analyze large datasets in a reproducible way.",15891.0,2707.0,3.6,135.0
Compare Models with Experiments in Azure ML Studio,https://www.coursera.org/learn/compare-models-with-experiments-in-azure-ml-studio,Data Science,Machine Learning,Laura Ramov,"Did you know that you can compare models in Azure Machine Learning?
In this 1-hour project-based course, you will learn how to log plots in experiments, log numeric metrics in experiments and visualize metrics in Azure Machine Learning Studio. To achieve this, we will use one example data, train a couple of machine learning algorithms in Jupyter notebook and visualize their results in Azure Machine Learning Studio Portal interface. 
In order to be successful in this project, you will need knowledge of Python language and experience with machine learning in Python. Also, Azure subscription is required (free trial is an option for those who don’t have it), as well as Azure Machine Learning resource and a compute instance within. Instructional links will be provided to guide you through creation, if needed, in the first task.
If you are ready to make your experience training models simpler and more enjoyable, this is a course for you!
Let’s get started!",,,,
Compare time series predictions of COVID-19 deaths,https://www.coursera.org/learn/compare-time-series-predictions-of-covid19-deaths,Data Science,Machine Learning,Sherif A. Tawfik Abbas,"By the end of this project, you will learn how to perform the entire time series analysis workflow for the daily COVID-19 deaths. This workflow includes the following steps: how to examine time series data, prepare the data for analysis, train different models and test their performance, and finally use the models to forecast into the future. You will learn how to visualize data using the matplotlib library, extract features from a time series data set, and perform data splitting and normalization. You will create time series analysis models using the python programming language. You will create and train four time series models: SARIMAX, Facebook prophet, neural networks and XGBOOST.",,,4.2,32.0
Compartilhar os dados com a arte da visualização,https://www.coursera.org/learn/compartilhar-os-dados-com-a-arte-da-visualizacao,Data Science,Data Analysis,Google Career Certificates,"Este é o sexto curso do Certificado de Data Analytics do Google. Estes cursos darão a você as habilidades necessárias para se candidatar a cargos empregos de analista de dados de nível inicial. Você aprenderá a visualizar e apresentar as descobertas ao concluir o processo de análise de dados. Este curso mostrará a você de que maneira as visualizações de dados como painéis podem ajudar a dar vida aos seus dados. Você também descobrirá o Tableau, uma plataforma de visualização de dados que ajuda a criar visualizações eficazes para suas apresentações. Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível inicial para analista de dados. Nenhuma experiência anterior é necessária.

Ao final deste curso, você poderá:
 - Examinar a importância da visualização de dados.
 - Saber como desenvolver uma narrativa interessante para contar a história dos dados.
 - Compreender como usar o Tableau para criar painéis e filtros de painel.
 - Saber como usar o Tableau para criar visualizações eficazes. 
 - Explorar os princípios e práticas para criar apresentações efetivas.
 - Considerar as possíveis limitações associadas aos dados em suas apresentações.
 - Compreender como aplicar as práticas recomendadas de perguntas e respostas com o seu público-alvo.",,29470.0,4.5,15.0
Compartir datos a través del arte de la visualización,https://www.coursera.org/learn/compartir-datos-a-traves-del-arte-de-la-visualizacion,Data Science,Data Analysis,Google Career Certificates,"Este es el sexto curso del Certificado de análisis computacional de datos de Google. En estos cursos obtendrás las habilidades necesarias para solicitar empleos de analista de datos de nivel introductorio. A medida que realices el proceso de análisis de datos, aprenderás a visualizar y presentar tus descubrimientos con respecto a los datos. En este curso, se explicará de qué manera las visualizaciones de datos, como los paneles visuales, pueden darles vida a tus datos. Además, explorarás Tableau, una plataforma de visualización de datos que te permitirá crear visualizaciones eficaces para tus presentaciones. Los analistas de datos actuales de Google seguirán dándote instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, serás capaz de:
 - Comprender la importancia de la visualización de datos.
 - Aprender a crear una narrativa convincente por medio de historias de datos.
 - Comprender cómo usar Tableau para crear paneles y filtros de paneles.
 - Descubrir cómo usar Tableau para crear visualizaciones eficaces. 
 - Explorar las prácticas y los principios relacionados con las presentaciones eficaces.
 - Aprender a considerar posibles limitaciones relacionadas con los datos de tus presentaciones.
 - Comprender cómo aplicar las prácticas recomendadas en las sesiones de preguntas y respuestas con tu público.",2502.0,121776.0,4.7,62.0
Computational Neuroscience,https://www.coursera.org/learn/computational-neuroscience,Data Science,Machine Learning,"Rajesh P. N. Rao, Adrienne Fairhall","This course provides an introduction to basic computational methods for understanding what nervous systems do and for determining how they function. We will explore the computational principles governing various aspects of vision, sensory-motor control, learning, and memory. Specific topics that will be covered include representation of information by spiking neurons, processing of information in neural networks, and algorithms for adaptation and learning. We will make use of Matlab/Octave/Python demonstrations and exercises to gain a deeper understanding of concepts and methods introduced in the course. The course is primarily aimed at third- or fourth-year undergraduates and beginning graduate students, as well as professionals and distance learners interested in learning how the brain processes information.",104931.0,60946.0,4.6,977.0
Computational Social Science Capstone Project,https://www.coursera.org/learn/css-capstone,Data Science,Data Analysis,Martin Hilbert,"CONGRATULATIONS! Not only did you accomplish to finish our intellectual tour de force, but, by now, you also already have all required skills to execute a comprehensive multi-method workflow of computational social science. We will put these skills to work in this final integrative lab, where we are bringing it all together. We scrape data from a social media site (drawing on the skills obtained in the 1st course of this specialization). We then analyze the collected data by visualizing the resulting networks (building on the skills obtained in the 3rd course). We analyze some key aspects of it in depth, using machine learning powered natural language processing (putting to work the insights obtained during the 2nd course). Finally, we use a computer simulation model to explore possible generative mechanism and scrutinize aspects that we did not find in our empirical reality, but that help us to improve this aspect of society (drawing on the skills obtained during the 4th course of this specialization). The result is the first glimpse at a new way of doing social science in a digital age: computational social science. Congratulations! Having done all of this yourself, you can consider yourself a fledgling computational social scientist!",3447.0,3326.0,4.6,30.0
Computational Social Science Methods,https://www.coursera.org/learn/computational-social-science-methods,Data Science,Data Analysis,Martin Hilbert,"This course gives you an overview of the current opportunities and the omnipresent reach of computational social science. The results are all around us, every day, reaching from the services provided by the world’s most valuable companies, over the hidden influence of governmental agencies, to the power of social and political movements. All of them study human behavior in order to shape it. In short, all of them do social science by computational means.

In this course we answer three questions:
I.    Why Computational Social Science (CSS) now? 
II.    What does CSS cover?
III.    What are examples of CSS?

In this last part, we take a bird’s-eye view on four main applications of CSS. First, Prof. Blumenstock from UC Berkeley discusses how we can gain insights by studying the massive digital footprint left behind today’s social interactions, especially to foster international development. Second, Prof. Shelton from UC Riverside introduces us to the world of machine learning, including the basic concepts behind this current driver of much of today's computational landscape. Prof. Fowler, from UC San Diego introduces us to the power of social networks, and finally, Prof. Smaldino, from UC Merced, explains how computer simulation help us to untangle some of the mysteries of social emergence.",11722.0,11864.0,4.7,287.0
Computer Simulations,https://www.coursera.org/learn/computer-simulations,Data Science,Machine Learning,Martin Hilbert,"Big data and artificial intelligence get most of the press about computational social science, but maybe the most complex aspect of it refers to using computational tools to explore and develop social science theory. This course shows how computer simulations are being used to explore the realm of what is theoretically possible. Computer simulations allow us to study why societies are the way they are, and to dream about the world we would like to live in. This can be as intuitive as playing a video game. Much like the well-known video game SimCity is used to build and manage an artificial city, we use agent-based models to grow and study artificial societies. Without hurting anyone in the real world, computer simulations allow us explore how to make the world a better place. We play hands-on with several practical computer simulation models and explore how we can combine hypothetical models with real world data. Finally, you will program a simple artificial society yourself, bottom-up. This will allow you to feel the complexity that arises when designing social systems, while at the same time experiencing the ease with which our new computational tools allow us to pursue such daunting endeavors.",6816.0,9559.0,4.5,70.0
Computer Vision - Image Basics with OpenCV and Python,https://www.coursera.org/learn/computer-vision-opencv-for-images,Data Science,Machine Learning,Ilias Papachristos,"In this 1-hour long project-based course, you will learn how to do Computer Vision on images with OpenCV and Python using Jupyter Notebook. 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and OpenCV pre-installed.

Prerequisites:
In order to be successful in this project, you should have a basic knowledge of Python. 

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",14447.0,,4.3,671.0
Computer Vision Fundamentals with Google Cloud,https://www.coursera.org/learn/image-understanding-tensorflow-gcp,Data Science,Machine Learning,Google Cloud Training,"This course describes different types of computer vision use cases and then highlights different machine learning strategies for solving these use cases. The strategies vary from experimenting with pre-built ML models through pre-built ML APIs and AutoML Vision to building custom image classifiers using linear models, deep neural network (DNN) models or convolutional neural network (CNN) models. 

The course shows how to improve a model's accuracy with augmentation, feature extraction, and fine-tuning hyperparameters while trying to avoid overfitting the data. 

The course also looks at practical issues that arise, for example, when one doesn't have enough data and how to incorporate the latest research findings into different models.

Learners will get hands-on practice building and optimizing their own image classification models on a variety of public datasets in the labs they will work on.",14333.0,6000.0,4.6,516.0
Computer Vision with Embedded Machine Learning,https://www.coursera.org/learn/computer-vision-with-embedded-machine-learning,Data Science,Machine Learning,Shawn Hymel,"Computer vision (CV) is a fascinating field of study that attempts to automate the process of assigning meaning to digital images or videos. In other words, we are helping computers see and understand the world around us! A number of machine learning (ML) algorithms and techniques can be used to accomplish CV tasks, and as ML becomes faster and more efficient, we can deploy these techniques to embedded systems.

This course, offered by a partnership among Edge Impulse, OpenMV, Seeed Studio, and the TinyML Foundation, will give you an understanding of how deep learning with neural networks can be used to classify images and detect objects in images and videos. You will have the opportunity to deploy these machine learning models to embedded systems, which is known as embedded machine learning or TinyML.

Familiarity with the Python programming language and basic ML concepts (such as neural networks, training, inference, and evaluation) is advised to understand some topics as well as complete the projects. Some math (reading plots, arithmetic, algebra) is also required for quizzes and projects. If you have not done so already, taking the ""Introduction to Embedded Machine Learning"" course is recommended.

This course covers the concepts and vocabulary necessary to understand how convolutional neural networks (CNNs) operate, and it covers how to use them to classify images and detect objects. The hands-on projects will give you the opportunity to train your own CNNs and deploy them to a microcontroller and/or single board computer.",9261.0,27307.0,4.7,73.0
Conceptos Básicos de Excel para el Análisis de Datos,https://www.coursera.org/learn/conceptos-basicos-de-excel-para-el-analisis-de-datos,Data Science,Data Analysis,"Sandip Saha Joy, Steve Ryan","Este curso está diseñado para proporcionarle los conocimientos básicos de trabajo para utilizar las hojas de cálculo de Excel para el análisis de datos. Cubre algunos de los primeros pasos para trabajar con hojas de cálculo y su uso en el proceso de análisis de datos.  Incluye muchos videos, demostraciones y ejemplos para que aprenda, seguidos de instrucciones paso a paso para que los aplique y practique en una hoja de cálculo en vivo.

Excel es una herramienta esencial para trabajar con datos, ya sea para negocios, marketing, análisis de datos o investigación. Este curso es adecuado para aquellos que aspiran a asumir el análisis de datos o la ciencia de los datos como una profesión, así como aquellos que sólo quieren utilizar Excel para el análisis de datos en sus propios dominios. Obtendrá una valiosa experiencia en la limpieza y la gestión de datos mediante funciones y luego analizará sus datos mediante técnicas como el filtrado, la clasificación y la creación de tablas dinámicas.   

Este curso comienza con una introducción a las hojas de cálculo como Microsoft Excel y Google Sheets y la carga de datos de múltiples formatos. Con esta introducción aprenderá a realizar algunas tareas de limpieza y de discusión de datos de nivel básico y continuarás ampliando tus conocimientos sobre el análisis de datos mediante el uso de filtros, clasificación y tablas dinámicas dentro de la hoja de cálculo. Realizando estas tareas a lo largo del curso, le dará una comprensión de cómo las hojas de cálculo pueden ser utilizadas como una herramienta de análisis de datos y comprenderá sus limitaciones. 

Hay un fuerte enfoque en la práctica y el aprendizaje aplicado en este curso. Con cada laboratorio, obtendrá experiencia práctica en la manipulación de datos y comenzará a comprender el importante papel de las hojas de cálculo. Limpie y analice sus datos más rápido al comprender las funciones en el formato de los datos. A continuación, convertirá sus datos en una tabla pivotante y aprenderá sus características para que sus datos estén organizados y sean legibles. El proyecto final le permite mostrar sus recién adquiridas habilidades de análisis de datos. Al final de este curso usted habrá trabajado con varios conjuntos de datos y hojas de cálculo y demostrado los fundamentos de la limpieza y el análisis de datos, todo ello sin tener que aprender ningún código. 

Comenzar a usar Excel es fácil en este curso. No requiere ninguna experiencia previa con hojas de cálculo o codificación. Tampoco requiere descargas o instalación de ningún software. Todo lo que se necesita es un dispositivo con un moderno navegador web, y la capacidad de crear una cuenta de Microsoft para acceder a Excel en línea sin costo alguno.  Sin embargo, si ya tiene una versión de escritorio de Excel, también puede seguirlo fácilmente.",7709.0,161641.0,4.6,168.0
Conducting Exploratory Data Analysis,https://www.coursera.org/learn/conducting-exploratory-data-analysis,Data Science,Data Analysis,João Vitor Boverio da Silva Gomes,"Conduct exploratory data analysis with a systematic approach to investigate different aspects of your data: comparisons, relationships, compositions, and distributions. This guided project gives you a framework so you can conduct your own exploratory data analysis and make your work more professional and organized. The language is Python and the libraries used are seaborn, pandas, and matplotlib.",,,,
Connect an App to a Cloud SQL for PostgreSQL Instance,https://www.coursera.org/learn/googlecloud-connect-an-app-to-a-cloud-sql-for-postgresql-instance-mhiqu,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Connecting Rasa Chatbot to External Platforms,https://www.coursera.org/learn/connecting-rasa-chatbot-to-external-platforms,Data Science,Machine Learning,Mohammed Murtuza Qureshi,"In this 1-hour long project-based course, you will learn how to connect Rasa Chatbot to external platforms. We will first look at enable a encrypted connection (HTTPS) using a proxy server from Ngrok. We will then look at how to connect to Facebook Messenger using Facebook Developer Account. We will look at how to create custom buttons like quick replies and Carousel Cards for listing elements. 

We will then move on to look at how to connect the chatbot to Telegram and how to customize buttons and add attachments to a response. Finally, we will also look like how to integrate the bot on the business communication platform Slack. By the end of the project, you will be able to connect your chatbot to external users on public platforms.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Convolutional Neural Networks,https://www.coursera.org/learn/convolutional-neural-networks,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","In the fourth course of the Deep Learning Specialization, you will understand how computer vision has evolved and become familiar with its exciting applications such as autonomous driving, face recognition, reading radiology images, and more.

By the end, you will be able to build a convolutional neural network, including recent variations such as residual networks; apply convolutional networks to visual detection and recognition tasks; and use neural style transfer to generate art and apply these algorithms to a variety of image, video, and other 2D or 3D data. 

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",428583.0,516955.0,4.9,41035.0
Convolutional Neural Networks in TensorFlow,https://www.coursera.org/learn/convolutional-neural-networks-tensorflow,Data Science,Machine Learning,Laurence Moroney,"If you are a software developer who wants to build scalable AI-powered algorithms, you need to understand how to use the tools to build them. This course is part of the upcoming Machine Learning in Tensorflow Specialization and will teach you best practices for using TensorFlow, a popular open-source framework for machine learning.

In Course 2 of the deeplearning.ai TensorFlow Specialization, you will learn advanced techniques to improve the computer vision model you built in Course 1. You will explore how to work with real-world images in different shapes and sizes, visualize the journey of an image through convolutions to understand how a computer “sees” information, plot loss and accuracy, and explore strategies to prevent overfitting, including augmentation and dropout. Finally, Course 2 will introduce you to transfer learning and how learned features can be extracted from models. 

The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization.",117517.0,155471.0,4.7,7572.0
Convolutions for Text Classification with Keras,https://www.coursera.org/learn/convolution-text-classification-keras,Data Science,Machine Learning,Snehan Kekre,"Welcome to this hands-on, guided introduction to Text Classification using 1D Convolutions with Keras. By the end of this project, you will be able to apply word embeddings for text classification, use 1D convolutions as feature extractors in natural language processing (NLP), and perform binary text classification using deep learning. 

As a case study, we will work on classifying a large number of Wikipedia comments as being either toxic or not (i.e. comments that are rude, disrespectful, or otherwise likely to make someone leave a discussion). This issue is especially important, given the conversations the global community and tech companies are having on content moderation, online harassment, and inclusivity. The data set we will use comes from the Toxic Comment Classification Challenge on Kaggle. 

To complete this guided project, we recommend that you have prior experience in Python programming, deep learning theory, and have used either Tensorflow or Keras to build deep learning models. We assume you have this foundational knowledge and want to learn how to use convolutions in NLP tasks such as classification.

Note: This course works best for learners based in the North America region. We’re currently working on providing the same experience in other regions.",5211.0,,4.7,126.0
Cours intensif sur la science des données,https://www.coursera.org/learn/data-science-course-fr,Data Science,Data Analysis,"Jeff Leek, PhD, Brian Caffo, PhD, Roger D. Peng, PhD","Vous avez sûrement déjà entendu parler de la science des données et du Big Data. Ce cours intensif d’une semaine vous permettra de comprendre ce que ces termes signifient et comment ils jouent un rôle dans les entreprises prospères. Ce cours intensif s’adresse à tous ceux qui souhaitent découvrir en quoi consiste la science des données, y compris ceux qui devront éventuellement encadrer des scientifiques des données. L’objectif est de vous familiariser avec la science des données le plus rapidement possible et de ne pas s’encombrer du superflu. Nous avons conçu ce cours afin qu’il soit aussi pratique que possible, sans pour autant sacrifier les éléments essentiels.

Il s'agit d’un cours ciblé conçue pour vous familiariser rapidement avec le domaine de la science des données. Notre objectif est de faire en sorte que cette formation soit aussi pratique que possible pour vous, sans pour autant sacrifier le contenu essentiel. Nous avons laissé les informations techniques de côté afin que vous puissiez vous concentrer sur l'encadrement et la progression de votre équipe.

Après avoir terminé ce cours, vous saurez. 

1. Décrire le rôle joué par la science des données dans différents contextes
2. Comment les statistiques, l’apprentissage automatique et le génie logiciel jouent un rôle dans la science des données
3. Comment décrire la structure d’un projet de science des données
4. Les termes et outils clés utilisés par les scientifiques des données
5. Comment identifier si un projet de science des données est réussi ou non
3. Le rôle d’un manager en science des données


Image de couverture du cours par r2hox. Creative Commons BY-SA : https://flic.kr/p/gdMuhT",,,,
Covid-19 Cases Forecasting Using Fbprophet,https://www.coursera.org/learn/covid-19-cases-forecasting-using-fbp,Data Science,Data Analysis,Ryan Ahmed,"Predictive models attempt at forecasting future value based on historical data. In this hands-on project, we will analyze the transmission of Covid-19 virus across the globe and train a time-series model (fbprophet) to get the projection of corona virus-related cases in the United States.",,,4.8,10.0
Covid-19 Death Medical Analysis & Visualization using Plotly,https://www.coursera.org/learn/covid-19-death-medical-analysis-visualization-using-plotly,Data Science,Data Analysis,Abhishek Jha,"In this 2-hour long project-based course, you will learn how to build bar graphs, scatter plots, Choropleth maps and Wordcloud to analyze and visualize the global scenario of Covid-19 and perform medical analysis to various conditions that contribute to death due to Covid-19. We will be using two separate datasets for this guided project. The first dataset has been taken from worldometer and the second one has been made available by the Centers for Disease Control and Prevention (CDC), United States. 

We will be using Python as our Programming language and Google Colab as our notebook. It is required for you to have a Gmail Account for this project. It is recommended to have some experience in the Python programming language but even if you do not have any prior experience in Python programming or medical science, you will be able to complete this project. This project is beginner-friendly.

We will visualize the current global scenario of Covid-19 using bar graphs and scatter plots followed by geographical data visualization using Choropleth maps. Then we will dive into medical analysis. We will then visualize how Covid deaths vary with respect to age group and how various pre-existing medical conditions vary with age. Then we will visualize and analyze how various medical conditions contribute to Covid death. We will also compare the performance of all the 50 states in the US against Covid. In the final task, we will finish by creating WordCloud text visualization of various medical conditions and condition groups that contribute to Covid deaths.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Crash Course on Interactive Data Visualization with Plotly,https://www.coursera.org/learn/crash-course-on-interactive-data-visualization-with-plotly,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will understand the fundamentals of interactive data visualization using Plolty Express. Plotly Express is a powerful Python package that empowers anyone to create, manipulate and render graphical figures with very few lines of code. Plotly Express is the recommended entry-point into the plotly package. We will leverage Plotly Express to generate interactive single Line plots, multiple line plots, histograms, pie charts, scatterplots, bubble charts, and bar charts. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Creación de aplicaciones de IA con las API de Watson,https://www.coursera.org/learn/creacion-de-aplicaciones-de-ia-con-las-api-de-watson,Data Science,Machine Learning,"Antonio Cangiano, Tanmay Bakshi","Este curso te enseñará cómo crear chatbots útiles sin la necesidad de escribir ningún código.

Aprovechando las capacidades de procesamiento de lenguaje natural de IBM Watson, aprenderá a planificar, implementar, probar e implementar chatbots que deleitan a sus usuarios, en lugar de frustrarlos.

Fiel a nuestra promesa de no requerir ningún código, aprenderá a crear visualmente chatbots con Watson Assistant (anteriormente Watson Conversation) y cómo implementarlos en su propio sitio web a través de un práctico complemento de WordPress. ¿No tienes un sitio web? No se preocupe, se le proporcionará uno.

Los chatbots son un tema candente en nuestra industria y están a punto de crecer. Todos los días se agregan nuevos trabajos que requieren esta habilidad específica, los consultores exigen tarifas premium y el interés en los chatbots está explotando rápidamente.

Gartner predice que para 2020, el 85% de las interacciones de los clientes con la empresa se realizará a través de medios automatizados (es decir, chatbots y tecnologías relacionadas).

Esta es su oportunidad de aprender este conjunto de habilidades altamente demandadas con una introducción suave al tema que no deja piedra sin remover.

Esta es una traducción al español de un curso que se creó originalmente en inglés. Muchos de los componentes del curso se han traducido al español, incluidos títulos de lecciones, transcripciones de videos, lecturas, instrucciones de laboratorio y cuestionarios. Sin embargo, algunos componentes del curso, incluidos los videos originales y su narración, todavía están en inglés.",,,,
Creando aplicaciones con Shiny,https://www.coursera.org/learn/creando-aplicaciones-shiny,Data Science,Data Analysis,Nestor Nicolas Campos Rojas,"En este proyecto, vamos a crear una simple Web que a partir de ciertos filtros seleccionados por un usuario, un set de datos pueda desplegarse.",,,,
Creando un modelo de lenguaje natural con Spacy,https://www.coursera.org/learn/lenguage-natural-spacy,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"Al completar este proyecto de 1 hora de duración, entenderás y podrás desarrollar tus propios modelos de lenguaje natural con Python, usando una de las librerías más populares para ello, Spacy, a partir de un conjunto de datos definidos, y entender las ventajas y qué otras acciones podemos hacer con esta librería.",,,,
Creando un proceso de MLOps con Azure Machine Learning,https://www.coursera.org/learn/mlops-azure-machine-learning,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto, vamos a levantar de forma simple un proceso DevOps con modelos de Machine Learning para entender todo un proceso MLOps.",,,,
Create Beautiful Data Visualizations with Python and Altair,https://www.coursera.org/learn/create-data-visualization-python-altair,Data Science,Data Analysis,Ikechukwu Nigel Ogbuchi,"In this Project, we would be creating some visualizations with Altair Python library and you will learn how to manipulate, interact with and save those charts.",,,,
Create Custom Layers in Keras,https://www.coursera.org/learn/custom-layers-keras,Data Science,Machine Learning,Amit Yadav,"In this 1-hour long project-based course, you will learn how to create a custom layer in Keras, and create a model using the custom layer. In this project, we will create a simplified version of a Parametric ReLU layer, and use it in a neural network model. Then we will use the neural network to solve a multi-class classiﬁcation problem. We will also compare our activation layer with the more commonly used ReLU activation layer. 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Prerequisites:
In order to be successful in this project, you should be familiar with python programming, neural networks, and Keras. 

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3830.0,,4.6,99.0
Create Experiments for Business or Research,https://www.coursera.org/learn/create-experiments-for-business,Data Science,Data Analysis,Shalini Gopalkrishnan ,"In this project , you will learn how to set up an experiment for business or research question. You will create your own question and we will help you follow the steps to setting up an experiment.",,,,
Create Interactive Dashboards with Streamlit and Python,https://www.coursera.org/learn/interactive-dashboards-streamlit-python,Data Science,Data Analysis,Snehan Kekre,"Welcome to this hands-on project on building your first interactive, data dashboard with the Streamlit library in Python. By the end of this project, you are going to be comfortable with using Python and Streamlit to build beautiful and interactive dashboards and web apps, all with zero web development experience! We are going to load, explore, visualize and interact with data, and generate dashboards in less than 150 lines of Python code!

Prior experience with writing simple Python scripts and using pandas for data manipulation is recommended.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9072.0,,4.7,364.0
Create Mapping Data Flows in Azure Data Factory,https://www.coursera.org/learn/create-mapping-data-flows-in-azure-data-factory,Data Science,Data Analysis,Priya Jha,"In this 1 hour long project-based course, we’ll learn to create a mapping data flow on the azure data factory. First, we’ll learn to create an azure data factory on the Azure portal. Then we’ll learn to create an azure storage account so that we could store the source data on the blob containers. We’ll learn to configure the source and the sink transformation. We’ll learn to work with basic data flow transformations such as select, filters, sort, joins , derived columns, and conditional split transformations. We’ll learn to create a simple mapping data flow in the azure data factory. We’ll also learn to create and combine multiple streams of data on mapping data flows. Finally, we’ll also learn to store the transformed data to the destination.

You must have an Azure account prior.",,,,
Create Technical Stock Charts Using R and Quantmod,https://www.coursera.org/learn/create-technical-stock-charts-r-quantmod,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to pull down Stock Data using the R quantmod Package and Yahoo Finance API.  You will also learn how to apply Technical Indicators to the data and draw graphs based on those Indicators.  


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4133.0,,4.5,124.0
Create a Buy Signal using RSI in R with the Quantmod Package,https://www.coursera.org/learn/create-rsi-buy-signal-using-r,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to pull down Stock Data using the R quantmod package.   You will also learn how to perform analytics and pass financial risk functions to the data.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2786.0,,4.4,65.0
Create a Sales Dashboard using Power BI,https://www.coursera.org/learn/create-sales-dashboard-using-power-bi,Data Science,Data Analysis,Abhishek Jha,"In this 1 hour long project, you will build an attractive and eye-catching sales dashboard using Power BI in a black and blue theme that will make your audience go ""wow"". We will begin this guided project by importing data. We will then create bar charts and pie charts to visualize the sales data and then position the graphs on the dashboard. In the final tasks, we will create interactive maps to visualize sales data by countries and markets. By the end of this course, you will be confident in creating beautiful dashboards with many different kinds of visualizations.",,,,
Create a Superhero Name Generator with TensorFlow,https://www.coursera.org/learn/superhero-tensorflow,Data Science,Machine Learning,Amit Yadav,"In this guided project, we are going to create a neural network and train it on a small dataset of superhero names to learn to generate similar names. The dataset has over 9000 names of superheroes, supervillains and other fictional characters from a number of different comic books, TV shows and movies.

Text generation is a common natural language processing task. We will create a character level language model that will predict the next character for a given input sequence. In order to get a new predicted superhero name, we will need to give our model a seed input - this can be a single character or a sequence of characters, and the model will then generate the next character that it predicts should after the input sequence. This character is then added to the seed input to create a new input, which is then used again to generate the next character, and so on.

You will need prior programming experience in Python. Some experience with TensorFlow is recommended. This is a practical, hands on guided project for learners who already have theoretical understanding of Neural Networks, Recurrent Neural Networks, and optimization algorithms like gradient descent but want to understand how to use the TensorFlow to start performing natural language processing tasks like text classification or text generation.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.9,29.0
Create an infographic with Infogram,https://www.coursera.org/learn/create-an-infographic-with-infogram,Data Science,Data Analysis,Angelo Paolillo,"In this 2-hour long project-based course, you will learn how to design effectively an infographic with infogram.com, adding line, bar and map charts, and connecting the data story with text and visuals.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Create and Lead an Ethical Data-Driven Organization,https://www.coursera.org/learn/ethical-data-driven-technology-leader,Data Science,Machine Learning,"Aaron Hui, Abhishek Gupta, Megan Smith Branch","Creating and leading an ethical data-driven organization, when done successfully, is a cultural transformation for an organization. Navigating a cultural shift requires leadership buy in, resourcing, training, and support through creation of boards, policies, and governance. Beyond leadership and organization, it is imperative to engage employees through forums  and incentive programs for continual involvement. A strong understanding of ethical organizational policies provides the foundation for consistent monitoring to maintain an ethical culture. 

In this fifth course of the CertNexus Certified Ethical Emerging Technologist (CEET) professional certificate, learners will develop strategies to lead an applied ethics initiative, champion its crucial importance, and promote an ethical organizational culture. Learners will learn how to develop and implement ethical organizational policies and a code of ethics. They will also be prepared to evaluate the effectiveness of policies with internal and external stakeholders.

This course is the fifth of five courses within the Certified Ethical Emerging Technologist (CEET) professional certificate. The preceding courses are titled Promote the Ethical Use of Data-Driven Technologies, Turn Ethical Frameworks into Actionable Steps, Detect and Mitigate Ethical Risks, and Communicate Effectively about Ethical Challenges in Data-Driven Technologies.",6972.0,28536.0,4.6,65.0
Create digit recognition web app with Streamlit,https://www.coursera.org/learn/create-digit-recognition-web-app-with-streamlit,Data Science,Machine Learning,Parth Dhameliya,"In this 1-hour long project-based course, you will learn how to create a digit recognition web application using streamlit. This project is divided into two stages. In the first stage, you are going to write the training pipeline in which you will load MNIST Handwritten dataset. You will write the training and validation functions in order to train and validate the dataset. Lastly, in this stage you will do inference. In the second stage, you will use the best trained model from the training pipeline and you will use that in your web app. You will create the web user interface using streamlit python library. In this web app a user will draw a digit and given that drawn digit, the best trained model will output the probabilities.",,,,
Creating Advanced Reports with SAS Visual Analytics,https://www.coursera.org/learn/advanced-reports-sas-va,Data Science,Data Analysis,Nicole Ball,"In this course, you learn how to create advanced data items, filters, and parameters in SAS Visual Analytics.",8972.0,11594.0,4.7,194.0
Creating Custom Callbacks in Keras,https://www.coursera.org/learn/custom-callbacks-keras,Data Science,Machine Learning,Amit Yadav,"In this 1.5-hour long project-based course, you will learn to create a custom callback function in Keras and use the callback during a model training process. We will implement the callback function to perform three tasks: Write a log file during the training process, plot the training metrics in a graph during the training process, and reduce the learning rate during the training with each epoch.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Prerequisites:
In order to be successful in this project, you should be familiar with Python, Neural Networks, and the Keras framework. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3270.0,,4.7,67.0
Creating Dashboards and Storytelling with Tableau,https://www.coursera.org/learn/dataviz-dashboards,Data Science,Data Analysis,"Govind Acharya, Hunter Whitney","Leveraging the visualizations you created in the previous course, Visual Analytics with Tableau, you will create dashboards that help you identify the story within your data, and you will discover how to use Storypoints to create a powerful story to leave a lasting impression with your audience.

You will balance the goals of your stakeholders with the needs of your end-users, and be able to structure and organize your story for maximum impact. Throughout the course you will apply more advanced functions within Tableau, such as hierarchies, actions and parameters to guide user interactions.  For your final project, you will create a compelling narrative to be delivered in a meeting, as a static report, or in an interactive display online.",46951.0,66539.0,4.6,910.0
Creating Features for Time Series Data,https://www.coursera.org/learn/time-series-features,Data Science,Data Analysis,Chip Wells,"This course focuses on data exploration, feature creation, and feature selection for time sequences. The topics discussed include binning, smoothing, transformations, and data set operations for time series, spectral analysis, singular spectrum analysis, distance measures, and motif analysis. 

In this course you learn to perform motif analysis and implement analyses in the spectral or frequency domain. You also discover how distance measures work, implement applications, explore signal components, and create time series features.

This course is appropriate for analysts with a quantitative background as well as domain experts who would like to augment their time-series tool box. Before taking this course, you should be comfortable with basic statistical concepts. You can gain this experience by completing the Statistics with SAS course. Familiarity with matrices and principal component analysis are also helpful but not required.",,2327.0,,
Creating Models using Smartpls,https://www.coursera.org/learn/smartpls-advanced-regression,Data Science,Data Analysis,Shalini Gopalkrishnan ,"In this 1-hour long project-based course, you will learn how to  create path models using Smartpls. We will take a project on changing behavior and check if attitudes or subjective norms impact behavior the most.
 We will learn how to launch this new software, create the model and run it. We will then show you how to interpret the same.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,17.0
Creating Multi Task Models With Keras,https://www.coursera.org/learn/multi-task-models-keras,Data Science,Machine Learning,Amit Yadav,"In this 1 hour long guided project, you will learn to create and train multi-task, multi-output models with Keras. You will learn to use Keras' functional API to create a multi output model which will be trained to learn two different labels given the same input example. The model will have one input but two outputs. A few of the shallow layers will be shared between the two outputs, you will also use a ResNet style skip connection in the model. If you are familiar with Keras, you have probably come across examples of models that are trained to perform multiple tasks. For example, an object detection model where a CNN is trained to find all class instances in the input images as well as give a regression output to localize the detected class instances in the input. Being able to use Keras' functional API is a first step towards building complex, multi-output models like object detection models.

We will be using TensorFlow as our machine learning framework. The project uses the Google Colab environment. You will need prior programming experience in Python. You will also need prior experience with Keras. Consider this to be an intermediate level Keras project. This is a practical, hands on guided project for learners who already have theoretical understanding of Neural Networks, Convolutional Neural Networks, and optimization algorithms like gradient descent but want to understand how to use use Keras to write custom, more complex models than just plain sequential neural networks.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3138.0,,4.6,61.0
Creating a Data Transformation Pipeline with Cloud Dataprep,https://www.coursera.org/learn/googlecloud-creating-a-data-transformation-pipeline-with-cloud-dataprep-dymxo,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Creating a Data Warehouse Through Joins and Unions,https://www.coursera.org/learn/googlecloud-creating-a-data-warehouse-through-joins-and-unions-z45uo,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Creating a Looker Modeled Query and Working with Quick Start,https://www.coursera.org/learn/googlecloud-creating-a-looker-modeled-query-and-working-with-quick-start-ehagk,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Creating a Wordcloud using NLP and TF-IDF in Python,https://www.coursera.org/learn/wordcloud-nlp-tfidf-python,Data Science,Machine Learning,Dr. Nikunj Maheshwari,"By the end of this project, you will learn how to create a professional looking wordcloud from a text dataset in Python. You will use an open source dataset containing Christmas recipes and will create a wordcloud of the most important ingredients used in these recipes. I will teach you how load a JSON dataset, clean the dataset by removing encodings and unwanted characters, and lemmatize your dataset. I will also teach you how to calculate TF-IDF weights of words in your dataset and use these weights to create a wordcloud. You will create a ready-to-use Jupyter notebook for creating a wordcloud on any text dataset. 

Lemmatization is a process of removing inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma. TF-IDF stands for term frequency-inverse document frequency. TF-IDF gives a weight to each word which tells how important that term is. Using both lemmatization and TF-IDF, one can find the important words in the text dataset and use these important words to create the wordcloud. For example, these datasets could be customer complaints and the business can focus on the important issues that the customers are facing. Wordcloud is a powerful resource which can be used in reports and presentations.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Creating an Interactive Graph with Tableau Public,https://www.coursera.org/learn/tableau-public-interactive-graph,Data Science,Data Analysis,Emily Carlson,"By the end of this guided project, learners will have created an interactive graph that applies principles of data visualization to tell a story using basic sales data. This project will illustrate some of the basic features of Tableau software and allow learners to obtain a good introduction to using the open source software, Tableau Public. In this project, learners will use sample data as a building block to  create a shareable interactive data visualization chart. This skill is helpful for anyone interested in learning more about how to begin working with data to tell a story, highlight change over time, see and understand data, or make well-informed data driven decisions. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,11.0
Creating an Interactive KPI Management Dashboard in Tableau,https://www.coursera.org/learn/interactive-kpi-tableau-dashboard,Data Science,Data Analysis,Emily Kund,"In less than one hour, you will learn how to connect to data, create key performance indicators, create sparkline charts, create a dashboard map, create dual axis charts and put it all together in a well-formatted and interactive dashboard. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",1913.0,,4.5,36.0
Crime Zone Heatmaps with Python and Folium,https://www.coursera.org/learn/crime-zone-heatmaps-python-folium,Data Science,Data Analysis,Daniel Romaniuk,"In this one hour long project-based course, you will tackle a real-world problem in data analysis and visualization.  You will process a dataset of crime incidents in the city of Boston, and use this data to create an animated heatmap displaying crime hotspots.

Heatmaps use color to display a quantity that changes over two dimensions.  
By the end of this project, you will have created heatmaps using code you will write in Python.",,,,
Création de chaînes en Python,https://www.coursera.org/learn/creation-de-chaines-en-python,Data Science,Machine Learning,Mirna Saad,"Dans ce cours d'une heure, basé sur un projet vous apprendrez les principes de base de la création de chaînes en python, ainsi que les méthodes et les propriétés des chaînes en Python.
A la fin de ce projet, vous aurez appris la chaîne en Python tel que sa définition , sa création , son impression, ses notions de base , son indexation, ses propriétés et ses méthodes.",,,,
Curso Completo de Data Science,https://www.coursera.org/learn/curso-completo-data-science,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender Data Science de manera práctica y aplicada. Aprenderemos desde cero todo el proceso y fases del data science, desarrollando un proyecto práctico de cada una de estas fases.
Gracias a ello aprenderás a desarrollar un modelo completo de Machine learning, desde el pre-procesamiento de datos hasta la validación del modelo.",,,,
Curso Completo de Deep Learning,https://www.coursera.org/learn/curso-completo-deep-learning,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender Deep Learning con ejercicios aplicados. Aprenderás desde cero los fundamentos del Deep Learning. Después irás aprendiendo a desarrollar redes neuronales con Python y Keras a través de ejercicios prácticos.

Gracias a este curso aprenderás a programar tus propios modelos de Deep Learning. Gracias a esto podrás predecir si un cliente comprará o no un producto, el precio de la vivienda, etc.",,,,
Curso Completo de Machine Learning en Microsoft Power BI,https://www.coursera.org/learn/curso-completo-machine-learning-microsoft-powerbi,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a integrar modelos de Machine Learning en tus dashboards de Power BI Desktop. Aprenderás, de manera practica y efectiva a generar y evaluar diferentes tipos de modelos de ML como: clasificación, regresión, reglas de asociación, clustering y detección de anomalías.",,,,
Curso Completo de Power BI Desktop,https://www.coursera.org/learn/curso-completo-power-bi,Data Science,Data Analysis,Leire Ahedo,Este proyecto es un curso práctico y efectivo para aprender a programar Power BI desde cero. Te permitirá adquirir los conocimientos de Power BI Desktop de manera práctica y efectiva. También te permitirá aprender las nociones básicas de DAX y a generar tu propio dashboard.,10381.0,,4.4,500.0
Curso Completo de Power BI Service,https://www.coursera.org/learn/curso-completo-power-bi-service,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender en profundidad la herramienta de Power BI Service. Practicaremos con las diferentes funcionalidades de Power BI Service, desde la publicación de informes hasta la creación de alarmar y quick insights. Practicaremos también con las funciones de preguntas en lenguaje natural (NLP) y seguridad a nivel de fila.
Al finalizar este curso sabrás como crear y compartir informes en Power BI Service con tu organización.",,,3.8,12.0
Curso Completo de Spark con Databricks (Big Data),https://www.coursera.org/learn/curso-completo-spark-databricks,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a utilizar el entorno de Big Data de Spark y Databricks desde cero. Aprenderás, de manera practica y efectiva a generar a utilizar todos los componentes de Spark como Spark SQL, MLlib... Además desarrollaras un modelo de Machine Learning completo con Spark en Databricks.",,,3.9,14.0
Curso final de análisis computacional de datos de Google: completa un caso práctico,https://www.coursera.org/learn/completa-un-caso-practico,Data Science,Data Analysis,Google Career Certificates,"Este es el octavo curso del Certificado de análisis computacional de datos de Google. Tendrás la oportunidad de realizar un caso práctico opcional que te ayudará a prepararte para la búsqueda de empleos de análisis computacional de datos. Los empleadores suelen usar casos prácticos para evaluar las destrezas analíticas. En tu caso práctico, elegirás un escenario creado en función del análisis de datos. Luego, harás preguntas sobre los datos de este escenario y los prepararás, procesarás, analizarás y visualizarás, además de actuar en función de ellos. También aprenderás otras habilidades útiles para la búsqueda de empleos mediante videos sobre preguntas y respuestas frecuentes en las entrevistas, materiales de ayuda para crear un portfolio en línea y mucho más. Los analistas de datos actuales de Google seguirán dándote instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, serás capaz de:
 - Aprender los beneficios y los posibles usos de los casos prácticos y los portfolios en la búsqueda de empleo.
 - Explorar escenarios de entrevistas en el mundo real y preguntas frecuentes de estas entrevistas.
 - Descubrir de qué manera los casos prácticos pueden formar parte del proceso de entrevista laboral. 
 - Analizar y considerar diversos escenarios de casos prácticos. 
 - Tener la oportunidad de realizar tu propio caso práctico para agregarlo a tu portfolio.",1969.0,39209.0,4.8,85.0
Custom Attribution Modeling with Google Analytics,https://www.coursera.org/learn/custom-attribution-modeling-with-google-analytics,Data Science,Data Analysis,Angelo Paolillo,"In this 1-hour long project-based course, you will learn how to build and share a custom attribution model in Google Analytics, understand attribution modeling, export and import data for elaboration outside of Analytics platform.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4191.0,,4.5,82.0
"Custom Models, Layers, and Loss Functions with TensorFlow",https://www.coursera.org/learn/custom-models-layers-loss-functions-with-tensorflow,Data Science,Machine Learning,"Laurence Moroney, Eddy Shyu","In this course, you will:

• Compare Functional and Sequential APIs, discover new models you can build with the Functional API, and build a model that produces multiple outputs including a Siamese network.
• Build custom loss functions (including the contrastive loss function used in a Siamese network) in order to measure how well a model is doing and help your neural network learn from training data. 
• Build off of existing standard layers to create custom layers for your models, customize a network layer with a lambda layer, understand the differences between them, learn what makes up a custom layer, and explore activation functions. 
• Build off of existing models to add custom functionality, learn how to define your own custom class instead of using the Functional or Sequential APIs, build models that can be inherited from the TensorFlow Model class, and build a residual network (ResNet) through defining a custom model class. 


The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture and tools that help them create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",21863.0,46172.0,4.9,798.0
Custom Prediction Routine on Google AI Platform,https://www.coursera.org/learn/custom-prediction-routine-google-ai-platform,Data Science,Machine Learning,Amit Yadav,"Please note: You will need a Google Cloud Platform account to complete this course. Your GCP account will be charged as per your usage. Please make sure that you are able to access Google AI Platform within your GCP account. You should be familiar with python programming, and Google Cloud Platform before starting this hands on project. Please also ensure that you have access to the custom prediction routine feature in Google AI Platform.

In this 2-hour long project-based course, you will learn how to deploy, and use a model on Google’s AI Platform. Normally, any model trained with the TensorFlow framework is quite easy to deploy, and you can simply upload a Saved Model on Google Storage, and create an AI Platform model with it. But, in practice, we may not always use TensorFlow. Fortunately, the AI Platform allows for custom prediction routines as well and that’s what we are going to focus on. Instead of converting a Keras model to a TensorFlow Saved Model, we will use the h5 ﬁle as is. Additionally, since we will be working with image data, we will use this opportunity to look at encoding and decoding of byte data into string for data transmission and then encoding of the received data in our custom prediction routine on the AI Platform before using it with our model.  

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",13796.0,,4.6,420.0
Custom Reports in Google Analytics,https://www.coursera.org/learn/custom-reports-in-google-analytics,Data Science,Data Analysis,Carma Baughman,"In this project, you will create three custom reports in Google Analytics, using three different methods. You will understand the building blocks of a custom report. You will determine what data is needed for a custom report. And, you will create the custom report to best meet your analysis and monitoring needs. You will also discover the Google Gallery where you can find various types of custom reports, and import the ones that best meet your needs.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7518.0,,4.6,146.0
Custom and Distributed Training with TensorFlow,https://www.coursera.org/learn/custom-distributed-training-with-tensorflow,Data Science,Machine Learning,"Laurence Moroney, Eddy Shyu","In this course, you will:

• Learn about Tensor objects, the fundamental building blocks of TensorFlow, understand the difference between the eager and graph modes in TensorFlow, and learn how to use a TensorFlow tool to calculate gradients.
• Build your own custom training loops using GradientTape and TensorFlow Datasets to gain more flexibility and visibility with your model training. 
• Learn about the benefits of generating code that runs in graph mode, take a peek at what graph code looks like, and practice generating this more efficient code automatically with TensorFlow’s tools.
• Harness the power of distributed training to process more data and train larger models, faster, get an overview of various distributed training strategies, and practice working with a strategy that trains on multiple GPU cores, and another that trains on multiple TPU cores.


The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture and tools that help them create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",11827.0,23872.0,4.8,321.0
Customer Segmentation using K-Means Clustering in R,https://www.coursera.org/learn/customer-segmentation-using-k-means-clustering-in-r,Data Science,Machine Learning,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course, Customer Segmentation using K-Means Clustering in R. In this project, you will learn how to perform customer market segmentation on mall customers data using different R packages.
By the end of this 2-and-a-half-hour long project, you will understand how to get the mall customers data into your RStudio workspace and explore the data. By extension, you will learn how to use the ggplot2 package to render beautiful plots of the data. Also, you will learn how to get the optimal number of clusters for the customers' segments and use K-Means to create distinct groups of customers based on their characteristics. Finally, you will learn how to use the R markdown file to organise your work and how to knit your code into an HTML document for publishing.
Although you do not need to be a data analyst expert or data scientist to succeed in this guided project, it requires a basic knowledge of using R, especially writing R syntaxes. Therefore, to complete this project, you must have prior experience with using R. If you are not familiar with working with using R, please go ahead to complete my previous project titled: “Getting Started with R”. It will hand you the needed knowledge to go ahead with this project on Customer Segmentation. However, if you are comfortable with working with R, please join me on this beautiful ride! Let’s get our hands dirty!",,,,
Customising your models with TensorFlow 2,https://www.coursera.org/learn/customising-models-tensorflow2,Data Science,Machine Learning,Dr Kevin Webster,"Welcome to this course on Customising your models with TensorFlow 2!

In this course you will deepen your knowledge and skills with TensorFlow, in order to develop fully customised deep learning models and workflows for any application. You will use lower level APIs in TensorFlow to develop complex model architectures, fully customised layers, and a flexible data workflow. You will also expand your knowledge of the TensorFlow APIs to include sequence models.

You will put concepts that you learn about into practice straight away in practical, hands-on coding tutorials, which you will be guided through by a graduate teaching assistant. In addition there is a series of automatically graded programming assignments for you to consolidate your skills.

At the end of the course, you will bring many of the concepts together in a Capstone Project, where you will develop a custom neural translation model from scratch.

TensorFlow is an open source machine library, and is one of the most widely used frameworks for deep learning. The release of TensorFlow 2 marks a step change in the product development, with a central focus on ease of use for all users, from beginner to advanced level. 

This course follows on directly from the previous course Getting Started with TensorFlow 2. The additional prerequisite knowledge required in order to be successful in this course is proficiency in the python programming language, (this course uses python 3), knowledge of general machine learning concepts (such as overfitting/underfitting, supervised learning tasks, validation, regularisation and model selection), and a working knowledge of the field of deep learning, including typical model architectures (MLP, CNN, RNN, ResNet), and concepts such as transfer learning, data augmentation and word embeddings.",11600.0,21363.0,4.8,163.0
Cómo combinar y analizar datos complejos,https://www.coursera.org/learn/data-collection-analytics-project-es,Data Science,Data Analysis,"Richard Valliant, Ph.D.","En este curso, aprenderás a usar las ponderaciones de las encuestas para estimar estadísticas descriptivas (como medias y totales) y cantidades más complejas (como parámetros de modelos para regresiones lineales y logísticas).  Se explicarán las capacidades de software, haciendo especial hincapié en R®.  El curso también abarcará nociones básicas sobre vinculación de registros y búsqueda de coincidencias estadísticas, dos procesos que son cada vez más importantes para combinar datos de fuentes distintas.  En el curso, también se exploran los problemas éticos que suscrita la combinación de conjuntos de datos.  Es posible que haga falta obtener el consentimiento informado de las personas para que permitan la vinculación de sus datos. Conocerás las diferencias entre los requisitos legales de distintos países.",,,,
Cómo importar datos y crear visualizaciones en Python,https://www.coursera.org/learn/como-importar-datos-y-crear-visualizaciones-en-python,Data Science,Data Analysis,Iván Pinar Domínguez,"Al final de este proyecto, podrás importar fuentes básicas de datos en Python y crear potentes visualizaciones a partir de su información y con muy pocas instrucciones de código.

En este proyecto guiado aprenderá qué es el Data Science y cómo podemos dominarlo con el lenguaje Python desde cero.

Python tiene un inmenso potencial con todas las librerías enfocadas en Data Science que le harán cambiar su día a día en el análisis de datos aportándole un salto cualitativo en su carrera profesional mejorando sustancialmente sus habilidades analíticas de manera muy eficiente.",,,,
Cómo manejar datos faltantes,https://www.coursera.org/learn/missing-data-es,Data Science,Data Analysis,"Richard Valliant, Ph.D.","En este curso, se tratarán los pasos que se deben seguir para ponderar encuestas de muestra. Se incluirán los métodos para ajustar las no respuestas y para usar datos externos a la encuesta para calibrarla.  Entre las técnicas que se abordarán, se encuentran los ajustes que se utilizan para las propensiones de respuesta estimada, la postestratificación, el rastrillado y la estimación de regresión general.  Asimismo, se discutirán las técnicas alternativas para imputar los valores de los elementos faltantes.  Se tratarán las funciones que ofrecen los diferentes paquetes de software estadístico R®, Stata® y SAS® para la ponderación y la imputación.",,,,
"Cómo usar funciones, métodos y bucles en Python desde cero",https://www.coursera.org/learn/como-usar-funciones-mtodos-y-bucles-en-python-desde-cero,Data Science,Data Analysis,Iván Pinar Domínguez,"Al final de este proyecto, podrás interiorizar los fundamentos del lenguaje Python siendo capaz de crear funciones para reutilizar el código, aplicar métodos de Python y construir bucles para el uso eficiente de Python.

Estos conocimientos le ayudarán a automatizar gran parte del trabajo de análisis de datos convirtiendo sus actividades en un trabajo más eficiente mejorando sustancialmente sus habilidades analíticas.",,,,
D3Js Basics,https://www.coursera.org/learn/d3-basics,Data Science,Data Analysis,Ola Giwa,"In this 1.5-hour long project-based course I will show you the basic concepts to create data visualizations in D3.js. You will learn how to use  SVGs, select, and bind data in order to create a  bar chart. We will be visualizing firecracker injuries in 2019. This data is from the U.S. Consumer Product Safety Commission (CPSC) Fireworks Annual Report. Inspired by recent events this summer we are going to visualize firework injuries in the United States.  Firework injury data can be found at U.S. Consumer Product Safety Commission (CPSC) .",,,,
"Dasar-dasar Analitik Data: Data, Data di Mana-mana",https://www.coursera.org/learn/dasar-dasar-analitik-data-data-data-di-mana-mana,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi pertama dalam program Sertifikasi Data Analitik Google. Materi ini akan membekali Anda dengan keterampilan yang Anda butuhkan untuk melamar kerja sebagai analis data tingkat pemula. Semua jenis organisasi membutuhkan analis data untuk memperbaiki proses operasional mereka, mengidentifikasi peluang dan tren, meluncurkan produk baru, dan membuat keputusan yang tepat. Di materi ini, Anda akan diperkenalkan dengan dunia analitik data berdasarkan kurikulum yang langsung dikembangkan oleh Google. Materi yang dibahas mencakup berbagai topik penting dalam analisis data, dan dirancang untuk memberi gambaran umum tentang apa yang akan Anda pelajari dalam program Sertifikasi Analitik Data Google. Analis data Google akan mengajarkan dan memberi tahu Anda cara untuk menyelesaikan tugas analis data yang umum dengan menggunakan alat dan sumber daya terbaik.

Peserta didik yang menyelesaikan program sertifikasi ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak membutuhkan pengalaman apa pun.

Di akhir materi ini, Anda akan
- Mendapatkan pemahaman tentang praktik dan proses yang digunakan oleh analis data junior sehari-hari. 
- Mempelajari tentang keterampilan analitis utama (pembersihan data, analisis data, visualisasi data) dan alat (spreadsheet, SQL, pemrograman R, Tableau) yang dapat ditambahkan di set perangkat profesional Anda. 
- Menemukan berbagai macam istilah dan konsep yang berhubungan dengan pekerjaan analis data junior, seperti siklus hidup data dan proses analisis data. 
- Mengevaluasi peran analitik dalam ekosistem data. 
- Melakukan penilaian mandiri dengan pola pikir analitis. 
- Menelusuri peluang kerja yang tersedia setelah Anda menyelesaikan  program ini, dan mempelajari tentang praktik baik dalam pencarian kerja.",9103.0,568298.0,4.9,725.0
Dashboarding and Deployment,https://www.coursera.org/learn/dashboarding-deployment,Data Science,Data Analysis,"Julie Pai, Majed Al-Ghandour","This course will take you through the various parts of analytical dashboarding: from best practices for designing a dashboard, creating a unified analytical environment, to deploying and publishing visualizations. We will briefly discuss the advanced visualization techniques and you will develop an information layout of the biggest gainers and losers in the financial markets and compare those movements to the economic data as your capstone project.",,,,
Data Analysis Tools,https://www.coursera.org/learn/data-analysis-tools,Data Science,Data Analysis,"Jen Rose, Lisa Dierker","In this course, you will develop and test hypotheses about your data. You will learn a variety of statistical tests, as well as strategies to know how to apply the appropriate one to your specific data and question. Using your choice of two powerful statistical software packages (SAS or Python), you will explore ANOVA, Chi-Square, and Pearson correlation analysis. This course will guide you through basic statistical principles to give you the tools to answer questions you have developed. Throughout the course, you will share your progress with others to gain valuable feedback and provide insight to other learners about their work.",43903.0,9225.0,4.5,405.0
Data Analysis Using Pyspark,https://www.coursera.org/learn/data-analysis-using-pyspark,Data Science,Data Analysis,Ahmad Varasteh,"One of the important topics that every data analyst should be familiar with is the distributed data processing technologies. As a data analyst, you should be able to apply different queries to your dataset to extract useful information out of it. but what if your data is so big that working with it on your local machine is not easy to be done. That is when the distributed data processing and Spark Technology will become handy. So in this project, we are going to work with pyspark module in python and we are going to use google colab environment in order to apply some queries to the dataset we have related to lastfm website which is an online music service where users can listen to different songs. This dataset is containing two csv files listening.csv and genre.csv. Also, we will learn how we can visualize our query results using matplotlib.",8989.0,,4.4,238.0
Data Analysis Using Python,https://www.coursera.org/learn/data-analysis-python,Data Science,Data Analysis,Brandon Krakowsky,"This course provides an introduction to basic data science techniques using Python.  Students are introduced to core concepts like Data Frames and joining data, and learn how to use data analysis libraries like pandas, numpy, and matplotlib.  This course provides an overview of loading, inspecting, and querying real-world data, and how to answer basic questions about that data.  Students will gain skills in data aggregation and summarization, as well as basic data visualization.",14089.0,59655.0,4.5,268.0
Data Analysis and Interpretation Capstone,https://www.coursera.org/learn/data-analysis-capstone,Data Science,Data Analysis,"Jen Rose, Lisa Dierker","The Capstone project will allow you to continue to apply and refine the data analytic techniques learned from the previous courses in the Specialization to address an important issue in society. You will use real world data to complete a project with our industry and academic partners. For example, you can work with our industry partner, DRIVENDATA, to help them solve some of the world's biggest social challenges! DRIVENDATA at www.drivendata.org, is committed to bringing cutting-edge practices in data science and crowdsourcing to some of the world's biggest social challenges and the organizations taking them on. 

Or, you can work with our other industry partner, The Connection (www.theconnectioninc.org) to help them better understand recidivism risk for people on parole seeking substance use treatment. For more than 40 years, The Connection has been one of Connecticut’s leading private, nonprofit human service and community development agencies. Each month, thousands of people are assisted by The Connection’s diverse behavioral health, family support and community justice programs. The Connection’s Institute for Innovative Practice was created in 2010 to bridge the gap between researchers and practitioners in the behavioral health and criminal justice fields with the goal of developing maximally effective, evidence-based treatment programs. 

A major component of the Capstone project is for you to be able to choose the information from your analyses that best conveys results and implications, and to tell a compelling story with this information. By the end of the course, you will have a professional quality report of your findings that can be shown to colleagues and potential employers to demonstrate the skills you learned by completing the Specialization.",3578.0,1934.0,4.8,44.0
Data Analysis and Presentation Skills: the PwC Approach Final Project,https://www.coursera.org/learn/data-analysis-project-pwc,Data Science,Data Analysis,Alex Mannella,"In this Capstone Project, you'll bring together all the new skills and insights you've learned through the four courses. You'll be given a 'mock' client problem and a data set. You'll need to analyze the data to gain business insights, research the client's domain area, and create recommendations. You'll then need to visualize the data in a client-facing presentation. You'll bring it all together in a recorded video presentation.

This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",4355.0,8834.0,4.7,237.0
Data Analysis and Reporting in SAS Visual Analytics,https://www.coursera.org/learn/data-analysis-reporting-sas-va,Data Science,Data Analysis,Nicole Ball,"In this course, you learn how to use SAS Visual Analytics on SAS Viya to modify data for analysis, perform data discovery and analysis, and create interactive reports.",12444.0,15029.0,4.8,324.0
Data Analysis in Python with pandas & matplotlib in Spyder,https://www.coursera.org/learn/codio-data-analysis-in-python-with-pandas-and-matplotlib-in-spyder,Data Science,Data Analysis,"Kevin Noelsaint, Anh Le","Code and run your first Python script in minutes without installing anything!

This course is designed for learners with no coding experience, providing a crash course in Python, which enables the learners to delve into core data analysis topics that can be transferred to other languages. In this course, you will learn how to import and organize your data, use functions to gather descriptive statistics, and perform statistical tests.

To allow for a truly hands-on, self-paced learning experience, this course is video-free.

Assignments contain short explanations with images and runnable code examples with suggested edits to explore code examples further, building a deeper understanding by doing. You’ll benefit from instant feedback from a variety of assessment items along the way, gently progressing from quick understanding checks (multiple choice, fill in the blank, and un-scrambling code blocks) to small, approachable coding exercises that take minutes instead of hours. Finally, a longer-form lab at the end of the course will provide you an opportunity to apply all learned concepts within a real-world context.",,2142.0,,
Data Analysis in R with RStudio & Tidyverse,https://www.coursera.org/learn/codio-data-analysis-in-r-with-rstudio-and-tidyverse,Data Science,Data Analysis,Anh Le,"Code and run your first R program in minutes without installing anything!

This course is designed for learners with no prior coding experience, providing foundational knowledge of data analysis in R. The modules in this course cover descriptive statistics, importing and wrangling data, and using statistical tests to compare populations and describe relationships. This course presents examples in R using the industry-standard Integrated Development Environment (IDE) RStudio.

To allow for a truly hands-on, self-paced learning experience, this course is video-free.

Assignments contain short explanations with images and runnable code examples with suggested edits to explore code examples further, building a deeper understanding by doing. You’ll benefit from instant feedback from a variety of assessment items along the way, gently progressing from quick understanding checks (multiple choice, fill in the blank, and un-scrambling code blocks) to small, approachable coding exercises that take minutes instead of hours. Finally, a cumulative lab at the end of the course will provide you an opportunity to apply all learned concepts within a real-world context.",,1717.0,4.2,12.0
Data Analysis with Python,https://www.coursera.org/learn/data-analysis-with-python,Data Science,Data Analysis,Joseph Santarcangelo,"Analyzing data with Python is an essential skill for Data Scientists and Data Analysts. This course will take you from the basics of data analysis with Python to building and evaluating data models.  

Topics covered include:  
- collecting and importing data 
- cleaning, preparing & formatting data 
- data frame manipulation 
- summarizing data, 
- building machine learning regression models 
- model refinement 
- creating data pipelines 

You will learn how to import data from multiple sources, clean and wrangle data, perform exploratory data analysis (EDA), and create meaningful data visualizations. You will then predict future trends from data by developing linear, multiple, polynomial regression models & pipelines and learn how to evaluate them.  

In addition to video lectures you will learn and practice using hands-on labs and projects. You will work with several open source Python libraries, including Pandas and Numpy to load, manipulate, analyze, and visualize cool datasets. You will also work with scipy and scikit-learn, to build machine learning models and make predictions.  

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.",279276.0,717968.0,4.7,15863.0
Data Analysis with R,https://www.coursera.org/learn/data-analysis-with-r,Data Science,Data Analysis,"Tiffany Zhu, Yiwen Li, Gabriela de Queiroz","The R programming language is purpose-built for data analysis. R is the key that opens the door between the problems that you want to solve with data and the answers you need to meet your objectives.  This course starts with a question and then walks you through the process of answering it through data. You will first learn important techniques for preparing (or wrangling) your data for analysis. You will then learn how to gain a better understanding of your data through exploratory data analysis, helping you to summarize your data and identify relevant relationships between variables that can lead to insights. Once your data is ready to analyze, you will learn how to develop your model and evaluate and tune its performance. By following this process, you can be sure that your data analysis performs to the standards that you have set, and you can have confidence in the results. 

You will build hands-on experience by playing the role of a data analyst who is analyzing airline departure and arrival data to predict flight delays. Using an Airline Reporting Carrier On-Time Performance Dataset, you will practice reading data files, preprocessing data, creating models, improving models, and evaluating them to ultimately choose the best model. 

Watch the videos, work through the labs, and add to your portfolio. Good luck!

Note: The pre-requisite for this course is basic R programming skills. For example, ensure that you have completed a course like Introduction to R Programming for Data Science from IBM.",9011.0,67904.0,4.7,153.0
Data Analysis with R Programming,https://www.coursera.org/learn/data-analysis-r,Data Science,Data Analysis,Google Career Certificates,"This course is the seventh course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. In this course, you’ll learn about the programming language known as R. You’ll find out how to use RStudio, the environment that allows you to work with R. This course will also cover the software applications and tools that are unique to R, such as R packages. You’ll discover how R lets you clean, organize, analyze, visualize, and report data in new and more powerful ways.  Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
 - Examine the benefits of using the R programming language.
 - Discover how to use RStudio to apply R to your analysis. 
 - Explore the fundamental concepts associated with programming in R. 
 - Explore the contents and components of R packages including the Tidyverse package.
 - Gain an understanding of dataframes and their use in R.
 - Discover the options for generating visualizations in R.
 - Learn about R Markdown for documenting R programming.",226877.0,3229513.0,4.8,5582.0
Data Analysis with Tidyverse,https://www.coursera.org/learn/data-analysis-with-tidyverse,Data Science,Data Analysis,Jane Wall,"This course continues our gentle introduction to programming in R designed for 3 types of learners. It will be right for you, if:

•    you want to do data analysis but don’t know programming
•    you know programming but aren’t too familiar with R
•    you know some R programming but want to learn more about the tidyverse verbs

It is best taken following the first course in the specialization or if you already are familiar with ggplot, RMarkdown, and basic function writing in R.  You will use learn to use readr to read in your data, dplyr to analyze your data, and stringr and forcats to manipulate strings and factors.",,6145.0,,
Data Analyst Career Guide and Interview Preparation,https://www.coursera.org/learn/career-guide-and-interview-prep-for-data-analyst-pc,Data Science,Data Analysis,Skills Network,"This course is designed to prepare you to enter the job market as a data analyst. It provides guidance about the regular functions and tasks of data analysts and their place in the data ecosystem, as well as the opportunities of the profession and some options for career development. It explains practical techniques for creating essential job-seeking materials such as a resume and a portfolio, as well as auxiliary tools like a cover letter and an elevator pitch. You will learn how to find and assess prospective job positions, apply to them, and lay the groundwork for interviewing. You will also get inside tips and steps you can use to perform professionally and effectively at interviews. Let seasoned professionals share their experience to help you get ahead of the competition.",4279.0,18748.0,4.5,90.0
Data Analytics Foundations for Accountancy I,https://www.coursera.org/learn/data-analytics-accountancy-1,Data Science,Data Analysis,Robert Brunner,"Welcome to Data Analytics Foundations for Accountancy I! You’re joining thousands of learners currently enrolled in the course. I'm excited to have you in the class and look forward to your contributions to the learning community.

To begin, I recommend taking a few minutes to explore the course site. Review the material we’ll cover each week, and preview the assignments you’ll need to complete to pass the course. Click Discussions to see forums where you can discuss the course material with fellow students taking the class.

If you have questions about course content, please post them in the forums to get help from others in the course community. For technical problems with the Coursera platform, visit the Learner Help Center.

Good luck as you get started, and I hope you enjoy the course!",7891.0,5782.0,4.0,33.0
Data Analytics Foundations for Accountancy II,https://www.coursera.org/learn/data-analytics-accountancy-2,Data Science,Data Analysis,Robert Brunner,"Welcome to Data Analytics Foundations for Accountancy II!  I'm excited to have you in the class and look forward to your contributions to the learning community.

To begin, I recommend taking a few minutes to explore the course site. Review the material we’ll cover each week, and preview the assignments you’ll need to complete to pass the course. Click Discussions to see forums where you can discuss the course material with fellow students taking the class.

If you have questions about course content, please post them in the forums to get help from others in the course community. For technical problems with the Coursera platform, visit the Learner Help Center.

Good luck as you get started, and I hope you enjoy the course!",3145.0,2125.0,,
Data Analytics en Power BI,https://www.coursera.org/learn/data-analytics-power-bi,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender todo lo que necesitas saber de Data Analytics en Power BI. Te permitirá aprender a realizar funciones analíticas de datos, a identificar outliers, a aplicar técnicas de clustering y series temporales, a analizar los quick insights  y AI insights, entre otros.",4477.0,,4.4,117.0
Data Analytics for Lean Six Sigma,https://www.coursera.org/learn/data-analytics-for-lean-six-sigma,Data Science,Data Analysis,Inez Zwetsloot,"Welcome to this course on Data Analytics for Lean Six Sigma. 

In this course you will learn data analytics techniques that are typically useful within Lean Six Sigma improvement projects. At the end of this course you are able to analyse and interpret data gathered within such a project. You will be able to use Minitab to analyse the data. I will also briefly explain what Lean Six Sigma is.

I will emphasize on use of data analytics tools and the interpretation of the outcome. I will use many different examples from actual Lean Six Sigma projects to illustrate all tools. I will not discuss any mathematical background. 

The setting we chose for our data example is a Lean Six Sigma improvement project. However data analytics tools are very widely applicable. So you will find that you will learn techniques that you can use in a broader setting apart from improvement projects. 

I hope that you enjoy this course and good luck!
Dr. Inez Zwetsloot & the IBIS UvA team",61225.0,65597.0,4.8,2914.0
Data Analytics in Accounting Capstone,https://www.coursera.org/learn/accounting-data-analytics-capstone,Data Science,Data Analysis,Linden Lu,"This capstone is the last course in the Data Analytics in Accountancy Specialization. In this capstone course, you are going to take the knowledge and skills you have acquired from the previous courses and apply them to a real-world problem.

You will be provided with a loan dataset from Lending Club which is the largest peer-to-peer lending platform. You will explore the characteristics of the features in the dataset through statistical analysis, exploratory data analysis and visualization. You will also create a machine learning model to predict whether a loan will be fully paid or not. Finally, you will construct a portfolio with the help of your analysis. The goal is to create a portfolio that achieves better return than the overall return of all loans on the Lending Club platform.",2178.0,,,
Data Engineering with MS Azure Synapse Apache Spark Pools,https://www.coursera.org/learn/data-engineering-with-ms-azure-synapse-apache-spark-pools,Data Science,Data Analysis, Microsoft,"In this course, you will learn how to perform data engineering with Azure Synapse Apache Spark Pools, which enable you to boost the performance of big-data analytic applications by in-memory cluster computing.

You will learn how to differentiate between Apache Spark, Azure Databricks, HDInsight, and SQL Pools and understand the use-cases of data-engineering with Apache Spark in Azure Synapse Analytics. You will also learn how to ingest data using Apache Spark Notebooks in Azure Synapse Analytics and transform data using DataFrames in Apache Spark Pools in Azure Synapse Analytics. You will integrate SQL and Apache Spark pools in Azure Synapse Analytics. You will also learn how to monitor and manage data engineering workloads with Apache Spark in Azure Synapse Analytics.

This course is part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services for anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). You will take a practice exam that covers key skills measured by the certification exam.

This is the sixth course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",2158.0,11022.0,4.0,16.0
Data Integration with Microsoft Azure Data Factory,https://www.coursera.org/learn/azure-data-factory-data-integration,Data Science,Data Analysis, Microsoft,"In this course, you will learn how to create and manage data pipelines in the cloud using Azure Data Factory.

This course is part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services. It is ideal for anyone interested in preparing for the DP-203: Data Engineering on Microsoft Azure exam (beta). 

This is the third course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",5398.0,52173.0,3.9,68.0
Data Management and Visualization,https://www.coursera.org/learn/data-visualization,Data Science,Data Analysis,Lisa Dierker,"Whether being used to customize advertising to millions of website visitors or streamline inventory ordering at a small restaurant, data is becoming more integral to success. Too often, we’re not sure how use data to find answers to the questions that will make us more successful in what we do. In this course, you will discover what data is and think about what questions you have that can be answered by the data – even if you’ve never thought about data before. Based on existing data, you will learn to develop a research question, describe the variables and their relationships, calculate basic statistics, and present your results clearly. By the end of the course, you will be able to use powerful data analysis tools – either SAS or Python – to manage and visualize your data, including how to deal with missing data, variable groups, and graphs. Throughout the course, you will share your progress with others to gain valuable feedback, while also learning how your peers use data to answer their own questions.",77586.0,11475.0,4.4,915.0
Data Manipulation and Management using MYSQL Workbench,https://www.coursera.org/learn/data-manipulation-and-management-using-mysqlworkbench,Data Science,Data Analysis,Omnya Khaled,"By the end of this project, you will be able to manage data efficiently in a specific database using MYSQL Workbench. You will be able to select data from tables from your database and use keywords in select statements such as LIMIT and Top. You will be able to update the data and filter them using where statements, and also apply conditions with different ways and keywords such as like, and, or, and between. Moreover, you will be able to apply the aggregate functions in your select statement and the grouping by, and finally, you will be able to join tables with each other using three different joins, left, inner and right join. A database management system stores organize and manage a large amount of information within a single software application. The Use of this system increases the efficiency of business operations and reduces overall costs. The world of data is constantly changing and evolving every second. This in turn has created a completely new dimension of growth and challenges for companies around the globe like Google, Facebook, or Amazon.

This guided project is for beginners in the field of data management and databases. It provides you with the basics of managing the database and data. It equips you with knowledge of the first steps in data management and data extraction. This in turn has created a completely new dimension of growth and challenges for companies around the globe like Google, Facebook, or Amazon.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Data Manipulation at Scale: Systems and Algorithms,https://www.coursera.org/learn/data-manipulation,Data Science,Data Analysis,Bill Howe,"Data analysis has replaced data acquisition as the bottleneck to evidence-based decision making --- we are drowning in it.  Extracting knowledge from large, heterogeneous, and noisy datasets requires not only powerful computing resources, but the programming abstractions to use them effectively.  The abstractions that emerged in the last decade blend ideas from parallel databases, distributed systems, and programming languages to create a new class of scalable data analytics platforms that form the foundation for data science at realistic scales.

In this course, you will learn the landscape of relevant systems, the principles on which they rely, their tradeoffs, and how to evaluate their utility against your requirements. You will learn how practical systems were derived from the frontier of research in computer science and what systems are coming on the horizon.   Cloud computing, SQL and NoSQL databases, MapReduce and the ecosystem it spawned, Spark and its contemporaries, and specialized systems for graphs and arrays will be covered.

You will also learn the history and context of data science, the skills, challenges, and methodologies the term implies, and how to structure a data science project.  At the end of this course, you will be able to:

Learning Goals: 
1. Describe common patterns, challenges, and approaches associated with data science projects, and what makes them different from projects in related fields.
2. Identify and use the programming models associated with scalable data manipulation, including relational algebra, mapreduce, and other data flow models.
3. Use database technology adapted for large-scale analytics, including the concepts driving parallel databases, parallel query processing, and in-database analytics
4. Evaluate key-value stores and NoSQL systems, describe their tradeoffs with comparable systems, the details of important examples in the space, and future trends.
5. “Think” in MapReduce to effectively write algorithms for systems including Hadoop and Spark.  You will understand their limitations, design details, their relationship to databases, and their associated ecosystem of algorithms, extensions, and languages.
write programs in Spark
6. Describe the landscape of specialized Big Data systems for graphs, arrays, and streams",58939.0,8128.0,4.3,759.0
Data Manipulation with dplyr in R,https://www.coursera.org/learn/data-manipulation-with-dplyr-in-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Data Manipulation with dplyr in R. In this project, you will learn how to manipulate data with the dplyr package in R.

By the end of this 2-hour long project, you will understand how to use different dplyr verbs such as the select verb, filter verb, arrange verb, mutate verb, summarize verb, and the group_by verb to manipulate the gapminder dataset. Also, you will learn how to combine different dplyr verbs to manipulate the gapminder dataset to get the desired result.

Note, you do not need to be an expert data analyst, data scientist or statistical analyst to be successful in this guided project, just a familiarity with the R language will suffice. If you do not have a prior experience with R, I recommend that you should take the Getting Started with R project before taking this project.",,,4.5,13.0
Data Mining Methods,https://www.coursera.org/learn/data-mining-methods,Data Science,Data Analysis,Qin (Christine) Lv,"This course covers the core techniques used in data mining, including frequent pattern analysis, classification, clustering, outlier analysis, as well as mining complex data and research frontiers in the data mining field. 

Data Mining Methods can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Course logo image courtesy of Lachlan Cormie, available here on Unsplash: https://unsplash.com/photos/jbJp18srifE",1892.0,10378.0,,
Data Mining Pipeline,https://www.coursera.org/learn/data-mining-pipeline,Data Science,Data Analysis,Qin (Christine) Lv,"This course introduces the key steps involved in the data mining pipeline, including data understanding, data preprocessing, data warehousing, data modeling, interpretation and evaluation, and real-world applications.

Data Mining Pipeline can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Course logo image courtesy of Francesco Ungaro, available here on Unsplash: https://unsplash.com/photos/C89G61oKDDA",2749.0,15307.0,,
Data Mining Project,https://www.coursera.org/learn/data-mining-project,Data Science,Data Analysis,"Jiawei Han, ChengXiang Zhai, John C. Hart","Note: You should complete all the other courses in this Specialization before beginning this course.

This six-week long Project course of the Data Mining Specialization will allow you to apply the learned algorithms and techniques for data mining from the previous courses in the Specialization, including Pattern Discovery, Clustering, Text Retrieval, Text Mining, and Visualization, to solve interesting real-world data mining challenges. Specifically, you will work on a restaurant review data set from Yelp and use all the knowledge and skills you’ve learned from the previous courses to mine this data set to discover interesting and useful knowledge. The design of the Project emphasizes: 1) simulating the workflow of a data miner in a real job setting; 2) integrating different mining techniques covered in multiple individual courses; 3) experimenting with different ways to solve a problem to deepen your understanding of techniques; and 4) allowing you to propose and explore your own ideas creatively. 

The goal of the Project is to analyze and mine a large Yelp review data set to discover useful knowledge to help people make decisions in dining. The project will include the following outputs: 

1. Opinion visualization: explore and visualize the review content to understand what people have said in those reviews.
2. Cuisine map construction: mine the data set to understand the landscape of different types of cuisines and their similarities.
3. Discovery of popular dishes for a cuisine: mine the data set to discover the common/popular dishes of a particular cuisine.
4. Recommendation of restaurants to help people decide where to dine: mine the data set to rank restaurants for a specific dish and predict the hygiene condition of a restaurant.

From the perspective of users, a cuisine map can help them understand what cuisines are there and see the big picture of all kinds of cuisines and their relations. Once they decide what cuisine to try, they would be interested in knowing what the popular dishes of that cuisine are and decide what dishes to have. Finally, they will need to choose a restaurant. Thus, recommending restaurants based on a particular dish would be useful. Moreover, predicting the hygiene condition of a restaurant would also be helpful. 

By working on these tasks, you will gain experience with a typical workflow in data mining that includes data preprocessing, data exploration, data analysis, improvement of analysis methods, and presentation of results. You will have an opportunity to combine multiple algorithms from different courses to complete a relatively complicated mining task and experiment with different ways to solve a problem to understand the best way to solve it. We will suggest specific approaches, but you are highly encouraged to explore your own ideas since open exploration is, by design, a goal of the Project. 

You are required to submit a brief report for each of the tasks for peer grading. A final consolidated report is also required, which will be peer-graded.",6502.0,8237.0,4.6,42.0
Data Mining Project,https://www.coursera.org/learn/data-mining-theory-practice-project,Data Science,Data Analysis,Qin (Christine) Lv,"This course offers step-by-step guidance and hands-on experience of designing and implementing a real-world data mining project, including problem formulation, literature survey, proposed work, evaluation, discussion and future work. 

Data Mining Project can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Course logo image courtesy of Mariana Proença, available here on Unsplash: https://unsplash.com/photos/_WgnXndHmQ4",,8311.0,,
Data Processing and Feature Engineering with MATLAB,https://www.coursera.org/learn/feature-engineering-matlab,Data Science,Data Analysis,"Michael Reardon, Maria Gavilan-Alfonso, Erin Byrne, Amanda  Wang, Cris LaPierre, Matt Rich, Brandon Armstrong, Adam Filion, Isaac Bruss, Nikola Trica, Brian Buechel, Heather Gorr","In this course, you will build on the skills learned in Exploratory Data Analysis with MATLAB to lay the foundation required for predictive modeling.  This intermediate-level course is useful to anyone who needs to combine data from multiple sources or times and has an interest in modeling.  

These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background. To be successful in this course, you should have some background in basic statistics (histograms, averages, standard deviation, curve fitting, interpolation) and have completed Exploratory Data Analysis with MATLAB. 

Throughout the course, you will merge data from different data sets and handle common scenarios, such as missing data.  In the last module of the course, you will explore special techniques for handling textual, audio, and image data, which are common in data science and more advanced modeling.   By the end of this course, you will learn how to visualize your data, clean it up and arrange it for analysis, and identify the qualities necessary to answer your questions.  You will be able to visualize the distribution of your data and use visual inspection to address artifacts that affect accurate modeling.",13045.0,10304.0,4.7,312.0
Data Processing using Python Collections,https://www.coursera.org/learn/data-processing-python-collection,Data Science,Data Analysis,David Dalsveen,"By the end of this project you will use the Python Collections Counter, the CSV package's DictReader, and the Collections UserList to read student test data and find the most common test scores.

The Python Collection classes are convenience classes that make it easier to process data and extend capabilities of existing classes. The CSV package's DictReader is convenient for reading columnar data. The UserList allows the developer to add functionality to the List, for example to check types. The Counter class is useful for counting common occurrences in arrays and other structures.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Data Science Capstone,https://www.coursera.org/learn/data-science-project,Data Science,Data Analysis,"Jeff Leek, PhD, Roger D. Peng, PhD, Brian Caffo, PhD","The capstone project class will allow students to create a usable/public data product that can be used to show your skills to potential employers. Projects will be drawn from real-world problems and will be conducted with industry, government, and academic partners.",34989.0,12409.0,4.5,1208.0
Data Science Ethics,https://www.coursera.org/learn/data-science-ethics,Data Science,Data Analysis,H.V. Jagadish,"What are the ethical considerations regarding the privacy and control of consumer information and big data, especially in the aftermath of recent large-scale data breaches?

This course provides a framework to analyze these concerns as you examine the ethical and privacy implications of collecting and managing big data. Explore the broader impact of the data science field on modern society and the principles of fairness, accountability and transparency as you gain a deeper understanding of the importance of a shared set of ethical values. You will examine the need for voluntary disclosure when leveraging metadata to inform basic algorithms and/or complex artificial intelligence systems while also learning best practices for responsible data management, understanding the significance of the Fair Information Practices Principles Act and the laws concerning the ""right to be forgotten.""

This course will help you answer questions such as who owns data, how do we value privacy, how to receive informed consent and what it means to be fair.

Data scientists and anyone beginning to use or expand their use of data will benefit from this course. No particular previous knowledge needed.",28919.0,40535.0,4.8,744.0
Data Science Fundamentals for Data Analysts,https://www.coursera.org/learn/data-science-fundamentals-for-data-analysts,Data Science,Probability and Statistics,"Emma Freeman, Mark Roepke","In this course we're going to guide you through the fundamental building blocks of data science, one of the fastest-growing fields in the world! 

With the help of our industry-leading data scientists, we’ve designed this course to build ready-to-apply data science skills in just 15 hours of learning. First, we’ll give you a quick introduction to data science - what it is and how it is used to solve real-world problems. For the rest of the course, we'll teach you the skills you need to apply foundational data science concepts and techniques to solve these real-world problems. 

By the end of this course, you'll be able to leverage your existing data analysis skills to design, execute, assess, and communicate the results of your very own data science projects.",5071.0,15050.0,4.1,35.0
Data Science Methodology,https://www.coursera.org/learn/data-science-methodology,Data Science,Data Analysis,"Alex Aklson, Polong Lin","If there is a shortcut to becoming a Data Scientist, then learning to think and work like a successful Data Scientist is it. Most of the established data scientists follow a similar methodology for solving Data Science problems.  In this course you will learn and then apply this methodology that can be used to tackle any Data Science scenario.  

The purpose of this course is to share a methodology that can be used within data science, to ensure that the data used in problem solving is relevant and properly manipulated to address the question at hand.   

Accordingly, in this course, you will learn:  

- The major steps involved in practicing data science 
- Forming a business/research problem, collecting, preparing & analyzing data, building a model, 
  deploying a model and understanding the importance of feedback  
- Apply the 6 stages of the CRISP-DM methodology, the most popular methodology for Data Science and Data Mining problems 
- How data scientists think! 

To apply the methodology, you will work on a real-world inspired scenario and work with Jupyter Notebooks using Python to develop hands-on experience.",207982.0,296517.0,4.6,18403.0
Data Science Project: MATLAB for the Real World,https://www.coursera.org/learn/matlab-capstone,Data Science,Data Analysis,"Michael Reardon, Brandon Armstrong, Erin Byrne, Adam Filion, Heather Gorr, Maria Gavilan-Alfonso, Matt Rich, Isaac Bruss","Like most subjects, practice makes perfect in Data Science.   In the capstone project, you will apply the skills learned across courses in the Practical Data Science with MATLAB specialization to explore, process, analyze, and model data.   You will choose your own pathway to answer key questions with the provided data.

To complete the project, you must have mastery of the skills covered in other courses in the specialization.  The project will test your ability to import and explore your data, prepare the data for analysis, train a predictive model, evaluate and improve your model, and communicate your results.",3909.0,5299.0,4.7,19.0
Data Science as a Field,https://www.coursera.org/learn/data-science-as-a-field,Data Science,Data Analysis,Jane Wall,"This course provides a general introduction to the field of Data Science. It has been designed for aspiring data scientists, content experts who work with data scientists, or anyone interested in learning about what Data Science is and what it’s used for. Weekly topics include an overview of the skills needed to be a data scientist; the process and pitfalls involved in data science; and the practice of data science in the professional and academic world. This course is part of CU Boulder’s Master’s of Science in Data Science and was collaboratively designed by both academics and industry professionals to provide learners with an insider’s perspective on this exciting, evolving, and increasingly vital discipline.

Data Science as a Field can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",2626.0,24221.0,4.4,17.0
Data Science at Scale - Capstone Project,https://www.coursera.org/learn/datasci-capstone,Data Science,Data Analysis,Bill Howe,"In the capstone, students will engage on a real world project requiring them to apply skills from the entire data science pipeline: preparing, organizing, and transforming data, constructing a model, and evaluating results.    Through a collaboration with Coursolve, each Capstone project is associated with partner stakeholders who have a vested interest in your results and are eager to deploy them in practice.  These projects will not be straightforward and the outcome is not prescribed -- you will need to tolerate ambiguity and negative results!  But we believe the experience will be rewarding and will better prepare you for data science projects in practice.",2261.0,,4.1,22.0
Data Science for Business Innovation,https://www.coursera.org/learn/data-science-for-business-innovation,Data Science,Data Analysis,"Marco Brambilla, Emanuele Della Valle","The Data Science for Business Innovation nano-course is a compendium of the must-have expertise in data science for executives and middle-management to foster data-driven innovation. The course explains what Data Science is and why it is so hyped. 

You will learn:
* the value that Data Science can create
* the main classes of problems that Data Science can solve
* the difference is between descriptive, predictive, and prescriptive analytics
* the roles of machine learning and artificial intelligence. 

From a more technical perspective, the course covers supervised, unsupervised and semi-supervised methods, and explains what can be obtained with classification, clustering, and regression techniques. It discusses the role of NoSQL data models and technologies, and the role and impact of scalable cloud-based computation platforms. All topics are covered with example-based lectures, discussing use cases, success stories, and realistic examples.

Following this nano-course, if you wish to further deepen your data science knowledge, you can attend the Data Science for Business Innovation live course https://professionalschool.eitdigital.eu/data-science-for-business-innovation",11909.0,4940.0,4.3,244.0
Data Science in Real Life,https://www.coursera.org/learn/real-life-data-science,Data Science,Data Analysis,"Brian Caffo, PhD, Jeff Leek, PhD, Roger D. Peng, PhD","Have you ever had the perfect data science experience? The data pull went perfectly. There were no merging errors or missing data. Hypotheses were clearly defined prior to analyses. Randomization was performed for the treatment of interest. The analytic plan was outlined prior to analysis and followed exactly. The conclusions were clear and actionable decisions were obvious. Has that every happened to you? Of course not. Data analysis in real life is messy. How does one manage a team facing real data analyses? In this one-week course, we contrast the ideal with what happens in real life. By contrasting the ideal, you will learn key concepts that will help you manage real life analyses. 

This is a focused course designed to rapidly get you up to speed on doing data science in real life. Our goal was to make this as convenient as possible for you without sacrificing any essential content. We've left the technical information aside so that you can focus on managing your team and moving it forward.

After completing this course you will know how to:

1, Describe the “perfect” data science experience
2. Identify strengths and weaknesses in experimental designs
3. Describe possible pitfalls when pulling / assembling data and learn solutions for managing data pulls.
4. Challenge statistical modeling assumptions and drive feedback to data analysts
5. Describe common pitfalls in communicating data analyses
6. Get a glimpse into a day in the life of a data analysis manager.

The course will be taught at a conceptual level for active managers of data scientists and statisticians.  Some key concepts being discussed include:
1. Experimental design, randomization, A/B testing
2. Causal inference, counterfactuals, 
3. Strategies for managing data quality.
4. Bias and confounding
5. Contrasting machine learning versus classical statistical inference

Course promo:
https://www.youtube.com/watch?v=9BIYmw5wnBI

Course cover image by Jonathan Gross. Creative Commons BY-ND https://flic.kr/p/q1vudb",49035.0,11133.0,4.4,2324.0
Data Science in Stratified Healthcare and Precision Medicine,https://www.coursera.org/learn/datascimed,Data Science,Data Analysis,"Dr Areti Manataki, Dr Frances Wong","An increasing volume of data is becoming available in biomedicine and healthcare, from genomic data, to electronic patient records and data collected by wearable devices. Recent advances in data science are transforming the life sciences, leading to precision medicine and stratified healthcare. 

In this course, you will learn about some of the different types of data and computational methods involved in stratified healthcare and precision medicine.  You will have a hands-on experience of working with such data.  And you will learn from leaders in the field about successful case studies. 

Topics include: (i) Sequence Processing, (ii) Image Analysis, (iii) Network Modelling, (iv) Probabilistic Modelling, (v) Machine Learning, (vi) Natural Language Processing, (vii) Process Modelling and (viii) Graph Data.

Watch the course promo video here: http://edin.ac/2pn350P",20434.0,20149.0,4.6,268.0
Data Science with R - Capstone Project,https://www.coursera.org/learn/data-science-with-r-capstone-project,Data Science,Data Analysis,"Jeff Grossman, Yan Luo","In this capstone course, you will apply various data science skills and techniques that you have learned as part of the previous courses in the IBM Data Science with R Specialization or IBM Data Analytics with Excel and R Professional Certificate.

For this project, you will assume the role of a Data Scientist who has recently joined an organization and be presented with a challenge that requires data collection, analysis, basic hypothesis testing, visualization, and modeling to be performed on real-world datasets. You will collect and understand data from multiple sources, conduct data wrangling and preparation with Tidyverse, perform exploratory data analysis with SQL, Tidyverse and ggplot2, model data with linear regression, create charts and plots to visualize the data, and build an interactive dashboard.

The project will culminate with a presentation of your data analysis report, with an executive summary for the various stakeholders in the organization.",3847.0,14777.0,4.3,20.0
Data Scientist Career Guide and Interview Preparation,https://www.coursera.org/learn/career-guide-and-interview-prep-for-data-science-pc,Data Science,Data Analysis,Skills Network,"This course is designed to prepare you to enter the job market as a data scientist. It provides guidance about the regular functions and tasks of data scientists and their place in the data ecosystem, as well as the opportunities of the profession and some options for career development. It explains practical techniques for creating essential job-seeking materials such as a resume and a portfolio, as well as auxiliary tools like a cover letter and an elevator pitch. You will learn how to find and assess prospective job positions, apply to them, and lay the groundwork for interviewing. You will also get inside tips and steps you can use to perform professionally and effectively at interviews. Let seasoned professionals share their experience to help you get ahead of the competition.",3394.0,22317.0,4.8,39.0
Data Storage in Microsoft Azure,https://www.coursera.org/learn/data-storage-microsoft-azure,Data Science,Data Analysis, Microsoft,"Azure provides a variety of ways to store data: unstructured, archival, relational, and more. In this course, you will learn the basics of storage management in Azure, how to create a Storage Account, and how to choose the right model for the data you want to store in the cloud.

This course part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). 

This is the second in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",5761.0,45168.0,4.4,67.0
Data Storage in Microsoft Azure for Associate Developers,https://www.coursera.org/learn/data-storage-microsoft-azure-developers,Data Science,Data Analysis, Microsoft,"Azure provides a variety of ways to store data: unstructured, archival, relational, and more. In this course, you will learn the basics of storage management in Azure, how to create a Storage Account, and how to choose the right model for the data you want to store in the cloud.

This course part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). 

This is the second in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Professional Certificate program, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",,7795.0,,
Data Storytelling,https://www.coursera.org/learn/data-storytelling,Data Science,Data Analysis,"Julie Pai, Majed Al-Ghandour","This course will cover the more complex concepts that become involved when working beyond simple datasets.  Exploring the connection between visual aspects and data understanding, we will examine how those concepts work together through data storytelling. After reviewing key points on how to avoid problematic visualizations and data misrepresentation, you will continue working in Tableau performing multivariate descriptive analysis of the S&P 500 stock sectors.",,3912.0,,
Data Studio: Qwik Start,https://www.coursera.org/learn/googlecloud-data-studio-qwik-start-bc935,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Data Visualization,https://www.coursera.org/learn/datavisualization,Data Science,Data Analysis,John C. Hart,"Learn the general concepts of data mining along with basic methodologies and applications. Then dive into one subfield in data mining: pattern discovery. Learn in-depth concepts, methods, and applications of pattern discovery in data mining. We will also introduce methods for pattern-based classification and some interesting applications of pattern discovery. This course provides you the opportunity to learn skills and content to practice and engage in scalable pattern discovery methods on massive transactional data, discuss pattern evaluation measures, and study methods for mining diverse kinds of patterns, sequential patterns, and sub-graph patterns.",112192.0,37874.0,4.5,1311.0
Data Visualization & Storytelling in Python,https://www.coursera.org/learn/data-visualization--storytelling-in-python,Data Science,Data Analysis,Ryan Ahmed,"Hello everyone and welcome to this new hands-on project on data visualization and storytelling in python. In this project, we will leverage 3 powerful libraries known as Seaborn, Matplotlib and Plotly to visualize data in an interactive way. This project is practical and directly applicable to many industries. You can add this project to your portfolio of projects which is essential for your next job interview.",,,,
Data Visualization Best Practices,https://www.coursera.org/learn/data-visualization-best-practices,Data Science,Data Analysis,"Julie Pai, Majed Al-Ghandour","In this course, we will cover the basics of visualization and how it fits into the Data Science workflow. We will focus on the main concepts behind the purpose of visualization and the design principles for creating effective, easy-to-communicate results. You will also set up your Tableau environment, practice data loading, and perform univariate descriptive analysis of the S&P 500 stock sectors.",2195.0,3651.0,4.3,10.0
Data Visualization Capstone,https://www.coursera.org/learn/data-visualization-capstone,Data Science,Data Analysis,Collin Paschall,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance.

This is the final course in the Specialization ""Data Visualization and Dashboarding in R."" Learners in this course will enter with a well-developed set of skills making a wide variety of visualizations in R. The focus on this course will applying those skills to a unique project, drawing on publicly available data to tell a compelling story using the data visualization toolkit assembled in the previous courses.",,2555.0,5.0,24.0
Data Visualization and Communication with Tableau,https://www.coursera.org/learn/analytics-tableau,Data Science,Data Analysis,"Daniel Egger, Jana Schaich Borg","One of the skills that characterizes great business data analysts is the ability to communicate practical implications of quantitative analyses to any kind of audience member.  Even the most sophisticated statistical analyses are not useful to a business if they do not lead to actionable advice, or if the answers to those business questions are not conveyed in a way that non-technical people can understand.  

In this course you will learn how to become a master at communicating business-relevant implications of data analyses.  By the end, you will know how to structure your data analysis projects to ensure the fruits of your hard labor yield results for your stakeholders.  You will also know how to streamline your analyses and highlight their implications efficiently using visualizations in Tableau, the most popular visualization program in the business world.  Using other Tableau features, you will be able to make effective visualizations that harness the human brain’s innate perceptual and cognitive tendencies to convey conclusions directly and clearly.  Finally, you will be practiced in designing and persuasively presenting business “data stories” that use these visualizations, capitalizing on business-tested methods and design principles.",204776.0,66512.0,4.7,3128.0
Data Visualization and Dashboards with Excel and Cognos,https://www.coursera.org/learn/data-visualization-dashboards-excel-cognos,Data Science,Data Analysis,"Sandip Saha Joy, Kevin McFaul, Steve Ryan","This course covers some of the first steps in the development of data visualizations using spreadsheets and dashboards. Begin the process of telling a story with your data by creating the many types of charts that are available in spreadsheets like Excel. Explore the different tools of a spreadsheet, such as the important pivot function and the ability to create dashboards and learn how each one has its own unique property to transform your data. Continue to gain valuable experience by becoming familiar with the popular analytics tool - IBM Cognos Analytics - to create interactive dashboards.

By completing this course, you will have a basic understanding of using spreadsheets as a data visualization tool. You will gain the ability to effectively create data visualizations, such as charts or graphs, and will begin to see how they play a key role in communicating your data analysis findings. All of this can be accomplished by learning the basics of data analysis with Excel and IBM Cognos Analytics, without having to write any code. By the end of this course you will be able to describe common dashboarding tools used by a data analyst, design and create a dashboard in a cloud platform, and begin to elevate your confidence level in creating intermediate level data visualizations. 

Throughout this course you will encounter numerous hands-on labs and a final project. With each lab, gain hands-on experience with creating basic and advanced charts, then continue through the course and begin creating dashboards with spreadsheets and IBM Cognos Analytics. You will then end this course by creating a set of data visualizations with IBM Cognos Analytics and creating an interactive dashboard that can be shared with peers, professional communities or prospective employers.

This course does not require any prior data analysis, or computer science experience. All you need to get started is basic computer literacy, high school level math, access to a modern web browser such as Chrome or Firefox, the ability to create a Microsoft account to access Excel for the Web, and a basic understanding of Excel spreadsheets.",58066.0,258784.0,4.7,2154.0
Data Visualization e manipolazione dei dati con Tableau,https://www.coursera.org/learn/data-visualization-manipolazione-tableau,Data Science,Data Analysis,Manuel Belgioioso,"I contenuti di questo corso sono pensati per permettere agli utilizzatori di Tableau di migliorare le proprie capacità sull’uso del tool, a un livello intermedio.

Spesso i dati provengono da fonti diverse; dobbiamo quindi essere in grado di stabilire tra questi delle relazioni che ci permettano di includere in un’analisi tutte le informazioni di cui abbiamo bisogno. Vedremo quindi come costruire queste relazioni su Tableau, ricorrendo a Join, Union e Data Blending.

Lavoreremo con i campi calcolati e i parametri. I primi sono nuovi campi (dimensioni e misure) che, a partire dalla logica utilizzata, aggiungono nuovi dati al data base di partenza. I secondi, invece, sono valori dinamici che possono essere impiegati in tantissimi modi per personalizzare i propri calcoli e la loro visualizzazione all’interno dello spazio di lavoro.

Vedremo come Tableau esegue le operazioni di calcolo secondo un ordine preciso, che influisce sui risultati dei calcoli che facciamo. Andremo infine a lavorare con i dati geografici. Nel processo analitico, sono diverse le domande che possiamo porci. Padroneggiando le conoscenze sulla manipolazione dei dati geografici possiamo rispondere al “dove”, un aspetto fondamentale da considerare nel processo analitico.",,,,
Data Visualization in R with ggplot2,https://www.coursera.org/learn/jhu-data-visualization-r,Data Science,Data Analysis,Collin Paschall,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance.

This course is the second in a specialization in Data Visualization offered by Johns Hopkins. It is intended for learners who have either have some experience with R and data wrangling in the tidyverse or have taken the previous course in the specialization. The focus in this course learning to use ggplot2 to make a variety of visualizations and to polish those visualizations using tools within ggplot as well as vector graphics editing software. The course will not go into detail about how the data management works behind the scenes.",5134.0,17377.0,4.9,91.0
Data Visualization using Bokeh,https://www.coursera.org/learn/data-visualization-using-bokeh,Data Science,Data Analysis,Naina Chaturvedi,"Welcome to this 1 hour long guided project on data visualization using Bokeh. In this project you will learn the basics of Bokeh and create different plots and impressive data visualizations in detail. You will also learn Glyphs and how to Map Geo data using Bokeh. Please note that you will need prior programming experience ( beginner level) in Python. You will also need familiarity with Pandas. This is a practical, hands on guided project for learners who already have theoretical understanding of Pandas and Python.",,,,
Data Visualization using Plotly,https://www.coursera.org/learn/data-visualization-using-plotly,Data Science,Data Analysis,Naina Chaturvedi,"Welcome to this 1 hour long guided project on Data Visualization using Plotly. Plotly is a python graphing library which is used to make interactive, publication-quality graphs. It allows users to import, copy and paste, or stream data to be analyzed and visualized.

In this project you will learn how to create beautiful visualizations using Plotly constructs. This guided project is for anyone who wants to learn data visualization or already in the data science field.",1520.0,,3.5,22.0
Data Visualization using Plotnine and ggplot,https://www.coursera.org/learn/data-visualization-using-plotnine,Data Science,Data Analysis,Naina Chaturvedi,"Welcome to this 1.5 hour long guided project on Data Visualization using Plotnine and ggplot. Plotnine library is a powerful python visualization library based on R's ggplot2 package and a great package to make professional plots. It has the grammar of graphics from ggplot and is used to add layers that control geometries, facets, themes and many constructs. 

In this project you will learn how to create beautiful visualizations using plotnine and gglot constructs. This guided project is for anyone who wants to learn data visualization or already in the data science field.",,,,
Data Visualization using dplyr and ggplot2 in R,https://www.coursera.org/learn/data-visualization-using-dplyr-and-ggplot2-in-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Data Visualization using ggplot2 and dplyr in R. In this project, you will learn how to manipulate data with the dplyr package and create beautiful plots using the ggplot2 package in R.

By the end of this 2-hour long project, you will understand how to use different dplyr verbs such as the select verb, filter verb, arrange verb, mutate verb, summarize verb, and the group_by verb to manipulate the gapminder dataset. You will also learn how to use the ggplot2 package to render beautiful plots from the data returned from using the dplyr verbs.

Note that this is a follow-up to the project on Data Manipulation with dplyr in R. I recommend that you take the Data Manipulation with dplyr in R project before taking this project. This will give you better experience working on this project.",,,,
Data Visualization with Advanced Excel,https://www.coursera.org/learn/advanced-excel,Data Science,Data Analysis,Alex Mannella,"In this course, you will get hands-on instruction of advanced Excel 2013 functions.  You’ll learn to use PowerPivot to build databases and data models.  We’ll show you how to perform different types of scenario and simulation analysis and you’ll have an opportunity to practice these skills by leveraging some of Excel's built in tools including, solver, data tables, scenario manager and goal seek.  In the second half of the course, will cover how to visualize data, tell a story and explore data by reviewing core principles of data visualization and dashboarding.  You’ll use Excel to build complex graphs and Power View reports and then start to combine them into dynamic dashboards.

Note: Learners will need PowerPivot to complete some of the exercises. Please use MS Excel 2013 version. If you have other MS Excel versions or a MAC you might not be able to complete all assignments.

This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",84805.0,34904.0,4.8,2827.0
Data Visualization with Plotly Express,https://www.coursera.org/learn/data-visualization-plotly-express,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Data Visualization with Plotly Express. In this project, you will create quick and interactive data visualizations with Plotly Express: a high-level data visualization library in Python inspired by Seaborn and ggplot2. You will explore the various features of the in-built Gapminder dataset, and produce interactive, publication-quality graphs to augment analysis.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Plotly Express pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7192.0,,4.7,265.0
Data Visualization with Python,https://www.coursera.org/learn/python-for-data-visualization,Data Science,Data Analysis,Saishruthi Swaminathan,"One of the most important skills of successful data scientists and data analysts is the ability to tell a compelling story by visualizing data and findings in an approachable and stimulating way. In this course you will learn many ways to effectively visualize both small and large-scale data. You will be able to take data that at first glance has little meaning and present that data in a form that conveys insights. 

This course will teach you to work with many Data Visualization tools and techniques. You will learn to create various types of basic and advanced graphs and charts like: Waffle Charts, Area Plots, Histograms, Bar Charts, Pie Charts, Scatter Plots, Word Clouds, Choropleth Maps, and many more! You will also create interactive dashboards that allow even those without any Data Science experience to better understand data, and make more effective and informed decisions.   

You will learn hands-on by completing numerous labs and a final project to practice and apply the many aspects and techniques of Data Visualization using Jupyter Notebooks and a Cloud-based IDE. You will use several data visualization libraries in Python, including Matplotlib, Seaborn, Folium, Plotly & Dash.",178397.0,375027.0,4.5,10514.0
Data Visualization with R,https://www.coursera.org/learn/data-visualization-r,Data Science,Data Analysis,"Yiwen Li, Tiffany Zhu, Saishruthi Swaminathan, Gabriela de Queiroz","In this course, you will learn the Grammar of Graphics, a system for describing and building graphs, and how the ggplot2 data visualization package for R applies this concept to basic bar charts, histograms, pie charts, scatter plots, line plots, and box plots. You will also learn how to further customize your charts and plots using themes and other techniques. You will then learn how to use another data visualization package for R called Leaflet to create map plots, a unique way to plot data based on geolocation data. Finally, you will be introduced to creating interactive dashboards using the R Shiny package. You will learn how to create and customize Shiny apps, alter the appearance of the apps by adding HTML and image components, and deploy your interactive data apps on the web.

You will practice what you learn and build hands-on experience by completing labs in each module and a final project at the end of the course.

Watch the videos, work through the labs, and watch your data science skill grow. Good luck!

NOTE: This course requires knowledge of working with R and data. If you do not have these skills, it is highly recommended that you first take the Introduction to R Programming for Data Science as well as the Data Analysis with R courses from IBM prior to starting this course. Note: The pre-requisite for this course is basic R programming skills.",8532.0,29995.0,4.6,130.0
Data Visualization with Tableau Project,https://www.coursera.org/learn/dataviz-project,Data Science,Data Analysis,"Suk S. Brar, M.B.A., Hunter Whitney","In this project-based course, you will follow your own interests to create a portfolio worthy single-frame viz or multi-frame data story that will be shared on Tableau Public. You will use all the skills taught in this Specialization to complete this project step-by-step, with guidance from your instructors along the way. You will first create a project proposal to identify your goals for the project, including the question you wish to answer or explore with data. You will then find data that will provide the information you are seeking. You will then import that data into Tableau and  prepare it for analysis. Next you will create a dashboard that will allow you to explore the data in depth and identify meaningful insights. You will then give structure to your data story by writing the story arc in narrative form. Finally, you will consult your design checklist to craft the final viz or data story in Tableau. This is your opportunity to show the world what you’re capable of - so think big, and have confidence in your skills!",29189.0,43477.0,4.6,461.0
Data Warehousing with Microsoft Azure Synapse Analytics,https://www.coursera.org/learn/data-warehousing-with-microsoft-azure-synapse-analytics,Data Science,Data Analysis, Microsoft,"In this course, you will explore the tools and techniques that can be used to work with Modern Data Warehouses productively and securely within Azure Synapse Analytics. You will learn how Azure Synapse Analytics enables you to build Data Warehouses using modern architecture patterns and how the common schema is implemented in a data warehouse. You'll learn the best practices you need to adopt to load data into a data warehouse and the techniques that you can use to optimize query performance within Azure Synapse Analytics.

This course is part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services for anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). 

This is the fifth course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",2716.0,25538.0,4.2,21.0
"Data Wrangling, Analysis and AB Testing with SQL",https://www.coursera.org/learn/data-wrangling-analysis-abtesting,Data Science,Data Analysis,Katrina Glaeser Poole,"This course allows you to apply the SQL skills taught in “SQL for Data Science” to four increasingly complex and authentic data science inquiry case studies. We'll learn how to convert timestamps of all types to common formats and perform date/time calculations. We'll select and perform the optimal JOIN for a data science inquiry and clean data within an analysis dataset by deduping, running quality checks, backfilling, and handling nulls. We'll learn how to segment and analyze data per segment using windowing functions and use case statements to execute conditional logic to address a data science inquiry. We'll also describe how to convert a query into a scheduled job and how to insert data into a date partition. Finally, given a predictive analysis need, we'll engineer a feature from raw data using the tools and skills we've built over the course. The real-world application of these skills will give you the framework for performing the analysis of an AB test.",45011.0,130460.0,3.4,698.0
Data and Statistics Foundation for Investment Professionals,https://www.coursera.org/learn/data-statistics-foundation-investment,Data Science,Probability and Statistics,"Neil Govier, CFA","Aimed at investment professionals or those with investment industry knowledge, this course offers an introduction to the basic data and statistical techniques that underpin data analysis and lays an essential foundation in the techniques that are used in big data and machine learning. It introduces the topics and gives practical examples of how they are used by investment professionals, including the importance of presenting the “data story"" by using appropriate visualizations and report writing. 

In this course you will learn how to: 
- Explain basic statistical measures and their application to real-life data sets 
- Calculate and interpret measures of dispersion and explain deviations from a normal distribution 
- Understand the use and appropriateness of different distributions 
- Compare and contrast ways of visualizing data and create them using Python (no prior knowledge of Python necessary)
- Explain sampling theory and draw inferences about population parameters from sample statistics 
- Formulate hypotheses on investment problems

This course is part of the Data Science for Investment Professionals Specialization offered by CFA Institute.",4494.0,41523.0,4.5,31.0
Data for Machine Learning,https://www.coursera.org/learn/data-machine-learning,Data Science,Machine Learning,Anna Koop,"This course is all about data and how it is critical to the success of your applied machine learning model. Completing this course will give learners the skills to:

Understand the critical elements of data in the learning, training and operation phases
Understand biases and sources of data
Implement techniques to improve the generality of your model
Explain the consequences of overfitting and identify mitigation measures
Implement appropriate test and validation measures.
Demonstrate how the accuracy of your model can be improved with thoughtful feature engineering.
Explore the impact of the algorithm parameters on model strength

To be successful in this course, you should have at least beginner-level background in Python programming (e.g., be able to read and code trace existing code, be comfortable with conditionals, loops, variables, lists, dictionaries and arrays). You should have a basic understanding of linear algebra (vector notation) and statistics (probability distributions and mean/median/mode).

This is the third course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute.",7224.0,3344.0,4.4,96.0
Data mining of Clinical Databases - CDSS 1,https://www.coursera.org/learn/cdss1,Data Science,Machine Learning,Fani Deligianni,"This course will introduce MIMIC-III, which is the largest publicly Electronic Health Record (EHR) database available to benchmark machine learning algorithms. In particular, you will learn about the design of this relational database, what tools are available to query, extract and visualise descriptive analytics. 

The schema and International Classification of Diseases coding is important to understand how to map research questions to data and how to extract key clinical outcomes in order to develop clinically useful machine learning algorithms.",,4340.0,,
Data science perspectives on pandemic management,https://www.coursera.org/learn/data-science-perspectives-on-pandemic-management,Data Science,Data Analysis,Marco Brambilla,"The COVID-19 pandemic is one of the first world-wide scenarios where data made a difference in capturing and analyzing the diffusion and impact of the disease. 

We offer an introductory course for decision makers, policy makers, public bodies, NGOs, and private organizations about methods, tools, and experiences on the use of data for managing current and future pandemic scenarios. 

This course describes modern methods for data-driven policy making in the context of pandemics. Discussed methods include policy making, innovation, and technology governance; data collection from citizens, crowdsourcing, gamification, and game with a purpose (GWAP); crowd monitoring and sensing; mobility and traffic analysis; disinformation and fake news impacts; and economical and financial impacts and sustainability models. Methods, tools, and analyses are presented to demonstrate how data can help in designing better solutions to pandemics and world-wide critical events. 

In this course you will discover the role of policy making and technology governance for managing pandemics. 
You will learn about methods like crowdsourcing, gamification, sensing of crowds and built environments, and contact tracing for understanding the dynamics of the pandemic. 
You will understand the risk of disinformation and its impact on people perception and decisions. 
The course also covers the financial models that describe the pandemic monetary impact on individuals and organizations, as well as the financial sustainability  models that can be defined. 
Thanks to this course you will get a deeper understanding of motivations, perceptions, choices, and actions of individuals in a pandemic setting, and you will be able to start defining appropriate mitigation actions.  

This course was developed by a set of European research and education institutions as part of the research project 'Pan-European Response to the Impacts of the COVID-19 and future Pandemics and Epidemics' (PERISCOPE, https://www.periscopeproject.eu/). Funded by the European Commission Research Funding programme Horizon 2020 under the Grant Agreement number 101016233, PERISCOPE investigates the broad socio-economic and behavioural impacts of the COVID-19 pandemic, to make Europe more resilient and prepared for future large-scale risks.",,,,
"Data – What It Is, What We Can Do With It",https://www.coursera.org/learn/data-what-it-is-what-can-we-do-with-it,Data Science,Probability and Statistics,"Jennifer Bachner, PhD","This course introduces students to data and statistics.  By the end of the course, students should be able to interpret descriptive statistics, causal analyses and visualizations to draw meaningful insights.  

The course first introduces a framework for thinking about the various purposes of statistical analysis.  We’ll talk about how analysts use data for descriptive, causal and predictive inference.  We’ll then cover how to develop a research study for causal analysis, compute and interpret descriptive statistics and design effective visualizations.  The course will help you to become a thoughtful and critical consumer of analytics. 

If you are in a field that increasingly relies on data-driven decision making, but you feel unequipped to interpret and evaluate data, this course will help you develop these fundamental tools of data literacy.",4302.0,6401.0,4.6,105.0
Data-driven Decision Making,https://www.coursera.org/learn/decision-making,Data Science,Data Analysis,Alex Mannella,"Welcome to Data-driven Decision Making. In this course, you'll get an introduction to Data Analytics and its role in business decisions. You'll learn why data is important and how it has evolved. You'll be introduced to “Big Data” and how it is used. You'll also be introduced to a framework for conducting Data Analysis and what tools and techniques are commonly used. Finally, you'll have a chance to put your knowledge to work in a simulated business setting.

This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",159370.0,61324.0,4.6,5804.0
DataOps Methodology,https://www.coursera.org/learn/ibm-data-ops-methodology,Data Science,Data Analysis,Elaine Hanley,"DataOps is defined by Gartner as ""a collaborative data management practice focused on improving the communication, integration and automation of data flows between data managers and consumers across an organization. Much like DevOps, DataOps is not a rigid dogma, but a principles-based practice influencing how data can be provided and updated to meet the need of the organization’s data consumers.”

The DataOps Methodology is designed to enable an organization to utilize a repeatable process to build and deploy analytics and data pipelines. By following data governance and model management practices they can deliver high-quality enterprise data to enable AI. Successful implementation of this methodology allows an organization to know, trust and use data to drive value.

In the DataOps Methodology course you will learn about best practices for defining a repeatable and business-oriented framework to provide delivery of trusted data. This course is part of the Data Engineering Specialization which provides learners with the foundational skills required to be a Data Engineer.",1511.0,7299.0,4.7,32.0
DataViz - Grammaire des Graphiques avec Python,https://www.coursera.org/learn/dataviz-grammaire-des-graphiques-avec-python,Data Science,Data Analysis,ELINGUI Pascal Uriel,"Dans ce projet guidé vous apprendrez à créer des graphiques de très hautes qualités à l’image de ceux que vous voyez dans des revues scientifiques et des magazines. Vous ferez cela en utilisant le paquet Python plotnine, qui implémente la ""Grammaire des Graphiques"" telle que édictée par Leland Wilkinson en 1999. Plotnine est l’équivalent du célèbre paquet R appelé  ggplot. 

Contrairement à matplotlib ou seaborn plotnine est très flexible et par une démarche logique vous permet de faire rapidement des jolis graphiques.

Savoir créer des graphiques scientifiquement est une qualité très importante à avoir pour tout professionnel des données, dans ce cours pour apprendre un outil extrêmement flexible et surtout des principes simples et pratiques.

Ce projet guidé estime que vous avez des bases en programmation en Python pour l'analyse des données.",,,,
Database Creation and Modeling using MYSQL Workbench,https://www.coursera.org/learn/database-creation-and-modeling-using-mysql-workbench,Data Science,Data Analysis,Omnya Khaled,"In this 1-hour long project-based course, you will be able to identify and fully comprehend the basics of the MYSQL workbench and create a new connection to the local server. you will also learn how to create a new database and drop it, create new tables, and delete them. Moreover, You will be able to rename columns of a table, connect tables with each other, and add data to tables. And finally, you will learn how to add columns and apply some features professionally on these columns using some keywords such as PRIMARY KEY, FOREIGN KEY, NOT NULL, AUTO_INCREMENT, and DISTINCT and update the tables with new data. SQL is used by all the big names in tech like Netflix or Airbnb. If you target Google, Facebook, or Amazon, they, of course, have their database systems. But SQL will be there too to query and analyze the data.

This guided project is for beginners in the field of data management data modeling and databases. It provides you with the basics of creating the whole database. It equips you with knowledge of the first steps in modeling.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,13.0
Databases and SQL for Data Science with Python,https://www.coursera.org/learn/sql-data-science,Data Science,Data Analysis,"Rav Ahuja, Hima Vasudevan","Working knowledge of SQL (or Structured Query Language) is a must for data professionals like Data Scientists, Data Analysts and Data Engineers. Much of the world's data resides in databases. SQL is a powerful language used for communicating with and extracting data from databases.  

In this course you will learn SQL inside out- from the very basics of Select statements to advanced concepts like JOINs.  

You will:  
-write foundational SQL statements like: SELECT, INSERT, UPDATE, and DELETE 
-filter result sets, use WHERE, COUNT, DISTINCT, and LIMIT clauses 
-differentiate between DML & DDL  
-CREATE, ALTER, DROP and load tables 
-use string patterns and ranges; ORDER and GROUP result sets, and built-in database functions 
-build sub-queries and query data from multiple tables  
-access databases as a data scientist using Jupyter notebooks with SQL and Python 
-work with advanced concepts like Stored Procedures, Views, ACID Transactions, Inner & Outer JOINs 

Through hands-on labs and projects, you will practice building SQL queries, work with real databases on the Cloud, and use real data science tools. In the final project you’ll analyze multiple real-world datasets to demonstrate your skills.",286030.0,920326.0,4.6,16480.0
Datadog: Getting started with the Helm Chart,https://www.coursera.org/learn/googlecloud-datadog-getting-started-with-the-helm-chart-10c7n,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Datastore: Qwik Start,https://www.coursera.org/learn/googlecloud-datastore-qwik-start-mjbwh,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Datastream MySQL to BigQuery,https://www.coursera.org/learn/googlecloud-datastream-mysql-to-bigquery-ej1ht,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
"Daten Analysieren, um Fragen zu Beantworten",https://www.coursera.org/learn/daten-analysieren-um-fragen-zu-beantworten,Data Science,Data Analysis,Google Career Certificates,"Dies ist der fünfte Kurs im Google Data Analytics Certificate. In diesen Kursen lernen Sie alles, was Sie für eine Einstiegsposition in der Datenanalyse benötigen. In diesem Kurs untersuchen Sie die Analysephase des Datenanalyseprozesses. Sie wenden das, was Sie bisher gelernt haben, auf Ihre Analyse an, um die erfassten Daten zu verstehen. Sie erfahren, wie Sie Ihre Daten mithilfe von Tabellenkalkulationen und SQL organisieren und formatieren, damit Sie sie auf unterschiedliche Weise betrachten und über sie nachdenken können. Außerdem erfahren Sie, wie Sie komplexe Berechnungen mit Ihren Daten durchführen, um Geschäftsziele zu erreichen. Während Sie Ihre Analyse durchführen, lernen Sie, wie Sie Formeln, Funktionen und SQL-Abfragen verwenden. Bei Google tätige Fachleute für die Datenanalyse werden Sie weiterhin anleiten und Ihnen praktische Möglichkeiten zeigen, wie Sie häufige Datenanalyseaufgaben mithilfe der besten Tools und Ressourcen erledigen können.

Nach Abschluss dieses Zertifikatsprogramms sind Lernende bestens gerüstet, um sich auf Einstiegspositionen in der Datenanalyse zu bewerben. Es sind keine Vorkenntnisse erforderlich.

Im Verlauf dieses Kurses werden Sie:
 - erfahren, wie Sie Daten für die Analyse organisieren
 - die Prozesse zum Formatieren und Anpassen von Daten kennenlernen 
 - lernen, wie Sie Daten in Tabellenkalkulationen und mithilfe von SQL aggregieren
 - Formeln und Funktionen in Tabellenkalkulationen für Datenberechnungen verwenden
 - erfahren, wie Sie Berechnungen mithilfe von SQL-Abfragen durchführen",,,,
Daten bereinigen,https://www.coursera.org/learn/daten-bereinigen,Data Science,Data Analysis,Google Career Certificates,"Dies ist der vierte Kurs im Google Data Analytics Certificate. In diesen Kursen lernen Sie alles, was Sie für eine Einstiegsposition in der Datenanalyse benötigen. In diesem Kurs bauen Sie Ihr Verständnis für Data Analytics und die Konzepte und Tools aus, die Fachkräfte für Datenanalyse bei ihrer Arbeit verwenden. Sie erfahren, wie Sie Ihre Daten mithilfe von Tabellenkalkulationen und SQL überprüfen und bereinigen und wie Sie die Ergebnisse der Datenbereinigung verifizieren und einen Bericht dazu erstellen können. Bei Google tätige Fachleute für Datenanalyse werden Sie weiterhin anleiten und Ihnen praktische Möglichkeiten zeigen, mit denen Sie übliche Aufgaben von Fachleuten für Datenanalyse mithilfe der besten Tools und Ressourcen erledigen können.

Nach Abschluss dieses Zertifikatsprogramms sind Lernende gerüstet, um sich auf Einstiegspositionen in der Datenanalyse zu bewerben. Es sind keine Vorkenntnisse erforderlich.

Nach Abschluss dieses Kurses können Sie Folgendes:
 - Lernen, die Datenintegrität zu überprüfen
 - Datenbereinigungstechniken mit Tabellenkalkulationen entdecken 
 - Grundlegende SQL-Abfragen zur Verwendung mit Datenbanken entwickeln
 - Grundlegende SQL-Funktionen zum Transformieren von Datenvariablen anwenden
 - Eine Vorstellung entwickeln, wie die Ergebnisse von Datenbereinigungen verifiziert werden
 - Die Elemente und die Bedeutung von Berichten zur Datenbereinigung erörtern",,1935.0,,
Daten für die Erkundung Vorbereiten,https://www.coursera.org/learn/daten-fur-die-erkundung-vorbereiten,Data Science,Data Analysis,Google Career Certificates,"Dies ist der dritte Kurs des Google Data Analytics Certificate. In diesen Kursen lernen Sie alles, was Sie für eine Einstiegsposition in der Datenanalyse benötigen. Während Sie Ihr Verständnis der Themen aus den ersten beiden Kursen weiter ausbauen, werden Sie auch in neue Themen eingeführt, die Ihnen helfen, praktische Data-Analytics-Fähigkeiten zu erwerben. Sie erfahren, wie Sie Tools wie Tabellenkalkulationen und SQL verwenden, um die richtigen Daten für Ihre Ziele zu extrahieren und zu nutzen und wie Sie Ihre Daten organisieren und schützen. Bei Google tätige Fachleute für Datenanalyse werden Sie weiterhin anleiten und Ihnen praktische Möglichkeiten zeigen, mit denen Sie übliche Aufgaben von Fachleuten für Datenanalyse mithilfe der besten Tools und Ressourcen erledigen können.

Nach Abschluss dieses Zertifikatsprogramms sind Lernende gerüstet, um sich auf Einstiegspositionen in der Datenanalyse zu bewerben. Es sind keine Vorkenntnisse erforderlich.

Im Verlauf dieses Kurses werden Sie:
 - Herausfinden, wie Fachkräfte für Datenanalyse entscheiden, welche Daten für die Analyse gesammelt werden
 - Mehr über strukturierte und unstrukturierte Daten, Datentypen und Datenformate erfahren
 - Erfahren, wie Sie verschiedene Arten von Verzerrungen in Daten identifizieren können, um die Glaubwürdigkeit der Daten sicherzustellen 
 - Erfahren, wie Fachkräfte für Datenanalyse Tabellenkalkulationen und SQL mit Datenbanken und Datensätzen verwenden
 - Sich mit Open Data und dem Verhältnis zwischen Datenethik und Datenschutz sowie mit deren Bedeutung auseinandersetzen
 - Lernen, wie Sie auf Datenbanken zugreifen und die darin enthaltenen Daten extrahieren, filtern und sortieren
 - Die Best Practices zum Strukturieren und Schützen von Daten kennenlernen",,2232.0,,
Daten über Visualisierungen teilen,https://www.coursera.org/learn/daten-uber-visualisierungen-teilen,Data Science,Data Analysis,Google Career Certificates,"Dies ist der sechste Kurs im Google Data Analytics Certificate. In diesen Kursen lernen Sie alles, was Sie für eine Einstiegsposition in der Datenanalyse benötigen. Sie lernen, wie Sie Ihre Datenergebnisse visualisieren und präsentieren, während Sie den Datenanalyseprozess abschließen. In diesem Kurs erfahren Sie, wie Datenvisualisierungen, wie z. B. visuelle Dashboards, dazu beitragen können, Ihre Daten zum Leben zu erwecken. Außerdem lernen Sie Tableau kennen, eine Datenvisualisierungsplattform, mit der Sie effektive Visualisierungen für Ihre Präsentationen erstellen können. Bei Google tätige Fachleute für die Datenanalyse werden Sie weiterhin anleiten und Ihnen praktische Möglichkeiten zeigen, wie Sie häufige Datenanalyseaufgaben mithilfe der besten Tools und Ressourcen erledigen können.

Nach Abschluss dieses Zertifikatsprogramms sind Lernende bestens gerüstet, um sich auf Einstiegspositionen in der Datenanalyse zu bewerben. Es sind keine Vorkenntnisse erforderlich.

Im Verlauf dieses Kurses werden Sie:
 - die Bedeutung der Datenvisualisierung untersuchen;
 - erfahren, wie Sie mithilfe von Data Storys eine überzeugende Erzählung entwickeln
 - sich mit der Verwendung von Tableau zum Erstellen von Dashboards und Dashboard-Filtern vertraut machen
 - erfahren, wie Sie mit Tableau effektive Visualisierungen erstellen 
 - die Prinzipien und Praktiken für effektive Präsentationen kennenlernen
 - erfahren, wie Sie potenzielle Einschränkungen im Zusammenhang mit den Daten in Ihren Präsentationen berücksichtigen können
 - Best Practices für das Beantworten von Fragen aus dem Publikum kennenlernen",,1679.0,,
Datenaggregation mit SQL,https://www.coursera.org/learn/datenaggregation-mit-sql,Data Science,Data Analysis,Sandro Raabe,"In diesem zweistündigen Projekt wirst du Daten aus Datenbanktabellen mit dem SQL-GROUP-BY-Statement in Verbindung SQL-Aggregationsfunktionen abrufen. Wir werden die Aggregationsfunktionen COUNT(), SUM(), MIN(), MAX() und AVG() kennen lernen. Aggregationsfunktionen werden verwendet, um Zeilen einer Tabelle in einen einzigen Wert zusammen zu fassen. Außerdem wirst du lernen, wie du das gruppierten und aggregierten Ergebnis mit HAVING filtern kannst.

Hinweis: Du musst kein Data Analyst sein, um in diesem angeleiteten Projekt erfolgreich zu sein! Grundlegende Kenntnis von SQL SELECT- und WHERE-Statements sollte genügen.",,,,
Datenanalyse mit R und dplyr,https://www.coursera.org/learn/datenanalyse-mit-r-und-dplyr,Data Science,Data Analysis,Sandro Raabe,"In diesem Projekt wirst du das erfolgreiche Datenanalyse-R-Paket ""dplyr"" so benutzen, dass deine nächste Datenanalyse oder -transformation zum Erfolg wird! 

Wir werden dich in die Lage versetzen, mit dem dplyr-Paket in R eigene Datenanalyse-Pipelines zu bauen, die dir analytische Einblicke in einen Datensatz offenbaren.

Während des Projekts wirst du einen Datensatz flexibel sortieren, interessante Beobachtungen herausfiltern, wichtige Variablen auswählen, diese dann modifizieren oder neue Informationen aus ihnen generieren, und nicht zuletzt Statistiken für Gruppen in den Daten erzeugen. Das beste: Dieses Data Mining kannst du schnell und einfach in der R-Konsole erledigen, ohne dich anstrengend durch ein unübersichtliches BI-Interface klicken zu müssen.

Dieses angeleitete Projekt ist gut geeignet für Anfänger. Du wirst in der Lage sein, selbstständig mit großen unbekannten Datensätzen zu jonglieren und relevante Informationen aus großen Daten zu erzeugen.

Wenn dir also demnächst in der freien Wildbahn ein Datensatz begegnet und du dich fragst, welche interessanten und nützlichen Informationen darin verborgen sind, dann hast du nach diesem Kurs das Handwerkszeug dazu!",,,,
Datenanalyse mit deskriptiver Statistik in R,https://www.coursera.org/learn/datenanalyse-mit-deskriptiver-statistik-in-r,Data Science,Probability and Statistics,Sandro Raabe,"In diesem Projekt wirst du lernen, wie du aus beliebigen Datensätzen deskriptive Statistiken berechnest. Deskriptive Statistiken sind Kennzahlen, die du explizit aus dem Datensatz berechnen kannst (im Gegensatz zu induktiver Statistik, bei der du den vollen Datensatz nicht kennst und deshalb Hypothesentests ausführst, um Kennzahlen zu schätzen).

Im Anschluss wirst du lernen, wie du automatisiert einen statistischen Report für beliebige Datensätze erstellst, der dir tabellarisch berichtet, wie viele Werte fehlen, wo die Mittelwerte liegen, und so weiter. Dieser Report ist meistens der erste Schritt, einen Datensatz zu verstehen und deine nächsten Datenanalyse-Schritte zu planen.

Am Ende dieses Projekts wirst du in der Lage sein, jeden dir unbekannten Datensatz mit deskriptiver Statistik zu analysieren und einen Datenreport automatisiert zu erstellen.",,,,
Datenvisualisierung mit ggplot2,https://www.coursera.org/learn/datenvisualisierung-mit-ggplot2,Data Science,Data Analysis,Sandro Raabe,"Willkommen zu diesem projektbasierten Kurs über Datenvisualisierung mit `ggplot2` in R! Du wirst hier lernen, wie du wunderschöne und erkenntnisreiche Grafiken aus Data Frames in R erstellst. Das R-Paket `ggplot2` benutzt hierfür eine intuitive Grammatik, die deinen Denkprozess beim Erstellen der Visualisierung elegant abbildet.

Am Ende dieses zweistündigen Projekts wirst du in der Lage sein, intuitive, elegante und ansprechende Datenvisualisierungen eines beliebigen Datensatzes mithilfe des ggplot2-Pakets durchzuführen.",,,,
Dealing With Missing Data,https://www.coursera.org/learn/missing-data,Data Science,Data Analysis,"Richard Valliant, Ph.D.","This course will cover the steps used in weighting sample surveys, including methods for adjusting for nonresponse and using data external to the survey for calibration.  Among the techniques discussed are adjustments using estimated response propensities, poststratification, raking, and general regression estimation.  Alternative techniques for imputing values for missing items will be discussed.  For both weighting and imputation, the capabilities of different statistical software packages will be covered, including R®, Stata®, and SAS®.",10659.0,9279.0,3.8,122.0
Decision Tree Classifier for Beginners in R,https://www.coursera.org/learn/decision-tree-classifier-for-beginners-in-r,Data Science,Machine Learning,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Decision Tree Classifier for Beginners in R. This is a hands-on project that introduces beginners to the world of statistical modeling. In this project, you will learn how to build decision tree models using the tree and rpart libraries in R. We will start this hands-on project by importing the Sonar data into R and exploring the dataset.
By the end of this 2-hour long project, you will understand the basic intuition behind the decision tree algorithm and how it works. To build the model, we will divide or partition the data into the training and testing data set. Finally, you will learn how to evaluate the model’s performance using metrics like Accuracy, Sensitivity, Specificity, F1-Score, and so on. By extension, you will learn how to save the trained model on your local system.
Although you do not need to be a data analyst expert or data scientist to succeed in this guided project, it requires a basic knowledge of using R, especially writing R syntaxes. Therefore, to complete this project, you must have prior experience with using R. If you are not familiar with working with using R, please go ahead to complete my previous project titled: “Getting Started with R”. It will hand you the needed knowledge to go ahead with this project on Decision Tree. However, if you are comfortable with working with R, please join me on this beautiful ride! Let’s get our hands dirty!",,,,
Decision Tree and Random Forest Classification using Julia,https://www.coursera.org/learn/decision-tree-random-forest-classification-julia,Data Science,Machine Learning,Vinita Silaparasetty,"This guided project is about glass classification using decision tree classification and random forest classification in Julia. It is ideal for beginners who do not know what decision trees or random forests are because this project explains these concepts in simple terms.

While you are watching me code, you will get a cloud desktop with all the required software pre-installed. This will allow you to code along with me. After all, we learn best with active, hands-on learning.

Special features:

1) Simple explanations of important concepts.
2) Use of images to aid in explanation.
3) Challenges to ensure that the learner gets practice.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.3,15.0
Deep Learning Applications for Computer Vision,https://www.coursera.org/learn/deep-learning-computer-vision,Data Science,Machine Learning,Ioana Fleming,"This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

In this course, you’ll be learning about Computer Vision as a field of study and research. First we’ll be exploring several Computer Vision tasks and suggested approaches, from the classic Computer Vision perspective. Then we’ll introduce Deep Learning methods and apply them to some of the same problems. We will analyze the results and discuss advantages and drawbacks of both types of methods. We'll use tutorials to let you explore hands-on some of the modern machine learning tools and software libraries. Examples of Computer Vision tasks where Deep Learning can be applied include: image classification, image classification with localization, object detection, object segmentation, facial recognition, and activity or pose estimation.",2875.0,15561.0,4.6,34.0
Deep Learning Inference with Azure ML Studio,https://www.coursera.org/learn/azure-machine-learning-studio-deep-learning-inference,Data Science,Machine Learning,Snehan Kekre,"In this project-based course, you will use the Multiclass Neural Network module in Azure Machine Learning Studio to train a neural network to recognize handwritten digits. Microsoft Azure Machine Learning Studio is a drag-and-drop tool you can use to rapidly build and deploy machine learning models on Azure. The data used in this course is the popular MNIST data set consisting of 70,000 grayscale images of hand-written digits. You are going to deploy the trained neural network model as an Azure Web service. Azure Web Services provide an interface between an application and a Machine Learning Studio workflow scoring model.  You will write a Python application to use the Batch Execution Service and predict the class labels of handwritten digits.

This is the third course in this series on building machine learning applications using Azure Machine Learning Studio. I highly encourage you to take the first course before proceeding. It has instructions on how to set up your Azure ML account with $200 worth of free credit to get started with running your experiments! 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6303.0,,4.8,123.0
Deep Learning Methods for Healthcare,https://www.coursera.org/learn/deep-learning-methods-healthcare,Data Science,Machine Learning,Jimeng Sun,"This course covers deep learning (DL) methods, healthcare data and applications using DL methods. The courses include activities such as video lectures, self guided programming labs, homework assignments (both written and programming), and a large project.

The first phase of the course will include video lectures on different DL and health applications topics, self-guided labs and multiple homework assignments. In this phase, you will build up your knowledge and experience in developing practical deep learning models on healthcare data. The second phase of the course will be a large project that can lead to a technical report and functioning demo of the deep learning models for addressing some specific healthcare problems. We expect the best projects can potentially lead to scientific publications.",,2703.0,,
Deep Learning and Reinforcement Learning,https://www.coursera.org/learn/deep-learning-reinforcement-learning,Data Science,Machine Learning,"Mark J Grover, Miguel Maldonado","This course introduces you to two of the most sought-after disciplines in Machine Learning: Deep Learning and Reinforcement Learning. Deep Learning is a subset of Machine Learning that has applications in both Supervised and Unsupervised Learning, and is frequently used to power most of the AI applications that we use on a daily basis. First you will learn about the theory behind Neural Networks, which are the basis of Deep Learning, as well as several modern architectures of Deep Learning. Once you have developed a few  Deep Learning models, the course will focus on Reinforcement Learning, a type of Machine Learning that has caught up more attention recently. Although currently Reinforcement Learning has only a few practical applications, it is a promising area of research in AI that might become relevant in the near future.

After this course, if you have followed the courses of the IBM Specialization in order, you will have considerable practice and a solid understanding in the main types of Machine Learning which are: Supervised Learning, Unsupervised Learning, Deep Learning, and Reinforcement Learning.

By the end of this course you should be able to:
Explain the kinds of problems suitable for Unsupervised Learning approaches
Explain the curse of dimensionality, and how it makes clustering difficult with many features
Describe and use common clustering and dimensionality-reduction algorithms
Try clustering points where appropriate, compare the performance of per-cluster models
Understand metrics relevant for characterizing clusters

Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience with Deep Learning and Reinforcement Learning.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Unsupervised Learning, Supervised Learning, Calculus, Linear Algebra, Probability, and Statistics.",10805.0,48460.0,4.6,112.0
Deep Learning for Real Estate Price Prediction,https://www.coursera.org/learn/deep-learning-for-real-estate-price-prediction,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on guided project, we will predict real estate prices with deep learning. In this project, we will predict home sale prices in King County in the U.S. between May, 2014 and May, 2015 using several features such as number of bedrooms, bathrooms, view, and square footage. This guided project is practical and directly applicable to the real estate industry. You can add this project to your portfolio of projects which is essential for your next job interview.",,,4.1,10.0
Deep Learning with PyTorch : Build an AutoEncoder,https://www.coursera.org/learn/deep-learning-with-pytorch-build-an-autoencoder,Data Science,Machine Learning,Parth Dhameliya,"In these one hour project-based course, you will learn to implement autoencoder using PyTorch. An autoencoder is a type of neural network that learns to copy its input to its output. In autoencoder, encoder encodes the image into compressed representation, and the decoder decodes the representation to reconstruct the image. We will use autoencoder for denoising hand written digits using a deep learning framework like pytorch. 

This guided project is for learners who want to use pytorch for building deep learning models.Learners who want to apply autoencoder practically using PyTorch. In order to be successful in this project, you should be familiar with python , basic pytorch like creating or defining neural network and convolutional neural network.",,,4.2,11.0
Deep Learning with PyTorch : Generative Adversarial Network,https://www.coursera.org/learn/deep-learning-with-pytorch-generative-adversarial-network,Data Science,Machine Learning,Parth Dhameliya,"In this two hour project-based course, you will implement Deep Convolutional Generative Adversarial Network using PyTorch to generate handwritten digits. You will create a generator that will learn to generate images that look real and a discriminator that will learn to tell real images apart from fakes. This hands-on-project will provide you the detail information on how to implement such network and train to generate handwritten digit images.  

In order to be successful in this project, you will need to have a theoretical understanding on convolutional neural network and optimization algorithm like Adam or gradient descent. This project will focus more on the practical aspect of DCGAN and less on theoretical aspect. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3279.0,,4.6,36.0
Deep Learning with PyTorch : GradCAM,https://www.coursera.org/learn/deep-learning-with-pytorch-gradcam,Data Science,Machine Learning,Parth Dhameliya,"Gradient-weighted Class Activation Mapping (Grad-CAM), uses the class-specific gradient information flowing into the final convolutional layer of a CNN to produce a coarse localization map of the important regions in the image. In this 2-hour long project-based course, you will implement GradCAM on simple classification dataset. You will write a custom dataset class for Image-Classification dataset. Thereafter, you will create custom CNN architecture. Moreover, you are going to create train function and evaluator function which will be helpful to write the training loop. After, saving the best model, you will write GradCAM function which return the heatmap of localization map of a given class. Lastly, you plot the heatmap which the given input image.",,,,
Deep Learning with PyTorch : Image Segmentation,https://www.coursera.org/learn/deep-learning-with-pytorch-image-segmentation,Data Science,Machine Learning,Parth Dhameliya,"In this 2-hour project-based course, you will be able to :

-  Understand the Segmentation Dataset and you will write a custom dataset class for Image-mask dataset. Additionally,  you will apply segmentation augmentation to augment images as well as its masks. For image-mask augmentation you will use albumentation library. You will plot the image-Mask pair.

- Load a pretrained state of the art convolutional neural network for segmentation problem(for e.g, Unet) using segmentation model pytorch library. 

- Create train function and evaluator function which will helpful to write training loop. Moreover, you will use training loop to train the model.",4897.0,,4.2,55.0
Deep Learning with PyTorch : Neural Style Transfer,https://www.coursera.org/learn/deep-learning-with-pytorch-neural-style-transfer,Data Science,Machine Learning,Parth Dhameliya,"In this 2 hour-long project-based course, you will learn to implement neural style transfer using PyTorch. Neural Style Transfer is an optimization technique used to take a content and a style image and blend them together so the output image looks like the content image but painted in the style of the style image. We will create artistic style image using content and given style image. We will compute the content and style loss function. We will minimize this loss function using optimization techniques to get an artistic style image that retains content features and style features.

This guided project is for learners who want to apply neural style transfer practically using PyTorch.

In order to be successful in this guided project, you should be familiar with the theoretical concept of neural style transfer, python programming, and convolutional neural networks.A google account is needed to use the Google colab environment.",5365.0,,4.3,86.0
Deep Learning with PyTorch : Object Localization,https://www.coursera.org/learn/deep-learning-with-pytorch--object-localization,Data Science,Machine Learning,Parth Dhameliya,"Object Localization is the task of locating an instance of a particular object category in an image, typically by specifying a tightly cropped bounding box centered on the instance. In this 2-hour project-based course, you will be able to understand the Object Localization Dataset and you will write a custom dataset class for Image-bounding box dataset. Additionally,  you will apply augmentation for localization task to augment images as well as its effect on bounding box. For localization task augmentation you will use albumentation library. We will plot the (image-bounding box) pair. Thereafter, we will load a pretrained state of the art convolutional neural network using timm library.Moreover, we are going to create train function and evaluator function which will be helpful to write training loop. Lastly, you will use best trained model to find bounding box given any image.",1768.0,,4.5,11.0
Deep Learning with PyTorch : Siamese Network,https://www.coursera.org/learn/deep-learning-with-pytorch-siamese-network,Data Science,Machine Learning,Parth Dhameliya,"In this 2-hour long guided-project course, you will learn how to implement a Siamese Network, you will train the network with the Triplet loss function. You will create Anchor, Positive and Negative image dataset, which will be the inputs of triplet loss function, through which the network will learn feature embeddings. Siamese Network have plethora of applications such as face recognition, signature checking, person re-identification, etc. In this project, you will train a simple Siamese Network for person re-identification.",,,4.3,10.0
Deep Neural Networks with PyTorch,https://www.coursera.org/learn/deep-neural-networks-with-pytorch,Data Science,Machine Learning,Joseph Santarcangelo,"The course will teach you how to develop deep learning models using  Pytorch. The course will start with Pytorch's  tensors and Automatic differentiation package. Then each section will cover different models starting off with fundamentals such as Linear Regression, and logistic/softmax regression. Followed by  Feedforward deep neural networks, the role of different activation functions, normalization and dropout layers. Then Convolutional Neural Networks and Transfer learning will be covered. Finally, several other Deep learning methods will be covered.

Learning Outcomes:
After completing this course, learners will be able to:
•	explain and apply their knowledge of Deep Neural Networks and related machine learning methods
•	know how to use Python libraries such as PyTorch  for Deep Learning applications 
•	build Deep Neural Networks using PyTorch",39625.0,113009.0,4.4,1235.0
Deep learning in Electronic Health Records - CDSS 2,https://www.coursera.org/learn/cdss2,Data Science,Machine Learning,Fani Deligianni,"Overview of the main principles of Deep Learning along with common architectures. Formulate the problem for time-series classification and apply it to vital signals such as ECG. Applying this methods in Electronic Health Records is challenging due to the missing values and the heterogeneity in EHR, which include both continuous, ordinal and categorical variables. Subsequently, explore imputation techniques and different encoding strategies to address these issues. Apply these approaches to formulate clinical prediction benchmarks derived from information available in MIMIC-III database.",,2663.0,,
Deep-Dive into Tensorflow Activation Functions,https://www.coursera.org/learn/deep-dive-tensorflow-activation-functions,Data Science,Machine Learning,Charles Ivan Niswander II,"You've learned how to use Tensorflow. You've learned the important functions, how to design and implement sequential and functional models, and have completed several test projects. What's next? It's time to take a deep dive into activation functions, the essential function of every node and layer of a neural network, deciding whether to fire or not to fire, and adding an element of non-linearity (in most cases).  

In this 2 hour course-based project, you will join me in a deep-dive into an exhaustive list of activation functions usable in Tensorflow and other frameworks. I will explain the working details of each activation function, describe the differences between each and their pros and cons, and I will demonstrate each function being used, both from scratch and within Tensorflow. Join me and boost your AI & machine learning knowledge, while also receiving a certificate to boost your resume in the process!

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Demand Forecasting Using Time Series,https://www.coursera.org/learn/demand-prediction-using-time-series,Data Science,Machine Learning,"Rajvir Dua, Neelesh Tiruviluamala","This course is the second in a specialization for Machine Learning for Supply Chain Fundamentals. In this course, we explore all aspects of time series, especially for demand prediction. We'll start by gaining a foothold in the basic concepts surrounding time series, including stationarity, trend (drift), cyclicality, and seasonality. Then, we'll spend some time analyzing correlation methods in relation to time series (autocorrelation). In the 2nd half of the course, we'll focus on methods for demand prediction using time series, such as autoregressive models. Finally, we'll conclude with a project, predicting demand using ARIMA models in Python.",1526.0,3755.0,3.2,19.0
Deploy A Microsoft Azure Speech To Text Web App,https://www.coursera.org/learn/deploy-a-microsoft-azure-speech-to-text-web-app,Data Science,Machine Learning,Emmanuel Acheampong,"In this 2-hour-long project-based course, you will learn how to import the necessary python modules for Azure Speech to Text SDK, Create a function to transcribe audio to text, Build a web app using Streamlit and deploy the web app to Heroku.

This project is a beginner python project for anyone interested in learning about how to productionize cloud speech-to-text services, Azure, particularly through a web app on Heroku and leveraging python audio modules. 

At the end of this project, learners will have a publicly available Streamlit web app that can transcribe uploaded audio files",,,,
Deploy Bridgerton NLP SMS Text Generator,https://www.coursera.org/learn/deploy-bridgerton-nlp-text-generator-and-send-sms,Data Science,Machine Learning,Emmanuel Acheampong,"Welcome to the “Deploy Bridgerton NLP SMS Text Generator” guided project. 

In this project, we will deploy an NLP text generator model that sends text messages of generated words to a phone number via SMS through a python Streamlit app. The model has been trained on quotes from Netflix's popular tv show ""Bridgerton"".

This project is an intermediate python project for anyone interested in learning about how to productionize natural language text generator models as a Streamlit app on Heroku and leveraging python modules to send SMS texts. 

It requires preliminary knowledge on how to build and train NLP text generator models (as we will not be building or training models), how to utilize Git, and how to leverage multiple Python modules like the email and smtp modules. Learners would also need a Heroku account and some familiarity with the Python Streamlit module.

At the end of this project, learners will have a publicly available Streamlit web app that leverages natural language processing text generation to send generated Bridgerton quotes via SMS to a phone number.",,,,
Deploy Machine Learning Models in Azure,https://www.coursera.org/learn/deploy-machine-learning-models-in-azure,Data Science,Machine Learning,Laura Ramov,"Did you know that there is more than one way you can deploy models in Azure?
This Guided Project “Deploy machine learning models in Azure” is for everybody working with ml models in Azure . In this 1-hour long project-based course, you will learn how to deploy machine learning models from Portal in Azure, deploy machine learning models in Azure from Python script and deploy machine learning models using Azure CLI.
To achieve this, we will use one example data, train a machine learning model, prepare all the files needed for deployment and deploy it! There a couple of ways of deployment in Azure, so you can pick your most convenient and favourite one. In order to be successful in this project, you will need knowledge of Python language and experience with machine learning in Python. Also, Azure subscription is required (free trial is an option for those who don’t have it), as well as Azure Machine Learning resource and a compute instance within. Instructional links will be provided to guide you through creation, if needed.
Let's get started!",,,,
Deploy Models with TensorFlow Serving and Flask,https://www.coursera.org/learn/deploy-models-tensorflow-serving-flask,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn how to deploy TensorFlow models using TensorFlow Serving and Docker, and you will create a simple web application with Flask which will serve as an interface to get predictions from the served TensorFlow model.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Prerequisites:
In order to be successful in this project, you should be familiar with Python, TensorFlow, Flask, and HTML.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7753.0,,4.5,197.0
Deploy a Video Indexer Application using Azure Video Analyze,https://www.coursera.org/learn/deploy-video-indexing-application-using-azure-video-analyzer,Data Science,Machine Learning,Rogerio Guimaraes,"In this one-hour project, you will understand how Azure Video Analyzer works for video analysis and what information is generated for video indexing. You will learn how to deploy a simple Web Application that uses the Azure Video Analyzer SDK to upload and index videos to detect faces, labels in scenes, identify celebrities, and more.  

  

Azure Video Analyzer is one of the most popular Artificial Intelligence services in the Azure ecosystem and is favored to analyze images and videos with confidence and low costs.  

Once you're done with this project, you will be able to use Azure Video Analyzer to analyze and index your videos in just a few steps.",,,,
Deploy a Video indexing Application using Amazon Rekognition,https://www.coursera.org/learn/deploy-a-video-indexing-application-using-amazon-rekognition,Data Science,Machine Learning,Rogerio Guimaraes,"In this one-hour project, you will understand how Amazon Rekognition works for video analysis and what information is generated for video indexing. You will learn how to deploy a Web Application that uses the AWS SDK to upload and index videos to detect faces, objects, and labels in scenes, maturity content, identify celebrities, and more.  
Amazon Rekognition is one of the most used Artificial Intelligence services in AWS and is favored to analyze images and videos with colossal confidence and low costs.  
Once you're done with this project, you will be able to use Amazon Rekognition to analyze and index your videos in just a few steps.",,,,
Deploy a predictive machine learning model using IBM Cloud,https://www.coursera.org/learn/deploy-predictive-ml-model-ibm-cloud,Data Science,Machine Learning,Mírian Silva,"In this 1-hour long project-based course, you will be able to create, evaluate and save a machine learning model (without writing a single line of code) using Watson Studio on IBM Cloud Platform, and you will make deployment of the model and try out as a web service frontend to make predictions. 

This guided project is for Data Scientists, Machine Learning Engineers, and Developers who want a way to deliver their machine learning code available to be integrated into an application and using it as a web service. We will do everything in a development mode without any costs using a free IBM Cloud account. 

To be successful in this project, you should be familiar with machine learning methodologies, like training, prediction, evaluation, and basic knowledge in some machine learning algorithms is appreciated too, so that way you will understand the results before making a deployment.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Deploy an NLP Text Generator: Bart Simpson Chalkboard Gag,https://www.coursera.org/learn/deploy-bart-simpson-chalkboard-text-generator,Data Science,Machine Learning,Emmanuel Acheampong,"Welcome to the “Deploy an NLP Text Generator: Bart Simpson Chalkboard Gag” guided project. 

Text Generation is a natural language technique that leverages language modeling to create or predict new text based on texts it has been trained on. An example of text generation can be identified in the Gmail sentence autocomplete feature.

In this project, we will deploy an NLP text generator model as a python Streamlit app. The model, which has been trained on all the text from Bart Simpsons chalkboard gag from the Simpsons, will be able to autogenerate new chalkboard gags.

This project is an intermediate python project for anyone interested in learning about how to productionize natural language text generator models as a Streamlit app on Heroku. It requires preliminary knowledge on how to build and train NLP text generator models (as we will not be building or training models) and how to utilize Git. Learners would also need a Heroku account and some familiarity with the Python Streamlit module.

At the end of this project, learners will have a publicly available Streamlit web app that leverages natural language processing text generation to generate new text for Bart Simpsons' chalkboard gags.",,,,
Deploying Machine Learning Models,https://www.coursera.org/learn/deploying-machine-learning-models,Data Science,Data Analysis,"Ilkay Altintas, Julian McAuley","In this course we will learn about Recommender Systems (which we will study for the Capstone project), and also look at deployment issues for data products. By the end of this course, you should be able to implement a working recommender system (e.g. to predict ratings, or generate lists of related products), and you should understand the tools and techniques required to deploy such a working system on real-world, large-scale datasets.

This course is the final course in the Python Data Products for Predictive Analytics Specialization, building on the previous three courses (Basic Data Processing and Visualization, Design Thinking and Predictive Analytics for Data Products, and Meaningful Predictive Modeling). At each step in the specialization, you will gain hands-on experience in data manipulation and building your skills, eventually culminating in a capstone project encompassing all the concepts taught in the specialization.",9242.0,3569.0,3.5,50.0
Deploying Machine Learning Models in Production,https://www.coursera.org/learn/deploying-machine-learning-models-in-production,Data Science,Machine Learning,"Laurence Moroney, Robert Crowe","In the fourth course of Machine Learning Engineering for Production Specialization, you will learn how to deploy ML models and make them available to end-users. You will build scalable and reliable hardware infrastructure to deliver inference requests both in real-time and batch depending on the use case. You will also implement workflow automation and progressive delivery that complies with current MLOps practices to keep your production system running. Additionally,  you will continuously monitor your system to detect model decay, remediate performance drops, and avoid system failures so it can continuously operate at all times.  

Understanding machine learning and deep learning concepts is essential, but if you’re looking to build an effective AI career, you need production engineering capabilities as well. Machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production-ready skills.

Week 1: Model Serving Introduction
Week 2: Model Serving Patterns and Infrastructures
Week 3: Model Management and Delivery
Week 4: Model Monitoring and Logging",16683.0,77924.0,4.6,207.0
Deploying a Python Data Analytics web app on Heroku,https://www.coursera.org/learn/deploying-a-python-data-analytics-web-app-on-heroku,Data Science,Data Analysis,Emmanuel Acheampong,"Welcome to the “Deploying a Python data analytics web app on Heroku” guided project.

This project is for anyone interested in breaking or transitioning into the data science field and hopes to build a portfolio that stands out with unique projects. In this project we’re going to be building and deploying a python data analytics web application leveraging the General Social Survey data, which collects information and records of behaviours, experiences and opinions of residents of the Us and is funded by the National Science Foundation, particularly finding the correlation between education, income and happiness for US residents in 2016. 

At the end of this project, learners will be able to deploy a python data analytics website using Python, Streamlit, Git and Heroku that they can show to potential hiring managers and recruiters as part of their portfolio.",,,,
Deploying a Pytorch Computer Vision Model API to Heroku,https://www.coursera.org/learn/deploying-a-pytorch-computer-vision-model-api-on-heroku,Data Science,Machine Learning,Emmanuel Acheampong,"Welcome to the “Deploying a Pytorch Computer Vision Model API to Heroku” guided project.

Computer vision is one of the prominent fields of AI with numerous applications in the real world including self-driving cars, image recognition, and object tracking, among others. The ability to make models available for real-world use is an essential skill anyone interested in AI engineering should have especially for computer vision and this is why this project exists.

In this project, we will deploy a Flask REST API using one of Pytorch's pre-trained computer vision image classification models. This API will be able to receive an image, inference the pre-trained model, and return its predicted classification.

This project is an intermediate python project for anyone interested in learning about how to productionize Pytorch computer vision models in the real world via a REST API on Heroku. It requires preliminary knowledge on how to build and train PyTorch models (as we will not be building or training models), how to utilize Git and a fundamental understanding of REST APIs. Learners would also need a Heroku account and some familiarity with the Python Flask module and the Postman API Platform.

At the end of this project, learners will have a publicly available API they can use to demonstrate their knowledge in deploying computer vision models.",,,,
Der Werkzeugkasten des Data Scientist,https://www.coursera.org/learn/data-scientists-tools-de,Data Science,Data Analysis,"Localization Team, Jeff Leek, PhD","In this course you will get an introduction to the main tools and ideas in the data scientist's toolbox. The course gives an overview of the data, questions, and tools that data analysts and data scientists work with. There are two components to this course. The first is a conceptual introduction to the ideas behind turning data into actionable knowledge. The second is a practical introduction to the tools that will be used in the program like version control, markdown, git, GitHub, R, and RStudio.",,,,
Des nombres et plus en Python,https://www.coursera.org/learn/des-nombres-et-plus-en-python,Data Science,Machine Learning,Fatima Youssef,"Dans ce cours d'une heure, basé sur un projet vous apprendrez les types de nombres en python, ainsi que les arithmétiques et les opérateurs de comparaison en Python.
A la fin de ce projet, vous serez capable d'utiliser les nombres en Python tel que ses types , ses affectations, les arithmétiques, et les opérateurs de comparaison.",,,,
Desarrollando modelos con Azure Custom Vision,https://www.coursera.org/learn/modelos-azurecustomvision,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a desarrollar modelos de aprendizaje supervisado con uno de los servicios cognitivos de Azure (Custom Vision) para analizar  imágenes y detectar objetivos sobre ellas de forma fácil, aprovechando las ventajas y potencia de la nube.",,,,
Desarrollar una aplicación web de ML con PyCaret y Streamlit,https://www.coursera.org/learn/web-app-ml-pycaret-streamlit,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico para crear una aplicación web con un modelo de aprendizaje automático. Aprenderemos desde las bases a utilizar librerías y herramientas como Pycaret, Streamlit, Heroku y GitHub, entre otros.
Gracias a este curso desarrollarás tu propio modelo de ML y página web y lo desplegarás en un servidor de Heroku.",,,,
Descriptive and Inferential Statistics in R,https://www.coursera.org/learn/descriptive-and-inferential-statistics-in-r,Data Science,Data Analysis,Emmanuel Segui,"In this 1-hour long project-based course, you will learn how to summarize descriptive statistics, calculate correlations and perform hypothesis testing in R


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Design Strategies for Maximizing Total Data Quality,https://www.coursera.org/learn/design-strategies-for-maximizing-total-data-quality,Data Science,Data Analysis,"Brady T. West, James Wagner, Jinseok Kim, Trent D Buskirk","By the end of this third course in the Total Data Quality Specialization, learners will be able to:

1. Learn about design tools and techniques for maximizing TDQ across all stages of the TDQ framework during a data collection or a data gathering process.
2. Identify aspects of the data generating or data gathering process that impact TDQ and be able to assess whether and how such aspects can be measured.
3. Understand TDQ maximization strategies that can be applied when gathering designed and found/organic data.
4. Develop solutions to hypothetical design problems arising during the process of data collection or data gathering and processing.

This specialization as a whole aims to explore the Total Data Quality framework in depth and provide learners with more information about the detailed evaluation of total data quality that needs to happen prior to data analysis. The goal is for learners to incorporate evaluations of data quality into their process as a critical component for all projects. We sincerely hope to disseminate knowledge about total data quality to all learners, such as data scientists and quantitative analysts, who have not had sufficient training in the initial steps of the data science process that focus on data collection and evaluation of data quality. We feel that extensive knowledge of data science techniques and statistical analysis procedures will not help a quantitative research study if the data collected/gathered are not of sufficiently high quality.

This specialization will focus on the essential first steps in any type of scientific investigation using data: either generating or gathering data, understanding where the data come from, evaluating the quality of the data, and taking steps to maximize the quality of the data prior to performing any kind of statistical analysis or applying data science techniques to answer research questions. Given this focus, there will be little material on the analysis of data, which is covered in myriad existing Coursera specializations. The primary focus of this specialization will be on understanding and maximizing data quality prior to analysis.",,,,
Design Thinking and Predictive Analytics for Data Products,https://www.coursera.org/learn/design-thinking-predictive-analytics-data-products,Data Science,Data Analysis,"Julian McAuley, Ilkay Altintas","This is the second course in the four-course specialization Python Data Products for Predictive Analytics, building on the data processing covered in Course 1 and introducing the basics of designing predictive models in Python. In this course, you will understand the fundamental concepts of statistical learning and learn various methods of building predictive models. At each step in the specialization, you will gain hands-on experience in data manipulation and building your skills, eventually culminating in a capstone project encompassing all the concepts taught in the specialization.",8540.0,4335.0,4.5,61.0
Design and Build a Data Warehouse for Business Intelligence Implementation,https://www.coursera.org/learn/data-warehouse-bi-building,Data Science,Data Analysis,"Michael Mannino, Jahangir Karimi","The capstone course, Design and Build a Data Warehouse for Business Intelligence Implementation, features a real-world case study that integrates your learning across all courses in the specialization. In response to business requirements presented in a case study, you’ll design and build a small data warehouse, create data integration workflows to refresh the warehouse, write SQL statements to support analytical and summary query requirements, and use the MicroStrategy business intelligence platform to create dashboards and visualizations.

In the first part of the capstone course, you’ll be introduced to a medium-sized firm, learning about their data warehouse and business intelligence requirements and existing data sources. You’ll first architect a warehouse schema and dimensional model for a small data warehouse. You’ll then create data integration workflows using Pentaho Data Integration to refresh your data warehouse. Next, you’ll write SQL statements for analytical query requirements and create materialized views to support summary data management. For data integration workflows and analytical queries, you can use either Oracle or PostgreSQL. Finally, you will use MicroStrategy OLAP capabilities to gain insights into your data warehouse. In the completed project, you’ll have built a small data warehouse containing a schema design, data integration workflows, analytical queries, materialized views, dashboards and visualizations that you’ll be proud to show to your current and prospective employers.",9951.0,8394.0,4.6,266.0
Designing Autonomous AI,https://www.coursera.org/learn/designing-autonomous-ai,Data Science,Machine Learning,Kence Anderson,"When children learn how to hit a baseball, they don’t start with fastballs. Their coaches begin with the basics: how to grip the handle of the bat, where to put their feet and how to keep their eyes on the ball. Similarly, an autonomous AI system needs a subject matter expert (SME) to break a complex process or problem into easier tasks that give the AI important clues about how to find a solution faster.  

In this course, you’ll learn how to distill a business challenge into its component parts by creating an autonomous AI design plan. Using lessons, goal setting, skills, strategies and rewards, you’ll incorporate your SME’s knowledge directly into your AI’s “brain,” the agent that powers your autonomous system. You'll learn when and how to combine various AI architecture design patterns, as well as how to design an advanced AI at the architectural level without worrying about the implementation of neural networks or machine learning algorithms. 

At the end of this course, you’ll be able to: 
•  Interview SMEs to extract their unique knowledge about a system or process  
•  Combine reinforcement learning with expert rules, optimization and mathematical calculations in an AI brain 
•  Design an autonomous AI brain from modular components to guide the learning process for a particular task 
•. Validate your brain design against existing expertise and techniques for solving problems 
•  Produce a detailed specifications document so that someone else can build your AI brain 

This course is part of a specialization called Autonomous AI for Industry, which will launch in fall 2022.",,3619.0,,
Designing data-intensive applications,https://www.coursera.org/learn/data-intensive-applications,Data Science,Data Analysis,María del Pilar Ángeles,"Welcome to the specialization course of Designing data-intensive applications. 

This course will be completed on four weeks, it will be supported with videos and exercises.

By the end of this specialization, learners will be able to propose, design, justify and develop high reliable information systems according to type of data and volume of information, response time, type of processing and queries in order to support scalability, maintainability, security and reliability considering the last information technologies.

Software to download:
MySQL Workbench 
Rapidminer
Hadoop framework Hortonworks
MongoDB

In case you have a Mac / IOS operating system you need to perform an action called VirtualBox.",6658.0,3442.0,4.4,36.0
Desplegando modelos de Machine Learning con Pycaret en Azure,https://www.coursera.org/learn/desplegando-modelos-ml-pycaret-azure,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a como desplegar modelos en Azure. Aprenderemos además a generar modelos de Machine Learning desde cero con Pycaret.
Al acabar este curso abras aprendido el ciclo completo de desarrollo de modelos de Machine Learning con Pycaret y su despliegue en la plataforma de Azure.",,,,
"Despliegue de modelos Deep Learning: Flask, heroku, Postman",https://www.coursera.org/learn/despliegue-modelos-deep-learning-flask-heroku-postman,Data Science,Machine Learning,Leire Ahedo,"En este proyecto aprenderás acerca del despliegue de modelos Deep Learning en producción, utilizando herramientas como Flask, heroku y Postman.",,,,
Despliegue de modelos de IA en IoT Edge con ONNX,https://www.coursera.org/learn/despliegue-de-modelos-ia-iot-edge-con-onnx,Data Science,Data Analysis,Leire Ahedo,"En este proyecto se aprenderá acerca del despliegue de modelos de IA en dispositivos IoT Edge con ONNX de manera práctica y aplicada. 
Aprenderemos a desarrollar modelos de Machine Learning desde cero para después desplegarlos en ONNX. Finalmente, aprenderemos también a como cargar los modelos en ONNX para hacer predicciones.",,,,
Detect Fake News in Python with Tensorflow,https://www.coursera.org/learn/detect-fake-news-python-tensorflow,Data Science,Machine Learning,Charles Ivan Niswander II,"""Fake News"" is a word used to mean different things to different people. At its heart, we define ""fake news"" as any news stories which are false: the article itself is fabricated without verifiable evidence, citations or quotations. Often these stories may be lies and propaganda that is deliberately intended to confuse the viewer, or may be characterized as ""click-bait"" written for monetary incentives (the writer profits on the number of people who click on the story). In recent years, fake news stories have proliferated via social media, partially because they are so readily and widely spread online. Worse yet, Artificial Intelligence and natural language processing, or NLP, technology is ushering in an era of artificially-generated fake news. Both types of fake news are detectable with the use of NLP and deep learning. 

In this project, you will learn multiple computational methods of identifying and classifying Fake News.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Detect and Mitigate Ethical Risks,https://www.coursera.org/learn/detect-mitigate-ethical-risks,Data Science,Machine Learning,"Renée Cummings, Jennifer Fischer, Eleanor 'Nell' Watson","Data-driven technologies like AI, when designed with ethics in mind, benefit both the business and society at large. But it’s not enough to say you will “be ethical” and expect it to happen. We need tools and techniques to help us assess gaps in our ethical behaviors and to identify and stop threats to our ethical goals. We also need to know where and how to improve our ethical processes across development lifecycles. What we need is a way to manage ethical risk. This third course in the Certified Ethical Emerging Technologist (CEET) professional certificate is designed for learners seeking to detect and mitigate ethical risks in the design, development, and deployment of data-driven technologies. Students will learn the fundamentals of ethical risk analysis, sources of risk, and how to manage different types of risk. Throughout the course, learners will learn strategies for identifying and mitigating risks.

This course is the third of five courses within the Certified Ethical Emerging Technologist (CEET) professional certificate. The preceding courses are titled Promote the Ethical Use of Data-Driven Technologies and Turn Ethical Frameworks into Actionable Steps.",7807.0,60693.0,4.5,66.0
Detecting COVID-19 with Chest X-Ray using PyTorch,https://www.coursera.org/learn/covid-19-detection-x-ray,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long guided project, we will use a ResNet-18 model and train it on a COVID-19 Radiography dataset. This dataset has nearly 3000 Chest X-Ray scans which are categorized in three classes - Normal, Viral Pneumonia and COVID-19. Our objective in this project is to create an image classification model that can predict Chest X-Ray scans that belong to one of the three classes with a reasonably high accuracy. Please note that this dataset, and the model that we train in the project, can not be used to diagnose COVID-19 or Viral Pneumonia. We are only using this data for educational purpose.

Before you attempt this project, you should be familiar with programming in Python. You should also have a theoretical understanding of Convolutional Neural Networks, and optimization techniques such as gradient descent. This is a hands on, practical project that focuses primarily on implementation, and not on the theory behind Convolutional Neural Networks.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",10593.0,,4.5,322.0
Determine Shortest Paths Between Routers Using Python,https://www.coursera.org/learn/shortest-paths-between-routers-using-python,Data Science,Data Analysis,David Dalsveen,"By the end of this project you will use the adjacency list data structure and other data structures to find the shortest distance between a set of routers loaded from a file.

The shortest path problem is well known in the field of computer science. An adjacency list is probably the best data structure to represent a set of connected vertices to find the shortest path from one vertex to another. One application for shortest paths is in mapping. Another common application for its use is in computer networking routing to find the shortest trip for a packet.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,17.0
Developing AI Applications on Azure,https://www.coursera.org/learn/developing-ai-applications-azure,Data Science,Machine Learning,"Ronald J. Daskevich, DCS","This course introduces the concepts of Artificial Intelligence and Machine learning. We'll discuss machine learning types and tasks, and machine learning algorithms. You'll  explore Python as a popular programming language for machine learning solutions, including using some scientific ecosystem packages which will help you implement machine learning. 

Next, this course introduces the machine learning tools available in Microsoft Azure. We'll review standardized approaches to data analytics and you'll receive specific guidance on Microsoft's Team Data Science Approach. As you go through the course, we'll introduce you to Microsoft's pre-trained and managed machine learning offered as REST API's in their suite of cognitive services. We'll implement solutions using the computer vision API and the facial recognition API, and we'll do sentiment analysis by calling the natural language service.   

Using the Azure Machine Learning Service you'll create and use an Azure Machine Learning Worksace.Then you'll train your own model, and you'll deploy and test your model in the cloud. Throughout the course you will perform hands-on exercises to practice your new AI skills. By the end of this course, you will be able to create, implement and deploy machine learning models.",45454.0,9074.0,4.4,962.0
Developing Data Models with LookML,https://www.coursera.org/learn/developing-data-models-with-lookml,Data Science,Data Analysis,Google Cloud Training,"This course empowers you to develop scalable, performant LookML (Looker Modeling Language) models that provide your business users with the standardized, ready-to-use data that they need to answer their questions. Upon completing this course, you will be able to start building and maintaining LookML models to curate and manage data in your organization’s Looker instance.",2113.0,15474.0,4.7,31.0
Developing Data Models with LookML 日本語版,https://www.coursera.org/learn/developing-data-models-with-lookml-ja,Data Science,Data Analysis,Google Cloud Training,このコースを受講すると、スケーラブルで高パフォーマンスの LookML（Looker モデリング言語）を開発し、ビジネス ユーザーの疑問解決に必要な、標準化されたすぐに使えるデータを提供できるようになります。このコースの修了時には、組織の Looker インスタンスでデータをキュレートして管理するための LookML モデルの構築と維持が可能になります。,,,,
Developing Data Products,https://www.coursera.org/learn/data-products,Data Science,Data Analysis,"Brian Caffo, PhD, Jeff Leek, PhD, Roger D. Peng, PhD","A data product is the production output from a statistical analysis. Data products automate complex analysis tasks or use technology to expand the utility of a data informed model, algorithm or inference. This course covers the basics of creating data products using Shiny, R packages, and interactive graphics. The course will focus on the statistical fundamentals of creating a data product that can be used to tell a story about data to a mass audience.",81545.0,37517.0,4.6,2243.0
Diabetes Disease Detection with XG-Boost and Neural Networks,https://www.coursera.org/learn/diabetes-disease-detection-with-xg-boost-and-neural-networks,Data Science,Machine Learning,Ryan Ahmed,"In this project-based course, we will build, train and test a machine learning model to detect diabetes with XG-boost and Artificial Neural Networks. The objective of this project is to predict whether a patient has diabetes or not based on their given features and diagnostic measurements such as number of pregnancies, insulin levels, Body mass index, age and blood pressure.",,,,
Diabetes Prediction With Pyspark MLLIB,https://www.coursera.org/learn/diabetes-prediction-with-pyspark-mllib,Data Science,Machine Learning,Priya Jha,"In this 1 hour long project-based course, you will learn to build a logistic regression model using Pyspark MLLIB to classify patients as either diabetic or non-diabetic. We will use the popular Pima Indian Diabetes data set. Our goal is to use a simple logistic regression classifier from the pyspark Machine learning library for diabetes classification. We will be carrying out the entire project on the Google Colab environment with the installation of Pyspark.You will need a free Gmail account to complete this project. Please be aware of the fact that the dataset and the model in this project, can not be used in the real-life. We are only using this data for the educational purpose.

By the end of this project, you will be able to build the logistic regression classifier using Pyspark MLlib to classify between the diabetic and nondiabetic patients.You will also be able to setup and work with  Pyspark on Google colab environment. Additionally, you will also be able to clean and prepare data for analysis.

You should be familiar with the Python Programming language and you should have a theoretical understanding of the Logistic Regression algorithm. You will need a free Gmail account to complete this project.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,16.0
Diabetic Retinopathy Detection with Artificial Intelligence,https://www.coursera.org/learn/retinopathy-detection-using-deep-learning,Data Science,Data Analysis,Ryan Ahmed,"In this project, we will train deep neural network model based on Convolutional Neural Networks (CNNs) and Residual Blocks to detect the type of Diabetic Retinopathy from images. Diabetic Retinopathy is the leading cause of blindness in the working-age population of the developed world and estimated to affect over 347 million people worldwide. Diabetic Retinopathy is disease that results from complication of type 1 & 2 diabetes and can develop if blood sugar levels are left uncontrolled for a prolonged period of time. With the power of Artificial Intelligence and Deep Learning, doctors will be able to detect blindness before it occurs.",,,4.5,34.0
Digging Deeper into Audience Reports in Google Analytics,https://www.coursera.org/learn/digging-deeper-into-audience-reports-in-google-analytics,Data Science,Data Analysis,Carma Baughman,"In this project, you will discover some of the potentially less familiar Audience Reports. You will learn about the Active Users report, the Lifetime Value report, the Cohort Analysis report, the Benchmarking reports and the Users Flow Report. But, even more importantly, you will learn how to use these reports to help you make better decisions when it comes to reaching and engaging your website audience.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3666.0,,4.6,52.0
Digital Marketing Analytics in Practice,https://www.coursera.org/learn/digital-analytics,Data Science,Data Analysis,Kevin Hartman,"Successfully marketing brands today requires a well-balanced blend of art and science. This course introduces students to the science of web analytics while casting a keen eye toward the artful use of numbers found in the digital space. The goal is to provide the foundation needed to apply data analytics to real-world challenges marketers confront daily. Digital Analytics for Marketing Professionals: Marketing Analytics in Practice is the second in a two-part series of complementary courses and focuses on the skills and practical abilities analysts need to be successful in today's digital business world.

You will be able to:
-	Identify the web analytic tool right for your specific needs
-	Understand valid and reliable ways to collect, analyze, and visualize data from the web
-	Utilize data in decision making for agencies, organizations, or clients

This course is part of Gies College of Business’ suite of online programs, including the iMBA and iMSM. Learn more about admission into these programs and explore how your Coursera work can be leveraged if accepted into a degree program at https://degrees.giesbusiness.illinois.edu/idegrees/.",115053.0,32031.0,4.5,3231.0
Digital Marketing Analytics in Theory,https://www.coursera.org/learn/marketing-analytics,Data Science,Data Analysis,Kevin Hartman,"Successfully marketing brands today requires a well-balanced blend of art and science. This course introduces students to the science of web analytics while casting a keen eye toward the artful use of numbers found in the digital space. The goal is to provide the foundation needed to apply data analytics to real-world challenges marketers confront daily. Digital Analytics for Marketing Professionals: Marketing Analytics in Theory is the first in a two-part series of complementary courses and focuses on the background information and frameworks analysts need to be successful in today's digital business world.

You will be able to:
-	Identify the web analytic tool right for your specific needs
-	Understand valid and reliable ways to collect, analyze, and visualize data from the web
-	Utilize data in decision making for agencies, organizations, or clients

This course is part of Gies College of Business’ suite of online programs, including the iMBA and iMSM. Learn more about admission into these programs and explore how your Coursera work can be leveraged if accepted into a degree program at https://degrees.giesbusiness.illinois.edu/idegrees/.",122766.0,48234.0,4.5,4676.0
Dimensionality Reduction using an Autoencoder in Python,https://www.coursera.org/learn/dimensionality-reduction-autoencoder-python,Data Science,Machine Learning,Ari Anastassiou,"In this 1-hour long project, you will learn how to generate your own high-dimensional dummy dataset. You will then learn how to preprocess it effectively before training a baseline PCA model. You will learn the theory behind the autoencoder, and how to train one in scikit-learn. You will also learn how to extract the encoder portion of it to reduce dimensionality of your input data. In the course of this project, you will also be exposed to some basic clustering strength metrics.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3436.0,,4.6,94.0
Diseñando tu primer modelo con Pytorch,https://www.coursera.org/learn/disenando-tu-primer-modelo-con-pytorch,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a crear, entrenar y evaluar una red neuronal convolucional básica para predecir la categoría asociada a imágenes
Además, cómo trabajar con Pytorch de forma online, usando Google Colaboratory.",,,,
Diseñando un bot con Azure LUIS,https://www.coursera.org/learn/bot-luis,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a desarrollar un modelo de entendimiento de lenguaje con Azure LUIS para desarrollar tus propios bots que entiendan las preguntas que sean formuladas por los usuarios.",,,4.9,10.0
Distributed Computing with Spark SQL,https://www.coursera.org/learn/spark-sql,Data Science,Data Analysis,"Brooke Wenig, Conor Murphy","This course is all about big data. It’s for students with SQL experience that want to take the next step on their data journey by learning distributed computing using Apache Spark. Students will gain a thorough understanding of this open-source standard for working with large datasets. Students will gain an understanding of the fundamentals of data analysis using SQL on Spark, setting the foundation for how to combine data with advanced analytics at scale and in production environments. The four modules build on one another and by the end of the course you will understand: the Spark architecture, queries within Spark, common ways to optimize Spark SQL, and how to build reliable data pipelines. 

The first module introduces Spark and the Databricks environment including how Spark distributes computation and Spark SQL. Module 2 covers the core concepts of Spark such as storage vs. compute, caching, partitions, and troubleshooting performance issues via the Spark UI. It also covers new features in Apache Spark 3.x such as Adaptive Query Execution. The third module focuses on Engineering Data Pipelines including connecting to databases, schemas and data types, file formats, and writing reliable data. The final module covers data lakes, data warehouses, and lakehouses. Students build production grade data pipelines by combining Spark with the open-source project Delta Lake. By the end of this course, students will hone their SQL and distributed computing skills to become more adept at advanced analysis and to set the stage for transitioning to more advanced analytics as Data Scientists.",33799.0,78869.0,4.5,540.0
Documentation and Usability for Cancer Informatics,https://www.coursera.org/learn/documentation-usability-cancer-informatics,Data Science,Data Analysis,"Candace Savonen, MS","Introduction: 

Cancer datasets are plentiful, complicated, and hold information that may be critical for the next research advancements. In order to use these data to their full potential, researchers are dependent on the specialized data tools that are continually being published and developed. Bioinformatics tools can often be unfriendly to their users, who often have little to no background in programming (Bolchini et al. 2008). The usability and quality of the documentation of a tool can be a major factor in how efficiently a researcher is able to obtain useful findings for the next steps of their research.

Increasing the usability and quality of documentation for a tool is not only helpful for the researcher users, but also for the developers themselves – the many hours of work put into the product will have a higher impact if the tool is usable by the target user community. 70% of bioinformatics tools surveyed by Duck et al. (2016) were not reused beyond their introductory publication. Even the most well-programmed tool will be overlooked by the user community if there is little to no user-friendly documentation or if they were not designed with the user in mind.

Target Audience:
The course is intended for cancer informatics tool developers, particularly those creating tools as a part of the Informatics Technology Cancer Research.

Learning Objectives: 
1. Understanding why usability and documentation is vital
2. Identifying your user community
3. Building documentation and tutorials to maximize the usability of developed tools
4. Obtaining feedback from your users

Curriculum:
This course will demonstrate how to: Understanding why usability and documentation is vital, Identifying your user community, Building documentation and tutorials to maximize the usability of developed tools, Obtaining feedback from your users

The course includes a hands-on exercises with templates for building documentation and tutorials for cancer informatics tools. Individuals who take this course are encouraged to use these templates as they follow along with the course material to help increase the usability of their informatics tool.

This course is part of a series of courses for the Informatics Technology for Cancer Research (ITCR) called the Informatics Technology for Cancer Research Education Resource. This material was created by the ITCR Training Network (ITN) which is a collaborative effort of researchers around the United States to support cancer informatics and data science training through resources, technology, and events. This initiative is funded by the following grant: National Cancer Institute (NCI) UE5 CA254170. Our courses feature tools developed by ITCR Investigators and make it easier for principal investigators, scientists, and analysts to integrate cancer informatics into their workflows. Please see our website at www.itcrtraining.org for more information.",,,,
Doing Clinical Research: Biostatistics with the Wolfram Language,https://www.coursera.org/learn/clinical-research-biostatistics-wolfram,Data Science,Data Analysis,Juan H Klopper,"This course has a singular and clear aim, to empower you to do statistical tests, ready for incorporation into your dissertations, research papers, and presentations.  The ability to summarize data, create plots and charts, and to do the tests that you commonly see in the literature is a powerful skill indeed.  Not only will it further your career, but it will put you in the position to contribute to the advancement of humanity through scientific research. 

We live in a wonderful age with great tools at our disposal, ready to achieve this goal.  None are quite as easy to learn, yet as powerful to use, as the Wolfram Language.  Knowledge is literally built into the language.  With its well-structured and consistent approach to creating code, you will become an expert in no time. 

This course follows the modern trend of learning statistical analysis through the use of a computer language.  It requires no prior knowledge of coding.  An exciting journey awaits. If you wanting even more, there are optional Honors lessons on machine learning that cover the support in the Wolfram Language for deep learning.",4962.0,4117.0,4.7,46.0
Doing Economics: Measuring Climate Change,https://www.coursera.org/learn/doing-economics-measuring-climate-change,Data Science,Data Analysis,"Eileen Tipoe, Wendy Carlin","This course will give you practical experience in working with real-world data, with applications to important policy issues in today’s society. Each week, you will learn specific data handling skills in Excel and use these techniques to analyse climate change data, with appropriate readings to provide background information on the data you are working with. You will also learn about the consequences of climate change and how governments can address this issue.

After completing this course, you should be able to:
•	Understand how data can be used to assess the extent of climate change
•	Produce appropriate bar charts, line charts, and scatterplots to visualise data  
•	Calculate and interpret summary statistics (mean, median, variance, percentile, correlation)
•	Explain the challenges with designing and implementing policies that address climate change

No prior knowledge in economics or statistics is required for this course. No knowledge of Excel is required, except a familiarity with the interface and how to enter and clear data.",,7366.0,4.9,12.0
Doing More with SAS Programming,https://www.coursera.org/learn/sas-programming-advanced,Data Science,Data Analysis,Stacey Syphus,"This course is for business analysts and SAS programmers who want to learn data manipulation techniques using the SAS DATA step and procedures to access, transform, and summarize data. The course builds on the concepts that are presented in the Getting Started with SAS Programming course and is not recommended for beginning SAS software users.

In this course you learn how to understand and control DATA step processing, create an accumulating column and process data in groups, manipulate data with functions, convert column type, create custom formats, concatenate and merge tables, process repetitive code, and restructure tables. This course addresses Base SAS software.

Before attending this course, you should be able to write DATA step code to access data, subset rows and columns, compute new columns, and process data conditionally. You should also be able to sort tables using the SORT procedure and
apply SAS formats.",25646.0,76399.0,4.8,852.0
Draw Insights with Crosstabs Reports in Google Sheets,https://www.coursera.org/learn/draw-insights-with-crosstabs-reports-google-sheets,Data Science,Data Analysis,Tricia Bagley,"Crosstabs reports present select slices of data in a matrix format making it easier to visualize patterns and explore similarities and differences between categories or variables. In this course, we’ll explore the pivot-table tactics applied in Google Sheets to create crosstabs reports, conduct a preliminary—exploratory—analysis of the data within the report, and learn how visually presenting data in a crosstabs report can aid the user in their discovery of insights that tell the data’s story. By the end of this course, you will be able to apply pivot table tactics to create crosstabs reports and share data in your business’s domain.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,27.0
Débuter avec ImageJ,https://www.coursera.org/learn/debuter-imagej,Data Science,Data Analysis,Delphine Sangotokun,"À la fin de ce projet, vous apprendrez à utiliser télécharger et commencer avec ImageJ et à utiliser les commandes principales de ce logiciel pour le traitement et l'analyse d'images, entre autres scientifiques.
Ce projet guidé s'adresse aux personnes intéressées par l’analyse d’image, telles que pour déterminer le nombre ou la taille d’objet dans une image, pour des raisons scientifiques ou personnelles.
ImageJ est un logiciel gratuit à télécharger en ligne qui offre une très grande variété d’outils pour le traitement d’images et qui peut être particulièrement efficace pour des analyses scientifiques.
Après avoir terminé ce projet, vous aurez accès au logiciel ImageJ et vous serez capable d’utiliser les fonctions de base pour analyser des images et détecter par exemple le nombre et la taille d’objet dans une image. ImageJ est un logiciel simple et gratuit qui fournit tous les outils dont vous avez besoin pour traiter et analyser toutes vos images. Le logiciel est très facile à utiliser et offre une capacité d’analyse très impressionnante !",,,,
Econometrics: Methods and Applications,https://www.coursera.org/learn/erasmus-econometrics,Data Science,Probability and Statistics,"Francine Gresnigt, Dennis Fok, Michel van der Wel, Erik Kole, Christiaan Heij, Wendun Wang, Richard Paap, Dick van Dijk , Philip Hans Franses, Myrthe van Dieijen","Welcome!

Do you wish to know how to analyze and solve business and economic questions with data analysis tools? Then Econometrics by Erasmus University Rotterdam is the right course for you, as you learn how to translate data into models to make forecasts and to support decision making.

* What do I learn?
When you know econometrics, you are able to translate data into models to make forecasts and to support decision making in a wide variety of fields, ranging from macroeconomics to finance and marketing. Our course starts with introductory lectures on simple and multiple regression, followed by topics of special interest to deal with model specification, endogenous variables, binary choice data, and time series data.  You learn these key topics in econometrics by watching the videos with in-video quizzes and by making post-video training exercises. 

* Do I need prior knowledge?
The course is suitable for (advanced undergraduate) students in economics, finance, business, engineering, and data analysis, as well as for those who work in these fields. The course requires some basics of matrices, probability, and statistics, which are reviewed in the Building Blocks module. If you are searching for a MOOC on econometrics of a more introductory nature that needs less background in mathematics, you may be interested in the Coursera course “Enjoyable Econometrics” that is also from Erasmus University Rotterdam.

* What literature can I consult to support my studies?
You can follow the MOOC without studying additional sources. Further reading of the discussed topics (including the Building Blocks) is provided in the textbook that we wrote and on which the MOOC is based: Econometric Methods with Applications in Business and Economics, Oxford University Press. The connection between the MOOC modules and the book chapters is shown in the Course Guide – Further Information – How can I continue my studies.

* Will there be teaching assistants active to guide me through the course?
Staff and PhD students of our Econometric Institute will provide guidance in January and February of each year. In other periods, we provide only elementary guidance. We always advise you to connect with fellow learners of this course to discuss topics and exercises.

* How will I get a certificate?
To gain the certificate of this course, you are asked to make six Test Exercises (one per module) and a Case Project. Further, you perform peer-reviewing activities of the work of three of your fellow learners of this MOOC. You gain the certificate if you pass all seven assignments.

Have a nice journey into the world of Econometrics!
The Econometrics team",161374.0,65748.0,4.6,1123.0
Effectively Dealing with Imbalance Classes,https://www.coursera.org/learn/imbalance-classes,Data Science,Data Analysis,Muhammad Saad uddin,"In this 2 hour guided project you will learn how to deal with imbalance classification problems in a profound manner, applying several resampling strategies and visualizing the effects of resampling on imbalance classification dataset.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Ein Crashkurs in Datenwissenschaft,https://www.coursera.org/learn/data-science-course-de,Data Science,Data Analysis,"Jeff Leek, PhD, Brian Caffo, PhD, Roger D. Peng, PhD","Inzwischen haben Sie sicher schon von Datenwissenschaft und Big Data gehört. In diesem einwöchigen Kurs werden wir in einem Crashkurs vermitteln, was diese Begriffe bedeuten und inwiefern sie in erfolgreichen Organisationen eine Rolle spielen. Dieser Kurs richtet sich an alle, die mehr über die Datenwissenschaft erfahren möchten, aber auch an jene, die vorhaben, ein Team von Datenwissenschaftlern zu leiten. Das Ziel ist es, Sie so schnell wie möglich pragmatisch mit der Datenwissenschaft vertraut zu machen. Wir haben diesen Kurs so praktisch und zweckmäßig wie möglich angelegt, ohne jedoch auf die Grundlagen zu verzichten.

Hierbei handelt es sich um einen zielgerichteten Kurs, der Sie im Bereich der Datenwissenschaft schnell auf den neuesten Stand bringen soll. Unser Ziel war es, dies für Sie so bequem wie möglich zu gestalten, ohne auf wesentliche Inhalte zu verzichten. Wir haben die technischen Informationen beiseitegelassen, damit Sie sich darauf konzentrieren können, Ihr Team zu managen und voranzubringen.

Nach Abschluss dieses Kurses werden Sie:

1. Wissen, wie man die Rolle der Datenwissenschaft in verschiedenen Kontexten beschreibt
2. Wissen, inwiefern Statistik, maschinelles Lernen und Software-Engineering in der Datenwissenschaft eine Rolle spielen
3. Wissen, wie man die Struktur eines datenwissenschaftlichen Projekts beschreibt
4. Die wichtigsten Begriffe und Tools kennen, die von Datenwissenschaftlern verwendet werden
5. Wissen, wie man ein erfolgreiches und ein erfolgloses datenwissenschaftliches Projekt erkennt
3. Mehr über die Rolle eines Data Science Managers wissen


Kurs-Cover-Bild von r2hox. Creative Commons BY-SA: https://flic.kr/p/gdMuhT",,,,
Eine Fallstudie Anfertigen,https://www.coursera.org/learn/google-data-analytics-eine-fallstudie-anfertigen,Data Science,Data Analysis,Google Career Certificates,"Dies ist der achte Kurs im Google Data Analytics Certificate. Sie haben die Möglichkeit, eine optionale Fallstudie anzufertigen, die Sie auf die Jobsuche im Bereich Data Analytics vorbereitet. Fallstudien werden häufig von Arbeitgebenden verwendet, um analytische Fähigkeiten zu bewerten. Für Ihre Fallstudie wählen Sie ein analysebasiertes Szenario aus. Anschließend stellen Sie Fragen, bereiten die Daten aus dem Szenario vor, verarbeiten, analysieren, visualisieren sie und reagieren auf sie. Sie erlernen auch andere nützliche Fähigkeiten für die Jobsuche durch Videos mit häufigen Fragen und Antworten bei Vorstellungsgesprächen, hilfreiche Materialien zum Aufbau eines Online-Portfolios und vieles mehr. Bei Google tätige Fachleute für die Datenanalyse werden Sie weiterhin anleiten und Ihnen praktische Möglichkeiten zeigen, wie Sie häufige Datenanalyseaufgaben mithilfe der besten Tools und Ressourcen erledigen können.

Nach Abschluss dieses Zertifikatsprogramms sind Lernende bestens gerüstet, um sich auf Einstiegspositionen in der Datenanalyse zu bewerben. Es sind keine Vorkenntnisse erforderlich.

Im Verlauf dieses Kurses werden Sie:
 - die Vorteile und Nutzen von Fallstudien und Portfolios bei der Jobsuche kennenlernen
 - reale Szenarien und häufige Fragen eines Vorstellungsgesprächs kennenlernen
 - erfahren, inwiefern Fallstudien Teil des Bewerbungsprozesses sein können 
 - verschiedene Fallstudienszenarien untersuchen und berücksichtigen 
 - die Möglichkeit haben, Ihre eigene Fallstudie für Ihr Portfolio anzufertigen",,,,
Einführung in Zeitreihenanalyse mit R,https://www.coursera.org/learn/einfhrung-in-zeitreihenanalyse-mit-r,Data Science,Machine Learning,Sandro Raabe,"In diesem zweistündigen Projekt wirst du eine gründliche Analyse einer Zeitreihe mithilfe eines ARIMA-Modells durchführen. Dieses Projekt erklärt die grundlegenden Konzepte von Zeitreihenanalyse und illustriert dies praktisch in RStudio. Wir beschreiben die Arten von Zeitreihen und ihre verschiedenen Komponenten. Das Projekt deckt ab, wie man diagnostische Tests durchführt, um die grundlegenden Vorraussetzungen für ARIMA-Modelle zu testen. Schließlich leiten wir das beste Modell ab, um zukünftige Werte vorherzusagen. Wir werden gemeinsam die grundlegenden Pakete und Funktionen in R durchgehen, um Zeitreihenanalyse einfach zu machen. Du benötigst für dieses Projekt keine Vorkenntnisse! Wir werden alles Schritt für Schritt erklären. 

Am Ende dieses Projektes wirst du in der Lage sein, eine Zeitreihe systematisch zu analysieren, die Vorraussetzungen für ein ARIMA-Modell zu prüfen, eine Zeitreihe mithilfe eines passenden ARIMA-Modells zu modellieren und daraus zukünftige Werte vorherzusagen.",,,,
Einführung in die Datenanalyse mit Excel,https://www.coursera.org/learn/excel-data-analysis-de,Data Science,Data Analysis,Sharad Borle,"Die Verwendung von Excel ist in der Branche weit verbreitet. Es ist ein sehr leistungsfähiges Datenanalysetool und fast alle großen und kleinen Unternehmen verwenden Excel für ihre tägliche Arbeit. Dies ist ein Einführungskurs in die Verwendung von Excel, der Ihnen Kenntnisse in Excel vermitteln soll, um es später für weiterführende Themen in der Unternehmensstatistik verwenden zu können. Der Kurs ist so konzipiert, dass zwei Arten von Teilnehmern berücksichtigt werden – diejenigen, die nur sehr geringe funktionale Kenntnisse in Excel haben und diejenigen, die Excel regelmäßig, aber auf peripherer Ebene verwenden und ihre Fähigkeiten verbessern möchten. Der Kurs führt Sie von grundlegenden Vorgängen wie dem Einlesen von Daten in Excel mithilfe verschiedener Datenformate und dem Organisieren und Bearbeiten von Daten bis hin zu einigen der erweiterten Funktionen von Excel. Während der gesamten Zeit wird die Excel-Funktionalität anhand leicht verständlicher Beispiele vorgestellt, die so demonstriert werden, dass die Teilnehmer sie besser verstehen und anwenden können.

Um Kursaufgaben erfolgreich abzuschließen, müssen die Teilnehmer Zugriff auf eine Windows-Version von Microsoft Excel 2010 oder höher haben. 
________________________________________
WOCHE 1
Modul 1: Einführung in die Tabellenkalkulation
Dieses Modul bietet eine Einführung in die Excel-Tabellenkalkulation und die verschiedenen grundlegenden Datenfunktionen von Excel.

Zu den behandelten Themen gehören:
•	Einlesen von Daten in Excel in verschiedenen Formaten
•	Grundfunktionen in Excel, Arithmetik sowie verschiedene logische Funktionen
•	Formatieren von Zeilen und Spalten
•	Verwenden von Formeln in Excel und diese unter Verwendung absoluter und relativer Referenzierung kopieren und einfügen
________________________________________
WOCHE 2
Modul 2: Tabellenkalkulationsfunktionen zum Organisieren von Daten
Dieses Modul führt verschiedene Excel-Funktionen zum Organisieren und Abfragen von Daten ein. Die Teilnehmer werden in die Funktionen WENN, Verschachteltes WENN, SVERWEIS und WVERWEIS von Excel eingeführt. 

Zu den behandelten Themen gehören:
•	WENN und geschachtelte WENN-Funktionen
•	SVERWEIS und WVERWEIS
•	Die ZUFALLSBEREICH-Funktion
________________________________________
Woche 3
Modul 3: Einführung in Filterung, Pivottabellen und Diagramme
Dieses Modul führt verschiedene Datenfilterfunktionen von Excel ein. Sie lernen, wie Sie Filter in Daten festlegen, um selektiv auf Daten zuzugreifen. Ein sehr leistungsfähiges Tool zum Zusammenfassen von Daten, die Pivottabelle, wird ebenfalls erläutert, und wir beginnen mit der Einführung der Diagrammfunktion von Excel.

Zu den behandelten Themen gehören:
•	SVERWEIS über Arbeitsblätter hinweg
•	Datenfilterung in Excel
•	Verwendung von Pivottabellen mit kategorialen sowie numerischen Daten
•	Einführung in die Diagrammfunktion von Excel
________________________________________
WOCHE 4
Modul 4: Erweiterte grafische Darstellung und Diagrammerstellung
In diesem Modul werden verschiedene erweiterte Grafik- und Diagrammtechniken erläutert, die in Excel verfügbar sind. Ausgehend von verschiedenen Linien-, Balken- und Kreisdiagrammen führen wir Pivotdiagramme, Streudiagramme und Histogramme ein. Sie werden lernen, diese verschiedenen Diagramme zu verstehen und selbst zu erstellen.

Zu den behandelten Themen gehören:
•	Linien-, Balken- und Kreisdiagramme
•	Pivotdiagramme
•	Streudiagramme
•	Histogramme",,,,
Einführung in die Datenvisualisierung mit Microsoft Excel,https://www.coursera.org/learn/einfuehrung-in-die-datenvisualisierung-mit-microsoft-excel,Data Science,Data Analysis,Nadine Rodriguez,"Nach Abschluss dieses Projekts wirst du ein paar Grundregeln der Datenvisualisierung kennengelernt haben und kannst diese bei der Erstellung von Diagrammen anwenden.   
Heutzutage kann man Datenvisualisierung in so ziemlicher jedem Fachgebiet finden. Unternehmen zeigen Grafiken, um ihre Umsatzzahlen zu vermelden, Polizeidienststellen erstellen Karten von Verbrechen in der Stadt und auf der Website des Einwohnermeldeamtes kann man visuelle Vergleiche von Zugezogenen und Weggezogenen Einwohnern finden. Aus diesem Grund ist es für viele Menschen unumgänglich sich mit den Grundlagen der Datenvisualisierung auseinanderzusetzen.",,,,
Einstieg in die Raeumliche Datenanalyse mit GeoDa,https://www.coursera.org/learn/einstieg-raeumliche-datenanalyse-mit-geoda,Data Science,Data Analysis,Nadine Rodriguez,"Am Ende dieses Projekts wirst du mit ein paar Grundlagen der räumlichen Datenanalyse in GeoDa vertraut sein. Zum Beispiel wirst du lernen, wo du die Software und kostenlose Datensätze finden kannst. Außerdem erhältst du eine Einführung in die Software und lernst, wie man mehrere Daten-Layer in eine Karte einfügt. Die räumliche Datenanalyse hat über die letzten Jahrzehnte stets an Bedeutung zugenommen.  Die Anfänge sind oft auf John Snow’s Karten, welche die Cholera Epidemie im 18. Jahrhundert veranschaulichen, zurückzuführen. Heutzutage wird die räumliche Datenanalyse in vielen verschiedenen Aufgabenfeldern verwendet, wie zum Beispiel für die Planung von Städten und Infrastruktur, um Verbrechen zu visualisieren und für das Notfallmanagement. In 2003 haben Dr. Luc Anselin und sein Team an der University of Chicago GeoDa entwickelt, um eine kostenlose Software zur Verfügung zu stellen, die hilft die altmodischen Stecknadelkarten zu digitalisieren.",,,,
Emotion AI: Facial Key-points Detection,https://www.coursera.org/learn/facial-key-point-detection,Data Science,Machine Learning,Ryan Ahmed,"In this 1-hour long project-based course, you will be able to:
- Understand the theory and intuition behind Deep Learning, Convolutional Neural Networks (CNNs) and Residual Neural Networks.
- Import Key libraries, dataset and visualize images.
- Perform data augmentation to increase the size of the dataset and improve model generalization capability.
- Build a deep learning model based on Convolutional Neural Network and Residual blocks using Keras with Tensorflow 2.0 as a backend.
- Compile and fit Deep Learning model to training data. 
- Assess the performance of trained CNN and ensure its generalization using various KPIs.
- Improve network performance using regularization techniques such as dropout.",7064.0,,4.6,149.0
Employee Attrition Prediction Using Machine Learning,https://www.coursera.org/learn/employee-attrition-prediction,Data Science,Machine Learning,Ryan Ahmed,"In this project-based course, we will build, train and test a machine learning model to predict employee attrition using features such as employee job satisfaction, distance from work, compensation and performance. We will explore two machine learning algorithms, namely: (1) logistic regression classifier model and (2) Extreme Gradient Boosted Trees (XG-Boost). This project could be effectively applied in any Human Resources department to predict which employees are more likely to quit based on their features. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
English/French Translator: Long Short Term Memory Networks,https://www.coursera.org/learn/nlp-english-to-french-translation,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train a Long Short Term (LSTM) Network to perform English to French Translation. This project could be practically used by travelers or people who are settling into a new country.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2946.0,,4.8,49.0
Enjoyable Econometrics,https://www.coursera.org/learn/enjoyable-econometrics,Data Science,Probability and Statistics,Philip Hans Franses,"The goal of this MOOC is to show that econometric methods are often needed to answer questions. A question comes first, then data are to be collected, and then finally the model or method comes in. Depending on the data, however, it can happen that methods need to be adapted. For example, where we first look at two variables, later we may need to look at three or more. Or, when data are missing, what then do we do? And, if the data are counts, like the number of newspaper articles citing someone, then matters may change too. But these modifications always come last, and are considered only when relevant. 

An important motivation for me to make this MOOC is to emphasize that econometric models and methods can also be applied to more unconventional settings, which are typically settings where the practitioner has to collect his or her own data first. Such collection can be done by carefully combining existing databases, but also by holding surveys or running experiments. A byproduct of having to collect your own data is that this helps to choose amongst the potential methods and techniques that are around.

If you are searching for a MOOC on econometrics that treats (mathematical and statistical) methods of econometrics and their applications, you may be interested in the Coursera course “Econometrics: Methods and Applications” that is also from Erasmus University Rotterdam.",17744.0,10418.0,4.1,80.0
Ensemble Methods in Machine Learning,https://www.coursera.org/learn/ensemble-methods-machine-learning,Data Science,Machine Learning,Farhad Abdi,"In this 2-hour long project-based course, you will learn how to implement various ensemble techniques and use it in machine learning. Ensemble models in machine learning combine the decisions from multiple models to improve the overall performance, The main causes of error in learning models are due to noise, bias and variance, Ensemble methods help to minimize these factors.",,,3.8,11.0
Entendiendo un proceso de MLOps con Azure Databricks,https://www.coursera.org/learn/mlops-databricks,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto, vamos a comprender el concepto de MLOps y su función dentro de un proceso de Data Science, enfocado con la herramienta de Azure Databricks.",,,,
Erste Schritte mit R,https://www.coursera.org/learn/erste-schritte-mit-r,Data Science,Machine Learning,Sandro Raabe,"In diesem zweistündigen Projekt wirst du die Basics der Programmiersprache R kennen lernen. Darüberhinaus wirst du deine ersten Schritte mit R für Data Analysis gehen. Du wirst die Programmierumgebung RStudio benutzen und Datentypen und Datenstrukturen in R unterscheiden und benutzen lernen. Außerdem wirst du Daten, die in externen CSV- und XLSX-Dateien gespeichert sind, in RStudion einlesen und filtern.

R ist eine anfängerfreundliche Programmiersprache, die ursprünglich in der Biologie, Psychologie und Statistik weit verbreitet war und heute neben Python der de-facto Standard in Data Analytics, Data Science und Machine Learning ist.

Dieser Kurs richtet sich an Lernende, die daran interessiert sind, mit R zu programmieren. Es gibt keine harten Voraussetzungen!",,,,
Erste Schritte mit R Markdown,https://www.coursera.org/learn/erste-schritte-mit-r-markdown,Data Science,Data Analysis,Sandro Raabe,"Dieses Projekt richtet sich an Anfänger, die die Programmier- und Analysesprache R nutzen möchten, um reproduzierbare Analysedokumente zu erstellen. 

R Markdown ist ein Veröffentlichungs-Framework für Data Science. Du kannst eine R-Markdown-Datei benutzen, um R-Code zu erstellen, zu speichern, auszuführen und hochqualitative Reports aus deiner Analyse zu erstellen, die du mit anderen teilen kannst. R-Markdown-Dokumente sind 100 % reproduzierbar und lassen sich in vielfältige statische Formate wie PDF oder Microsoft Word oder dynamische Formate wie Webseiten, Dashboards oder Apps exportieren.

Am Ende der fünf Tasks, die etwa eine Stunde in Anspruch nehmen, wirst du in der Lage sein, ein R-Markdown-Dokument zu erstellen, die verschiedenen Komponenten einer R-Markdown-Datei zu verstehen, R-Markdown-Kommandos zu verwenden und deine Analyse als Word- und PDF- und HTML-Dokument auszuleiten. Es gibt keine harten Voraussetzungen - jeder sichere Computerbenutzer mit Interesse an Datenanalyse sollte das Projekt erfolgreich beenden können!",,,,
Erste Schritte mit SQL,https://www.coursera.org/learn/erste-schritte-mit-sql,Data Science,Data Analysis,Sandro Raabe,"SQL ist DIE grundlegende Technologie, um Informationen strukturiert abzulegen. In diesem anfängerfreundlichen Projekt wirst du grundlegende SQL-Abfragen schreiben! Du wirst damit Daten aus Tabellen einer sogenannten relationalen Datenbank extrahieren und modifizieren.

In praktischen Übungen wirst du SQL-Code schreiben und ausführen, der die gewünschten Daten aus der Datenbank sammelt und bereit stellt. Zusätzlich wirst du die Ergebnisse modifizieren, indem du sie filterst, sortierst und neue Spalten erzeugst, um verborgene Daten ans Licht zu bringen!",,,,
Erste Schritte mit dem tidyverse,https://www.coursera.org/learn/erste-schritte-mit-dem-tidyverse,Data Science,Data Analysis,Sandro Raabe,"In diesem angeleiteten Projekt wirst du die berühmte tidyverse-Paketfamilie kennen lernen! Das tidyverse ist eine Sammlung von R-Paketen für Data Analysis und Data Science, die die gleiche Philosophie und die gleichen Regeln teilen und perfekt ineinander greifen. Dabei löst jedes Paket einen definierten Job. Das tidyverse hat die Art, wie Data Scientists fast jeden Aspekt ihrer Arbeit tun, revolutioniert.

Du wirst in diesem Kurs lernen, Daten auszuwerten, Zeichenketten zu filtern, Tabellen zu transformieren, Informationen zu visualisieren und elegant über Listen zu iterieren.

Am Ende dieses Kurses wirst du in der Lage sein, die Stärken der verschiedenen tidyverse-Pakete für den Erfolg deiner eigenen Projekte zu verwenden.",,,,
Essential Causal Inference Techniques for Data Science,https://www.coursera.org/learn/essential-causal-inference-for-data-science,Data Science,Data Analysis,Vinod Bakthavachalam,"Data scientists often get asked questions related to causality: (1) did recent PR coverage drive sign-ups, (2) does customer support increase sales, or (3) did improving the recommendation model drive revenue? Supporting company stakeholders requires every data scientist to learn techniques that can answer questions like these, which are centered around issues of causality and are solved with causal inference.

In this project, you will learn the high level theory and intuition behind the four main causal inference techniques of controlled regression, regression discontinuity, difference in difference, and instrumental variables as well as some techniques at the intersection of machine learning and causal inference that are useful in data science called double selection and causal forests. These will help you rigorously answer questions like those above and become a better data scientist!",,,4.5,30.0
Essential Design Principles for Tableau,https://www.coursera.org/learn/dataviz-design,Data Science,Data Analysis,"Govind Acharya, Hunter Whitney","In this course, you will analyze and apply essential design principles to your Tableau visualizations. This course assumes you understand the tools within Tableau and have some knowledge of the fundamental concepts of data visualization. You will define and examine the similarities and differences of exploratory and explanatory analysis as well as begin to ask the right questions about what’s needed in a visualization. You will assess how data and design work together, including how to choose the appropriate visual representation for your data, and the difference between effective and ineffective visuals. You will apply effective best practice design principles to your data visualizations and be able to illustrate examples of strategic use of contrast to highlight important elements. You will evaluate pre-attentive attributes and why they are important in visualizations. You will exam the importance of using the ""right"" amount of color and in the right place and be able to apply design principles to de-clutter your data visualization.",55347.0,81288.0,4.4,1841.0
Estadística aplicada a los negocios,https://www.coursera.org/learn/estadistica-aplicada-negocios,Data Science,Probability and Statistics,Magdalena Cornejo,"La toma de decisiones está en la esencia de los negocios. Gerenciar es tomar decisiones, muchas veces bajo presión, con información desordenada y en un contexto de incertidumbre. Un aspecto básico es entender y analizar la información, organizar los datos de forma de facilitar su posterior uso y la toma de decisiones. Si bien hay muchas otras dimensiones que entran en juego, el primer paso es formular bien el problema, estructurarlo y procesar la información. En este sentido, el principal objetivo de este curso es ayudarlo a ser un mejor tomador de decisiones a través de herramientas técnicas.

A lo largo de este curso el alumno desarrollará habilidades cuantitativas para la toma de decisiones, a través del aprendizaje de métodos estadísticos con aplicaciones a los negocios en Excel. El foco está en la comprensión y en el uso de herramientas básicas de análisis e inferencia estadística tratando de que el alumno sea un usuario de estos métodos, comprenda en qué consisten, cuál es la intuición, su uso y aplicaciones.",50183.0,42127.0,4.6,681.0
Estadística y probabilidad,https://www.coursera.org/learn/estadistica-probabilidad,Data Science,Probability and Statistics,Hugo Mael Hernández Trevethan,"En este curso podrás apoyar tu formación en temas de estadística y probabilidad

Más allá de que encuentres aquí un apoyo para lograr una calificación, el curso busca ayudarte a que adquieras los aprendizajes que comprenden temas de estadística descriptiva, datos bivariados y probabilidad, los cuales te serán de utilidad en tu paso por la licenciatura y en tu vida profesional.",77096.0,159692.0,4.6,1296.0
Estadística y probabilidad: principios de Inferencia,https://www.coursera.org/learn/inferencia-estadistica,Data Science,Probability and Statistics,Hugo Mael Hernández Trevethan,"En este curso aprenderás los conceptos y aplicaciones propias de las distribuciones de probabilidad, distribuciones muestrales, estimación por intervalos y pruebas de hipótesis. 

Si ya estás familiarizado con los fundamentos de la estadística descriptiva, los datos bivariados y principios básicos de probabilidad, este curso viene a complementar perfectamente esos saberes. Si te estás adentrando por primera vez en el universo de la estadística y la probabilidad, te recomendamos ampliamente que realices el curso ""estadística y probabilidad"", disponible en esta misma plataforma https://www.coursera.org/learn/estadistica-probabilidad/",,5922.0,,
Estadísticas para la Ciencia de Datos con Python,https://www.coursera.org/learn/estadisticas-para-la-ciencia-de-datos-con-python,Data Science,Probability and Statistics,"Murtaza Haider, Aije Egwaikhide","Este curso de Estadística para la Ciencia de Datos está diseñado para presentarle los principios básicos de los métodos y procedimientos estadísticos utilizados para el análisis de datos. Después de completar este curso, tendrá conocimientos prácticos de temas cruciales en estadística que incluyen: recopilación de datos, resumen de datos utilizando estadísticas descriptivas, visualización de datos, examen de relaciones entre variables, distribuciones de probabilidad, valores esperados, pruebas de hipótesis, introducción a ANOVA (análisis de la varianza), análisis de regresión y correlación. Adoptará un enfoque práctico para el análisis estadístico utilizando Python y los Notebooks Jupyter, las herramientas elegidas por los científicos y analistas de datos.

Al final del curso, completará un proyecto para aplicar varios conceptos en el curso a un problema de Ciencia de Datos que involucre un escenario inspirado en la vida real y demostrará una comprensión del pensamiento y razonamiento estadístico fundamental. El objetivo es desarrollar una comprensión clara de los diferentes enfoques para diferentes tipos de datos, desarrollar una comprensión intuitiva, realizar evaluaciones apropiadas de los métodos propuestos, utilizar Python para analizar nuestros datos e interpretar el resultado con precisión.

Este curso es adecuado para una variedad de profesionales y estudiantes que deseen comenzar su viaje en roles basados en datos y estadísticas, como Científicos de Datos, Analistas de Datos, Analistas de Negocios, Estadísticos e Investigadores. No requiere ningún conocimiento de informática o estadística. Recomendamos encarecidamente tomar el curso Python para Ciencia de Datos antes de comenzar este curso para familiarizarse con el lenguaje de programación Python, los notebooks Jupyter y las bibliotecas. También se proporciona un repaso opcional en Python.

Después de completar este curso, un alumno podrá:
✔Calcular y aplicar medidas de tendencia central y medidas de dispersión a datos agrupados y no agrupados.
✔ Resumir, presentar y visualizar datos de una manera clara, concisa y que proporcione una visión práctica para los no estadísticos que necesitan los resultados.
✔Identificar las pruebas de hipótesis apropiadas para usar en conjuntos de datos comunes.
✔ Realizar pruebas de hipótesis, pruebas de correlación y análisis de regresión.
✔ Demostrar competencia en análisis estadístico utilizando Python y Notebooks Jupyter.",,4916.0,,
Estatística não-paramétrica para a tomada de decisão,https://www.coursera.org/learn/estatistica-nao-parametrica,Data Science,Probability and Statistics,Alexandre Leoneti,"Os testes estatísticos não-paramétricos são métodos que têm maior relevância nas ciências sociais aplicadas, pois permitem trabalhar com pequenas amostras ou amostras das quais não se tenha certeza de que sejam provenientes de população com distribuição normal, assumindo poucas hipóteses sobre a distribuição de probabilidade da população. Estes testes são adequados para apoiar a tomada de decisão dentro das organizações em situações nas quais não seja atendido algum dos requisitos para a aplicação dos testes estatísticos paramétricos, como o teste Z, o teste T, e o teste F de análise de variância – ANOVA, que dependem: (i) da condição de a amostra ter sido extraída de uma população distribuída de acordo com distribuição normal (de Gauss); (ii) da escala de medida da variável aleatória ser contínua; e (iii) do tamanho da amostra ser maior do que 30 observações. Neste sentido, este curso irá abordar as principais técnicas não-paramétricas incluindo: testes de hipótese não-paramétricos para uma amostra, duas ou mais amostras relacionadas, duas ou mais amostras independentes e suas aplicações. Ao terminar o curso, você terá aumentado significativamente seu repertório de técnicas estatísticas com base nestes testes não-paramétricos para o adequado apoio a tomada de decisão.",10907.0,4294.0,4.4,126.0
Ethical Issues in Data Science,https://www.coursera.org/learn/ethical-issues-data-science,Data Science,Data Analysis,Bobby Schnabel,"Computing applications involving large amounts of data – the domain of data science – impact the lives of most people in the U.S. and the world. These impacts include recommendations made to us by internet-based systems, information that is available about us online, techniques that are used for security and surveillance, data that is used in health care, and many more.  In many cases, they are affected by techniques in artificial intelligence and machine learning.

This course examines some of the ethical issues related to data science, with the fundamental objective of making data science professionals aware of and sensitive to ethical considerations that may arise in their careers. It does this through a combination of discussion of ethical frameworks, examination of a variety of data science applications that lead to ethical considerations, reading current media and scholarly articles, and drawing upon the perspectives and experiences of fellow students and computing professionals.

Ethical Issues in Data Science can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",1752.0,21395.0,4.6,21.0
Evaluate Machine Learning Models with Yellowbrick,https://www.coursera.org/learn/machine-learning-model-yellowbrick,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Evaluating Machine Learning Models with Yellowbrick. In this course, we are going to use visualizations to steer our machine learning workflow. The problem we will tackle is to predict whether rooms in apartments are occupied or unoccupied based on passive sensor data such as temperature, humidity, light and CO2 levels. We will build a logistic regression model for binary classification. This is a continuation of the course on Room Occupancy Detection. With an emphasis on visual steering of our analysis, we will cover the following topics in our machine learning workflow: model evaluation with ROC/AUC plots, confusion matrices, cross-validation scores, and setting discrimination thresholds for logistic regression models.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, Yellowbrick, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2956.0,,4.8,50.0
Evaluations of AI Applications in Healthcare,https://www.coursera.org/learn/evaluations-ai-applications-healthcare,Data Science,Machine Learning,"Tina Hernandez-Boussard, Mildred Cho","With artificial intelligence applications proliferating throughout the healthcare system, stakeholders are faced with both opportunities and challenges of these evolving technologies. This course explores the principles of AI deployment in healthcare and the framework used to evaluate downstream effects of AI healthcare solutions.

The Stanford University School of Medicine is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.  Visit the FAQs below for important information regarding 1) Date of original release and Termination or expiration date; 2) Accreditation and Credit Designation statements; 3) Disclosure of financial relationships for every person in control of activity content.",6731.0,12464.0,4.5,133.0
Excel Basics for Data Analysis,https://www.coursera.org/learn/excel-basics-data-analysis-ibm,Data Science,Data Analysis,"Sandip Saha Joy, Steve Ryan","This course is designed to provide you with basic working knowledge for using Excel spreadsheets for Data Analysis. It covers some of the first steps for working with spreadsheets and their usage in the process of analyzing data.  It includes plenty of videos, demos, and examples for you to learn, followed by step-by-step instructions for you to apply and practice on a live spreadsheet.

Excel is an essential tool for working with data - whether for business, marketing, data analytics, or research. This course is suitable for those aspiring to take up Data Analysis or Data Science as a profession, as well as those who just want to use Excel for data analysis in their own domains. You will gain valuable experience in cleansing and wrangling data using functions and then analyze your data using techniques like filtering, sorting and creating pivot tables.   

This course starts with an introduction to spreadsheets like Microsoft Excel and Google Sheets and loading data from multiple formats. With this introduction you will then learn to perform some basic level data wrangling and cleansing tasks and continue to expand your knowledge of analyzing data through the use of filtering, sorting, and using pivot tables within the spreadsheet. By performing these tasks throughout the course, it will give you an understanding of how spreadsheets can be used as a data analysis tool and understand its limitations. 

There is a strong focus on practice and applied learning in this course. With each lab, you will gain hands-on experience in manipulating data and begin to understand the important role of spreadsheets. Clean and analyze your data faster by understanding functions in the formatting of data. You will then convert your data to a pivot table and learn its features to make your data organized and readable. The final project enables you to show off your newly acquired data analysis skills. By the end of this course you will have worked with several data sets and spreadsheets and demonstrated the basics of cleaning and analyzing data all without having to learn any code. 

Getting started with Excel is made easy in this course. It does not require any prior experience with spreadsheets or coding. Nor does it require downloads or installation of any software. All you need is a device with a modern web browser, and ability to create a Microsoft account to access Excel online at no-cost.  However if you already have a desktop version of Excel, you can follow along quite easily as well.",140512.0,630994.0,4.7,4434.0
Excel aplicado a los negocios (Nivel Avanzado),https://www.coursera.org/learn/excel-aplicado-negocios-avanzado,Data Science,Data Analysis,"Jorge Lardizabal, Paola Serafini","Objetivos Generales: Al finalizar el curso, podrás:

1.- ENTENDER y profundizar convenientemente aspectos específicos de   diferentes formas de trabajo (individual o grupal), 
2.- EVALUAR el uso de funciones avanzadas para manipular datos y CREAR tus propios análisis utilizando técnicas específicas tales como tablas dinámicas, análisis de hipótesis, administración de escenarios, tablas de simple y doble entrada, análisis de optimización de recursos. 
3.- ANALIZAR cómo vincular Excel con otras aplicaciones importando información desde archivos de texto y bases de datos, exportando información a archivos de texto de diversas formas. 
4.- ENTENDER  el uso de macros lo que te permitirá vislumbrar otro universo de aplicaciones que harán mucho más productiva tu labor.

Los ejemplos sobre los cuales se apoyan los contenidos dictados por los profesores, tienen una profunda aplicabilidad al mundo de los negocios, con lo que su inmediata utilización empresarial está al alcance de la mano.
Finalmente, los profesores que han diseñado y elaborado este curso para ti, no solamente dan una visión académica de los usos avanzados del software, sino que, debido a su gran trayectoria profesional apoyada justamente en un uso intensivo y profundo de Excel, te transmitirán su propia vivencia, lo cual te permitirá tener una visión más concreta de las posibilidades que te brinda esta herramienta.",160567.0,185194.0,4.8,2537.0
Experimental Design Basics,https://www.coursera.org/learn/introduction-experimental-design-basics,Data Science,Probability and Statistics,Douglas C. Montgomery,"This is a basic course in designing experiments and analyzing the resulting data. The course objective is to learn how to plan, design and conduct experiments efficiently and effectively, and analyze the resulting data to obtain objective conclusions. Both design and statistical analysis issues are discussed. Opportunities to use the principles taught in the course arise in all aspects of today’s industrial and business environment. Applications from various fields will be illustrated throughout the course.  Computer software packages (JMP, Design-Expert, Minitab) will be used to implement the methods presented and will be illustrated extensively. 

All experiments are designed experiments; some of them are poorly designed, and others are well-designed. Well-designed experiments allow you to obtain reliable, valid results faster, easier, and with fewer resources than with poorly-designed experiments. You will learn how to plan, conduct and analyze experiments efficiently in this course.",13602.0,33034.0,4.7,204.0
Experimentation for Improvement,https://www.coursera.org/learn/experimentation,Data Science,Probability and Statistics,Kevin Dunn,"We are always using experiments to improve our lives, our community, and our work. Are you doing it efficiently? Or are you (incorrectly) changing one thing at a time and hoping for the best? 

In this course, you will learn how to plan efficient experiments - testing with many variables. Our goal is to find the best results using only a few experiments. A key part of the course is how to optimize a system.

We use simple tools: starting with fast calculations by hand, then we show how to use FREE software. 

The course comes with slides, transcripts of all lectures, subtitles (English, Spanish and Portuguese; some Chinese and French), videos, audio files, source code, and a free textbook. You get to keep all of it, all freely downloadable.

This course is for anyone working in a company, or wanting to make changes to their life, their community, their neighbourhood. You don't need to be a statistician or scientist! There's something for everyone in here. 
⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯
Over 1500 people have completed this online course. What have prior students said about this course?

""This definitely is one of the most fruitful courses I have participated at Coursera, considering the takeaways and implementations! And so far I finished 12 [courses].""

""Excelente curso, flexible y con suficiente material didáctico fácilmente digerible y cómodo. No importa si se tiene pocas bases matemáticas o estadísticas, el curso proporciona casi toda explicación necesaria para un entendimiento alto.""

""I wish I had enrolled in your course years ago -- it would have saved us a lot of time in optimizing experimental conditions."" Jason Eriksen, 3 Jan 2017

""Interesting and developing both analytical and creative thinking. The lecturer took care to bring lots of real live examples which are fun to analyze."" 20 February 2016.

""... love your style of presentation, and the examples you took from everyday life to explain things. It is very difficult to make such a mathematical course accessible and comprehensible to this wide a variety of people!""
⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯",34353.0,12497.0,4.8,879.0
Explainable AI: Scene Classification and GradCam Visualization,https://www.coursera.org/learn/scene-classification-gradcam,Data Science,Machine Learning,Ryan Ahmed,"In this 2 hour long hands-on project, we will train a deep learning model to predict the type of scenery in images. In addition, we are going to use a technique known as Grad-Cam to help explain how AI models think. This project could be practically used for detecting the type of scenery from the satellite images.",2223.0,,4.7,51.0
Explainable Machine Learning with LIME and H2O in R,https://www.coursera.org/learn/explainable-machine-learning-lime-h2o,Data Science,Machine Learning,Snehan Kekre,"Welcome to this hands-on, guided introduction to Explainable Machine Learning with LIME and H2O in R. By the end of this project, you will be able to use the LIME and H2O packages in R for automatic and interpretable machine learning, build classification models quickly with H2O AutoML and explain and interpret model predictions using LIME. 

Machine learning (ML) models such as Random Forests, Gradient Boosted Machines, Neural Networks, Stacked Ensembles, etc., are often considered black boxes. However, they are more accurate for predicting non-linear phenomena due to their flexibility. Experts agree that higher accuracy often comes at the price of interpretability, which is critical to business adoption, trust, regulatory oversight (e.g., GDPR, Right to Explanation, etc.).  As more industries from healthcare to banking are adopting ML models, their predictions are being used to justify the cost of healthcare and for loan approvals or denials. For regulated industries that use machine learning, interpretability is a requirement.  As Finale Doshi-Velez and Been Kim put it, interpretability is ""The ability to explain or to present in understandable terms to a human."".

To successfully complete the project, we recommend that you have prior experience with programming in R, basic machine learning theory, and have trained ML models in R. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2063.0,,4.7,54.0
Explainable deep learning models for healthcare - CDSS 3,https://www.coursera.org/learn/cdss3,Data Science,Machine Learning,Fani Deligianni,"This course will introduce the concepts of interpretability and explainability in machine learning applications. The learner will understand the difference between global, local, model-agnostic and model-specific explanations. State-of-the-art explainability methods such as Permutation Feature Importance (PFI), Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanation (SHAP) are explained and applied in time-series classification. Subsequently, model-specific explanations such as Class-Activation Mapping (CAM) and Gradient-Weighted CAM are explained and implemented. The learners will understand axiomatic attributions and why they are important. Finally, attention mechanisms are going to be incorporated after Recurrent Layers and the attention weights will be visualised to produce local explanations of the model.",,6217.0,,
Explaining machine learning models,https://www.coursera.org/learn/explaining-ml-models,Data Science,Machine Learning,Muhammad Saad uddin,"In this 2-hour long project-based course, you will learn how to understand the predictions of your model, feature relations, visualize and interpret feature & model relation with statistics and much more.",,,,
Explorando lenguaje natural con NLTK,https://www.coursera.org/learn/lenguaje-natural-nltk,Data Science,Data Analysis,Nestor Nicolas Campos Rojas,"En este proyecto, entenderás y podrás desarrollar tus propios procesos de lenguaje natural usando la librería NLTK para python, entendiendo conceptos como tokens y corpus para trabajar los textos como datos de forma simple.",,,,
Explorar precios de acciones con Spark SQL,https://www.coursera.org/learn/explorar-data-con-spark-sql,Data Science,Data Analysis,Florencia Silvestre,"En este proyecto guiado de 1 hora, aprenderemos cómo interactuar con un clúster de Spark usando el entorno Jupyter y cómo crear una aplicación Spark.

Aprenderemos a utilizar Spark Resisilent Distributed Datasets y Spark Data Frames para explorar colecciones de datos. Cargaremos un conjunto de datos en nuestro programa Spark y realizaremos análisis de datos utilizando acciones, transformaciones, Spark DataFrame API y Spark SQL.

Aprenderemos como elegir las mejores herramientas para utilizar en cada escenario. Finalmente, aprenderemos a guardar resultados en tablas de Parquet.",,,,
Exploratory Data Analysis,https://www.coursera.org/learn/exploratory-data-analysis-python,Data Science,Data Analysis,Mo Rebaie,"In this 1-hour long project-based course, you will learn exploratory data analysis techniques and create visual methods to analyze trends, patterns, and relationships in the data. By the end of this project, you will have applied EDA on a real-world dataset.

This class is for learners who want to use Python for applying data visualization and data analysis, and for learners who are currently taking a basic machine learning course or have already finished a machine learning course and are searching for a practical data visualization and analysis project course. Also, this project provides learners with basic knowledge about exploratory analysis and improves their skills in creating maps which helps them in fulfilling their career goals by adding this project to their portfolios.",5461.0,,4.2,134.0
Exploratory Data Analysis,https://www.coursera.org/learn/exploratory-data-analysis,Data Science,Data Analysis,"Roger D. Peng, PhD, Jeff Leek, PhD, Brian Caffo, PhD",This course covers the essential exploratory techniques for summarizing data. These techniques are typically applied before formal modeling commences and can help inform the development of more complex statistical models. Exploratory techniques are also important for eliminating or sharpening potential hypotheses about the world that can be addressed by the data. We will cover in detail the plotting systems in R as well as some of the basic principles of constructing data graphics. We will also cover some of the common multivariate statistical techniques used to visualize high-dimensional data.,169641.0,45010.0,4.7,6004.0
Exploratory Data Analysis With Python and Pandas,https://www.coursera.org/learn/exploratory-data-analysis-python-pandas,Data Science,Data Analysis,Bassim Eledath ,"In this 2-hour long project-based course, you will learn how to perform Exploratory Data Analysis (EDA) in Python. You will use external Python packages such as Pandas, Numpy, Matplotlib, Seaborn etc. to conduct univariate analysis, bivariate analysis, correlation analysis and identify and handle duplicate/missing data.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9330.0,,4.5,336.0
Exploratory Data Analysis for Machine Learning,https://www.coursera.org/learn/ibm-exploratory-data-analysis-for-machine-learning,Data Science,Machine Learning,"Joseph Santarcangelo, Svitlana (Lana) Kramar","This first course in the IBM Machine Learning Professional Certificate introduces you to Machine Learning and the content of the professional certificate. In this course you will realize the importance of good, quality data. You will learn common techniques to retrieve your data, clean it, apply feature engineering, and have it ready for preliminary analysis and hypothesis testing.

By the end of this course you should be able to:
Retrieve data from multiple data sources: SQL, NoSQL databases, APIs, Cloud 
Describe and use common feature selection and feature engineering techniques
Handle categorical and ordinal features, as well as missing values
Use a variety of techniques for detecting and dealing with outliers
Articulate why feature scaling is important and use a variety of scaling techniques
 
Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience  with Machine Learning and Artificial Intelligence in a business setting.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Calculus, Linear Algebra, Probability, and Statistics.",43594.0,147793.0,4.6,966.0
Exploratory Data Analysis for the Public Sector with ggplot,https://www.coursera.org/learn/exploratory-data-analysis-for-public-administration-with-ggplot,Data Science,Data Analysis,"Christopher Brooks, Paula Lantz","Learn about the core pillars of the public sector and the core functions of public administration through statistical Exploratory Data Analysis (EDA). Learn analytical and technical skills using the R programming language to explore, visualize, and present data, with a focus on equity and the administrative functions of planning and reporting. Technical skills in this course will focus on the ggplot2 library of the tidyverse, and include developing bar, line, and scatter charts, generating trend lines, and understanding histograms, kernel density estimations, violin plots, and ridgeplots. These skills are enhanced with lessons on best practices for good information visualization design. Upon completing this course, you will understand the layered grammar of graphics and its implementation in ggplot2, all while exploring a diverse set of authentic public datasets.

All coursework is completed in RStudio in Coursera without the need to install additional software.

This is the second of four courses within the Data Analytics in the Public Sector with R Specialization. The series is ideal for current or early-career professionals working in the public sector looking to gain skills in analyzing public data effectively. It is also ideal for current data analytics professionals or students looking to enter the public sector.",,4865.0,,
Exploratory Data Analysis in R,https://www.coursera.org/learn/exploratory-data-analysis-in-r,Data Science,Data Analysis,Emmanuel Segui,"In this 1-hour long project-based course, you will learn how to do basic exploratory data analysis (EDA) in R, automate your EDA reports and learn advanced EDA tips


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Exploratory Data Analysis with MATLAB,https://www.coursera.org/learn/exploratory-data-analysis-matlab,Data Science,Data Analysis,"Erin Byrne, Michael Reardon, Maria Gavilan-Alfonso, Brandon Armstrong, Nikola Trica, Cris LaPierre, Adam Filion, Heather Gorr","In this course, you will learn to think like a data scientist and ask questions of your data.  You will use interactive features in MATLAB to extract subsets of data and to compute statistics on groups of related data. You will learn to use  MATLAB to automatically generate code so you can learn syntax as you explore.  You will also use interactive documents, called live scripts,  to capture the steps of your analysis, communicate the results, and provide interactive controls allowing others to experiment by selecting groups of data.

These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background is required. To be successful in this course, you should have some knowledge of basic statistics (e.g., histograms, averages, standard deviation, curve fitting, interpolation). 

By the end of this course, you will be able to load data into MATLAB, prepare it for analysis, visualize it, perform basic computations, and communicate your results to others. In your last assignment, you will combine these skills to assess damages following a severe weather event and communicate a polished recommendation based on your analysis of the data.  You will be able to visualize the location of these events on a geographic map and create sliding controls allowing you to quickly visualize how a phenomenon changes over time.",34138.0,25920.0,4.8,759.0
Exploratory Data Analysis with Seaborn,https://www.coursera.org/learn/exploratory-data-analysis-seaborn,Data Science,Machine Learning,Snehan Kekre,"Producing visualizations is an important first step in exploring and analyzing real-world data sets. As such, visualization is an indispensable method in any data scientist's toolbox. It is also a powerful tool to identify problems in analyses and for illustrating results.In this project-based course, we will employ the statistical data visualization library, Seaborn, to discover and explore the relationships in the Breast Cancer Wisconsin (Diagnostic) Data Set. We will cover key concepts in exploratory data analysis (EDA) using visualizations to identify and interpret inherent relationships in the data set, produce various chart types including histograms, violin plots, box plots, joint plots, pair grids, and heatmaps, customize plot aesthetics and apply faceting methods to visualize higher dimensional data.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",12459.0,,4.6,399.0
Exploratory Data Analysis with Textual Data in R / Quanteda,https://www.coursera.org/learn/eda-text-r-quanteda,Data Science,Data Analysis,Nicole Baerg,"In this 1-hour long project-based course, you will learn how to explore presidential concession speeches by US presidential candidates over time, looking specifically at speech length and top words and examining variation by Democrat and Republican candidates. You will learn how to import textual data stored in raw text files, turn these files into a corpus (a collection of textual documents) and tokenize the text all using the software package quanteda. You will also learn how to extract useful information from filenames and how to use this information to generate visualizations of textual data using the stringr and ggplot2 packages.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Exploratory vs Confirmatory data analysis using Python,https://www.coursera.org/learn/exploratory-vs-confirmatory-data-analysis-using-python,Data Science,Data Analysis,Ahmad Varasteh,"This Guided Project, Exploratory and Confirmatory Data Analysis using python, is for those who want to learn about different methods of data analysis. In this 2-hour-long project-based course, you will understand and apply Exploratory Data Analysis, build different Data visualizations, apply different exploration techniques based on the data at hand and define and understand the concept of Confirmatory Data Analysis.
This project is unique because you will learn how and where to start your data exploration. You will also learn how to implement different data visualizations using python and when to use them. To be successful in this project, you will need to be experienced in python programming language and working with jupyter notebook environment.
Let's get started!",,,,
Explore and Create Reports with Data Studio,https://www.coursera.org/learn/googlecloud-explore-and-create-reports-with-data-studio-owwup,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Explore insights from text analysis using Amazon Comprehend,https://www.coursera.org/learn/explore-insights-from-text-analysis-using-amazon-comprehend,Data Science,Machine Learning,Rogerio Guimaraes,"In this one-hour project, you will understand how Amazon Comprehend works and how you can use the power of Natual Language Processing, NLP, and Machine Learning to extract information and explore insights from text. You will learn how to use Amazon Comprehend to extract entities, people, sentiments, and other elements from text like Tweets, understand how the results are organized, manipulate the data and generate a report to explore the insights. 
Amazon Comprehend is a fully managed service and it is one of the most powerful Natural Language Processing engines in the market, so you can get up and running quickly, without having to train models from scratch. 
Once you're done with this project, you will be able to use Amazon Comprehend to extract, analyze and explore insights in your documents in just a few steps.",,,,
Explore insights in text analysis using Azure Text Analytics,https://www.coursera.org/learn/explore-insights-in-text-analysis-using-azure-text-analytics,Data Science,Machine Learning,Rogerio Guimaraes,"In this one-hour project, you will understand how Azure Text Analytics works and how you can use the power of Natual Language Processing, NLP, and Machine Learning to extract information and explore insights from text. You will learn how to use Azure Text Analytics to extract entities' sentiments, key phrases, and other elements from text like product reviews, understand how the results are organized, manipulate the data and generate a report to explore the insights. 
Azure Text Analytics is a fully managed service, and it is one of the most powerful Natural Language Processing engines in the market, so you can get up and running quickly, without having to train models from scratch. 
Once you're done with this project, you will be able to use Azure Text Analytics to extract, analyze and explore insights in your documents in just a few steps.",,,,
Explore stock prices with Spark SQL,https://www.coursera.org/learn/data-exploration-spark-sql,Data Science,Data Analysis,Florencia Silvestre,"In this 1-hour long project-based course, you will learn how to interact with a Spark cluster using Jupyter notebook and how to start a Spark application. 

You will learn how to utilize Spark Resisilent Distributed Datasets and Spark Data Frames to explore a dataset. We will load a dataset into our Spark program, and perform analysis on it by using Actions, Transformations,  Spark DataFrame API and Spark SQL. 

You will learn how to choose the best tools to use for each scenario. Finally, you will learn to save your results in Parquet tables.",2281.0,,4.5,52.0
Exploring Dataset Metadata Between Projects with Data Catalog,https://www.coursera.org/learn/googlecloud-exploring-dataset-metadata-between-projects-with-data-catalog-sxyce,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Exploring NCAA Data with BigQuery,https://www.coursera.org/learn/googlecloud-exploring-ncaa-data-with-bigquery-crrvv,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Exploring and Analyzing Fifa's Datasets Using Python,https://www.coursera.org/learn/analyzing-fifa-datasets-using-pandas,Data Science,Data Analysis,Ali Amr Souidan,"In this 1-hour long project-based course, you will learn how to load a dataset into a pandas dataframe, you will learn how to tidy a messy dataset (Data Tidying), you will get to also visualize the dataset using Matplotlib and seaborn, you will learn how to engineer new features, you will also get to learn how to merge datasets (Data Integration)

By the end of this project, you will be able to fully analyze a FIFA dataset using python’s Pandas library. Throughout the tasks you will be able to identify and apply the  key aspects about data analysis such as Data Cleaning, Data transformation, Data Visualization , Data tidying and feature engineering.
All these skills are crucial to the world of data engineering and are very beneficial in today’s job market that is leaning more and more towards utilizing data in every way 


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Exploring the Public Cryptocurrency Datasets Available in BigQuery,https://www.coursera.org/learn/googlecloud-exploring-the-public-cryptocurrency-datasets-available-in-bigq-duxi2,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Extract Text Data with Python and Regex,https://www.coursera.org/learn/extract-text-data-with-python-and-regex,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project you will learn what is regular expressions and how it works. during this project we are going to learn about basic to advanced concepts of regex by formatting phone numbers, email addresses and URLs. after that we will learn how to use regular expressions for data cleaning. and finally in the final task we are going to work with a dataset consists of daily personal notes, and we are going to use RegEx to pull out useful information out of our raw text data.",,,4.3,12.0
"Extract, Transform, and Load Data",https://www.coursera.org/learn/extract-transform-and-load-data,Data Science,Data Analysis,"Stacey McBrine, Sarah Haq, Megan Smith Branch","This course is designed for business and data professional seeking to learn the first technical phase of the data science process known as Extract, Transform and Load or ETL.  

Learners will be taught how to collect data from multiple sources so it is available to be transformed and cleaned and then will dive into collected data sets to prepare and clean data so that it can later be loaded into its ultimate destination. In the conclusion of the course learners will load data into its ultimate destination so that it can be analyzed and modeled. 

The typical student in this course will have experience working with data and aptitude with computer programming.",,12372.0,,
FIFA20 Data Exploration using Python,https://www.coursera.org/learn/fifa20-data-exploration-using-python,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project, you will learn to use data Exploration techniques in order to uncover some initial patterns, insights and interesting points in your dataset. We are going to use a dataset consisting 5 CSV files, consisting of the data related to players in FIFA video game. We will clean and prepare it by dropping useless columns, calculating new features for our dataset and filling up the null values properly. and then we will start our exploration and we'll do some visualizations.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2074.0,,4.6,50.0
Facebook Network Analysis using Python and Networkx,https://www.coursera.org/learn/facebook-network-analysis-using-python-and-networkx,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project, you will learn how to Analyze a real network graph using python. you will learn how to use Networkx module to Visualize a graph and to calculate some important measures which can describe characteristics of our graph. you will also learn About Centrality measures to find Important nodes in a graph. In the final task of the project we are going talk about Scale-free networks and we are going to prove that Facebook Network graph has familiarities with Scale-free networks.",,,,
Facial Expression Classification Using Residual Neural Nets,https://www.coursera.org/learn/facial-expression-classification,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train a deep learning model based on Convolutional Neural Networks (CNNs) and Residual Blocks to detect facial expressions. This project could be practically used for detecting customer emotions and facial expressions.

By the end of this project, you will be able to: 

- Understand the theory and intuition behind Deep Learning, Convolutional Neural Networks (CNNs) and Residual Neural Networks.
- Import Key libraries, dataset and visualize images.
- Perform data augmentation to increase the size of the dataset and improve model generalization capability.
- Build a deep learning model based on Convolutional Neural Network and Residual blocks using Keras with Tensorflow 2.0 as a backend.
- Compile and fit Deep Learning model to training data. 
- Assess the performance of trained CNN and ensure its generalization using various KPIs.
- Improve network performance using regularization techniques such as dropout.",4092.0,,4.6,71.0
Facial Expression Recognition with Keras,https://www.coursera.org/learn/facial-expression-recognition-keras,Data Science,Machine Learning,Snehan Kekre,"In this 2-hour long project-based course, you will build and train a convolutional neural network (CNN) in Keras from scratch to recognize facial expressions. The data consists of 48x48 pixel grayscale images of faces. The objective is to classify each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). You will use OpenCV to automatically detect faces in images and draw bounding boxes around them. Once you have trained, saved, and exported the CNN, you will directly serve the trained model to a web interface and perform real-time facial expression recognition on video and image data. 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Keras pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",22425.0,,4.5,933.0
Facial Expression Recognition with PyTorch,https://www.coursera.org/learn/facial-expression-recognition-with-pytorch,Data Science,Machine Learning,Parth Dhameliya,"In this 2-hour long guided-project course, you will load a pretrained state of the art model CNN and you will train in PyTorch to classify facial expressions. The data that you will use, consists of 48 x 48 pixel grayscale images of faces and there are seven targets (angry, disgust, fear, happy, sad, surprise, neutral). Furthermore, you will apply augmentation for classification task to augment images. Moreover, you are going to create train and evaluator function which will be helpful to write training loop. Lastly, you will use best trained model to classify expression given any input image.",,,3.5,11.0
Facial Keypoint Detection with PyTorch,https://www.coursera.org/learn/facial-keypoint-detection,Data Science,Machine Learning,Parth Dhameliya,"In this 2-hour project-based course, you will be able to :

-  Understand the Facial Keypoint Dataset and you will write a custom dataset class for Image-Keypoint dataset. Additionally,  you will apply keypoint augmentation to augment images as well as its keypoints. For keypoint augmentation you will use albumentation library. You will plot the image keypoint pair.

- Load a pretrained state of the art convolutional neural network using timm library. 

- Create train function and evaluator function which will helpful to write training loop. Moreover, you will use training loop to train the model.

- Lastly, you will use trained model to find keypoints given any image.",,,,
Factorial and Fractional Factorial Designs,https://www.coursera.org/learn/factorial-fractional-factorial-designs,Data Science,Probability and Statistics,Douglas C. Montgomery,"Many experiments in engineering, science and business involve several factors.  This course is an introduction to these types of multifactor experiments.  The appropriate experimental strategy for these situations is based on the factorial design, a type of experiment where factors are varied together.  This course focuses on designing these types of experiments and on using the ANOVA for analyzing the resulting data.  These types of experiments often include nuisance factors, and  the blocking principle can be used in factorial designs to handle these situations.  As the number of factors of interest grows full factorials become too expensive and fractional versions of the factorial design are useful.  This course will  cover the benefits of fractional factorials, along with methods for constructing and analyzing the data from these experiments.",4099.0,13118.0,4.8,58.0
Fake Instagram Profile Detector,https://www.coursera.org/learn/instagram-fake-profile-detector,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will build and train a simple artificial neural network model to detect spam/fake Instagram accounts. Fake and spam accounts are a major problem in social media. Many social media influencers use fake Instagram accounts to create an illusion of having so many social media followers. Fake accounts can be used to impersonate or catfish other people and be used to sell fake services/products.   

By the end of this project, you will be able to: 

- Understand the applications of Artificial Intelligence and Machine Learning techniques in the banking industry
- Understand the theory and intuition behind Deep Neural Networks
- Import key Python libraries, dataset, and perform Exploratory Data Analysis.
- Perform data visualization using Seaborn.
- Standardize the data and split them into train and test datasets.   
- Build a deep learning model using Keras with Tensorflow 2.0 as a back-end.
- Assess the performance of the model and ensure its generalization using various Key Performance Indicators (KPIs).

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,28.0
Fake News Detection with Machine Learning,https://www.coursera.org/learn/nlp-fake-news-detector,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train a Bidirectional Neural Network and LSTM based deep learning model to detect fake news from a given news corpus. This project could be practically used by any media company to automatically predict whether the circulating news is fake or not. The process could be done automatically without having humans manually review thousands of news related articles.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9572.0,,4.6,233.0
Fashion Classification with Deep Learning for Beginners,https://www.coursera.org/learn/fashion-classification-with-deep-learning,Data Science,Machine Learning,Ryan Ahmed,"Hello everyone and welcome to this hands-on guided project on deep learning 101. The objective of this project is to predict fashion class such as pants, shirts, and shoes from grayscale images. This guided project is practical and directly applicable to the fashion industry. You guys can add this project to your portfolio of projects which is essential for your next job interview.",,,,
Fashion Image Classification using CNNs in Pytorch,https://www.coursera.org/learn/fashion-image-classification-cnn-pytorch,Data Science,Machine Learning,Mohammed Murtuza Qureshi,"In this 1-hour long project-based course, you will learn how to create Neural Networks in the Deep Learning Framework PyTorch. We will creating a Convolutional Neural Network for a 10 Class Image Classification problem which can be extended to more classes. We will start off by looking at how perform data preparation and Augmentation in Pytorch. 

We will be building a Neural Network in Pytorch. We will add the Convolutional Layers as well as Linear Layers. We will then look at how to add optimizer and train the model. Finally, we will test and evaluate our model on test data.

The project will get you introduced with Pytorch. You will in the end understand how the framework works and get you started with building Neural Networks in Pytorch.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Fazer perguntas para tomar decisões com base em dados,https://www.coursera.org/learn/fazer-perguntas-para-tomar-decisoes-com-base-em-dados,Data Science,Data Analysis,Google Career Certificates,"Este é o segundo curso do Certificado de Análise de Dados do Google. Estes cursos darão a você as habilidades necessárias para se candidatar a cargos empregos de analista de dados de nível introdutório. Você aprenderá sobre os tópicos que foram introduzidos no primeiro curso de Certificado de Análise de Dados do Google. O material ajudará você a aprender como fazer perguntas eficazes para tomar decisões baseadas nos dados, enquanto se conecta com as necessidades das partes interessadas. Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível introdutório como analista de dados. Nenhuma experiência anterior é necessária.

Ao final deste curso, você poderá:
- Aprender sobre técnicas eficazes para fazer perguntas que podem ajudar você a orientar sua análise. 
- Obter uma compreensão de tomada de decisão com base em dados e como os analistas de dados apresentam as descobertas.
- Explorar uma gama de diferentes cenários de negócios do mundo real para ajudar você na compreensão do questionamento e da tomada de decisões.
- Descobrir como e por que as planilhas são uma ferramenta importante para o analista de dados.
- Examinar as principais ideias associadas ao pensamento estruturado e como elas podem ajudar os analistas a entender melhor os problemas e desenvolver soluções.
- Aprender estratégias para gerenciar as expectativas das partes interessadas enquanto estabelece uma comunicação clara com uma equipe de análise de dados para atingir os objetivos de negócios.",4310.0,146557.0,4.7,197.0
Feature Engineering,https://www.coursera.org/learn/feature-engineering,Data Science,Machine Learning,Google Cloud Training,"Want to know about Vertex AI Feature Store? Want to know how you can improve the accuracy of your ML models? What about how to find which data columns make the most useful features? Welcome to Feature Engineering, where we discuss good versus bad features and how you can preprocess and transform them for optimal use in your models. This course includes content and labs on feature engineering using BigQuery ML, Keras, and TensorFlow.",29146.0,21427.0,4.5,1717.0
Feature Engineering em Português Brasileiro,https://www.coursera.org/learn/feature-engineering-br,Data Science,Machine Learning,Google Cloud Training,"Quer saber como melhorar a acurácia dos modelos de ML e quais colunas de dados são os atributos mais úteis? Neste curso Feature Engineering, abordaremos os atributos bons e ruins, bem como o pré-processamento e a transformação deles para otimizar os modelos.",,,4.5,13.0
Feature Engineering en Español,https://www.coursera.org/learn/feature-engineering-es,Data Science,Machine Learning,Google Cloud Training,"¿Quiere saber cómo mejorar la exactitud de los modelos de AA?, ¿cómo puede averiguar qué columnas de datos crean los atributos más útiles? Le damos la bienvenida a Feature Engineering, donde analizaremos los atributos buenos y los malos, y cómo los puede preprocesar y transformar para aprovecharlos al máximo en sus modelos.",2558.0,,4.5,24.0
Feature Engineering en Français,https://www.coursera.org/learn/feature-engineering-fr,Data Science,Machine Learning,Google Cloud Training,"Vous voulez savoir comment améliorer la précision de vos modèles de ML ? Et quelles colonnes de données créent les caractéristiques les plus utiles ? Bienvenue dans ""Extraction de caractéristiques"". Nous allons passer en revue les bonnes et les mauvaises caractéristiques, et voir comment les prétraiter et les transformer pour les utiliser efficacement dans vos modèles.",,,,
Feature Engineering 日本語版,https://www.coursera.org/learn/feature-engineering-jp,Data Science,Machine Learning,Google Cloud Training,機械学習（ML）モデルの精度を高める方法や、最も有用な特徴量を作成するためのデータ列の見極め方を学びたい方におすすめのコースです。この Feature Engineering コースでは、「良い」特徴量と「悪い」特徴量について説明し、それらをモデルで最大限に活用できるように前処理して変換する方法を解説します。,,1831.0,4.5,10.0
Ferramentas para Ciência de Dados: Introdução ao R,https://www.coursera.org/learn/ferramentas-para-ciencia-de-dados-introducao-ao-r,Data Science,Data Analysis,Anderson França,"Nossas boas-vindas ao Curso Ferramentas para Ciência de Dados: Introdução ao R.

Neste curso, você aprenderá que o mundo evoluiu muito quando o assunto é tomada de decisão baseada em dados e já não é possível comparar a quantidade de informações a que temos acesso atualmente com o que tínhamos disponíveis décadas atrás. 

Basicamente, a ciência de dados tem como objetivo encontrar formas inovadoras para analisar e impulsionar o crescimento de negócios, por isso, muitas ferramentas analíticas foram adotadas pelo mercado e são utilizadas para processar os dados, realizar análises avançadas e facilitar o processo de tomada de decisão. 

Ao final deste curso, você será capaz de conhecer as principais ferramentas de mercado e aprender os fundamentos da linguagem R e como utilizá-la em seu dia-a-dia. O curso cobre a os principais tópicos:
- Ferramentas para Data Science;
- Introdução à linguagem de programação em R;
- Utilização de ambiente de desenvolvimento; 
- Instalação e utilização de bibliotecas no R; 
- Escrita de funções em R;
- Escrita, leitura e manipulação de dados;
- Análises gráficas.",,,,
Finalize a Data Science Project,https://www.coursera.org/learn/finalize-a-data-science-project,Data Science,Data Analysis,"Sarah Haq, Stacey McBrine, Megan Smith Branch","This course is designed for business professionals that want to learn how to gather results from previous stages of the data science project and present them to stakeholders. Learners will communicate the results of a model to stakeholders, be shown how to build a basic web app to demonstrate machine learning models  and implement and test pipelines that automate the model training, tuning and deployment processes.  

The typical student in this course will have completed previous courses in the CDSP professional certificate program, and have several years of experience with computing technology, including some aptitude in computer programming.",,1533.0,,
Finding bibliography metrics using the Crossref API,https://www.coursera.org/learn/finding-bibliography-metrics-using-crossref-api,Data Science,Data Analysis,You (Lilian) Cheng,"Manually searching specific metadata for an academic paper is laborious. Is there any magic that we can get all metadata for the bibliography search done at once? Crossref is the tool for you. It can extract the metadata for tens of thousands of papers online in one run.

 By the end of this project, learners will be able to create their own tailored R function to find paper metrics from the Crossref API. The function, which will be guided to build step by step, can easily be re-used when there are newly added articles or if the learners want to get the most up-to-date metrics. In this guided project, the instructor will walk learners through understanding the Crossref API, tailoring an R function, and wrangling the bibliography dataset. A good handle of this method will make it convenient for learners to analyze different metrics for bibliography from different fields, such as impact and number of collaborators.",,,,
Fine Tune BERT for Text Classification with TensorFlow,https://www.coursera.org/learn/fine-tune-bert-tensorflow,Data Science,Machine Learning,Snehan Kekre,"This is a guided project on fine-tuning a Bidirectional Transformers for Language Understanding (BERT) model for text classification with TensorFlow. In this 2.5 hour long project, you will learn to preprocess and tokenize data for BERT classification, build TensorFlow input pipelines for text data with the tf.data API, and train and evaluate a fine-tuned BERT model for text classification with TensorFlow 2 and TensorFlow Hub. 

Prerequisites:
In order to successfully complete this project, you should be competent in the Python programming language, be familiar with deep learning for Natural Language Processing (NLP), and have trained models with TensorFlow or and its Keras API.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",10630.0,,4.6,164.0
Fine-tuning Convolutional Networks to Classify Dog Breeds,https://www.coursera.org/learn/classify-dog-breeds,Data Science,Machine Learning,Ari Anastassiou,"In this 2 hour-long project, you will learn how to approach an image classification task using TensorFlow. You will learn how to effectively preprocess your data to improve model generalizability, as well as build a performant modeling pipeline. Furthermore, you will learn how to accurately evaluate model performance using a confusion matrix; how to interpret results; and how to ask poignant questions about your dataset. Finally, you will fine-tune an existing, state-of-the-art-ready model to improve performance further.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Fitting Statistical Models to Data with Python,https://www.coursera.org/learn/fitting-statistical-models-data-python,Data Science,Probability and Statistics,"Brenda Gunderson, Brady T. West, Kerby Shedden","In this course, we will expand our exploration of statistical inference techniques by focusing on the science and art of fitting statistical models to data. We will build on the concepts presented in the Statistical Inference course (Course 2) to emphasize the importance of connecting research questions to our data analysis methods. We will also focus on various modeling objectives, including making inference about relationships between variables and generating predictions for future observations.

This course will introduce and explore various statistical modeling techniques, including linear regression, logistic regression, generalized linear models, hierarchical and mixed effects (or multilevel) models, and Bayesian inference techniques. All techniques will be illustrated using a variety of real data sets, and the course will emphasize different modeling approaches for different types of data sets, depending on the study design underlying the data (referring back to Course 1, Understanding and Visualizing Data with Python).

During these lab-based sessions, learners will work through tutorials focusing on specific case studies to help solidify the week’s statistical concepts, which will include further deep dives into Python libraries including Statsmodels, Pandas, and Seaborn. This course utilizes the Jupyter Notebook environment within Coursera.",28555.0,26153.0,4.4,626.0
Follow a Machine Learning Workflow,https://www.coursera.org/learn/follow-machine-learning-workflow,Data Science,Machine Learning,Renée Cummings,"Machine learning is not just a single task or even a small group of tasks; it is an entire process, one that practitioners must follow from beginning to end. It is this process—also called a workflow—that enables the organization to get the most useful results out of their machine learning technologies. No matter what form the final product or service takes, leveraging the workflow is key to the success of the business's AI solution. 

This second course within the Certified Artificial Intelligence Practitioner (CAIP) professional certificate explores each step along the machine learning workflow, from problem formulation all the way to model presentation and deployment. The overall workflow was introduced in the previous course, but now you'll take a deeper dive into each of the important tasks that make up the workflow, including two of the most hands-on tasks: data analysis and model training. You'll also learn about how machine learning tasks can be automated, ensuring that the workflow can recur as needed, like most important business processes.

Ultimately, this course provides a practical framework upon which you'll build many more machine learning models in the remaining courses.",,2494.0,,
Fondamentaux du Système de Base de Données,https://www.coursera.org/learn/fondamentaux-du-systme-de-base-de-donnes,Data Science,Data Analysis,Yasmine Elfares,"À la fin de ce projet, vous serez capables de comprendre et appliquer les fondamentaux du système de base de données. Étant programmeurs de bases de données débutants, vous serez capables de créer des fichiers SQL, de créer des bases de données, de créer des tables pour représenter les relations d’une base de données relationnelle et enfin de manipuler ces données.
A travers ce projet, nous allons renforcer ces notions en créant une base de données complète des fameux films français comprenant les infos des films en plus de leurs acteurs, tout en utilisant SQL.
SQL comprend plusieurs types de langages. Dans ce projet, nous nous concentrerons sur 3 types de langages : langage de définition de données (DDL), langage de manipulation de données (DML) et langage de requête de données (DQL).
-Le langage de définition de données est utilisé pour définir les structures telles que le schéma, la base de données, les tables, les contraintes, etc. Des exemples sont les instructions de création.
-Le langage de manipulation de données est utilisé pour manipuler des données. Des exemples sont les instructions d'insertion, de mise à jour et de suppression.
- Le langage de requête de données est utilisé pour effectuer des requêtes sur les données dans les objets de schéma. Le but des commandes DQL est d'obtenir la relation de schéma en fonction de la requête qui lui est transmise. Des exemples sont les instructions de sélection.


Ces langages construisent le système de gestion de base de données qui est un logiciel moteur qui manipule la base de données et dirige l'accès à son contenu.

La compréhension des bases de données vous aidera à progresser dans une entreprise étant donné que les bases de données sont nécessaires pour toute organisation puisqu'elles servent à communiquer les informations facilement et efficacement.",,,,
Forecasting US Presidential Elections with Mixed Models,https://www.coursera.org/learn/forecasting-us-elections-mixed-effects,Data Science,Probability and Statistics,Vinod Bakthavachalam,"In this project-based course, you will learn how to forecast US Presidential Elections. We will use mixed effects models in the R programming language to build a forecasting model for the 2020 election. The project will review how the US selects Presidents in the Electoral College, stylized facts about voting trends, the basics of mixed effects models, and how to use them in forecasting.",,,4.4,13.0
Formula preguntas para tomar decisiones basadas en datos,https://www.coursera.org/learn/formula-preguntas-para-tomar-decisiones-basadas-en-datos,Data Science,Data Analysis,Google Career Certificates,"Este es el segundo curso del Certificado de análisis de datos de Google. En estos cursos obtendrás las habilidades necesarias para solicitar empleos de analista de datos de nivel introductorio. Te basarás en tu comprensión de los temas que se presentaron en el primer curso del Certificado de análisis de datos de Google. El material te ayudará a aprender cómo hacer preguntas efectivas para tomar decisiones basadas en datos, al tiempo que te conectas con las necesidades de los interesados. Los analistas de datos actuales de Google seguirán dándote instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, habrás hecho lo siguiente:
- Aprendido sobre técnicas efectivas de hacer preguntas que pueden ayudarte a guiar el análisis. 
- Obtenido una comprensión de la toma de decisiones basada en datos y cómo los analistas de datos presentan los hallazgos.
- Explorado una variedad de escenarios empresariales del mundo real para respaldar la comprensión del cuestionamiento y la toma de decisiones.
- Descubierto cómo y por qué las hojas de cálculo son una herramienta importante para los analistas de datos.
- Examinado las ideas clave asociadas con el pensamiento estructurado y cómo pueden ayudar a los analistas a comprender mejor los problemas y desarrollar soluciones.
- Aprendido estrategias para gestionar las expectativas de los interesados mientras estableces una comunicación clara con un equipo de análisis de datos para lograr los objetivos empresariales.",9800.0,356878.0,4.7,404.0
Formulaire HTML,https://www.coursera.org/learn/formulaire-html,Data Science,Machine Learning,Fatima Youssef,"Dans ce cours d'une heure, basé sur un projet vous apprendrez une manière pratique de demander de l'information à un utilisateur et de les aderesser à un serveur web.
A la fin de ce projet, vous serez capable d'utiliser les formulaires en HTML, et ses éléments tels que l'élément input avec ses différents types, l'élément label, les boutons radio et cases à cocher et le bouton submit.",,,,
Foundations for Big Data Analysis with SQL,https://www.coursera.org/learn/foundations-big-data-analysis-sql,Data Science,Data Analysis,Glynn Durham,"In this course, you'll get a big-picture view of using SQL for big data, starting with an overview of data, database systems, and the common querying language (SQL). Then you'll learn the characteristics of big data and SQL tools for working on big data platforms. You'll also install an exercise environment (virtual machine) to be used through the specialization courses, and you'll have an opportunity to do some initial exploration of databases and tables in that environment.

By the end of the course, you will be able to
• distinguish operational from analytic databases, and understand how these are applied in big data;
• understand how database and table design provides structures for working with data;
• appreciate how differences in volume and variety of data affects your choice of an appropriate database system;
• recognize the features and benefits of SQL dialects designed to work with big data systems for storage and analysis; and 
• explore databases and tables in a big data platform.

To use the hands-on environment for this course, you need to download and install a virtual machine and the software on which to run it. Before continuing, be sure that you have access to a computer that meets the following hardware and software requirements:
• Windows, macOS, or Linux operating system (iPads and Android tablets will not work)
• 64-bit operating system (32-bit operating systems will not work)
• 8 GB RAM or more
• 25GB free disk space or more
• Intel VT-x or AMD-V virtualization support enabled (on Mac computers with Intel processors, this is always enabled;
on Windows and Linux computers, you might need to enable it in the BIOS)
• For Windows XP computers only: You must have an unzip utility such as 7-Zip or WinZip installed (Windows XP’s built-in unzip utility will not work)",44965.0,35234.0,4.8,1035.0
Foundations of Data Science: K-Means Clustering in Python,https://www.coursera.org/learn/data-science-k-means-clustering-python,Data Science,Machine Learning,"Dr Matthew Yee-King, Dr Betty Fyn-Sydney, Dr Jamie A Ward, Dr Larisa Soldatova","Organisations all around the world are using data to predict behaviours and extract valuable real-world insights to inform decisions. Managing and analysing big data has become an essential part of modern finance, retail, marketing, social science, development and research, medicine and government.

This MOOC, designed by an academic team from Goldsmiths, University of London, will quickly introduce you to the core concepts of Data Science to prepare you for intermediate and advanced Data Science courses. It focuses on the basic mathematics, statistics and programming skills that are necessary for typical data analysis tasks. 

You will consider these fundamental concepts on an example data clustering task, and you will use this example to learn basic programming skills that are necessary for mastering Data Science techniques. During the course, you will be asked to do a series of mathematical and programming exercises and a small data clustering project for a given dataset.",38944.0,135296.0,4.6,480.0
"Foundations of Sports Analytics: Data, Representation, and Models in Sports",https://www.coursera.org/learn/foundations-sports-analytics,Data Science,Data Analysis,"Wenche Wang, Stefan Szymanski","This course provides an introduction to using Python to analyze team performance in sports. Learners will discover a variety of techniques that can be used to represent sports data and how to extract narratives based on these analytical techniques. The main focus of the introduction will be on the use of regression analysis to analyze team and player performance data, using examples drawn from the National Football League (NFL), the National Basketball Association (NBA), the National Hockey League (NHL), the English Premier LEague (EPL, soccer) and the Indian Premier League (IPL, cricket). 

This course does not simply explain methods and techniques, it enables the learner to apply them to sports datasets of interest so that they can generate their own results, rather than relying on the data processing performed by others.  As a consequence the learning will be empowered to explore their own ideas about sports team performance, test them out using the data, and so become a producer of sports analytics rather than a consumer.

While the course materials have been developed using Python, code has also been produced to derive all of the results in R, for those who prefer that environment.",11105.0,34070.0,4.4,117.0
Foundations of mining non-structured medical data,https://www.coursera.org/learn/mining-medical-data,Data Science,Data Analysis,"Alejandro Rodríguez González, Consuelo Gonzalo-Martín, Ernestina Menasalvas","The goal of this course is to understand the foundations of Big Data and the data that is being generated in the health domain and how the use of technology would help to integrate and exploit all those data to extract meaningful information that can be later used in different sectors of the health domain from physicians to management, from patients to caregivers, etc. 

The course offers a high-level perspective of the importance of the medical context within the European context, the types of data that are managed in the health (clinical) context, the challenges to be addressed in the mining of unstructured medical data (text and image) as well as the opportunities from the analytical point of view with an introduction to the basics of data analytics field.",2563.0,,3.9,21.0
"Foundations: Data, Data, Everywhere",https://www.coursera.org/learn/foundations-data,Data Science,Data Analysis,Google Career Certificates,"This is the first course in the Google Data Analytics Certificate. These courses will equip you with the skills you need to apply to introductory-level data analyst jobs. Organizations of all kinds need data analysts to help them improve their processes, identify opportunities and trends, launch new products, and make thoughtful decisions. In this course, you’ll be introduced to the world of data analytics through hands-on curriculum developed by Google. The material shared covers plenty of key data analytics topics, and it’s designed to give you an overview of what’s to come in the Google Data Analytics Certificate. Current Google data analysts will instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
- Gain an understanding of the practices and processes used by a junior or associate data analyst in their day-to-day job. 
- Learn about key analytical skills (data cleaning, data analysis, data visualization) and tools (spreadsheets, SQL, R programming, Tableau) that you can add to your professional toolbox. 
- Discover a wide variety of terms and concepts relevant to the role of a junior data analyst, such as the data life cycle and the data analysis process. 
- Evaluate the role of analytics in the data ecosystem. 
- Conduct an analytical thinking self-assessment. 
- Explore job opportunities available to you upon program completion, and learn about best practices in the job search.",1300766.0,9815802.0,4.8,65743.0
Four Rare Machine Learning Skills All Data Scientists Need,https://www.coursera.org/learn/four-rare-machine-learning-skills-all-data-scientists-need,Data Science,Machine Learning,Eric Siegel,"This course covers the most neglected yet critical skills in machine learning, four vital techniques that are very rarely covered – most courses and books omit them entirely.

1) UPLIFT MODELING (AKA PERSUASION MODELING): When you're modeling, are you even predicting the right thing?

2) THE ACCURACY FALLACY: When evaluating how well a model works, are you even reporting on the right thing?

3) P-HACKING: Are your simplest discoveries from data even real?

4) THE PARADOX OF ENSEMBLE MODELS: Do you understand how they work, even though they seem to defy Occam's Razor?

>> WHY THESE ADVANCED METHODS ARE ESSENTIAL: Each one addresses a question that is fundamental to machine learning (above). For many projects, success hinges on these particular skills.

>> NO HANDS-ON – BUT FOR TECHNICAL LEARNERS: This course has no coding and no use of machine learning software. Instead, it lays the conceptual groundwork before you take on the hands-on practice. When it comes to these state-of-the-art techniques and prevalent pitfalls, there's a foundation of conceptual knowledge to build before going hands-on – and you'll be glad you did.

>> VENDOR-NEUTRAL: This course includes illuminating software demos of machine learning in action using SAS products. However, the curriculum is vendor-neutral and universally-applicable. The contents and learning objectives apply, regardless of which machine learning software tools you end up choosing to work with.",,,,
Fragen Für Eine Datengesteuerte Entscheidungsfindung Stellen,https://www.coursera.org/learn/fragen-fur-eine-datengesteuerte-entscheidungsfindung-stellen,Data Science,Data Analysis,Google Career Certificates,"Dies ist der zweite Kurs des Google Data Analytics Certificate. In diesen Kursen lernen Sie alles, was Sie für eine Einstiegsposition in der Datenanalyse benötigen. Wir bauen auf den Themen aus dem ersten Kurs des Google Data Analytics Certificate auf. Sie lernen mithilfe des Materials, wie Sie effektive Fragen stellen, um datengesteuerte Entscheidungen zu treffen, und gleichzeitig die Bedürfnisse der Stakeholder berücksichtigen. Bei Google tätige Fachleute für Datenanalyse werden Sie weiterhin anleiten und Ihnen praktische Möglichkeiten zeigen, mit denen Sie übliche Aufgaben von Fachleuten für Datenanalyse mithilfe der besten Tools und Ressourcen erledigen können.

Nach Abschluss dieses Zertifikatsprogramms sind Lernende gerüstet, um sich auf Einstiegspositionen in der Datenanalyse zu bewerben. Es sind keine Vorkenntnisse erforderlich.

Nach Abschluss dieses Kurses können Sie:
- effektive Fragetechniken anwenden, die für Ihre Analysen hilfreich sein können. 
- datengesteuerte Entscheidungsfindungen und die Präsentation von Erkenntnissen überblicken.
- zahlreiche reale Fallbeispiele kennenlernen, die zu einem besseren Verständnis für Fragestellungen und Entscheidungsfindungen beitragen.
- verstehen, inwiefern und warum Tabellenkalkulationen ein wichtiges Tool in der Datenanalyse sind.
- Kernkonzepte des strukturierten Denkens kennenlernen und erkennen, wie Fachleute für Datenanalyse dadurch Probleme besser verstehen und Lösungen entwickeln können.
- Strategien für den Umgang mit den Erwartungen der Stakeholder kennenlernen und gleichzeitig für eine klare Kommunikation mit dem Data-Analytics-Team sorgen, um Geschäftsziele zu erreichen.",,2023.0,,
Framework for Data Collection and Analysis,https://www.coursera.org/learn/data-collection-framework,Data Science,Data Analysis,"Frauke Kreuter, Ph.D., Mariel Leonard","This course will provide you with an overview over existing data products and a good understanding of the data collection landscape. With the help of various examples you will learn how to identify which data sources likely matches your research question, how to turn your research question into measurable pieces, and how to think about an analysis plan. Furthermore this course will provide you with a general framework that allows you to not only understand each step required for a successful data collection and analysis, but also help you to identify errors associated with different data sources. You will learn some metrics to quantify each potential error, and thus you will have tools at hand to describe the quality of a data source. Finally we will introduce different large scale data collection efforts done by private industry and government agencies, and review the learned concepts through these examples. This course is suitable for beginners as well as those that know about one particular data source, but not others, and are looking for a general framework to evaluate data products.",26641.0,11313.0,4.2,685.0
Functional Programming in Scala Capstone,https://www.coursera.org/learn/scala-capstone,Data Science,Data Analysis,Julien Richard-Foy,"In the final capstone project you will apply the skills you learned by building a large data-intensive application using real-world data.

You will implement a complete application processing several gigabytes of data. This application will show interactive visualizations of the evolution of temperatures over time all over the world.

The development of such an application will involve:
 — transforming data provided by weather stations into meaningful information like, for instance, the average temperature of each point of the globe over the last ten years ;
 — then, making images from this information by using spatial and linear interpolation techniques ;
 — finally, implementing how the user interface will react to users’ actions.",12883.0,5511.0,4.4,538.0
Fundamentals of  CNNs and RNNs,https://www.coursera.org/learn/cnns-and-rnns,Data Science,Data Analysis,Jee-Hyong Lee,"This course covers fundamental concepts of convolutional neural networks (CNNs) and recurrent neural networks (RNNs), which are widely used in computer vision and natural language processing areas.  

In the CNN part, you will learn the concepts of CNNs, the two major operators (convolution  and pooling), and the structure of CNNs. In the RNN part, you will learn the concept and the structure of RNNs, and the two variants of RNNs, LSTMs and GRUs.
 
The goal of this course is to give learners basic understanding of CNNs and RNNs. Throughout this course, you will be equipped with skills required for computer vision and natural language processing.",2412.0,3536.0,4.3,14.0
Fundamentals of Data Analysis,https://www.coursera.org/learn/fundamentals-of-data-analysis,Data Science,Data Analysis,Erik Herman,"This course is the first of a series that aims to prepare you for a role working in data analytics. In this course, you’ll be introduced to many of the primary types of data analytics and core concepts. You’ll learn about the tools and skills required to conduct data analysis. We’ll go through some of the foundational math and statistics used in data analysis and workflows for conducting efficient and effective data analytics. This course covers a wide variety of topics that are critical for working in data analytics and are designed to give you an introduction and overview as you begin to build relevant knowledge and skills.",,5775.0,3.9,14.0
Fundamentals of Data Analytics in the Public Sector with R,https://www.coursera.org/learn/fundamentals-of-data-analytics-in-the-public-sector-with-r,Data Science,Data Analysis,"Christopher Brooks, Paula Lantz","Gain a foundational understanding of key terms and concepts in public administration and public policy while learning foundational programming techniques using the R programming language. You will learn how to execute functions to load, select, filter, mutate, and summarize data frames using the tidyverse libraries with an emphasis on the dplyr package. By the end of the course, you will create custom functions and apply them to population data which is commonly found in public sector analytics.

Throughout the course, you will work with authentic public datasets, and all programming can be completed in RStudio on the Coursera platform without additional software.

This is the first of four courses within the Data Analytics in the Public Sector with R Specialization. The series is ideal for current or early career professionals working in the public sector looking to gain skills in analyzing public data effectively. It is also ideal for current data analytics professionals or students looking to enter the public sector.",,29546.0,,
Fundamentals of Data Visualization,https://www.coursera.org/learn/fundamentals-of-data-visualization,Data Science,Data Analysis,Danielle Szafir,"Data is everywhere. Charts, graphs, and other types of information visualizations help people to make sense of this data. This course explores the design, development, and evaluation of such information visualizations. By combining aspects of design, computer graphics, HCI, and data science, you will gain hands-on experience with creating visualizations, using exploratory tools, and architecting data narratives. Topics include user-centered design, web-based visualization, data cognition and perception, and design evaluation.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",2067.0,15534.0,4.8,12.0
Fundamentals of Database Systems,https://www.coursera.org/learn/fundamentals-database-systems,Data Science,Data Analysis,Judy Richardson,"In this project you will learn to identify the components of a database system, also sometimes referred to as an information system. As you examine a database system and diagram a database, you will gain an understanding of how those components interact and fit together. The overall purpose of the database system is to store and provide access to secure, relevant, timely, accurate data which can be presented as information used for making business decisions. Whether you are in Information Technology or an end user, understanding how data is used by your organization makes you a more valuable employee. This project now has an optional challenge activity and an optional capstone activity to give you opportunities for extra review and practice!",,,,
Fundamentals of Machine Learning for Healthcare,https://www.coursera.org/learn/fundamental-machine-learning-healthcare,Data Science,Machine Learning,"Matthew Lungren, Serena Yeung","Machine learning and artificial intelligence hold the potential to transform healthcare and open up a world of incredible promise. But we will never realize the potential of these technologies unless all stakeholders have basic competencies in both healthcare and machine learning concepts and principles. 

This course will introduce the fundamental concepts and principles of machine learning as it applies to medicine and healthcare. We will explore machine learning approaches, medical use cases, metrics unique to healthcare, as well as best practices for designing, building, and evaluating machine learning applications in healthcare.

The course will empower those with non-engineering backgrounds in healthcare, health policy, pharmaceutical development, as well as data science with the knowledge to critically evaluate and use these technologies.

 
Co-author: Geoffrey Angus
 
Contributing Editors:
Mars Huang
Jin Long
Shannon Crawford
Oge Marques


The Stanford University School of Medicine is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.  Visit the FAQs below for important information regarding 1) Date of original release and Termination or expiration date; 2) Accreditation and Credit Designation statements; 3) Disclosure of financial relationships for every person in control of activity content.",12049.0,24181.0,4.8,254.0
Fundamentals of Machine Learning for Supply Chain,https://www.coursera.org/learn/machine-learning-for-supply-chain-fundamentals,Data Science,Data Analysis,"Rajvir Dua, Neelesh Tiruviluamala","This course will teach you how to leverage the power of Python to understand complicated supply chain datasets. Even if you are not familiar with supply chain fundamentals, the rich data sets that we will use as a canvas will help orient you with several Pythonic tools and best practices for exploratory data analysis (EDA). As such, though all datasets are geared towards supply chain minded professionals, the lessons are easily generalizable to other use cases.",1676.0,5259.0,3.9,23.0
Fundamentals of Machine Learning in Finance,https://www.coursera.org/learn/fundamentals-machine-learning-in-finance,Data Science,Machine Learning,Igor Halperin,"The course aims at helping students to be able to solve practical ML-amenable problems that they may encounter in real life that include: (1) understanding where the problem one faces lands on a general landscape of available ML methods, (2) understanding which particular ML approach(es) would be most appropriate for resolving the problem, and (3) ability to successfully implement a solution, and assess its performance.  

A learner with some or no previous knowledge of Machine Learning (ML)  will get to know main algorithms of Supervised and Unsupervised Learning, and Reinforcement Learning, and will be able to use ML open source Python packages to design, test, and implement ML algorithms in Finance.
Fundamentals of Machine Learning in Finance will provide more at-depth view of supervised, unsupervised, and reinforcement learning, and end up in a project on using unsupervised learning for implementing a simple portfolio trading strategy.

The course is designed for three categories of students:
Practitioners working at financial institutions such as banks, asset management firms or hedge funds
Individuals interested in applications of ML for personal day trading
Current full-time students pursuing a degree in Finance, Statistics, Computer Science, Mathematics, Physics, Engineering or other related disciplines who want to learn about practical applications of ML in Finance  

Experience with Python (including numpy, pandas, and IPython/Jupyter notebooks), linear algebra, basic probability theory and basic calculus is necessary to complete assignments in this course.",17926.0,8372.0,3.8,315.0
Fundamentals of Reinforcement Learning,https://www.coursera.org/learn/fundamentals-of-reinforcement-learning,Data Science,Machine Learning,"Martha White, Adam White","Reinforcement Learning is a subfield of Machine Learning, but is also a general purpose formalism for automated decision-making and AI. This course introduces you to statistical learning techniques where an agent explicitly takes actions and interacts with the world. Understanding the importance and challenges of learning agents that make decisions is of vital importance today, with more and more companies interested in interactive agents and intelligent decision-making. 

This course introduces you to the fundamentals of Reinforcement Learning. When you finish this course, you will:
- Formalize problems as Markov Decision Processes 
- Understand basic exploration methods and the exploration/exploitation tradeoff
- Understand value functions, as a general-purpose tool for optimal decision-making
- Know how to implement dynamic programming as an efficient solution approach to an industrial control problem

This course teaches you the key concepts of Reinforcement Learning, underlying classic and modern algorithms in RL. After completing this course, you will be able to start using RL for real problems, where you have or can specify the MDP. 

This is the first course of the Reinforcement Learning Specialization.",68721.0,101020.0,4.8,2453.0
Fundamentals of Scalable Data Science,https://www.coursera.org/learn/ds,Data Science,Data Analysis,Romeo Kienzler,"Apache Spark is the de-facto standard for large scale data processing. This is the first course of a series of courses towards the IBM Advanced Data Science Specialization. We strongly believe that is is crucial for success to start learning a scalable data science platform since memory and CPU constraints are to most limiting factors when it comes to building advanced machine learning models.

In this course we teach you the fundamentals of Apache Spark using python and pyspark. We'll introduce Apache Spark in the first two weeks and learn how to apply it to compute basic exploratory and data pre-processing tasks in the last two weeks. Through this exercise you'll also be introduced to the most fundamental statistical measures and data visualization technologies.

This gives you enough knowledge to take over the role of a data engineer in any modern environment. But it gives you also the basis for advancing your career towards data science. 

Please have a look at the full specialization curriculum:
https://www.coursera.org/specializations/advanced-data-science-ibm

If you choose to take this course and earn the Coursera course certificate, you will also earn an IBM digital badge.  To find out more about IBM digital badges follow the link ibm.biz/badging.


After completing this course, you will be able to:
•	Describe how basic statistical measures, are used to reveal  patterns within the data 
•	Recognize data characteristics, patterns, trends, deviations or inconsistencies, and potential outliers.
•	Identify useful techniques for working with big data such as dimension reduction and feature selection methods 
•	Use advanced tools and charting libraries to:
      o	improve efficiency of analysis of big-data with partitioning and parallel analysis 
      o	Visualize the data in an number of 2D and 3D formats (Box Plot, Run Chart, Scatter Plot, Pareto Chart, and Multidimensional Scaling)

For successful completion of the course, the following prerequisites are recommended: 
•	Basic programming skills in python
•	Basic math
•	Basic SQL (you can get it easily from https://www.coursera.org/learn/sql-data-science if needed)

In order to complete this course, the following technologies will be used:
(These technologies are introduced in the course as necessary so no previous knowledge is required.)
•	Jupyter notebooks (brought to you by IBM Watson Studio for free)
•	ApacheSpark (brought to you by IBM Watson Studio for free)
•	Python

We've been reported that some of the material in this course is too advanced. So in case you feel the same, please have a look at the following materials first before starting this course, we've been reported that this really helps.

Of course, you can give this course a try first and then in case you need, take the following courses / materials. It's free...

https://cognitiveclass.ai/learn/spark

https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/f8982db1-5e55-46d6-a272-fd11b670be38/view?access_token=533a1925cd1c4c362aabe7b3336b3eae2a99e0dc923ec0775d891c31c5bbbc68

This course takes four weeks, 4-6h per week",66260.0,17412.0,4.3,1997.0
Fundamentals of Visualization with Tableau,https://www.coursera.org/learn/data-visualization-tableau,Data Science,Data Analysis,Desiree' Abbott,"In this first course of this specialization, you will discover what data visualization is, and how we can use it to better see and understand data. Using Tableau, we’ll examine the fundamental concepts of data visualization and explore the Tableau interface, identifying and applying the various tools Tableau has to offer. By the end of the course you will be able to prepare and import data into Tableau and explain the relationship between data analytics and data visualization. This course is designed for the learner who has never used Tableau before, or who may need a refresher or want to explore Tableau in more depth. No prior technical or analytical background is required. The course will guide you through the steps necessary to create your first visualization from the beginning based on data context, setting the stage for you to advance to the next course in the Specialization.",176004.0,228773.0,4.5,5854.0
Fundamentos de Excel para Negocios,https://www.coursera.org/learn/excel-para-negocios,Data Science,Data Analysis,"Jorge Lardizabal, Paola Serafini","Descripción del curso: 

Cuando finalices este curso habrás logrado un gran número de habilidades como introducir información, ordenarla, manipularla, realizar cálculos de diversa índole (matemáticos, trigonométricos, estadísticos, financieros, ingenieriles, probabilísticos), extraer conclusiones, trabajar con fechas y horas, construir gráficos, imprimir reportes y muchas más.

Asimismo, los ejemplos sobre los cuales se apoyan los contenidos dictados en este curso tienen una profunda aplicabilidad al mundo de los negocios, con lo que su inmediata utilización empresarial está al alcance de la mano.

Finalmente, los profesores que han diseñado y elaborado este curso para ti, no solamente dan una visión académica del software sino que, debido a su gran trayectoria profesional apoyada justamente en una profunda utilización de Excel, te transmitirán su propia vivencia que te permitirá tener una visión más concreta de las posibilidades que te brinda esta herramienta.",285405.0,216810.0,4.8,4653.0
Fundamentos de Inteligência Artifical em Marketing,https://www.coursera.org/learn/fundamentos-de-inteligencia-artifical-em-marketing,Data Science,Data Analysis,Anderson França,"Nossas boas-vindas ao Curso Fundamentos de Inteligência Artificial em Marketing.

A razão pela qual essa transformação se tornou tão importante é que as empresas estão repensando as estratégias por meio das quais atendem às necessidades de seus clientes e a maneira como esses clientes se envolvem com os serviços e ofertas das empresas, seja por meio de dispositivos móveis, internet das coisas ou outros dispositivos.

Neste curso, você aprenderá sobre a transformação digital em marketing, passando por toda a história até chegarmos aos dias atuais.

Ao final deste curso, você será capaz de colocar em prática temas como transformação digital, cultura de marca, customer experience, estratégias de marketing, bem como saber como criar uma cultura de inovação com ênfase em marketing. 

Este curso é composto por quatro módulos, disponibilizados em semanas de aprendizagem. Cada módulo é composto por vídeos, leituras e testes de verificação de aprendizagem. Ao final de cada módulo, temos uma avaliação de verificação dos conhecimentos.

Estamos muito felizes com sua presença neste curso e esperamos que você tire o máximo de proveito dos conceitos aqui apresentados.

Bons estudos!",,,,
Fundamentos de Inteligência Artificial para Finanças,https://www.coursera.org/learn/fundamentos-de-inteligencia-artificial-para-financas,Data Science,Data Analysis,Anderson França,"Nossas boas-vindas ao Curso Fundamentos de Inteligência Artificial para Finanças.

Neste curso, você aprenderá que a transformação digital em Finanças é a reorganização e a remodelagem das funções financeiras e contábeis, utilizando a tecnologia para recriar sistemas operacionais e processos eficientes, que inclui substituir ou não os sistemas tradicionais para todas as áreas do negócio. 

Podemos resumir como uma mudança de mentalidade que as empresas passam com o objetivo de se tornarem mais modernas e acompanharem os avanços tecnológicos que não param de surgir, como Internet das Coisas (IoT), computação em nuvem, Big Data, inteligência artificial e os robôs.

Ao final deste curso, você será capaz de entender temas como Aprendizado de Máquinas, Aprendizado Profundo e Inteligência Artificial.

Este curso é composto por quatro módulos, disponibilizados em semanas de aprendizagem. Cada módulo é composto por vídeos, leituras e testes de verificação de aprendizagem. Ao final de cada módulo, temos uma avaliação de verificação dos conhecimentos.

Estamos muito felizes com sua presença neste curso e esperamos que você tire o máximo de proveito dos conceitos aqui apresentados.",,,,
Fundamentos de estadística aplicada,https://www.coursera.org/learn/estadistica-aplicada-fundamentos,Data Science,Probability and Statistics,"Astrid Bernal, Mario Castillo, Daniela Angulo","El curso está orientado a profesionales de diferentes campos, que estén interesados en adquirir conceptos fundamentales de estadística aplicada. El contenido del curso será particularmente útil para profesionales que estén interesados en adelantar estudios de postgrado en ingeniería, administración o economía, entre otras profesiones, y que requieran de una adecuada fundamentación en estadística. También será de utilidad para estudiantes universitarios que deseen reforzar o complementar su formación básica en estadística, aprovechando los diferentes recursos con los que cuenta este MOOC.

o	La estadística es un campo de la matemática aplicada que se ocupa de la recolección, descripción y análisis de datos. Actualmente, esta disciplina no es solo fundamental para el ejercicio de la ingeniería, la economía y las ciencias básicas, sino que cada vez es más importante en aspectos de la vida moderna. Múltiples artículos son publicados diariamente en periódicos y revistas a través de los cuales se pretenden explicar tendencias sociales o económicas, siendo evidente que la estadística no solo es importante para ser un buen profesional, sino también para ser un miembro de la sociedad bien informado. 
o	Las aplicaciones de la Estadística van desde la organización de grandes cantidades de datos, pasando por la caracterización de los clientes de una compañía o individuos de una región, hasta el diseño de campañas de mercadotecnia más eficientes, y el desarrollo de políticas sociales. Algo a lo que se atribuye el gran éxito de los japoneses en la industria de la manufactura, durante el siglo XX, es al uso de métodos estadísticos y al pensamiento estadístico del personal gerencial, lo cual permitió enfocar la atención en el análisis y uso de los datos para mejorar la calidad y eficiencia de sus procesos de fabricación. 
o	El curso tiene como objetivo principal que los participantes adquieran una formación sólida en los conceptos más importantes de estadística, y sus aplicaciones. En este curso haremos especial énfasis en que logres una adecuada comprensión del análisis descriptivo de datos estadísticos, así como de los métodos básicos para la estimación de parámetros poblacionales, finalizando con el entendimiento de los modelos de Regresión Lineal Simple y Múltiple, y las oportunidades de aplicación de dichos modelos.
o	El curso tiene un buen balance entre el rigor en el tema y la presentación del contenido de una forma sencilla, con base en ejemplos que abordan situaciones reales simplificadas, y cuenta con videos y ejercicios orientados a facilitar la comprensión de los conceptos que se cubren en este curso.",9282.0,16889.0,4.4,63.0
Fundamentos de la visualización de datos con Tableau,https://www.coursera.org/learn/fundamentos-de-la-visualizacion-de-datos-con-tableau,Data Science,Data Analysis,Valeria Andrea Labath,"En este curso descubrirás qué es la visualización de datos y cómo podemos usarla para ver y comprender mejor los datos. Con Tableau, examinaremos los conceptos fundamentales de visualización de datos y exploraremos la interfaz de Tableau, identificando y aplicando las diversas herramientas que Tableau tiene para ofrecer. Este curso está diseñado para el alumno que nunca ha usado antes Tableau, o que puede necesitar un repaso, o desea explorar Tableau con más profundidad. No se requieren antecedentes técnicos o analíticos previos. El curso te guiará a través de los pasos necesarios para crear tu primera visualización desde el principio en función del contexto de los datos.",1733.0,3167.0,4.7,34.0
Fundamentos de probabilidad y aplicaciones,https://www.coursera.org/learn/probabilidad,Data Science,Probability and Statistics,"Mario Castillo, Astrid Bernal, Daniela Angulo","Actualmente la probabilidad se ha convertido en una disciplina fundamental para científicos, ingenieros, economistas y administradores. La probabilidad es una poderosa herramienta, pero es, ante todo, una forma de pensar. Tanto en el mundo de los negocios, como en el campo de la salud y en las ciencias sociales, entre otros, cada vez es más relevante el entendimiento de los fenómenos y situaciones de naturaleza probabilística (no determinística), y de desarrollar modelos basados en el análisis de datos para cuantificar el riesgo con el propósito de tomar mejores decisiones. Es entonces importante entender los conceptos básicos sobre los cuales se establecen los pilares de esta disciplina, los cuales permitirán más adelante convertir la probabilidad en una herramienta básica para la conceptualización y la solución de problemas reales. 

El curso tiene como objetivo principal que los participantes adquieran una formación sólida en los conceptos más importantes de probabilidad, y sus aplicaciones. Se hace especial énfasis en que los participantes logren una adecuada comprensión y utilización de los modelos de naturaleza probabilística en la solución de problemas de la vida real que comportan riesgo e incertidumbre.

El curso tiene un buen balance entre el rigor en el tema y la presentación del contenido de una forma simple, con base en ejemplos sencillos basado en situaciones reales, y cuenta con videos y ejercicios orientados a facilitar la comprensión de los conceptos que se cubren.",7930.0,36238.0,4.8,106.0
"Fundamentos: dados, dados, em todos os lugares",https://www.coursera.org/learn/fundamentos-dados-dados-em-todos-os-lugares,Data Science,Data Analysis,Google Career Certificates,"Este é o primeiro curso do Certificado de análise de dados do Google. Estes cursos darão a você as habilidades necessárias para se candidatar em empregos de analista de dados de nível introdutório. Organizações de todos os tipos precisam de analistas de dados para ajudá-las a melhorar os processos, identificar oportunidades e tendências, lançar novos produtos e tomar decisões conscientes. Neste curso, você conhecerá o mundo da análise de dados com um currículo prático desenvolvido pelo Google. O material compartilhado abrange muitos tópicos importantes de análise de dados e foi projetado para oferecer uma visão geral do que está por vir no Certificado de análise de dados do Google. Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível introdutório para analista de dados. Nenhuma experiência anterior é necessária.

Ao final deste curso, você poderá:
- Ter uma compreensão das práticas e dos processos utilizados por um analista de dados júnior ou associado no trabalho cotidiano. 
- Aprender sobre as principais habilidades (limpeza, análise e visualização de dados) e ferramentas (planilhas, SQL, programação R, Tableau) analíticas que você pode incluir às ferramentas profissionais que já tem. 
- Descobrir uma ampla variedade de termos e conceitos relevantes para a função de analista de dados júnior, como o ciclo de vida e o processo de análise de dados. 
- Avaliar o papel da análise no ecossistema de dados. 
- Realizar uma autoavaliação de pensamento analítico. 
- Explorar as oportunidades de emprego disponíveis após a conclusão do programa e aprender sobre as práticas recomendadas na procura de uma vaga.",15850.0,313167.0,4.9,747.0
Gehaltsvorhersage mit Linearer Regression in R,https://www.coursera.org/learn/gehaltsvorhersage-mit-linearer-regression-in-r,Data Science,Machine Learning,Sandro Raabe,"In diesem zweistündigen Projekt wirst du lernen, wie du ein einfaches lineares Regressionsmodell in R erstellst und wie du es verwendest, um ein grundlegendes Regressionsproblem zu lösen. Ein solches Modell benutzt genau eine Variable, um genau eine andere Zielvariable vorherzusagen. Am Ende dieses Projekts wirst du ein Regressionsmodell erstellt, trainiert, getestet, und visualisiert haben. Dieses Modell wird in der Lage sein, das Gehalt von Data Scientists vorherzusagen, wenn man ihm Informationen über die Erfahrungsjahre gibt.

In diesem Projekt fokussieren wir uns nicht auf die mathematischen Hintergründe der Regression, sondern auf die sogenannte “End-to-End-Machine-Learning-Pipeline”: Vom Import des Datensatzes über das Erstellen des Modells über die Visualisierung seiner Ergebnisse.

Um dieses Projekt erfolgreich abschließen zu können, solltest du die Basics der Programmiersprache R kennen (Variablenzuweisungen, RStudio, Funktionsaufrufe).",,,,
Generalized Linear Models and Nonparametric Regression,https://www.coursera.org/learn/generalized-linear-models-and-nonparametric-regression,Data Science,Probability and Statistics,Brian Zaharatos,"In the final course of the statistical modeling for data science program, learners will study a broad set of more advanced statistical modeling tools. Such tools will include generalized linear models (GLMs), which will provide an introduction to classification (through logistic regression); nonparametric modeling, including kernel estimators, smoothing splines; and semi-parametric generalized additive models (GAMs). Emphasis will be placed on a firm conceptual understanding of these tools. Attention will also be given to ethical issues raised by using complicated statistical models.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Logo adapted from photo by Vincent Ledvina on Unsplash",1921.0,16145.0,,
Generando modelos con Auto Machine Learning,https://www.coursera.org/learn/generando-modelos-automl,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a desarrollar modelos supervisados utilizando librerías de Auto Machine Learning (TPOT, MLBox y H2O) y optimizar los parámetros para hacer una búsqueda inteligencia de los mejores modelos.
Entenderás cuándo aplicar este tipo de librerías y en cuáles contextos no son viables de utilizar.

Además, podrás analizar los detalles de cada modelo generado, reutilizar los códigos o exportarlos para su posterior uso en entornos productivos.",,,4.4,34.0
Generate Synthetic Images with DCGANs in Keras,https://www.coursera.org/learn/generative-adversarial-networks-keras,Data Science,Machine Learning,Snehan Kekre,"In this hands-on project, you will learn about Generative Adversarial Networks (GANs) and you will build and train a Deep Convolutional GAN (DCGAN) with Keras to generate images of fashionable clothes.  We will be using the Keras Sequential API with Tensorflow 2 as the backend.

In our GAN setup,  we want to be able to sample from a complex, high-dimensional training distribution of the Fashion MNIST images. However, there is no direct way to sample from this distribution. The solution is to sample from a simpler distribution, such as Gaussian noise. We want the model to use the power of neural networks to learn a transformation from the simple distribution directly to the training distribution that we care about. The GAN consists of two adversarial players: a discriminator and a generator. We’re going to train the two players jointly in a minimax game theoretic formulation.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Keras pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",8533.0,,4.5,246.0
Generating New Recipes using GPT-2,https://www.coursera.org/learn/generating-new-recipes-python,Data Science,Machine Learning,Ari Anastassiou,"In this 2 hour long project, you will learn how to preprocess a text dataset comprising recipes, and split it into a training and validation set. You will learn how to use the HuggingFace library to fine-tune a deep, generative model, and specifically how to train such a model on Google Colab. Finally, you will learn how to use GPT-2 effectively to create realistic and unique recipes from lists of ingredients based on the aforementioned dataset. This project aims to teach you how to fine-tune a large-scale model, and the sheer magnitude of resources it takes for these models to learn. You will also learn about knowledge distillation and its efficacy in use cases such as this one.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2821.0,,4.1,38.0
Generative Deep Learning with TensorFlow,https://www.coursera.org/learn/generative-deep-learning-with-tensorflow,Data Science,Machine Learning,"Laurence Moroney, Eddy Shyu","In this course, you will: 

a) Learn neural style transfer using transfer learning: extract the content of an image (eg. swan), and the style of a painting (eg. cubist or impressionist), and combine the content and style into a new image. 
b) Build simple AutoEncoders on the familiar MNIST dataset, and more complex deep and convolutional architectures on the Fashion MNIST dataset, understand the difference in results of the DNN and CNN AutoEncoder models, identify ways to de-noise noisy images, and build a CNN AutoEncoder using TensorFlow to output a clean image from a noisy one.
c) Explore Variational AutoEncoders (VAEs) to generate entirely new data, and generate anime faces to compare them against reference images. 
d) Learn about GANs; their invention, properties, architecture, and how they vary from VAEs, understand the function of the generator and the discriminator within the model, the concept of 2 training phases and the role of introduced noise, and build your own GAN that can generate faces.

The DeepLearning.AI TensorFlow: Advanced Techniques Specialization introduces the features of TensorFlow that provide learners with more control over their model architecture, and gives them the tools to create and train advanced ML models.  

This Specialization is for early and mid-career software and machine learning engineers with a foundational understanding of TensorFlow who are looking to expand their knowledge and skill set by learning advanced TensorFlow features to build powerful models.",9702.0,19909.0,4.8,198.0
Geospatial Analysis Project,https://www.coursera.org/learn/gis-capstone,Data Science,Data Analysis,Nick Santos,"In this project-based course, you will design and execute a complete GIS-based analysis – from identifying a concept, question or issue you wish to develop, all the way to final data products and maps that you can add to your portfolio. Your completed project will demonstrate your mastery of the content in the GIS Specialization and is broken up into four phases:

Milestone 1: Project Proposal - Conceptualize and design your project in the abstract, and write a short proposal that includes the project description, expected data needs, timeline, and how you expect to complete it.

Milestone 2: Workflow Design - Develop the analysis workflow for your project, which will typically involve creating at least one core algorithm for processing your data. The model need not be complex or complicated, but it should allow you to analyze spatial data for a new output or to create a new analytical map of some type.

Milestone 3: Data Analysis – Obtain and preprocess data, run it through your models or other workflows in order to get your rough data products, and begin creating your final map products and/or analysis.

Milestone 4: Web and Print Map Creation – Complete your project by submitting usable and attractive maps and your data and algorithm for peer review and feedback.",11321.0,10406.0,4.8,246.0
Geospatial Big Data Visualization with Kepler GL,https://www.coursera.org/learn/geospatial-bigdata-visualization-keplergl,Data Science,Data Analysis,Abdishakur Hassan,"In this 1-hour long project-based course, you will learn how to easily create beautiful data visualization with Kepler and effectively design different geospatial data visualizations.",2822.0,,4.2,10.0
Geospatial Data Visualization using Python and Folium,https://www.coursera.org/learn/geospatial-data-visualization-using-python-and-folium,Data Science,Data Analysis,Ahmad Varasteh,"In this project, we are going to learn how to process and analyze geospatial data. we are going to work with a dataset containing information about almost 100 taxis running in Proto, Portugal. We are going to learn how to prepare our data and how to use different geospatial visualization techniques in order to answer some analytical questions. during this project, we will learn how to work with the Folium module in python which is one of the best tools when it comes to geospatial data visualization.",,,,
Get Familiar with ML basics in a Kaggle Competition,https://www.coursera.org/learn/ml-basics-kaggle-competition,Data Science,Machine Learning,Mírian Silva,"In this 1-hour long project, you will be able to understand how to predict which passengers survived the Titanic shipwreck and make your first submission in an Machine Learning competition inside the Kaggle platform. Also, you as a beginner in Machine Learning applications, will get familiar and get a deep understanding of how to start a model prediction using basic supervised Machine Learning models. We will choose classifiers to learn, predict,  and make an Exploratory Data Analysis (also called EDA). At the end, you will know how to measure a model performance, and submit your model to the competition and get a score from Kaggle. 

This guided project is for beginners in Data Science who want to do a practical application using Machine Learning. You will get familiar with the methods used in machine learning applications and data analysis. 

In order to be successful in this project, you should have an account on the Kaggle platform (no cost is necessary). Be familiar with some basic Python programming, we will use numpy and pandas libraries. Some background in Statistics is appreciated, like as knowledge in probability, but it’s not a requirement.",,,4.4,25.0
Get Started with Microsoft Forms,https://www.coursera.org/learn/get-started-microsoft-forms,Data Science,Data Analysis,Heidi Barker,"There are many uses for Microsoft online. In this project you will explore Microsoft Forms. You will be able to create surveys, polls, quizzes and invitations for free using the web based Microsoft Forms application. You can tailor the form that you make by adding special fonts, various answer choices and images. Data collection is made easy with the program and you can even track your responses and perform data analytics with your results.",,,,
"Get, Shape, Combine and Merge the datasets using Power BI",https://www.coursera.org/learn/get-shape-combine-and-merge-the-datasets-using-power-bi,Data Science,Data Analysis,Omnya Khaled,"By the end of this project, you will be able to professionally format and manipulate different datasets using Power Bi. you will be able to identify the basics of power BI, use it to create a model, and import data from different types of data sources. Moreover, you will be able to manipulate your data, reduce the number of data, merge columns, replace values, change data types and apply statistical and standard functions. You will also be able to insert a new index column, append two or more queries with each other, and sort and clean your dataset. Finally, you will be able to apply union, except and intersect, combine data of two tables and add results in a new table.
 Many companies use Power BI to connect, Transform and model the data and also create charts, graphs, reports, and dashboards, which are collections of visuals, and finally, share reports with others using the Power BI service.

This guided project is for people in the field of data and data analysis. people who want to learn Power BI. It provides you with the important steps to be a business intelligence specialist.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.1,14.0
Getting Started in Google Analytics,https://www.coursera.org/learn/getting-started-in-google-analytics,Data Science,Data Analysis,Carma Baughman,"In this project, you will learn how to connect your website to Google Analytics. You will be able to use Google Analytics to understand how your website is performing. You will become familiar with the Google Analytics interface and the standard reports to better understand your website audience. You will learn how to interpret this data to improve your website performance and effectiveness.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",58053.0,,4.4,1304.0
Getting Started with AI using IBM Watson,https://www.coursera.org/learn/ai-with-ibm-watson,Data Science,Machine Learning,Rav Ahuja,"In this course you will learn how to quickly and easily get started with Artificial Intelligence using IBM Watson. You will understand how Watson works, become familiar with its use cases and real life client examples, and be introduced to several of Watson AI services from IBM that enable anyone to easily apply AI and build smart apps. You will also work with several Watson services to demonstrate AI in action.

This course does not require any programming or computer science expertise and is designed for anyone whether you have a technical background or not.",39560.0,115956.0,4.5,2593.0
Getting Started with AWS Machine Learning,https://www.coursera.org/learn/aws-machine-learning,Data Science,Machine Learning,Blaine Sundrud,"Machine learning (ML) is one of the fastest growing areas in technology and a highly sought after skillset in today’s job market. The World Economic Forum states the growth of artificial intelligence (AI) could create 58 million net new jobs in the next few years, yet it’s estimated that currently there are 300,000 AI engineers worldwide, but millions are needed. This means there is a unique and immediate opportunity for you to get started with learning the essential ML concepts that are used to build AI applications – no matter what your skill levels are. Learning the foundations of ML now, will help you keep pace with this growth, expand your skills and even help advance your career. 

This course will teach you how to get started with AWS Machine Learning. Key topics include: Machine Learning on AWS, Computer Vision on AWS, and Natural Language Processing (NLP) on AWS. Each topic consists of several modules deep-diving into variety of ML concepts, AWS services as well as insights from experts to put the concepts into practice.",194374.0,26134.0,4.5,6386.0
Getting Started with CyberGIS,https://www.coursera.org/learn/cybergis,Data Science,Data Analysis,"Shaowen Wang, Anand Padmanabhan","This course is intended to introduce students to CyberGIS—Geospatial Information Science and Systems (GIS)—based on advanced cyberinfrastructure as well as the state of the art in high-performance computing, big data, and cloud computing in the context of geospatial data science. Emphasis is placed on learning the cutting-edge advances of cyberGIS and its underlying geospatial data science principles.",,4140.0,4.1,16.0
Getting Started with Data Analytics on AWS,https://www.coursera.org/learn/getting-started-data-analytics-aws,Data Science,Data Analysis,Rafael Lopes,"Learn how to go from raw data to meaningful insights using AWS with this one-week course. Throughout the course, you’ll learn about the fundamentals of Data Analytics from AWS experts.

Start off with an overview of different types of data analytics techniques - descriptive, diagnostic, predictive, and prescriptive before diving deeper into the descriptive data analytics. Then, apply your knowledge with a guided project that makes use of a simple, but powerful dataset available by default in every AWS account: the logs from AWS CloudTrail. The CloudTrail service enables governance, compliance, operational auditing, and risk auditing of your AWS account. Through the project you’ll also get an introduction to Amazon Athena and Amazon QuickSight. And, you’ll learn how to build a basic security dashboard as a simple but practical method of applying your newfound data analytics knowledge.",32917.0,23030.0,4.5,608.0
Getting Started with Data Visualization in R,https://www.coursera.org/learn/jhu-getting-started-data-viz-r,Data Science,Data Analysis,Collin Paschall,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance.

To fill that need, this course is intended for learners who have little or no experience with R but who are looking for an introduction to this tool. By the end of this course, students will be able to import data into R, manipulate that data using tools from the popular tidyverse package, and make simple reports using R Markdown. The course is designed for students with good basic computing skills, but limited if any experience with programming.",10519.0,23480.0,4.8,190.0
Getting Started with Kaggle,https://www.coursera.org/learn/getting-started-with-kaggle,Data Science,Data Analysis,Abhishek Jha,"In this guided project, you will explore Kaggle Competitions, Kaggle Datasets, Kaggle Notebooks which is a cloud-based coding environment, Kaggle Discussion forum and Kaggle Courses.

We will begin this course by creating a Kaggle account. We will then explore Kaggle competitions, the prize money and how to participate in them. We will focus primarily on the legendary Titanic Machine learning competition. We will explore Kaggle datasets. We will also explore Kaggle Notebooks which is a cloud-based coding environment. We will also explore the awesome “Copy and Edit” feature from Kaggle notebooks that enables us to work on and improvise on the work of others. In the final tasks, we will explore the Kaggle community discussion forum and explore the theoretical and practical sections of Kaggle courses.

By the end of this project, you will be confident in using Kaggle for your data science and machine learning needs.",2384.0,,4.3,36.0
Getting Started with R,https://www.coursera.org/learn/getting-started-with-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"In this 2 hour-long project, you will learn the basics of R programming language. In addition, you will take your first steps in the use of R programming language for Data Analysis.

By the end of this 2-hour long project, you will understand how to use the R GUI called R studio. By extension, you will learn the different data types and data structures used in R. Finally, you will learn how to install packages and how to import data sets into the R studio work space.

This course is aimed at learners who are looking to get started with the R programming language. There are no hard prerequisites and any competent computer user should be able to complete the project successfully.",8967.0,,4.4,293.0
Getting Started with Rstudio,https://www.coursera.org/learn/getting-started-rstudio,Data Science,Data Analysis,Emmanuel Segui,"In this 1-hour long project-based course, you will learn everything you need to know to get started with RStudio IDE, including how to install RStudio onto your Windows, MAC or Linux machine, how to use RStudio Cloud, a lightweight, cloud-based version of RStudio, how to start creating R projects, install and load R packages, as well as display interactive maps, graphs and tables with 1 line of code.

This course is perfect if you want to start learning R programming with RStudio: the Premiere IDE for R

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3503.0,,4.7,103.0
Getting Started with SAS Programming,https://www.coursera.org/learn/sas-programming-basics,Data Science,Data Analysis,Stacey Syphus,"This course is for users who want to learn how to write SAS programs to access, explore, prepare, and analyze data. It is the entry point to learning SAS programming for data science, machine learning, and artificial intelligence. It is a prerequisite to many other SAS courses.

By the end of this course, you will know how to use SAS Studio to write and submit SAS programs that access SAS, Microsoft Excel, and text data. You will know how to explore and validate data, prepare data by subsetting rows and computing new columns, analyze and report on data, export data and results to other formats, use SQL in SAS to query and join tables.

Prerequisites:
Learners should have experience using computer software. Specifically, you should be able to understand file structures and system commands on your operating systems and access data files on your operating systems. No prior SAS experience is needed.",84508.0,200962.0,4.8,2694.0
Getting Started with SAS Visual Analytics,https://www.coursera.org/learn/preparing-data-sas-va,Data Science,Data Analysis,Nicole Ball,"In this course, you learn more about SAS Visual Analytics and the SAS Viya platform, how to access and investigate data in SAS Visual Analytics, and how to prepare data for analysis using SAS Data Studio.",23287.0,16781.0,4.7,786.0
Getting Started with Spatial Analysis in GeoDa,https://www.coursera.org/learn/getting-started-spatial-analysis-geoda,Data Science,Data Analysis,Nadine Rodriguez,"By the end of this project, learners will know how to start out with GeoDa to use it for spatial analyses. This includes how to access and download the software, import multiple layers, and a basic overview of GeoDa. Spatial analysis, as a type of data analysis, has been getting increasingly important. The beginnings are often dated back to John Snow’s cholera outbreak maps from the mid-1800s. In 2003, Dr. Luc Anselin at the University of Chicago developed GeoDa, together with his team, to provide free software that digitizes old school pin maps. Today, it is used in various fields to plan cities and infrastructure, create crime maps, emergency management, and visualize finds at archaeological sites. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Getting Started with Splunk Cloud GDI on Google Cloud,https://www.coursera.org/learn/googlecloud-getting-started-with-splunk-cloud-gdi-on-google-cloud-6x1wa,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Getting Started with Tensorflow.js,https://www.coursera.org/learn/getting-started-tensorflowjs-tensorflow-web-applications-machine-learning-python,Data Science,Machine Learning,Charles Ivan Niswander II,"By the end of this project, you will learn how to code a smart webcam to detect people and other everyday objects using a pre-trained COCO-SSD image recognition model with Tensorflow.js. 

Based on an older library called deeplearn.js, Tensorflow.js is a deep learning library that leverages Tensorflow to create, train and run inference on artificial neural network models directly in a web browser, utilizing the client's GPU/CPU resources (accelerated using WebGL). Tensorflow.js brings Tensorflow to the web! 

JavaScript/Typescript experience is heavily recommended.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Getting Started with Tidyverse,https://www.coursera.org/learn/getting-started-tidyverse,Data Science,Data Analysis,Dr. Karl Michel,"In this project, you will learn about Tidyverse, a system of packages for data manipulation, exploration and visualization in the R programming language. R is a computer programming language, and it is also an open-source software often used among data scientists, statisticians, and data miners in their everyday work with data sets.",,,,
Getting and Cleaning Data,https://www.coursera.org/learn/data-cleaning,Data Science,Data Analysis,"Jeff Leek, PhD, Roger D. Peng, PhD, Brian Caffo, PhD","Before you can work with data you have to get some. This course will cover the basic ways that data can be obtained. The course will cover obtaining data from the web, from APIs, from databases and from colleagues in various formats. It will also cover the basics of data cleaning and how to make data “tidy”. Tidy data dramatically speed downstream data analysis tasks. The course will also cover the components of a complete data set including raw data, processing instructions, codebooks, and processed data. The course will cover the basics needed for collecting, cleaning, and sharing data.",198202.0,47163.0,4.5,7981.0
Getting started with Azure Data Explorer,https://www.coursera.org/learn/getting-started-with-azure-data-explorer,Data Science,Data Analysis,Priya Jha,"In this 1 hour long project-based course, you will learn to create an Azure Data Explorer or ADX cluster in the Azure portal. You will learn to create databases and tables and perform data ingestion using commands as well as using one click ingestion method. You will also learn to manage scaling in Azure Data Explorer and manage database permissions. You will conclude by learning how to query data in Azure Data Explorer using Kusto Query Language.

You should have an active azure account",,,,
Getting started with ImageJ,https://www.coursera.org/learn/getting-started-imagej,Data Science,Data Analysis,Delphine Sangotokun,"At the end of this project, you will learn how to use download and get started with ImageJ and how to use the main commands of this software for image processing and analysis, among other scientific.
This guided project is for people interested in image analysis, such as determining the number or size of objects in an image, for scientific or personal reasons.
ImageJ is a free downloadable online software that offers a very wide variety of tools for image processing and can be particularly effective for scientific analysis.
After completing this project, you will have access to the ImageJ software, and you will be able to use the basic functions to analyze images and detect for example the number and size of objects in an image. ImageJ is simple, free software that provides all the tools you need to process and analyze all of your images. The software is very easy to use and offers a very impressive analysis capacity!",,,4.5,11.0
Getting started with TensorFlow 2,https://www.coursera.org/learn/getting-started-with-tensor-flow2,Data Science,Machine Learning,Dr Kevin Webster,"Welcome to this course on Getting started with TensorFlow 2!

In this course you will learn a complete end-to-end workflow for developing deep learning models with Tensorflow, from building, training, evaluating and predicting with models using the Sequential API, validating your models and including regularisation, implementing callbacks, and saving and loading models. 

You will put concepts that you learn about into practice straight away in practical, hands-on coding tutorials, which you will be guided through by a graduate teaching assistant. In addition there is a series of automatically graded programming assignments for you to consolidate your skills.

At the end of the course, you will bring many of the concepts together in a Capstone Project, where you will develop an image classifier deep learning model from scratch.

Tensorflow is an open source machine library, and is one of the most widely used frameworks for deep learning. The release of Tensorflow 2 marks a step change in the product development, with a central focus on ease of use for all users, from beginner to advanced level. This course is intended for both users who are completely new to Tensorflow, as well as users with experience in Tensorflow 1.x.

The prerequisite knowledge required in order to be successful in this course is proficiency in the python programming language, (this course uses python 3), knowledge of general machine learning concepts (such as overfitting/underfitting, supervised learning tasks, validation, regularisation and model selection), and a working knowledge of the field of deep learning, including typical model architectures (MLP/feedforward and convolutional neural networks), activation functions, output layers, and optimisation.",28947.0,47655.0,4.9,491.0
Global Statistics - Composite Indices for International Comparisons,https://www.coursera.org/learn/global-statistics,Data Science,Data Analysis,"Stefan Andreas Sperlich, Juan Manuel Rodriguez Poo (in Partnership with UNIGE)","The number of composite indices that are constructed and used internationally is growing very fast; but whilst the complexity of quantitative techniques has increased dramatically, the education and training in this area has been dragging and lagging behind. As a consequence, these simple numbers, expected to synthesize quite complex issues, are often presented to the public and used in the political debate without proper emphasis on their intrinsic limitations and correct interpretations. 

In this course on global statistics, offered by the University of Geneva jointly with the ETH Zürich KOF, you will learn the general approach of constructing composite indices and some of resulting problems. We will discuss the technical properties, the internal structure (like aggregation, weighting, stability of time series), the primary data used and the variable selection methods.  These concepts will be illustrated using a sample of the most popular composite indices. We will try to address not only statistical questions but also focus on the distinction between policy-, media- and paradigm-driven indicators.",3520.0,3516.0,4.6,45.0
Google Cloud Big Data and Machine Learning Fundamentals,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals,Data Science,Machine Learning,Google Cloud Training,"This course introduces the Google Cloud big data and machine learning products and services that support the data-to-AI lifecycle. It explores the processes, challenges, and benefits of building a big data pipeline and machine learning models with Vertex AI on Google Cloud.",268962.0,202764.0,4.7,15236.0
Google Cloud Big Data and Machine Learning Fundamentals en Español,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-es,Data Science,Machine Learning,Google Cloud Training,"En este curso, aprenderá sobre los productos y servicios de macrodatos y aprendizaje automático de Google Cloud involucrados en el ciclo de vida de datos a IA. También explorará los procesos, los desafíos y los beneficios de crear una canalización de macrodatos y modelos de aprendizaje automático con Vertex AI en Google Cloud.",20106.0,22603.0,4.7,656.0
Google Cloud Big Data and Machine Learning Fundamentals en Français,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-fr,Data Science,Machine Learning,Google Cloud Training,"Ce cours présente les produits et services Google Cloud pour le big data et le machine learning compatibles avec le cycle de vie ""des données à l'IA"". Il explore les processus, défis et avantages liés à la création d'un pipeline de big data et de modèles de machine learning avec Vertex AI sur Google Cloud.",2290.0,3452.0,4.3,34.0
Google Cloud Big Data and Machine Learning Fundamentals 日本語版,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-jp,Data Science,Machine Learning,Google Cloud Training,このコースでは、データから AI へのライフサイクルをサポートする Google Cloud のビッグデータと機械学習のプロダクトおよびサービスを紹介します。Google Cloud で Vertex AI を使用して、ビッグデータ パイプラインと機械学習モデルを構築するためのプロセス、課題、メリットについて説明します。,5242.0,7904.0,4.5,222.0
Google Cloud Platform Big Data and Machine Learning Fundamentals em Português Brasileiro,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals-br,Data Science,Machine Learning,Google Cloud Training,"Este curso intensivo sob demanda tem duração de uma semana e apresentará as funcionalidades de Big Data e Machine Learning do Google Cloud Platform (GCP). Ele fornecerá uma visão geral rápida do Google Cloud Platform e mostrará em detalhes os recursos do processamento de dados.

Ao final deste curso, você poderá:
• Identificar o objetivo e o valor dos principais produtos de Big Data e Machine Learning no Google Cloud Platform
• Usar o Cloud SQL e o Cloud Dataproc para migrar as cargas de trabalho MySQL e Hadoop/Pig/Spark/Hive para o Google Cloud Platform
• Usar o BigQuery e o Cloud Datalab para fazer análises de dados interativas
• Escolher entre o Cloud SQL, o Bigtable e o Datastore
• Treinar e usar uma rede neural com o TensorFlow
• Escolher entre diferentes produtos de processamento de dados no Google Cloud Platform

Para se inscrever neste curso, você deve ter aproximadamente um (1) ano de experiência em um ou mais destes itens:
• Uma linguagem de consulta de uso comum, como SQL
• Atividades de extração, transformação e carregamento
• Modelagem de dados
• Machine Learning e/ou estatísticas
• Programação em Python

Observações sobre a Conta do Google:
• Os serviços do Google estão temporariamente indisponíveis na China.",2361.0,2941.0,4.7,96.0
Google Cloud Pub/Sub: Qwik Start - Command Line,https://www.coursera.org/learn/googlecloud-google-cloud-pub-sub-qwik-start-command-line-nnzjc,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Google Data Analytics Capstone: Complete a Case Study,https://www.coursera.org/learn/google-data-analytics-capstone,Data Science,Data Analysis,Google Career Certificates,"This course is the eighth course in the Google Data Analytics Certificate. You’ll have the opportunity to complete an optional case study, which will help prepare you for the data analytics job hunt. Case studies are commonly used by employers to assess analytical skills. For your case study, you’ll choose an analytics-based scenario. You’ll then ask questions, prepare, process, analyze, visualize and act on the data from the scenario. You’ll also learn other useful job hunt skills through videos with common interview questions and responses, helpful materials to build a portfolio online, and more. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
 - Learn the benefits and uses of case studies and portfolios in the job search.
 - Explore real world job interview scenarios and common interview questions.
 - Discover how case studies can be a part of the job interview process. 
 - Examine and consider different case study scenarios. 
 - Have the chance to complete your own case study for your portfolio.",189130.0,1201689.0,4.8,7460.0
Google Data Studio - Création de Tableaux de Bords Interactifs,https://www.coursera.org/learn/google-data-studio-rapport,Data Science,Data Analysis,ELINGUI Pascal Uriel,"Dans ce projet guidé, vous manipulerez Google Data Studio, la plateforme de visualisation de données gratuite de Google. Vous connecterez vos données à Data Studio, vous créerez un rapport interactif de haute qualité, ensuite le partagerez avec vos collaborateurs. Tout ceci avec les données d’une plateforme de e-Commerce fictive.",4185.0,,4.4,82.0
Graduate Admission Prediction with Pyspark ML,https://www.coursera.org/learn/graduate-admission-prediction-with-pyspark-ml,Data Science,Machine Learning,Priya Jha,"In this 1 hour long project-based course, you will learn to build a linear regression model using Pyspark ML to predict students' admission at the university. We will use the graduate admission 2  data set from Kaggle. Our goal is to use a Simple Linear Regression Machine Learning Algorithm from the Pyspark Machine learning library to predict the chances of getting admission. We will be carrying out the entire project on the Google Colab environment with the installation of Pyspark. You will need a free Gmail account to complete this project. Please be aware of the fact that the dataset and the model in this project, can not be used in the real-life. We are only using this data for the learning purposes.

By the end of this project, you will be able to build the linear regression model using Pyspark ML to predict admission chances.You will also be able to setup and work with Pyspark on the Google Colab environment. Additionally, you will also be able to clean and prepare data for analysis.

You should be familiar with the Python Programming language and you should have a theoretical understanding of Linear Regression algorithm. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.7,24.0
Graph Analytics for Big Data,https://www.coursera.org/learn/big-data-graph-analytics,Data Science,Data Analysis,Amarnath Gupta,"Want to understand your data network structure and how it changes under different conditions? Curious to know how to identify closely interacting clusters within a graph? Have you heard of the fast-growing area of graph analytics and want to learn more? This course gives you a broad overview of the field of graph analytics so you can learn new ways to model, store, retrieve and analyze graph-structured data.

After completing this course, you will be able to model a problem into a graph database and perform analytical tasks over the graph in a scalable manner.  Better yet, you will be able to apply these techniques to understand the significance of your data sets for your own projects.",45716.0,49042.0,4.3,1227.0
"Grundlagen: Daten, überall Daten",https://www.coursera.org/learn/grundlagen-daten-uberall-daten,Data Science,Data Analysis,Google Career Certificates,"Dies ist der erste Kurs im Google Data Analytics Certificate. In diesen Kursen lernen Sie alles, was Sie für eine Einstiegsposition in der Datenanalyse benötigen. Unternehmen aller Art benötigen Fachleute für Datenanalyse, die ihnen helfen, Prozesse zu verbessern, Chancen und Trends zu erkennen, neue Produkte auf den Markt zu bringen und durchdachte Entscheidungen zu treffen. In diesem Kurs werden Sie anhand eines von Google entwickelten praxisorientierten Lehrplans in die Welt von Data Analytics eingeführt. Das Material deckt viele wichtige Themen der Data Analytics ab und soll Ihnen einen Überblick über das Google Data Analytics Certificate geben. Momentan bei Google tätige Fachleute für Datenanalyse werden Sie anleiten und Ihnen praktische Möglichkeiten zeigen, mit denen Sie die gängigen Aufgaben von Fachleuten für Datenanalyse mithilfe der besten Tools und Ressourcen erledigen können.

Lernende, die dieses Zertifikatsprogramm abschließen, können sich auf Einstiegspositionen in der Datenanalyse bewerben. Es sind keine Vorkenntnisse erforderlich.

Nach Abschluss dieses Kurses können Sie:
- Praktiken und Prozesse überblicken, die im Arbeitsalltag in Junior- oder Associate-Positionen in der Datenanalyse verwendet werden 
- wichtige analytische Fähigkeiten (Datenbereinigung, Datenanalyse, Datenvisualisierung) und Tools (Tabellenkalkulationen, SQL, R-Programmierung, Tableau) anwenden, die Sie Ihrer professionellen Toolbox hinzufügen können 
- zahlreiche Begriffe und Konzepte kennen, die für die Rolle von Junior-Fachleuten für Datenanalyse relevant sind, wie z. B. der Datenlebenszyklus und der Datenanalyseprozess 
- die Rolle von Analytics im Datenökosystem bewerten 
- eine Selbsteinschätzung Ihres analytischen Denkens durchführen 
- Stellenangebote erkunden, die Ihnen nach Abschluss des Programms zur Verfügung stehen, und mehr über bewährte Verfahren bei der Stellensuche erfahren",,3582.0,4.5,11.0
Guided Tour of Machine Learning in Finance,https://www.coursera.org/learn/guided-tour-machine-learning-finance,Data Science,Machine Learning,Igor Halperin,"This course aims at providing an introductory and broad overview of the field of ML with the focus on applications on Finance. Supervised Machine Learning methods are used in the capstone project to predict bank closures. Simultaneously, while this course can be taken as a separate course, it serves as a preview of topics that are covered in more details in subsequent modules of the specialization Machine Learning and Reinforcement Learning in Finance.

The goal  of Guided Tour of Machine Learning in Finance is to get a sense of what Machine Learning is, what it is for and in how many different financial problems it can be applied to.

The course is designed for three categories of students:
Practitioners working at financial institutions such as banks, asset management firms or hedge funds
Individuals interested in applications of ML for personal day trading
Current full-time students pursuing a degree in Finance, Statistics, Computer Science, Mathematics, Physics, Engineering or other related disciplines who want to learn about practical applications of ML in Finance  

Experience with Python (including numpy, pandas, and IPython/Jupyter notebooks), linear algebra, basic probability theory and basic calculus is necessary to complete assignments in this course.",29460.0,14262.0,3.8,637.0
HR Analytics- Build an HR dashboard using Power BI,https://www.coursera.org/learn/hr-analytics-build-hr-dashboard-using-power-bi,Data Science,Data Analysis,Abhishek Jha,"In this 1 hour long project, you will build an attractive and eye-catching HR dashboard using Power BI. We will begin this guided project by importing data & creating an employee demographics page that gives us the overall demographic outlook of the organization. We will then create pie charts and doughnut charts to visualize gender & racial diversity. In the final tasks, we will create an employee detail page that will provide you with all the important information about any employee with just a click. We will also explore buttons, themes, slicers & filters to make the dashboard more interactive & useful. By the end of this course, you will be confident in creating beautiful HR dashboards that you can use for your personal or organizational purpose.",3112.0,,4.7,166.0
Haciendo modelos con ML.NET,https://www.coursera.org/learn/modelos-ml-net,Data Science,Machine Learning,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a desarrollar un modelo de Machine Learning usando ML.NET.

Además, aprenderás a simplificar la creación inicial de aplicaciones y modelos usando ML.NET Model Builder.",,,,
Hadoop Platform and Application Framework,https://www.coursera.org/learn/hadoop,Data Science,Data Analysis,"Natasha Balac, Ph.D., Paul Rodriguez, Andrea Zonca","This course is for novice programmers or business people who would like to understand the core tools used to wrangle and analyze big data. With no prior experience, you will have the opportunity to walk through hands-on examples with Hadoop and Spark frameworks, two of the most common in the industry. You will be comfortable explaining the specific components and basic processes of the Hadoop architecture, software stack, and execution environment.   In the assignments you will be guided in how data scientists apply the important concepts and techniques such as Map-Reduce that are used to solve fundamental problems in big data.  You'll feel empowered to have conversations about big data and the data analysis process.",144944.0,18742.0,4.0,3298.0
Handling Imbalanced Data Classification Problems,https://www.coursera.org/learn/handling-imbalanced-data-classification-problems,Data Science,Machine Learning,Bhaskarjit Sarmah,"In this 2-hour long project-based course on handling imbalanced data classification problems, you will learn to understand the business problem related we are trying to solve and and understand the dataset. You will also learn how to select best evaluation metric for imbalanced datasets and data resampling techniques like undersampling, oversampling and SMOTE before we use them for model building process. At the end of the course you will understand and learn how to implement ROC curve and adjust probability threshold to improve selected evaluation metric of the model.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",1621.0,,4.6,54.0
Handling Missing Values in R using tidyr,https://www.coursera.org/learn/handling-missing-values-r-using-tidyr,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Missing data can be a “serious” headache for data analysts and scientists. This project-based course Handling Missing Values in R using tidyr is for people who are learning R and who seek useful ways for data cleaning and manipulation in R. In this project-based course, we will not only talk about missing values, but we will spend a great deal of our time here hands-on on how to handle missing value cases using the tidyr package. Be rest assured that you will learn a ton of good work here.
By the end of this 2-hour-long project, you will calculate the proportion of missing values in the data and select columns that have missing values. Also, you will be able to use the drop_na(), replace_na(), and fill() function in the tidyr package to handle missing values. By extension, we will learn how to chain all the operations using the pipe function.
This project-based course is an intermediate level course in R. Therefore, to complete this project, it is required that you have prior experience with using R. I recommend that you should complete the projects titled: “Getting Started with R” and “Data Manipulation with dplyr in R“ before you take this current project. These introductory projects in using R will provide every necessary foundation to complete this current project. However, if you are comfortable with using R, please join me on this wonderful ride! Let’s get our hands dirty!",,,,
Hands-on Machine Learning with AWS and NVIDIA,https://www.coursera.org/learn/machine-learning-aws-nvidia,Data Science,Machine Learning,"Isaac Privitera, Abhilash Somasamudramath, Antje Barth, Adam Tetelman, Chris Fregly, Pavan Kumar Sunder, Anish Mohan","Machine learning (ML) projects can be complex, tedious, and time consuming. AWS and NVIDIA solve this challenge with fast, effective, and easy-to-use capabilities for your ML project.

This course is designed for ML practitioners, including data scientists and developers, who have a working knowledge of machine learning workflows. In this course, you will gain hands-on experience on building, training, and deploying scalable machine learning models with Amazon SageMaker and Amazon EC2 instances powered by NVIDIA GPUs. Amazon SageMaker helps data scientists and developers prepare, build, train, and deploy high-quality ML models quickly by bringing together a broad set of capabilities purpose-built for ML. Amazon EC2 instances powered by NVIDIA GPUs along with NVIDIA software offer high performance GPU-optimized instances in the cloud for efficient model training and cost effective model inference hosting.

In this course, you will first get an overview of Amazon SageMaker and NVIDIA GPUs. Then, you will get hands-on, by running a GPU powered Amazon SageMaker notebook instance. You will then learn how to prepare a dataset for model training, build a model, execute model training, and deploy and optimize the ML model. You will also learn, hands-on, how to apply this workflow for computer vision (CV) and natural language processing (NLP) use cases. After completing this course, you will be able to build, train, deploy, and optimize ML workflows with GPU acceleration in Amazon SageMaker and understand the key Amazon SageMaker services applicable to computer vision and NLP ML tasks.",6955.0,9487.0,,
Hands-on Text Mining and Analytics,https://www.coursera.org/learn/text-mining-analytics,Data Science,Data Analysis,Min Song,"This course provides an unique opportunity for you to learn key components of text mining and analytics aided by the real world datasets and the text mining toolkit written in Java. Hands-on experience in core text mining techniques including text preprocessing, sentiment analysis, and topic modeling help learners be trained to be a competent data scientists. 

Empowered by bringing lecture notes together with lab sessions based on the y-TextMiner toolkit developed for the class, learners will be able to develop interesting text mining applications.",14589.0,3872.0,3.9,40.0
Health Data Science Foundation,https://www.coursera.org/learn/health-data-science-foundation,Data Science,Machine Learning,Jimeng Sun,"This course is intended for persons involved in machine learning who are interested in medical applications, or vice versa, medical professionals who are interested in the methods modern computer science has to offer to their field. We will cover health data analysis, different types of neural networks, as well as training and application of neural networks applied on real-world medical scenarios.

We cover deep learning (DL) methods, healthcare data and applications using DL methods. The courses include activities such as video lectures, self guided programming labs, homework assignments (both written and programming), and a large project.

The first phase of the course will include video lectures on different DL and health applications topics, self-guided labs and multiple homework assignments. In this phase, you will build up your knowledge and experience in developing practical deep learning models on healthcare data. The second phase of the course will be a large project that can lead to a technical report and functioning demo of the deep learning models for addressing some specific healthcare problems. We expect the best projects can potentially lead to scientific publications.",,5078.0,,
Herramientas para la ciencia de datos,https://www.coursera.org/learn/herramientas-para-la-ciencia-de-datos,Data Science,Data Analysis,"Romeo Kienzler, Svetlana Levitan","¿Cuáles son algunas de las herramientas de ciencia de datos más populares, cómo las usa y cuáles son sus características? En este curso, aprenderá sobre Jupyter Notebooks, RStudio IDE, Apache Zeppelin y Data Science Experience. Aprenderá para qué se utiliza cada herramienta, qué lenguajes de programación pueden ejecutar, sus características y limitaciones. Con las herramientas alojadas en la nube en Cognitive Class Labs, podrá probar cada herramienta y seguir las instrucciones para ejecutar código simple en Python, R o Scala. Para finalizar el curso, creará un proyecto final con un Jupyter Notebook en IBM Data Science Experience y demostrará su competencia preparando un cuaderno, escribiendo Markdown y compartiendo su trabajo con sus compañeros.",3566.0,142734.0,4.5,94.0
Hierarchical Clustering using Euclidean Distance,https://www.coursera.org/learn/genome-analysis-hierarchical-clustering,Data Science,Data Analysis,Usama A. F. Khalil,"By the end of this project, you will create a Python program using a jupyter interface that analyzes a group of viruses and plot a dendrogram based on similarities among them. The dendrogram that you will create will depend on the cumulative skew profile, which in turn depends on the nucleotide composition. You will use complete genome sequences for many viruses including, Corona, SARS, HIV, Zika, Dengue, enterovirus, and West Nile viruses.",,,,
Hierarchical relational data analysis using python,https://www.coursera.org/learn/hierarchical-relational-data-analysis-using-python,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project you will learn how to analyze Hierarchical Data. we are going to work with a dataset related to Mexico toy sales. The dataset contains some hierarchical data about different products sold in different stores in different cities in Mexico. we are going to load this data and after some preprocessing steps, we are going to learn how to analyze this data using different visualization techniques. During this project we are going to learn about a very important concept called Data Granularity. And we will also learn how to use different levels of granularity to answer some analytical question. and at the end we are going to talk about Treemaps and Sunburst Diagram, two handy visualization techniques used for hierarchical data.",,,,
High-dimensional Data visualization techniques using python,https://www.coursera.org/learn/high-dimensional-data-visualization-techniques-using-python,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project you will learn how to analyze high-dimensional data using different visualization techniques. We are going to learn how to implement Scatterplot Matrix and Parallel coordinate plots (PCP) in python. and We will learn how to use these two high-dimensional data visualization techniques to analyze our data by solving  three tasks: Outlier Detection, Correlation Analysis and Cluster analysis. we will also talk about Data reduction techniques. we will learn how to sample our data to reduce the number of the data points for a better visualization. We will also learn about the Dimensionality reduction technique to reduce the number of dimensions in our dataset and how it can help us for a better analysis.",,,,
How Google does Machine Learning,https://www.coursera.org/learn/google-machine-learning,Data Science,Machine Learning,Google Cloud Training,"What are best practices for implementing machine learning on Google Cloud? What is Vertex AI and how can you use the platform to quickly build, train, and deploy AutoML machine learning models without writing a single line of code? What is machine learning, and what kinds of problems can it solve? 

Google thinks about machine learning slightly differently: it’s about providing a unified platform for managed datasets, a feature store, a way to build, train, and deploy machine learning models without writing a single line of code, providing the ability to label data, create Workbench notebooks using frameworks such as TensorFlow, SciKit Learn, Pytorch, R, and others. Our Vertex AI Platform also includes the ability to train custom models, build component pipelines, and perform both online and batch predictions. We also discuss the five phases of converting a candidate use case to be driven by machine learning, and consider why it is important to not skip the phases. We end with a recognition of the biases that machine learning can amplify and how to recognize them.",115209.0,58900.0,4.6,7075.0
How Google does Machine Learning em Português Brasileiro,https://www.coursera.org/learn/google-machine-learning-br,Data Science,Machine Learning,Google Cloud Training,"""O que é machine learning e que tipos de problemas ele pode resolver? A abordagem de machine learning do Google é um pouco diferente. Ela se concentra na lógica, e não apenas nos dados. Vamos discutir por que essa abordagem é útil para os cientistas de dados durante a criação de um pipeline de modelos de machine learning. 

Depois vamos falar sobre as cinco fases da conversão de um possível caso de uso de machine learning e ver a importância de não pular essas fases. Por fim, vamos conhecer os vieses que podem ser amplificados pelo machine learning e aprender a identificá-los.
 
 >>> Ao se inscrever nesta especialização, você concorda com os Termos de Serviço do Qwiklabs, conforme estabelecidos na seção de perguntas frequentes em: https://qwiklabs.com/terms_of_service <<<""",1694.0,,4.8,73.0
How Google does Machine Learning en Español,https://www.coursera.org/learn/google-machine-learning-es,Data Science,Machine Learning,Google Cloud Training,"¿Qué es el aprendizaje automático y qué tipos de problemas puede solucionar? Google concibe el aprendizaje automático de una forma algo diferente: considera que se trata no solo de datos, sino también de lógica. Hablaremos de por qué es útil para los científicos de datos concebirlo así cuando piensan en compilar una canalización de modelos de aprendizaje automático. 

Luego, analizaremos las cinco fases de la transformación de un posible caso de uso en un recurso que pueda aprovechar la tecnología de aprendizaje automático. También consideramos por qué es importante no omitir ninguna fase. Finalizamos con un reconocimiento de los sesgos que puede amplificar el aprendizaje automático y cómo reconocerlos.
 
 >>> Al inscribirse en esta especialización, acepta las Condiciones del Servicio de Qwiklabs, que se indican en las Preguntas frecuentes. Puede consultarlas en https://qwiklabs.com/terms_of_service. <<<",6512.0,1732.0,4.6,193.0
How Google does Machine Learning en Français,https://www.coursera.org/learn/google-machine-learning-fr,Data Science,Machine Learning,Google Cloud Training,"Qu'est-ce que le machine learning et quels types de problèmes permet-il de résoudre ? Google adopte une approche particulière du machine learning qui s'appuie non seulement sur les données, mais également sur la logique. Nous expliquerons l'utilité d'une telle définition pour les data scientists à l'heure de créer un pipeline de modèles de machine learning. 

Ensuite, nous examinerons les cinq phases permettant de convertir un cas d'utilisation devant être traité à l'aide du machine learning et verrons pourquoi chaque phase est importante. Enfin, nous identifierons les biais que le machine learning est susceptible d'amplifier et apprendrons à les repérer.

 >>> En vous inscrivant à cette spécialisation, vous vous engagez à respecter les Conditions d'utilisation de Qwiklabs, telles que définies dans les questions fréquentes et disponibles à l'adresse : https://qwiklabs.com/terms_of_service <<<",,,4.3,16.0
How Google does Machine Learning 日本語版,https://www.coursera.org/learn/google-machine-learning-jp,Data Science,Machine Learning,Google Cloud Training,"機械学習とはどのようなもので、どのような問題を解決できるでしょうか。Google は機械学習について、データだけでなくロジックの面からも独自の視点で考えています。機械学習モデルのパイプラインの構築について検討する際、このようなフレーミングがなぜデータ サイエンティストにとって有益であるかを説明します。

次に、候補となるユースケースを機械学習を利用できるように変換する 5 つの段階について説明し、こうした段階を省略しないことの重要性について検討します。最後に、機械学習によって増幅される可能性のあるバイアスと、それを認識する方法について確認します。
 
 >>> この専門講座に登録すると、よくある質問に記載されているとおり、Qwiklabs の利用規約（https://qwiklabs.com/terms_of_service）に同意したことになります。<<<",2734.0,2504.0,4.5,131.0
How to Visualize Research Data in Tableau,https://www.coursera.org/learn/how-visualize-research-data-tableau,Data Science,Data Analysis,Carmen Rojas,"Publishing research often requires the preparation of visual elements like charts, tables, and graphs to better explain the text in a research report. Creating these elements can be done easily and effectively in Tableau. Using Tableau, large and small data sets can be visualized with precision, creativity, interactivity, and options in Tableau. After taking this course learners will know how to create a table, a geovisualization, and a pie chart. Three of the most common research visualizations available. The learners will also learn how to upload data, how to export these tables, and how to incorporate charts and graphs in research reports. 

Researchers from students to professionals will benefit from learning how to create visualizations based on surveys, observations, experiments, and other types of research methods. 

Knowledge of research is useful but not required for this project.",,,,
Human Factors in AI,https://www.coursera.org/learn/human-factors-in-artificial-intelligence,Data Science,Machine Learning,Jon Reifschneider,"This third and final course of the AI Product Management Specialization by Duke University's Pratt School of Engineering focuses on the critical human factors in developing AI-based products.  The course begins with an introduction to human-centered design and the unique elements of user experience design for AI products.  Participants will then learn about the role of data privacy in AI systems, the challenges of designing ethical AI, and approaches to identify sources of bias and mitigate fairness issues.  The course concludes with a comparison of human intelligence and artificial intelligence, and a discussion of the ways that AI can be used to both automate as well as assist human decision-making.

At the conclusion of this course, you should be able to:
1) Identify and mitigate privacy and ethical risks in AI projects
2) Apply human-centered design practices to design successful AI product experiences
3) Build AI systems that augment human intelligence and inspire model trust in users",2109.0,9444.0,4.9,18.0
Hyperparameter Tuning with Keras Tuner,https://www.coursera.org/learn/keras-tuner,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long guided project, we will use Keras Tuner to find optimal hyperparamters for a Keras model. Keras Tuner is an open source package for Keras which can help machine learning practitioners automate Hyperparameter tuning tasks for their Keras models. The concepts learned in this project will apply across a variety of model architectures and problem scenarios. Please note that we are going to learn to use Keras Tuner for hyperparameter tuning, and are not going to implement the tuning algorithms ourselves. At the time of recording this project, Keras Tuner has a few tuning algorithms including Random Search, Bayesian Optimization and HyperBand.

In order to complete this project successfully, you will need prior programming experience in Python. This is a practical, hands on guided project for learners who already have theoretical understanding of Neural Networks, and optimization algorithms like gradient descent but want to understand how to use Keras Tuner to start optimizing hyperparameters for training their Keras models. You should also be familiar with the Keras API.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2224.0,,4.6,62.0
Hyperparameter Tuning with Neural Network Intelligence,https://www.coursera.org/learn/hyperparameter-tuning,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long guided project, we will learn the basics of using Microsoft's Neural Network Intelligence (NNI) toolkit and will use it to run a Hyperparameter tuning experiment on a Neural Network. NNI is an open source, AutoML toolkit created by Microsoft which can help machine learning practitioners automate Feature engineering, Hyperparameter tuning, Neural Architecture search and Model compression. In this guided project, we are going to take a look at using NNI to perform hyperparameter tuning. Please note that we are going to learn to use the NNI toolkit for hyperparameter tuning, and are not going to implement the tuning algorithms ourselves. We will use the popular MNIST dataset and train a simple Neural Network to learn to classify images of hand-written digits from the dataset. Once a basic script is in place, we will use the NNI toolkit to run a hyperparameter tuning experiment to find optimal values for batch size, learning rate, choice of activation function for the hidden layer, number of hidden units for the hidden layer, and dropout rate for the dropout layer.

To be able to complete this project successfully, you should be familiar with the Python programming language. You should also be familiar with Neural Networks, TensorFlow and Keras.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2891.0,,4.7,38.0
Hypothesis Testing in R,https://www.coursera.org/learn/hypothesis-testing-in-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Hypothesis Testing in R. In this project, you will learn how to perform extensive hypothesis tests for one and two samples in R.
By the end of this 2-hour long project, you will understand the rationale behind performing hypothesis testing. Also, you will learn how to perform hypothesis tests for proportions and means. By extension, you will learn how to perform a hypothesis test for means of matched or paired samples in R.

Note, you do not need to be a statistical analyst or data scientist to be successful in this guided project, just a familiarity with basic statistics and using R suffice for this project. If you are not familiar with R and want to learn the basics, start with my previous guided project titled “Getting Started with R”, and ""Calculating Descriptive Statistics in R"".

A fundamental prerequisite is having a good understanding of the theory of hypothesis test.",,,4.6,21.0
Hypothesis Testing with Python and Excel,https://www.coursera.org/learn/hypothesis-testing-python-excel,Data Science,Data Analysis,"Gerald S. Brown, Kishore K. Pochampally","In today's job market, leaders need to understand the fundamentals of data to be competitive. An essential procedure to understand business and analytics is hypothesis testing. This short course, designed by Tufts University expert faculty, will teach the fundamentals of hypothesis testing of a population mean and a population proportion, using Excel and Python for calculations. You'll also discover the central limit theorem, which is essential for hypothesis testing. To conclude the course, you will apply your newfound skills by creating a plan for an experiment in your own workplace that uses hypothesis testing.",2596.0,,4.1,21.0
IBM Data Analyst Capstone Project,https://www.coursera.org/learn/ibm-data-analyst-capstone-project,Data Science,Data Analysis,"Ramesh Sannareddy, Rav Ahuja","In this course you will apply various Data Analytics skills and techniques that you have learned as part of the previous courses in the IBM Data Analyst Professional Certificate. You will assume the role of an Associate Data Analyst who has recently joined the organization and be presented with a business challenge that requires data analysis to be performed on real-world datasets. 

You will undertake the tasks of collecting data from multiple sources, performing exploratory data analysis, data wrangling and preparation, statistical analysis and mining the data, creating charts and plots to visualize data, and building an interactive dashboard. The project will culminate with a presentation of your data analysis report, with an executive summary for the various stakeholders in the organization. You will be assessed on both your work for the various stages in the Data Analysis process, as well as the final deliverable. 

This project is a great opportunity to showcase your Data Analytics skills, and demonstrate your proficiency to potential employers.",23000.0,151056.0,4.6,662.0
Identify Damaged Car Parts with Vertex AutoML Vision,https://www.coursera.org/learn/googlecloud-identify-damaged-car-parts-with-vertex-automl-vision-bugvm,Data Science,Machine Learning,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Identifying Patient Populations,https://www.coursera.org/learn/computational-phenotyping,Data Science,Data Analysis,"Laura K. Wiley, PhD","This course teaches you the fundamentals of computational phenotyping, a biomedical informatics method for identifying patient populations. In this course you will learn how different clinical data types perform when trying to identify patients with a particular disease or trait. You will also learn how to program different data manipulations and combinations to increase the complexity and improve the performance of your algorithms. Finally, you will have a chance to put your skills to the test with a real-world practical application where you develop a computational phenotyping algorithm to identify patients who have hypertension. You will complete this work using a real clinical data set while using a free, online computational environment for data science hosted by our Industry Partner Google Cloud.",2625.0,4565.0,4.4,35.0
Image Classification on Autopilot with AWS AutoGluon,https://www.coursera.org/learn/image-classification-with-aws-autogluon,Data Science,Machine Learning,Ryan Ahmed,"Hello everyone and welcome to this new hands-on project on image classification with Amazon Web Services (AWS) AutoGluon. In this project, we will train several deep neural networks models to classify images using a powerful library known as AutoGluon. AutoGluon is the library behind AWS SageMaker autopilot and it allows for quick prototyping of several powerful models using a few lines of code.",,,,
Image Classification with Amazon Sagemaker,https://www.coursera.org/learn/image-classification-sagemaker,Data Science,Machine Learning,Amit Yadav,"Please note: You will need an AWS account to complete this course. Your AWS account will be charged as per your usage. Please make sure that you are able to access Sagemaker within your AWS account. If your AWS account is new, you may need to ask AWS support for access to certain resources. You should be familiar with python programming, and AWS before starting this hands on project.  We use a Sagemaker P type instance in this project, and if you don't have access to this instance type, please contact AWS support and request access.

In this 2-hour long project-based course, you will learn how to train and deploy an image classifier using Amazon Sagemaker. Sagemaker provides a number of machine learning algorithms ready to be used for solving a number of tasks. We will use the image classification algorithm from Sagemaker to create, train and deploy a model that will be able to classify 37 breeds of dogs and cats from the popular IIIT-Oxford Pets Dataset.

Since this is a practical, project-based course, we will not dive in the theory behind deep learning based image classification, but will focus purely on training and deploying a model with Sagemaker. You will also need to have some experience with Amazon Web Services (AWS).

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",5054.0,,4.6,96.0
Image Classification with CNNs using Keras,https://www.coursera.org/learn/image-classification-cnn-keras,Data Science,Machine Learning,Amit Yadav,"In this 1-hour long project-based course, you will learn how to create a Convolutional Neural Network (CNN) in Keras with a TensorFlow backend, and you will learn to train CNNs to solve Image Classification problems. In this project, we will create and train a CNN model on a subset of the popular CIFAR-10 dataset.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Prerequisites:
In order to be successful in this project, you should be familiar with python and convolutional neural networks. 

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",12352.0,,4.4,545.0
Image Compression and Generation using Variational Autoencoders in Python,https://www.coursera.org/learn/image-compression-generation-vae,Data Science,Machine Learning,Ari Anastassiou,"In this 1-hour long project, you will be introduced to the Variational Autoencoder. We will discuss some basic theory behind this model, and move on to creating a machine learning project based on this architecture. Our data comprises 60.000 characters from a dataset of fonts. We will train a variational autoencoder that will be capable of compressing this character font data from 2500 dimensions down to 32 dimensions. This same model will be able to then reconstruct its original input with high fidelity. The true advantage of the variational autoencoder is its ability to create new outputs that come from distributions that closely follow its training data: we can output characters in brand new fonts.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3319.0,,4.7,71.0
Image Compression with K-Means Clustering,https://www.coursera.org/learn/scikit-learn-k-means-clustering-image-compression,Data Science,Machine Learning,Snehan Kekre,"In this project, you will apply the k-means clustering unsupervised learning algorithm using scikit-learn and Python to build an image compression application with interactive controls. By the end of this 45-minute long project, you will be competent in pre-processing high-resolution image data for k-means clustering, conducting basic exploratory data analysis (EDA) and data visualization, applying a computationally time-efficient implementation of the k-means algorithm, Mini-Batch K-Means, to compress images, and leverage the Jupyter widgets library to build interactive GUI components to select images from a drop-down list and pick values of k using a slider.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7842.0,,4.6,282.0
Image Data Augmentation with Keras,https://www.coursera.org/learn/data-augmentation-keras,Data Science,Machine Learning,Amit Yadav,"In this 1.5-hour long project-based course, you will learn how to apply image data augmentation in Keras. We are going to focus on using the ImageDataGenerator class from Keras’ image preprocessing package, and will take a look at a variety of options available in this class for data augmentation and data normalization.

Since this is a practical, project-based course, you will need to prior experience with Python programming, convolutional neural networks, and Keras with a TensorFlow backend.

Data augmentation is a technique used to create more examples, artiﬁcially, from an existing dataset. This is useful if your dataset is small and you want to increase the number of examples. Data augmentation can often solve over-fitting so that your model generalizes well after training. For images, a variety of augmentation can be applied to increase the number of examples.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9209.0,,4.6,446.0
Image Denoising Using AutoEncoders in Keras and Python,https://www.coursera.org/learn/autoencoders-image-denoising,Data Science,Machine Learning,Ryan Ahmed,"In this 1-hour long project-based course, you will be able to:
- Understand the theory and intuition behind Autoencoders
- Import Key libraries, dataset and visualize images
- Perform image normalization, pre-processing, and add random noise to images
- Build an Autoencoder using Keras with Tensorflow 2.0 as a backend
- Compile and fit Autoencoder model to training data 
- Assess the performance of trained Autoencoder using various KPIs 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6752.0,,4.5,269.0
Image Noise Reduction with Auto-encoders using TensorFlow,https://www.coursera.org/learn/image-noise-reduction-auto-encoders,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn the basics of image noise reduction with auto-encoders. Auto-encoding is an algorithm to help reduce dimensionality of data with the help of neural networks. It can be used for lossy data compression where the compression is dependent on the given data. This algorithm to reduce dimensionality of data as learned from the data can also be used for reducing noise in data.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Tensorflow pre-installed.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4711.0,,4.7,109.0
Image Super Resolution Using Autoencoders in Keras,https://www.coursera.org/learn/image-super-resolution-autoencoders-keras,Data Science,Machine Learning,Snehan Kekre,"Welcome to this 1.5 hours long hands-on project on Image Super Resolution using Autoencoders in Keras. In this project, you’re going to learn what an autoencoder is, use Keras with Tensorflow as its backend to train your own autoencoder, and use this deep learning powered autoencoder to significantly enhance the quality of images. That is, our neural network will create high-resolution images from low-res source images.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Keras pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",8695.0,,4.4,335.0
Imbalanced-learn: modelos de ML con datos desequilibrados,https://www.coursera.org/learn/imbalanced-learn-ml-datosdesequilibrados,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender que es el desbalanceo de clases en Machine leraning y como tratarlo. Aprenderemos las técnicas más avanzadas para trabajar con datos desbalanceados como: bSMOTE, ADASYN, SMOTEEN, etc. También aprenderemos a generar modelos capaces de trabajar con datos desbalanceados.

Una gran parte de los problemas de clasificación utilizan datos debalanceadas. Si no se tratan estos casos estaremos generando modelos que no estén funcionando correctamente, pese a que a priori parezca que si. Por eso, en este curso aprenderemos a como tratar este tipo de datos.",,,,
Implementar un modelo de aprendizaje automático con FastAPI,https://www.coursera.org/learn/implementar-un-modelo-de-aprendizaje-automtico-con-fastapi,Data Science,Machine Learning,Leire Ahedo,"En este curso te enseñaremos a utilizar FastAPI y sus múltiples capacidades para depurar errores, desarrollo automático de documentación , integración de variables y uso de funciones asíncronas. También veremos en detalle como desarrollar el modelo de ML para que se pueda desplegar mediante APIs.

Gracias a este curso podrás desarrollar y desplegar tus propios modelos mediante APIs, para que los usuarios los utilicen fácilmente.",,,,
Importer des Données dans R,https://www.coursera.org/learn/importer-donnees-dans-r,Data Science,Data Analysis,Emmanuel Segui,"Dans ce cours d'une heure, basé sur un projet, vous apprendrez comment lire toutes sortes de données et les importer dans R, y compris des fichiers CSV, des fichiers Excel, des données provenant d'autres logiciels statistiques, du Web et de bases de données relationnelles.

Remarque : ce cours fonctionne le mieux pour les étudiants basés en Amérique du Nord. Nous nous efforçons actuellement d'apporter la même expérience dans d'autres régions.",,,,
Importing Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-importing-data,Data Science,Data Analysis,"Carrie Wright, PhD, Shannon Ellis, PhD, Stephanie Hicks, PhD, Roger D. Peng, PhD","Getting data into your statistical analysis system can be one of the most challenging parts of any data science project. Data must be imported and harmonized into a coherent format before any insights can be obtained. You will learn how to get data into R from commonly used formats and harmonizing different kinds of datasets from different sources. If you work in an organization where different departments collect data using different systems and different storage formats, then this course will provide essential tools for bringing those datasets together and making sense of the wealth of information in your organization.

This course introduces the Tidyverse tools for importing data into R so that it can be prepared for analysis, visualization, and modeling. Common data formats are introduced, including delimited files, spreadsheets and relational databases, and techniques for obtaining data from the web are demonstrated, such as web scraping and web APIs.

In this specialization we assume familiarity with the R programming language. If you are not yet familiar with R, we suggest you first complete R Programming before returning to complete this course.",,2881.0,4.7,35.0
Importing Data into R,https://www.coursera.org/learn/import-data-into-r,Data Science,Data Analysis,Emmanuel Segui,"In this 1-hour long project-based course, you will learn how to read all sorts of data and import them into R, including CSV files, Excel files, data from other statistical software, the web and from relational databases.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,17.0
"Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization",https://www.coursera.org/learn/deep-neural-network,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","In the second course of the Deep Learning Specialization, you will open the deep learning black box to understand the processes that drive performance and generate good results systematically. 

By the end, you will learn the best practices to train and develop test sets and analyze bias/variance for building deep learning applications; be able to use standard neural network techniques such as initialization, L2 and dropout regularization, hyperparameter tuning, batch normalization, and gradient checking; implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence; and implement a neural network in TensorFlow.

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",468473.0,443348.0,4.9,61533.0
Improving Your Statistical Questions,https://www.coursera.org/learn/improving-statistical-questions,Data Science,Probability and Statistics,Daniel Lakens,"This course aims to help you to ask better statistical questions when performing empirical research. We will discuss how to design informative studies, both when your predictions are correct, as when your predictions are wrong. We will question norms, and reflect on how we can improve research practices to ask more interesting questions. In practical hands on assignments you will learn techniques and tools that can be immediately implemented in your own research, such as thinking about the smallest effect size you are interested in, justifying your sample size, evaluate findings in the literature while keeping publication bias into account, performing a meta-analysis, and making your analyses computationally reproducible.

If you have the time, it is recommended that you complete my course 'Improving Your Statistical Inferences' before enrolling in this course, although this course is completely self-contained.",7431.0,5255.0,4.9,100.0
Improving your statistical inferences,https://www.coursera.org/learn/statistical-inferences,Data Science,Probability and Statistics,Daniel Lakens,"This course aims to help you to draw better statistical inferences from empirical research. First, we will discuss how to correctly interpret p-values, effect sizes, confidence intervals, Bayes Factors, and likelihood ratios, and how these statistics answer different questions you might be interested in. Then, you will learn how to design experiments where the false positive rate is controlled, and how to decide upon the sample size for your study, for example in order to achieve high statistical power. Subsequently, you will learn how to interpret evidence in the scientific literature given widespread publication bias, for example by learning about p-curve analysis. Finally, we will talk about how to do philosophy of science, theory construction, and cumulative science, including how to perform replication studies, why and how to pre-register your experiment, and how to share your results following Open Science principles. 

In practical, hands on assignments, you will learn how to simulate t-tests to learn which p-values you can expect, calculate likelihood ratio's and get an introduction the binomial Bayesian statistics, and learn about the positive predictive value which expresses the probability published research findings are true. We will experience the problems with optional stopping and learn how to prevent these problems by using sequential analyses. You will calculate effect sizes, see how confidence intervals work through simulations, and practice doing a-priori power analyses. Finally, you will learn how to examine whether the null hypothesis is true using equivalence testing and Bayesian statistics, and how to pre-register a study, and share your data on the Open Science Framework.

All videos now have Chinese subtitles. More than 30.000 learners have enrolled so far! 

If you enjoyed this course, I can recommend following it up with me new course ""Improving Your Statistical Questions""",65763.0,40683.0,4.9,743.0
Increasing Real Estate Management Profits: Harnessing Data Analytics,https://www.coursera.org/learn/analytics-capstone,Data Science,Data Analysis,"Daniel Egger, Jana Schaich Borg","In this final course you will complete a Capstone Project using data analysis to recommend a method for improving profits for your company, Watershed Property Management, Inc. Watershed is responsible for managing thousands of residential rental properties throughout the United States. Your job is to persuade Watershed’s management team to pursue a new strategy for managing its properties that will increase their profits. To do this, you will: (1) Elicit information about important variables relevant to your analysis; (2) Draw upon your new MySQL database skills to extract relevant data from a real estate database; (3) Implement data analysis in Excel to identify the best opportunities for Watershed to increase revenue and maximize profits, while managing any new risks; (4) Create a Tableau dashboard to show Watershed executives the results of a sensitivity analysis; and (5) Articulate a significant and innovative business process change for Watershed based on your data analysis, that you will recommend to company executives. 

Airbnb, our Capstone’s official Sponsor, provided input on the project design. The top 10 Capstone completers each year will have the opportunity to present their work directly to senior data scientists at Airbnb live for feedback and discussion.

""Note: Only learners who have passed the four previous courses in the specialization are eligible to take the Capstone.""",13812.0,8617.0,4.7,238.0
Indices de base de données expliqués,https://www.coursera.org/learn/indices-de-base-de-donnees-expliques,Data Science,Data Analysis,Hodroj Jamal,"Dans ce projet guidé d'une heure, vous apprendrez les Indices de base de données, qui fait référence à un type spécial de structure de données qui accélère la récupération des enregistrements d'une table de base de données.
A la fin de ce cours nous aurons appris à créer et exploiter l’index.",,,,
Inferential Statistical Analysis with Python,https://www.coursera.org/learn/inferential-statistical-analysis-python,Data Science,Data Analysis,"Brenda Gunderson, Brady T. West, Kerby Shedden","In this course, we will explore basic principles behind using data for estimation and for assessing theories. We will analyze both categorical data and quantitative data, starting with one population techniques and expanding to handle comparisons of two populations. We will learn how to construct confidence intervals. We will also use sample data to assess whether or not a theory about the value of a parameter is consistent with the data. A major focus will be on interpreting inferential results appropriately.  

At the end of each week, learners will apply what they’ve learned using Python within the course environment. During these lab-based sessions, learners will work through tutorials focusing on specific case studies to help solidify the week’s statistical concepts, which will include further deep dives into Python libraries including Statsmodels, Pandas, and Seaborn. This course utilizes the Jupyter Notebook environment within Coursera.",36127.0,46457.0,4.6,825.0
Inferential Statistics,https://www.coursera.org/learn/inferential-statistics-intro,Data Science,Probability and Statistics,Mine Çetinkaya-Rundel,"This course covers commonly used statistical inference methods for numerical and categorical data. You will learn how to set up and perform hypothesis tests, interpret p-values, and report the results of your analysis in a way that is interpretable for clients or the public. Using numerous data examples, you will learn to report estimates of quantities in a way that expresses the uncertainty of the quantity of interest. You will be guided through installing and using R and RStudio (free statistical software), and will use this software for lab exercises and a final project. The course introduces practical tools for performing data analysis and explores the fundamental concepts necessary to interpret and report results for both categorical and numerical data",104240.0,120707.0,4.8,2505.0
Inferential Statistics,https://www.coursera.org/learn/inferential-statistics,Data Science,Probability and Statistics,"Annemarie Zand Scholten, Emiel van Loon","Inferential statistics are concerned with making inferences based on relations found in the sample, to relations in the population. Inferential statistics help us decide, for example, whether the differences between groups that we see in our data are strong enough to provide support for our hypothesis that group differences exist in general, in the entire population.

We will start by considering the basic principles of significance testing: the sampling and test statistic distribution, p-value, significance level, power and type I and type II errors. Then we will consider a large number of statistical tests and techniques that help us make inferences for different types of data and different types of research designs. For each individual statistical test we will consider how it works, for what data and design it is appropriate and how results should be interpreted. You will also learn how to perform these tests using freely available software. 

For those who are already familiar with statistical testing: We will look at z-tests for 1 and 2 proportions,  McNemar's test for dependent proportions, t-tests for 1 mean (paired differences) and 2 means, the Chi-square test for independence, Fisher’s exact test, simple regression (linear and exponential) and multiple regression (linear and logistic), one way and factorial analysis of variance, and non-parametric tests (Wilcoxon, Kruskal-Wallis, sign test,  signed-rank test, runs test).",59478.0,20195.0,4.3,564.0
Inferenzstatistik,https://www.coursera.org/learn/inferential-statistics-intro-de,Data Science,Probability and Statistics,Mine Çetinkaya-Rundel,"This course covers commonly used statistical inference methods for numerical and categorical data. You will learn how to set up and perform hypothesis tests, interpret p-values, and report the results of your analysis in a way that is interpretable for clients or the public. Using numerous data examples, you will learn to report estimates of quantities in a way that expresses the uncertainty of the quantity of interest. You will be guided through installing and using R and RStudio (free statistical software), and will use this software for lab exercises and a final project. The course introduces practical tools for performing data analysis and explores the fundamental concepts necessary to interpret and report results for both categorical and numerical data",,,,
Information Visualization: Advanced Techniques,https://www.coursera.org/learn/information-visualization-advanced-techniques,Data Science,Data Analysis,"Enrico Bertini , Cristian Felix ","This course aims to introduce learners to advanced visualization techniques beyond the basic charts covered in Information Visualization: Fundamentals. These techniques are organized around data types to cover advance methods for: temporal and spatial data, networks and trees and textual data. In this module we also teach learners how to develop innovative techniques in D3.js.

Learning Goals
Goal: Analyze the design space of visualization solutions for various kinds of data visualization problems. Learn what designs are available for a given problem and what are their respective advantages and disadvantages.
- Temporal
- Spatial
- Spatio-Temporal
- Networks
- Trees
- Text

This is the fourth course in the Information Visualization Specialization. The course expects you to have some basic knowledge of programming as well as some basic visualization skills (as those introduced in the first course of the specialization).",3865.0,5192.0,4.8,32.0
Information Visualization: Applied Perception,https://www.coursera.org/learn/information-visualization-applied-perception,Data Science,Data Analysis,"Enrico Bertini , Cristian Felix ",This module aims at introducing fundamental concepts of visual perception applied to information visualization. These concepts help the student ideate and evaluate visualization designs in terms of how well they leverage the capabilities of the human perceptual machinery.,4354.0,4040.0,4.7,136.0
Iniciación A La IA con IBM Watson,https://www.coursera.org/learn/aprenda-ia-con-ibm-watson,Data Science,Machine Learning,Rav Ahuja,"En este curso aprenderá cómo comenzar rápida y fácilmente con la Inteligencia Artificial utilizando IBM Watson. Comprenderá cómo funciona Watson, se familiarizará con sus casos de uso y ejemplos de clientes de la vida real, y se le presentarán varios de los servicios de inteligencia artificial de Watson de IBM que permiten a cualquiera aplicar fácilmente la inteligencia artificial y crear aplicaciones inteligentes. También trabajará con varios servicios de Watson para demostrar la IA en acción.

Este curso no requiere ninguna experiencia en programación o ciencias de la computación y está diseñado para cualquier persona, ya sea que tenga una formación técnica o no.

Esta es una traducción al español de un curso que se creó originalmente en inglés. Muchos de los componentes del curso se han traducido al español, incluidos títulos de lecciones, transcripciones de videos, lecturas, instrucciones de laboratorio y cuestionarios. Sin embargo, algunos componentes del curso, incluidos los videos originales y su narración, todavía están en inglés.",1605.0,8384.0,4.8,94.0
Integración y preparación de datos,https://www.coursera.org/learn/integracion-y-preparacion-de-datos,Data Science,Data Analysis,"Maria Del Pilar Villamil Giraldo, John Calvo Martínez","El manejo de datos que permita generar conocimiento útil para una organización es cada vez más importante en los trabajos de alta demanda al día de hoy. Es así como este curso presenta al estudiante una metodología para el desarrollo de proyectos basados en datos, en especial de ciencia de datos. Hace énfasis en los procesos de exploración, transformación, integración de fuentes de datos estructuradas y no estructuradas con el fin de mejorar la eficiencia y calidad en los resultados de análisis posteriores como los basados en modelos analíticos. El estudiante tendrá a su disposición diferentes tutoriales con ejemplos en contextos cercanos a la realidad para comprender mejor los conceptos desarrollados en el curso y practicar su aprendizaje con el punto de extensión propuesto en cada tutorial. De igual manera, contará con videos, lecturas ilustradas y sugerencias de lecturas para profundizar en los temas de interés. Consideramos que esto le permitirá al estudiante afianzar sus conocimientos llevando a la práctica lo aprendido.",,5711.0,,
Integrating BigQuery ML with Dialogflow ES Chatbot,https://www.coursera.org/learn/googlecloud-integrating-bigquery-ml-with-dialogflow-es-chatbot-ha8yo,Data Science,Machine Learning,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Inteligencia Artificial en Power BI,https://www.coursera.org/learn/inteligencia-artificial-powerbi,Data Science,Data Analysis,Leire Ahedo,Este proyecto es un curso práctico y efectivo para aprender todas las funcionalidades de Inteligencia Artificial de Power BI. No solo te permitirá conocer y aprender a utilizar los elementos visuales de IA propios de Power BI Desktop. Si no que además podrás aprender a integrar módulos avanzados de IA con Python y Pycaret,2044.0,,4.8,48.0
Interactive Geospatial Visualization:Kepler GL & Jupyter Lab,https://www.coursera.org/learn/geospatial-keplergl-jupyter,Data Science,Data Analysis,Abdishakur Hassan,"In this 1-hour long project-based course, you will learn how to easily create beautiful data visualization with Kepler inside Jupyter Notebooks and effectively design different geospatial data visualizations.",2944.0,,,
Interactive Machine Learning Dashboards using Plotly Dash,https://www.coursera.org/learn/interactive-dashboards-plotly-dash,Data Science,Machine Learning,Ari Anastassiou,"In this 2 hour long project-based course, you will learn how to create an HTML outline of a Plotly Dash dashboard. You will design interactive dropdown lists, radio buttons, and most importantly, scatter plots and bar charts that respond to your mouse's hover. You will learn how to visualize dimensionality reduction results intuitively and interactively, and see how these models can be used in Customer Segmentation. Furthermore, we will discuss how to critically evaluate these models, and what to look out for in a well-performing model.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,25.0
Interactive Statistical Data Visualization 101,https://www.coursera.org/learn/statistical-data-visualization,Data Science,Data Analysis,Ryan Ahmed,"In this guided project, we will explore plotly express to visualize statistical plots such as box plots, histograms, heatmaps, density maps, contour plots, and violin plots. Plotly express is a super powerful Python package that empowers anyone to create, manipulate and render graphical figures. This crash course is super practical and directly applicable to many industries such as banking, finance and tech industries.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Interactive Word Embeddings using Word2Vec and Plotly,https://www.coursera.org/learn/interactive-word2vec,Data Science,Machine Learning,Ari Anastassiou,"In this 2 hour long project, you will learn how to preprocess a text dataset comprising recipes. You will learn how to use natural language processing techniques to generate word embeddings for these ingredients, using Word2Vec. These word embeddings can be used for recommendations in an online store based on added items in a basket, or to suggest alternative items as replacements when stock is limited. You will build this recommendation/discovery feature in an interactive and aesthetic visualization tool.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,39.0
Interpretable Machine Learning Applications: Part 1,https://www.coursera.org/learn/interpretable-machine-learning-applications-part-1,Data Science,Machine Learning,Epaminondas Kapetanios,"In this 1-hour long project-based course, you will learn how to create interpretable machine learning applications on the example of two classification regression models, decision tree and random forestc classifiers. You will also learn how to explain such prediction models by extracting the most important features and their values, which mostly impact these prediction models. In this sense, the project will boost your career as Machine Learning (ML) developer and modeler in that you will be able to get a deeper insight into the behaviour of your ML model. The project will also benefit your career as a decision maker in an executive position, or consultant, interested in deploying trusted and accountable ML applications.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.3,18.0
Interpretable Machine Learning Applications: Part 2,https://www.coursera.org/learn/interpretable-machine-learning-applications-part-2,Data Science,Machine Learning,Epaminondas Kapetanios,"By the end of this project, you will be able to develop intepretable machine learning applications explaining individual predictions rather than explaining the behavior of the prediction model as a whole. This will be done via the well known Local Interpretable Model-agnostic Explanations (LIME) as a machine learning interpretation and explanation model.  In particular, in this project, you will learn how to go beyond the development and use of machine learning (ML) models, such as regression classifiers, in that we add on explainability and interpretation aspects for individual predictions. 

In this sense, the project will boost your career as a ML developer and modeler in that you will be able to explain and justify the behaviour of your ML model. The project will also benefit your career as a decision-maker in an executive position interested in deploying trusted and accountable ML applications.

This guided project is primarily targeting data scientists and machine learning modelers, who wish to enhance their machine learning application development with explanation components for predictions being made. The guided project is also targeting executive planners within business companies and public organizations interested in using machine learning applications for automating, or informing, human decision making, not as a ‘black box’, but also gaining some insight into the behavior of a machine learning classifier.

Note: This guided project based course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Interpretable Machine Learning Applications: Part 4,https://www.coursera.org/learn/interpretable-machine-learning-applications-part-4,Data Science,Machine Learning,Epaminondas Kapetanios,"In this 1-hour long guided project, you will learn how to use the ""What-If"" Tool (WIT) in the context of training and testing machine learning prediction models. In particular, you will learn a) how to set up a machine learning application in Python by using interactive Python notebook(s) on Google's Colab(oratory) environment, a.k.a. ""zero configuration"" environment, b) import and prepare the data, c) train and test classifiers as prediction models, d) analyze the behavior of the trained prediction models by using WIT for specific data points (individual basis), e)  moving on to the analysis of the behavior of the trained prediction models by using WIT global basis, i.e., all test data considered.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Interpretable machine learning applications: Part 3,https://www.coursera.org/learn/interpretable-machine-learning-applications-part-3,Data Science,Machine Learning,Epaminondas Kapetanios,"In this 50 minutes long project-based course, you will learn how to apply a specific explanation technique and algorithm for predictions (classifications) being made by inherently complex machine learning  models such as artificial neural networks.  The explanation technique and algorithm is based on the retrieval of similar cases with those individuals for which we wish to provide explanations. Since this explanation technique is model agnostic and treats the predictions model as a 'black-box', the guided project can be useful for decision makers within business environments, e.g., loan officers at a bank, and public organizations interested in using trusted machine learning applications for automating, or informing, decision making processes. 

The main learning objectives are as follows:

Learning objective 1: You will be able to define, train and evaluate an artificial neural network (Sequential model) based classifier  by using keras as API for TensorFlow. The pediction model will be trained and tested with the HELOC dataset for approved and rejected mortgage applications.

Learning objective 2: You will be able to generate explanations based on similar profiles for a mortgage applicant predicted either as of ""Good"" or ""Bad"" risk performance.

Learning objective 3:  you will be able to generate contrastive explanations based on feature and pertinent negative values, i.e., what an applicant should change in order to turn a ""rejected"" application to an ""approved"" one.",,,,
Interpretable machine learning applications: Part 5,https://www.coursera.org/learn/interpretable-machine-learning-applications-part-5,Data Science,Data Analysis,Epaminondas Kapetanios,"You will be able to use the Aequitas Tool as a tool to measure and detect bias in the outcome of a machine learning prediction model. As a use case, we will be working with the dataset about recidivism, i.e., the likelihood for a former imprisoned person to commit another offence within the first two years, since release from prison. The guided project will be making use of the COMPAS dataset, which already includes predicted as well as actual outcomes. Given also that this technique is largely based on statistical descriptors for measuring bias and fairness, it is very independent from specific Machine Learning (ML) prediction models. In this sense, the project will boost your career not only as a Data Scientists or ML developer, but also as a policy and decision maker.",,,,
Interpreting Machine Learning datasets,https://www.coursera.org/learn/interpreting-ml,Data Science,Data Analysis,Muhammad Saad uddin,"In this 2-hour long project-based course, you will learn how to interpret the dataset for machine learning, how different features impact on a mode and how to evaluate them.",,,,
Interprofessional Healthcare Informatics,https://www.coursera.org/learn/health-informatics-professional,Data Science,Data Analysis,"Karen A. Monsen, PhD, RN, FAMIA, FNAP, FAAN","Interprofessional Healthcare Informatics is a graduate-level, hands-on interactive exploration of real informatics tools and techniques offered by the University of Minnesota and the University of Minnesota's National Center for Interprofessional Practice and Education. We will be incorporating technology-enabled educational innovations to bring the subject matter to life. Over the 10 modules, we will create a vital online learning community and a working healthcare informatics network. 

We will explore perspectives of clinicians like dentists, physical therapists, nurses, and physicians in all sorts of practice settings worldwide. Emerging technologies, telehealth, gaming, simulations, and eScience are just some of the topics that we will consider. 

Throughout the course, we’ll focus on creativity, controversy, and collaboration - as we collectively imagine and create the future within the rapidly evolving healthcare informatics milieu. All healthcare professionals and IT geeks are welcome!",30166.0,6038.0,4.4,292.0
"Intro to Analytic Thinking, Data Science, and Data Mining",https://www.coursera.org/learn/intro-analyticthinking-datascience-datamining,Data Science,Data Analysis,"Dursun Delen, Julie Pai","Welcome to Introduction to Analytic Thinking, Data Science, and Data Mining. In this course, we will begin with an exploration of the field and profession of data science with a focus on the skills and ethical considerations required when working with data. We will review the types of business problems data science can solve and discuss the application of the CRISP-DM process to data mining efforts. A brief overview of Descriptive, Predictive, and Prescriptive Analytics will be provided, and we will conclude the course with an exploratory activity to learn more about the tools and resources you might find in a data science toolkit.",4952.0,13886.0,4.1,92.0
Intro to TensorFlow em Português Brasileiro,https://www.coursera.org/learn/intro-tensorflow-br,Data Science,Machine Learning,Google Cloud Training,"O objetivo deste curso é aproveitar a flexibilidade e a facilidade de uso do TensorFlow 2.x e do Keras para criar, treinar e implantar modelos de machine learning.  Você aprenderá sobre a hierarquia da API TensorFlow 2.x e conhecerá os principais componentes do TensorFlow nos exercícios práticos.  Mostraremos como trabalhar com conjuntos de dados e colunas de atributos. Você aprenderá a projetar e criar um pipeline de entrada de dados do TensorFlow 2.x.  Você terá uma experiência prática com o carregamento de dados CSV, matrizes numpy, dados de texto e imagens usando o tf.Data.Dataset e com a criação de colunas de atributos numéricas, categóricas, em bucket e com hash.

Apresentaremos as APIs Keras Sequential e Keras Functional para mostrar como criar modelos de aprendizado profundo.  Abordaremos as funções de ativação, perda e otimização.  Nos laboratórios práticos dos notebooks do Jupyter, você poderá criar modelos de machine learning de regressão linear básica e de regressão logística básica e avançada.  Você aprenderá a treinar, implantar e produzir modelos de machine learning em escala com o AI Platform do Cloud.",,,4.6,23.0
Intro to TensorFlow en Español,https://www.coursera.org/learn/intro-tensorflow-es,Data Science,Machine Learning,Google Cloud Training,"Este curso se enfoca en aprovechar la flexibilidad y facilidad de uso de TensorFlow 2.x y Keras para compilar, entrenar e implementar modelos de aprendizaje automático.  Aprenderá sobre la jerarquía de la API de TensorFlow 2.x y conocerá los componentes principales de TensorFlow mediante ejercicios prácticos.  Le mostraremos cómo trabajar con conjuntos de datos y columnas de atributos. Aprenderá a diseñar y compilar una canalización de datos de entrada de TensorFlow 2.x.  Adquirirá experiencia práctica en la carga de arreglos de NumPy, imágenes y datos de texto con tf.data.Dataset, así como de datos de CSV con Pandas. También adquirirá experiencia práctica en la creación de columnas de atributos numéricas, categóricas, agrupadas en depósitos y con hash.

Además, le presentaremos las API secuencial y funcional de Keras para mostrarle cómo crear modelos de aprendizaje profundo.  Hablaremos sobre las funciones de activación, pérdida y optimización.  Nuestros labs prácticos sobre los notebooks de Jupyter le permitirán compilar modelos de aprendizaje automático de regresión lineal básica, y de regresión logística básica y avanzada.  Aprenderá a entrenar, implementar y llevar a producción modelos de aprendizaje automático a gran escala con AI Platform de Cloud.",3702.0,1594.0,4.4,124.0
Intro to TensorFlow en Français,https://www.coursera.org/learn/intro-tensorflow-fr,Data Science,Machine Learning,Google Cloud Training,"Ce cours va vous expliquer comment exploiter la flexibilité et la facilité d'utilisation de TensorFlow 2.x et de Keras pour créer, entraîner et déployer des modèles de machine learning.  Vous en apprendrez plus sur la hiérarchie de l'API TensorFlow 2.x et découvrirez les principaux composants de TensorFlow à travers divers exercices pratiques.  Nous allons vous montrer comment travailler avec des ensembles de données et des colonnes de caractéristiques. Vous apprendrez à concevoir et à créer un pipeline de données d'entrée TensorFlow 2.x.  À l'aide d'exercices pratiques, vous vous entraînerez à charger des données CSV, des tableaux Numpy, des données de texte et des images à l'aide de tf.Data.Dataset. Vous vous entraînerez également à créer des colonnes de caractéristiques numériques, catégorielles, en buckets et hachées.

Nous vous présenterons l'API séquentielle Keras et l'API fonctionnelle Keras pour vous montrer comment créer des modèles de deep learning.  Nous aborderons les fonctions d'activation, la perte et l'optimisation.  Nos ateliers pratiques sur les notebooks Jupyter vous permettent de créer des modèles de machine learning à régression linéaire basique, à régression logistique basique et à régression logistique avancée.  Vous apprendrez à entraîner, à déployer et à mettre en production des modèles de machine learning à grande échelle avec Cloud AI Platform.",,,,
Intro to TensorFlow 日本語版,https://www.coursera.org/learn/intro-tensorflow-jp,Data Science,Machine Learning,Google Cloud Training,"このコースの目的は、柔軟で手軽な TensorFlow 2.x と Keras を使用して、機械学習モデルを作成、トレーニング、およびデプロイすることです。TensorFlow 2.x API の階層について学び、TensorFlow の主要コンポーネントを実践演習で理解します。データセットと特徴列の扱い方について学びます。TensorFlow 2.x 入力データ パイプラインの設計と作成の方法について学びます。tf.data.Dataset を使用して csv データ、NumPy 配列、テキストデータ、および画像を読み込む実践演習を行います。数値、カテゴリ、バケット、およびハッシュの特徴列を作成する実践演習も行います。

Keras Sequential API と Keras Functional API を使用してディープ ラーニング モデルを作成する方法を学びます。活性化関数、損失、および最適化について学びます。Jupyter ノートブックの実践演習では、基本的な線形回帰、基本的なロジスティック回帰、および高度なロジスティック回帰の機械学習モデルを作成できます。Cloud AI Platform での大規模な機械学習モデルのトレーニング、デプロイ、および本稼働の方法について学びます。",,,3.8,12.0
Intro to Time Series Analysis in R,https://www.coursera.org/learn/intro-time-series-analysis-in-r,Data Science,Probability and Statistics,Vinod Bakthavachalam,"In this 2 hour long project-based course, you will learn the basics of time series analysis in R. By the end of this project, you will understand the essential theory for time series analysis and have built each of the major model types (Autoregressive, Moving Average, ARMA, ARIMA, and decomposition) on a real world data set to forecast the future. We will go over the essential packages and functions in R as well to make time series analysis easy.",6416.0,,4.4,239.0
Introducción a Azure Data Factory para Big Data,https://www.coursera.org/learn/introduccion-azure-data-factory-big-data,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a utilizar la herramienta de Azure Data Factory desde cero. Aprenderás, de manera practica y efectiva a generar pipelines en Data Factory y a utilizar los recursos necesarios de Azure.",,,4.5,17.0
Introducción a Data Science: Programación Estadística con R,https://www.coursera.org/learn/intro-data-science-programacion-estadistica-r,Data Science,Data Analysis,Carlos Ernesto López Natarén,"Este curso te proporcionará las bases del lenguaje de programación estadística R, la lengua franca de la estadística, el cual te permitirá escribir programas que lean, manipulen y analicen datos cuantitativos. Te explicaremos la instalación del lenguaje; también verás una introducción a los sistemas base de gráficos y al paquete para graficar ggplot2, para visualizar estos datos. Además también abordarás la utilización de uno de los IDEs más populares entre la comunidad de usuarios de R, llamado RStudio.

Objetivo

Al término del curso:

Utilizarás el lenguaje de programación R con el fin de manipular datos, generar análisis estadísticos y representación gráfica, a través del procesamiento de datos cuantitativos.

Forma de trabajo

Este curso busca introducirte en el lenguaje de programación estadística R, un lenguaje computacional diseñado para el análisis estadístico de datos. Este curso está dirigido a estudiantes y profesionales que tienen interés en poder utilizar esta herramienta, para leer, manipular, analizar y graficar datos. 

Utilizarás un IDE (Ambiente de Desarrollo Integrado) muy popular para trabajar con el lenguaje R, llamado RStudio, que se ha vuelto el IDE de facto para programar en R.

En cada módulo encontrarás videos que te guiarán en la instalación de las herramientas a utilizar, así como explicaciones de las operaciones básicas y los elementos específicos que ofrecen un manejo más profundo del lenguaje. También hallarás algunas referencias bibliográficas para ahondar en el tema que sea de tu interés.

Para complementar las lecciones, realizarás prácticas con el lenguaje, las cuales tendrán valor para la evaluación.",202063.0,62340.0,4.7,7725.0
Introducción a La Inteligencia Artificial (IA),https://www.coursera.org/learn/introduccion-a-la-inteligencia-artificial,Data Science,Machine Learning,Rav Ahuja,"En este curso aprenderá qué es la Inteligencia Artificial (IA), explorará casos de uso y aplicaciones de IA, comprenderá conceptos y términos de IA como aprendizaje automático, aprendizaje profundo y redes neuronales. Estará expuesto a varios problemas y preocupaciones relacionados con la IA, como la ética y el sesgo, y los trabajos, y recibirá consejos de expertos sobre cómo aprender y comenzar una carrera en IA. También demostrará AI en acción con un mini proyecto.

Este curso no requiere ninguna experiencia en programación o ciencias de la computación y está diseñado para presentar los conceptos básicos de inteligencia artificial a cualquier persona, ya sea que tenga una formación técnica o no.

Esta es una traducción al español de un curso que se creó originalmente en inglés. Muchos de los componentes del curso se han traducido al español, incluidos títulos de lecciones, transcripciones de videos, lecturas, instrucciones de laboratorio y cuestionarios. Sin embargo, algunos componentes del curso, incluidos los videos originales y su narración, todavía están en inglés.",6713.0,25653.0,4.7,163.0
Introducción a la ciencia de datos aplicada,https://www.coursera.org/learn/introduccion-ciencia-de-datos-aplicada,Data Science,Data Analysis,"John Calvo Martínez, Harry Cristhian Torres Moreno ","Este curso es una primera inmersión en el mundo de la ciencia de datos, en el cual el estudiante comprenderá los fundamentos de la ciencia de datos, las características de un científico de datos, las herramientas que utiliza, la metodología que se debe seguir para este estilo de proyectos, y estará en capacidad de aplicar técnicas estadísticas para la construcción e interpretación de modelos analíticos descriptivos. 

El curso consta de 4 módulos, cada uno de una semana, en los cuales al final del mismo, se tiene una lección dedicada al desarrollo del proyecto del curso. Los módulos son:  

Módulo 1. La ciencia de datos y los científicos de datos: En este módulo, se presenta los aspectos fundamentales de la ciencia de datos, la metodología ASUM-DM para la implementación de estos proyectos y la metodología design thinking para identificar problemas y oportunidades de negocio. 

Módulo 2. Análisis exploratorio de datos: En este módulo, se presenta los conceptos asociados a estadística descriptiva y exploratoria univariada, y una ejemplificación de estos mediante el uso de la herramienta Jupyter Notebook, los cuales son utilizados para validar hipótesis de negocio. 

Módulo 3. Modelos analíticos basados en estadística bivariada:  En este módulo, se presenta los conceptos asociados a pruebas de correlación y análisis de tablas de contingencia, y una ejemplificación de estos mediante el uso de la herramienta Jupyter Notebook, los cuales son utilizados para validar hipótesis de negocio. 

Módulo 4. Comparaciones entre grupos y validación de modelos estadísticos: En este módulo, se presenta los conceptos asociados a ANOVAS a una y dos vías, y una ejemplificación de estos mediante el uso de la herramienta Jupyter Notebook, los cuales son utilizados para validar hipótesis de negocio. 

Este curso está pensado para personas de diferentes disciplinas que quieran adentrarse en el mundo de la ciencia de datos, que estén iniciando estudios universitarios o con títulos de técnicos o tecnológicos, así mismo, se recomienda tener un background de conocimientos básicos en probabilidad y estadística. El aspirante a tomar este curso puede provenir de cualquier campo del conocimiento ya sea de gobierno, la industria, la consultoría, la academia, etc. 

Para el desarrollo de este curso, es necesario la instalación de un programa especial (Anaconda – Jupyter Notebook) con el fin de poder realizar los análisis de los datos a través del lenguaje de programación Python, es recomendable que el equipo cuente con más de 4GB de RAM y espacio en disco duro superior a 1GB.",2348.0,17212.0,4.7,45.0
Introducción a la inteligencia artificial contemporánea,https://www.coursera.org/learn/introduccion-a-la-inteligencia-artificial-contemporanea,Data Science,Data Analysis,"Pablo Andrés Arbeláez Escalante, Nicolás Cardozo, Rubén Francisco Manrique, Nicanor Quijano Silva, Olga Mariño Drews, Andrés Páez Peñuela, María Lorena Flórez Rojas, Fredy Enrique Segura Quijano","La inteligencia artificial (IA) es un área del conocimiento enfocada en el diseño de componentes de hardware y software que emulen el comportamiento y pensamiento humano en la realización de tareas y toma de decisiones. Su objetivo es desarrollar capacidades computacionales que puedan resolver tareas previamente consideradas como exclusivas de la inteligencia humana. La IA ha sido especialmente útil para modelar y resolver problemas de alta complejidad que requieren del análisis de grandes volúmenes de datos y con un alto grado de incertidumbre. Por esta razón, en los últimos años, la investigación y áreas de aplicación de la IA han aumentado considerablemente, convirtiéndose en una parte esencial para el avance tecnológico y la transformación digital en la academia, la industria y los sectores empresariales.  

Este curso te permitirá comprender el concepto de inteligencia artificial, identificar los avances actuales y retos futuros en este campo y analizar las implicaciones éticas del despliegue de sistemas de IA en el mundo contemporáneo. En particular, podrás examinar los paradigmas más importantes de aprendizaje de máquinas y algunas aplicaciones claves de la inteligencia artificial en seis diferentes áreas del conocimiento: visión por computador, procesamiento de lenguaje natural, representación del conocimiento, sistemas embebidos, sistemas de control y aprendizaje por refuerzo.  

Este curso incluye videos de presentación y explicación de los temas, entrevistas con expertos en el área de la IA, actividades de aprendizaje y evaluación, lecturas, foros de reflexión, actividades de programación, etc. Todos estos elementos te llevarán por una ruta de aprendizaje que se ha diseñado para que comprendas los principales conceptos de la IA y logres ver su aplicación en cada una de las áreas con ejemplos de aplicación en la vida real.",,14716.0,,
Introducción a los Data Lakes con Azure,https://www.coursera.org/learn/data-lakes-azure,Data Science,Data Analysis,Nestor Nicolas Campos Rojas,"En este proyecto de 1 hora, aprenderás a usar la tecnología de Azure Data Lake Gen2, entender la diferencia con los otros servicios, gestionar los sistemas de archivos y manejar el ciclo de vida de la información para facilitar la gestión automática y eliminación de los datos según regulaciones.

Además, podrás entender cuáles aplicaciones se integran nativamente a Azure Data Lake Gen2.",,,4.8,12.0
Introducción a los algoritmos de regresión,https://www.coursera.org/learn/introduccion-algoritmos-regresion,Data Science,Data Analysis,Nestor Nicolas Campos Rojas,"Al completar este proyecto de 1 hora de duración, entenderás y podrás desarrollar tus propios modelos de regresión (lineal y logístico) a partir de un conjunto de datos definidos, y optimizar los algoritmos de forma automática para encontrar los mejores parámetros para tus modelos.
También podrás entender los pasos necesarios antes de diseñar tus modelos, como analizar tus datos y hacer limpiezas de acuerdo a los tipos de datos y caso de uso.",,,4.5,38.0
Introducción al Análisis de Datos,https://www.coursera.org/learn/introduction-al-analisis-de-datos,Data Science,Data Analysis,Rav Ahuja,"Este curso presenta una gentil introducción a los conceptos del análisis de datos, el rol de un Analista de Datos y las herramientas que se utilizan para realizar las funciones diarias. Obtendrás una comprensión del ecosistema de datos y de los fundamentos del análisis de datos, como la recopilación de datos o la minería de datos. También aprenderás las aptitudes generales que se requieren para comunicar eficazmente tus datos a los interesados y cómo el dominio de estas aptitudes puede darte la opción de convertirte en un tomador de decisiones impulsado por los datos.

Este curso te ayudará a diferenciar entre los roles de trabajo de un Analista de Datos, un Científico de Datos y un Ingeniero de Datos. Aprenderás las responsabilidades de un Analista de Datos y exactamente lo que implica el análisis de datos. Serás capaz de resumir el ecosistema de datos, como las bases de datos y los almacenes de datos. Luego descubrirás los principales proveedores dentro del ecosistema de datos y explorarás las diversas herramientas en las instalaciones y en la nube. Continúa este emocionante viaje y descubre las plataformas de Grandes Volúmenes de Datos como Hadoop, Hive y Spark. Al final de este curso podrás visualizar la vida diaria de una Analista de Datos, entender las diferentes carreras que están disponibles para el análisis de datos e identificar los muchos recursos disponibles para manejar esta profesión.

     A lo largo de este curso aprenderás los aspectos claves del análisis de datos. Empezarás a explorar los fundamentos de la recopilación de datos, y aprenderás a identificar tus fuentes de datos. Luego aprenderás a limpiar, analizar y compartir tus datos con el uso de visualizaciones y herramientas de paneles de datos. Todo esto se combina en el proyecto final donde se pondrán a prueba tus conocimientos del material del curso, explorarás lo que significa ser un Analista de Datos y te proporcionará un escenario del mundo real del análisis de datos.

     Este curso no requiere ningún tipo experiencia de análisis de datos, hojas de cálculo o ciencia de la computación. Todo lo que necesitas para comenzar es un conocimiento básico de computación, matemáticas de secundaria y acceso a un navegador web moderno como Chrome o Firefox.",8536.0,106155.0,4.7,226.0
Introducción al Aprendizaje Profundo,https://www.coursera.org/learn/introduccion-al-aprendizaje-profundo,Data Science,Data Analysis,"Rafael Crescenzi, Pablo Alejandro Albani","Este curso te brindará los conocimientos introductorios sobre Aprendizaje Profundo, vas a entender

los fundamentos teóricos y su implementación . Se comenzará entendiendo cómo evolucionó el
campo hasta llegar a las redes profundas y cuáles son sus principales beneficios frente a otras
técnicas de aprendizaje supervisado, así como también sus limitaciones y situaciones en donde no
posee un rendimiento superior",1881.0,1509.0,,
Introducción al Deep Learning,https://www.coursera.org/learn/introduccion-deep-learning,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender los fundamentos del Deep Learning con ejercicios aplicados. Aprenderemos desde cero los fundamentos del Deep Learning, de la librería Keras y a como programar una red neuronal. Todo ello con proyectos prácticos que nos permitirán consolidar los conocimientos.

Gracias a este curso aprenderemos a programar diferentes redes neuronales para predecir el precio de venta de una vivienda o si un cliente alquilará una bicicleta.",,,,
Introducción al procesamiento de lenguaje natural,https://www.coursera.org/learn/introduccion-al-procesamiento-de-lenguaje-natural,Data Science,Machine Learning,Hernán Daniel Merlino,"Este curso te brindará los conocimientos introductorios sobre el procesamiento de lenguaje natural y las diversas tareas relacionadas al pre procesamiento de grandes volúmenes de texto.

Te encontrarás con situaciones cotidianas que se enfrentan al trabajar con proyectos de NLP, para poder poner en juego todo lo aprendido.

Para desarrollar aplicaciones se va a utilizar Pyhon 3.6 o superior. Alternativamente se puede utilizar el entorno de Anaconda con la misma versión de Python.
Como editor de código, los ejemplos van a ser editados en el Notebook de Anaconda, pero el alumno puede utilizar cualquier editor de texto que reconozca notebooks de Anaconda.
Librerías que es necesario tener instaladas para realizar el curso: NLTK, Pandas, SCIKIT-learn.",2143.0,2009.0,4.4,15.0
Introduction A L’HTML,https://www.coursera.org/learn/introduction-a-l-html,Data Science,Machine Learning,Mirna Saad,"Dans ce cours d'une heure, basé sur un projet vous apprendrez la définition de l'HTML, ses éléments et la structure de la page HTML. 
A la fin de ce projet, vous serez capable d'utiliser les éléments HTML ,de comprendre la structure de la page HTML et d'écrire un simple document HTML.",,,,
Introduction to Accounting Data Analytics and Visualization,https://www.coursera.org/learn/intro-accounting-data-analytics-visual,Data Science,Data Analysis,Ronald Guymon,"Accounting has always been about analytical thinking. From the earliest days of the profession, Luca Pacioli emphasized the importance of math and order for analyzing business transactions. The skillset that accountants have needed to perform math and to keep order has evolved from pencil and paper, to typewriters and calculators, then to spreadsheets and accounting software. A new skillset that is becoming more important for nearly every aspect of business is that of big data analytics: analyzing large amounts of data to find actionable insights. This course is designed to help accounting students develop an analytical mindset and prepare them to use data analytic programming languages like Python and R.

We’ve divided the course into three main sections. In the first section, we bridge accountancy to analytics. We identify how tasks in the five major subdomains of accounting (i.e., financial, managerial, audit, tax, and systems) have historically required an analytical mindset, and we then explore how those tasks can be  completed more effectively and efficiently by using big data analytics. We then present a FACT framework for guiding big data analytics: Frame a question, Assemble data, Calculate the data, and Tell others about the results.
 
In the second section of the course, we emphasize the importance of assembling data. Using financial statement data, we explain desirable characteristics of both data and datasets that will lead to effective calculations and visualizations.
 
In the third, and largest section of the course, we demonstrate and explore how Excel and Tableau can be used to analyze big data. We describe visual perception principles and then apply those principles to create effective visualizations. We then examine fundamental data analytic tools, such as regression, linear programming (using Excel Solver), and clustering in the context of point of sale data and loan data. We conclude by demonstrating the power of data analytic programming languages to assemble, visualize, and analyze data. We introduce Visual Basic for Applications  as an example of a programming language, and the Visual Basic Editor as an example of an integrated development environment (IDE).",22262.0,38985.0,4.8,394.0
Introduction to Advance Features in Rasa Chatbot Framework 2,https://www.coursera.org/learn/advanced-features-in-chatbot-rasa-framework-2,Data Science,Machine Learning,Mohammed Murtuza Qureshi,"In this 1-hour long project-based course, you will learn how to add advanced features to your Rasa Chatbot. We will look at what's Rasa X, a tool for developing your chatbot. We will look at how we can use Rasa X to interactively train your chatbot and share it with others. We will then look at how to create Forms to collect information for a certain task from the users. 

We will look at how to validate inputs received by the Form and look at dynamic and conditional slot mapping. We will then move on to look at what are retrieval intents and how they can be used to handle small talk. Finally we will cover how to add Fallback Actions to handle failures in case the is not confident about the users message. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Introduction to Applied Machine Learning,https://www.coursera.org/learn/machine-learning-applied,Data Science,Machine Learning,Anna Koop,"This course is for professionals who have heard the buzz around machine learning and want to apply machine learning to data analysis and automation. Whether finance, medicine, engineering, business or other domains, this course will introduce you to problem definition and data preparation in a machine learning project.

By the end of the course, you will be able to clearly define a machine learning problem using two approaches. You will learn to survey available data resources and identify potential ML applications. You will learn to take a business need and turn it into a machine learning application. You will prepare data for effective machine learning applications.

This is the first course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute.",21591.0,7996.0,4.7,702.0
Introduction to Artificial Intelligence (AI),https://www.coursera.org/learn/introduction-to-ai,Data Science,Machine Learning,Rav Ahuja,"In this course you will learn what Artificial Intelligence (AI) is, explore use cases and applications of AI, understand AI concepts and terms like machine learning, deep learning and neural networks. You will be exposed to various issues and concerns surrounding AI such as ethics and bias, & jobs, and get advice from experts about learning and starting a career in AI.  You will also demonstrate AI in action with a mini project.

This course does not require any programming or computer science expertise and is designed to introduce the basics of AI to anyone whether you have a technical background or not.",183537.0,268703.0,4.7,10089.0
Introduction to Bayesian Statistics,https://www.coursera.org/learn/compstatsintro,Data Science,Probability and Statistics,Dr. Srijith Rajamohan,"The objective of this course is to introduce Computational Statistics to aspiring or new data scientists. The attendees will start off by learning the basics of probability, Bayesian modeling and inference. This will be the first course in a specialization of three courses .Python and Jupyter notebooks will be used throughout this course to illustrate and perform Bayesian modeling. The course website is located at https://sjster.github.io/introduction_to_computational_statistics/docs/index.html. The course notebooks can be downloaded from this website by following the instructions on page https://sjster.github.io/introduction_to_computational_statistics/docs/getting_started.html.

The instructors for this course will be Dr. Srijith Rajamohan and Dr. Robert Settlage.",2767.0,5213.0,3.4,29.0
Introduction to Big Data,https://www.coursera.org/learn/big-data-introduction,Data Science,Data Analysis,"Ilkay Altintas, Amarnath Gupta","Interested in increasing your knowledge of the Big Data landscape?  This course is for those new to data science and interested in understanding why the Big Data Era has come to be.  It is for those who want to become conversant with the terminology and the core concepts behind big data problems, applications, and systems.  It is for those who want to start thinking about how Big Data might be useful in their business or career.  It provides an introduction to one of the most common frameworks, Hadoop, that has made big data analysis easier and more accessible -- increasing the potential for data to transform our world!

At the end of this course, you will be able to:

* Describe the Big Data landscape including examples of real world big data problems including the three key sources of Big Data: people, organizations, and sensors. 

* Explain the V’s of Big Data (volume, velocity, variety, veracity, valence, and value) and why each impacts data collection, monitoring, storage, analysis and reporting.

* Get value out of Big Data by using a 5-step process to structure your analysis. 

* Identify what are and what are not big data problems and be able to recast big data problems as data science questions.

* Provide an explanation of the architectural components and programming models used for scalable big data analysis.

* Summarize the features and value of core Hadoop stack components including the YARN resource and job management system, the HDFS file system and the MapReduce programming model.

* Install and run a program using Hadoop!

This course is for those new to data science.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  

Hardware Requirements:
(A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size.  

Software Requirements:
This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge. Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.",292755.0,151239.0,4.6,10636.0
Introduction to Business Analysis Using Spreadsheets: Basics,https://www.coursera.org/learn/business-analysis-using-spreadsheets,Data Science,Data Analysis,Omnya Khaled,"In this 1-hour 30-mins long project-based course, you will learn the responsibilities of a Business Analyst such as Learn the basic concepts of data analysis and descriptive statistics. Learn how to manipulate, analyze, and visualize data in  Google Sheets using functions, aggregation functions, and logical aggregation functions. and present data using different types of charts.

This course works best for learners who wish to learn about Business Analysis and wish to learn about the role of a Business Analyst.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",26350.0,,4.3,563.0
Introduction to Clinical Data,https://www.coursera.org/learn/introduction-clinical-data,Data Science,Data Analysis,"Nigam Shah, Steven Bagley, David Magnus","This course introduces you to a framework for successful and ethical medical data mining. We will explore the variety of clinical data collected during the delivery of healthcare. You will learn to construct analysis-ready datasets and apply computational procedures to answer clinical questions. We will also explore issues of fairness and bias that may arise when we leverage healthcare data to make decisions about patient care.

The Stanford University School of Medicine is accredited by the Accreditation Council for Continuing Medical Education (ACCME) to provide continuing medical education for physicians.  Visit the FAQs below for important information regarding 1) Date of original release and Termination or expiration date; 2) Accreditation and Credit Designation statements; 3) Disclosure of financial relationships for every person in control of activity content.",10529.0,25847.0,4.6,182.0
Introduction to Clinical Data Science,https://www.coursera.org/learn/introduction-clinical-data-science,Data Science,Data Analysis,"Laura K. Wiley, PhD","This course will prepare you to complete all parts of the Clinical Data Science Specialization. In this course you will learn how clinical data are generated, the format of these data, and the ethical and legal restrictions on these data. You will also learn enough SQL and R programming skills to be able to complete the entire Specialization - even if you are a beginner programmer. While you are taking this course you will have access to an actual clinical data set and a free, online computational environment for data science hosted by our Industry Partner Google Cloud. 

At the end of this course you will be prepared to embark on your clinical data science education journey, learning how to take data created by the healthcare system and improve the health of tomorrow's patients.",15304.0,15546.0,4.6,354.0
Introduction to Computer Vision and Image Processing,https://www.coursera.org/learn/introduction-computer-vision-watson-opencv,Data Science,Machine Learning,"Aije Egwaikhide, Joseph Santarcangelo","Computer Vision is one of the most exciting fields in Machine Learning and AI. It has applications in many industries, such as self-driving cars, robotics, augmented reality, and much more. In this beginner-friendly course, you will understand computer vision and learn about its various applications across many industries.

As part of this course, you will utilize Python, Pillow, and OpenCV for basic image processing and perform image classification and object detection.

This is a hands-on course and involves several labs and exercises. Labs will combine Jupyter Labs and Computer Vision Learning Studio (CV Studio), a free learning tool for computer vision. CV Studio allows you to upload, train, and test your own custom image classifier and detection models.  At the end of the course, you will create your own computer vision web app and deploy it to the Cloud.

This course does not require any prior Machine Learning or Computer Vision experience. However, some knowledge of the Python programming language and high school math is necessary.",37395.0,101738.0,4.4,856.0
Introduction to Customer Segmentation in Python,https://www.coursera.org/learn/customer-segmentation-python,Data Science,Machine Learning,Ari Anastassiou,"In this 2 hour long project, you will learn how to approach a customer purchase dataset, and how to explore the intricacies of such a dataset. You will learn the basic underlying ideas behind Principal Component Analysis, Kernel Principal Component Analysis, and K-Means Clustering. You will learn how to leverage these concepts, paired with industry knowledge and auxiliary modeling concepts to segment the customers of a certain store, and find similarities and differences between different clusters using unsupervised machine learning techniques. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,22.0
Introduction to D3.js,https://www.coursera.org/learn/introduction-to-d3-js,Data Science,Data Analysis,Ahmad Varasteh,"This Guided Project, Introduction to D3.js is for those who want to learn about D3.js which is a JavaScript library for producing  SVG-based, dynamic, interactive data visualizations in web browsers. In this 2-hour-long project-based course, you will get to know different SVG elements, build SVG-based webpages using D3.js, Integrate data into the SVG elements, and build simple data visualizations using D3.js. This project is unique because you will learn to build simple SVG-based data representations from scratch using D3.js. You will also learn how to integrate JSON data into your D3 data visualization. To be successful in this project, you will need to have knowledge of HTML, CSS, and Javascript programming language and to be experienced working with Visual Studio Code IDE.",,,,
Introduction to Data Analysis Using Excel,https://www.coursera.org/learn/excel-data-analysis,Data Science,Data Analysis,Sharad Borle,"The use of Excel is widespread in the industry. It is a very powerful data analysis tool and almost all big and small businesses use Excel in their day to day functioning. This is an introductory course in the use of Excel and is designed to give you a working knowledge of Excel with the aim of getting to use it for more advance topics in Business Statistics later. The course is designed keeping in mind two kinds of learners -  those who have very little functional knowledge of Excel and those who use Excel regularly but at a peripheral level and wish to enhance their skills. The course takes you from basic operations such as reading data into excel using various data formats, organizing and manipulating data, to some of the more advanced functionality of Excel. All along, Excel functionality is introduced using easy to understand examples which are demonstrated in a way that learners can become comfortable in understanding and applying them.

To successfully complete course assignments, students must have access to a Windows version of Microsoft Excel 2010 or later. 
________________________________________
WEEK 1
Module 1: Introduction to Spreadsheets
In this module, you will be introduced to the use of Excel spreadsheets and various basic data functions of Excel.

Topics covered include:
•	Reading data into Excel using various formats
•	Basic functions in Excel, arithmetic as well as various logical functions
•	Formatting rows and columns
•	Using formulas in Excel and their copy and paste using absolute and relative referencing
________________________________________
WEEK 2
Module 2: Spreadsheet Functions to Organize Data
This module introduces various Excel functions to organize and query data. Learners are introduced to the IF, nested IF, VLOOKUP and the HLOOKUP functions of Excel. 

Topics covered include:
•	IF and the nested IF functions
•	VLOOKUP and HLOOKUP
•	The RANDBETWEEN function
________________________________________
WEEK 3
Module 3: Introduction to Filtering, Pivot Tables, and Charts
This module introduces various data filtering capabilities of Excel. You’ll learn how to set filters in data to selectively access data. A very powerful data summarizing tool, the Pivot Table, is also explained and we begin to introduce the charting feature of Excel.

Topics covered include:
•	VLOOKUP across worksheets
•	Data filtering in Excel
•	Use of Pivot tables with categorical as well as numerical data
•	Introduction to the charting capability of Excel
________________________________________
WEEK 4
Module 4: Advanced Graphing and Charting
This module explores various advanced graphing and charting techniques available in Excel. Starting with various line, bar and pie charts we introduce pivot charts, scatter plots and histograms. You will get to understand these various charts and get to build them on your own.

Topics covered include
•	Line, Bar and Pie charts
•	Pivot charts
•	Scatter plots
•	Histograms",232203.0,221856.0,4.7,9732.0
Introduction to Data Analytics,https://www.coursera.org/learn/introduction-to-data-analytics,Data Science,Data Analysis,Rav Ahuja,"This course presents a gentle introduction into the concepts of data analysis, the role of a Data Analyst, and the tools that are used to perform daily functions. You will gain an understanding of the data ecosystem and the fundamentals of data analysis, such as data gathering or data mining.  You will then learn the soft skills that are required to effectively communicate your data to stakeholders, and how mastering these skills can give you the option to become a data driven decision maker.

This course will help you to differentiate between the roles of a Data Analyst, Data Scientist, and Data Engineer. You will learn the responsibilities of a Data Analyst and exactly what data analysis entails. You will be able to summarize the data ecosystem, such as databases and data warehouses. You will then uncover the major vendors within the data ecosystem and explore the various tools on-premise and in the cloud. Continue this exciting journey and discover Big Data platforms such as Hadoop, Hive, and Spark. By the end of this course you will be able to visualize the daily life of a Data Analyst, understand the different career paths that are available for data analytics, and identify the many resources available for mastering this profession.

     Throughout this course you will learn the key aspects to data analysis. You will begin to explore the fundamentals of gathering data, and learning how to identify your data sources. You will then learn how to clean, analyze, and share your data with the use of visualizations and dashboard tools. This all comes together in the final project where it will test your knowledge of the course material, explore what it means to be a Data Analyst, and provide a real-world scenario of data analysis. 

     This course does not require any prior data analysis, spreadsheet, or computer science experience. All you need to get started is basic computer literacy, high school level math, and access to a modern web browser such as Chrome or Firefox.",237936.0,923743.0,4.8,9235.0
Introduction to Data Analytics for Accounting Professionals,https://www.coursera.org/learn/intro-to-data-analytics,Data Science,Data Analysis,AICPA ,"This course covers the foundations of data analytics and how to conduct and apply this to projects in your organization. This includes the following:

-	What does it mean to have a data-driven mindset? Having the right mindset will allow you to understand the problem that needs to be solved and make or recommend appropriate data-driven decisions in the context of the organization’s strategy and technologies.
-	What are the key considerations when identifying, establishing, and implementing a data analytics project? This course introduces and discusses important concepts and considerations, so you are ready to be effective no matter how your organization or industry changes. This includes everything from framing the problem and defining the scope, to understanding organizational requirements and gaps, to effectively working with key stakeholders. 
-	What is the required technical knowledge you need so that you can understand data? Whether the data you’re looking at is financial or non-financial data, structured or unstructured, you need to understand the language of data analytics so that you can communicate effectively with colleagues and add value when using data analytics in your organization.
By completing this course, you will be in a better position to ask the right questions, add greater value, and improve the quality of services to your stakeholders.",2284.0,15351.0,4.5,28.0
Introduction to Data Analytics for Business,https://www.coursera.org/learn/data-analytics-business,Data Science,Data Analysis,David Torgerson,"This course will expose you to the data analytics practices executed in the business world. We will explore such key areas as the analytical process, how data is created, stored, accessed, and how the organization works with data and creates the environment in which analytics can flourish.

What you learn in this course will give you a strong foundation in all the areas that support analytics and will help you to better position yourself for success within your organization. You’ll develop skills and a perspective that will make you more productive faster and allow you to become a valuable asset to your organization.

This course also provides a basis for going deeper into advanced investigative and computational methods, which you have an opportunity to explore in future courses of the Data Analytics for Business specialization.",163203.0,57185.0,4.7,3005.0
Introduction to Data Science and scikit-learn in Python,https://www.coursera.org/learn/data-science-and-scikit-learn-in-python,Data Science,Data Analysis,"Sabrina Moore, Rajvir Dua, Neelesh Tiruviluamala","This course will teach you how to leverage the power of Python and artificial intelligence to create and test hypothesis. We'll start for the ground up, learning some basic Python for data science before diving into some of its richer applications to test our created hypothesis. We'll learn some of the most important libraries for exploratory data analysis (EDA) and machine learning such as Numpy, Pandas, and Sci-kit learn. After learning some of the theory (and math) behind linear regression, we'll go through and full pipeline of reading data, cleaning it, and applying a regression model to estimate the progression of diabetes. By the end of the course, you'll apply a classification model to predict the presence/absence of heart disease from a patient's health data.",2407.0,14201.0,4.1,25.0
Introduction to Data Science in Python,https://www.coursera.org/learn/python-data-analysis,Data Science,Data Analysis,Christopher Brooks,"This course will introduce the learner to the basics of the python programming environment, including fundamental python programming techniques such as lambdas, reading and manipulating csv files, and the numpy library. The course will introduce data manipulation and cleaning techniques using the popular python pandas data science library and introduce the abstraction of the Series and DataFrame as the central data structures for data analysis, along with tutorials on how to use functions such as groupby, merge, and pivot tables effectively. By the end of this course, students will be able to take tabular data, clean it, manipulate it, and run basic inferential statistical analyses. 

This course should be taken before any of the other Applied Data Science with Python courses: Applied Plotting, Charting & Data Representation in Python, Applied Machine Learning in Python, Applied Text Mining in Python, Applied Social Network Analysis in Python.",703234.0,497713.0,4.5,26364.0
"Introduction to Data, Signal, and Image Analysis with MATLAB",https://www.coursera.org/learn/matlab-image-processing,Data Science,Data Analysis,Jack Noble,"Welcome to Introduction to Data, Signal, and Image Analysis with MATLAB!     

MATLAB is an extremely versatile programming language for data, signal, and image analysis tasks. This course provides an introduction on how to use MATLAB for data, signal, and image analysis. After completing the course,  learners will understand how machine learning methods can be used in MATLAB for data classification and prediction; how to perform data visualization, including data visualization for high dimensional datasets; how to perform image processing and analysis methods, including image filtering and image segmentation; and how to perform common signal analysis tasks, including filter design and frequency analysis.",21375.0,39766.0,4.7,161.0
Introduction to Deep Learning,https://www.coursera.org/learn/introduction-to-deep-learning-boulder,Data Science,Machine Learning,Geena Kim ,"Deep Learning is the go-to technique for many applications, from natural language processing to biomedical. Deep learning can handle many different types of data such as images, texts, voice/sound, graphs and so on. This course will cover the basics of DL including how to build and train multilayer perceptron, convolutional neural networks (CNNs), recurrent neural networks (RNNs), autoencoders (AE) and generative adversarial networks (GANs). The course includes several hands-on projects, including cancer detection with CNNs, RNNs on disaster tweets, and generating dog images with GANs.

Prior coding or scripting knowledge is required. We will be utilizing Python extensively throughout the course. We recommend taking the two previous courses in the specialization, Introduction to Machine Learning: Supervised Learning and Unsupervised Algorithms in Machine Learning, but they are not required. College-level math skills, including Calculus and Linear Algebra, are needed. Some parts of the class will be relatively math intensive.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Course logo image by Ryan Wallace on Unsplash.",2746.0,21183.0,,
Introduction to Deep Learning & Neural Networks with Keras,https://www.coursera.org/learn/introduction-to-deep-learning-with-keras,Data Science,Machine Learning,Alex Aklson,"Looking to start a career in Deep Learning? Look no further. This course will introduce you to the field of deep learning and help you answer many questions that people are asking nowadays, like what is deep learning, and how do deep learning models compare to artificial neural networks? You will learn about the different deep learning models and build your first deep learning model using the Keras library.

After completing this course, learners will be able to:
• Describe what a neural network is, what a deep learning model is, and the difference between them.
• Demonstrate an understanding of unsupervised deep learning models such as autoencoders and restricted Boltzmann machines.
• Demonstrate an understanding of supervised deep learning models such as convolutional neural networks and recurrent networks.
• Build deep learning models and networks using the Keras library.",28863.0,50638.0,4.7,1170.0
Introduction to Designing Data Lakes on AWS,https://www.coursera.org/learn/introduction-to-designing-data-lakes-in-aws,Data Science,Data Analysis,"Rafael Lopes, Morgan Willis","In this class, Introduction to Designing Data Lakes on AWS, we will help you understand how to create and operate a data lake in a secure and scalable way, without previous knowledge of data science! Starting with the ""WHY"" you may want a data lake, we will look at the Data-Lake value proposition, characteristics and components.

Designing a data lake is challenging because of the scale and growth of data. Developers need to understand best practices to avoid common mistakes that could be hard to rectify. In this course we will cover the foundations of what a Data Lake is, how to ingest and organize data into the Data Lake, and dive into the data processing that can be done to optimize performance and costs when consuming the data at scale. This course is for professionals (Architects, System Administrators and DevOps) who need to design and build an architecture for secure and scalable Data Lake components. Students will learn about the use cases for a Data Lake and, contrast that with a traditional infrastructure of servers and storage.",10128.0,23215.0,4.6,120.0
Introduction to Distributions in R,https://www.coursera.org/learn/intro-to-distributions-in-r,Data Science,Data Analysis,Nicole Baerg,"This project is aimed at beginners who have a basic familiarity with the statistical programming language R and the RStudio environment, or people with a small amount of experience who would like to review the fundamentals of generating random numerical data from distributions in R.",,,,
Introduction to EDA in R,https://www.coursera.org/learn/introduction-to-eda-in-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Introduction to EDA in R. In this project, you will learn how to perform extensive exploratory data analysis on both quantitative and qualitative variables using basic R functions.

By the end of this 2-hour long project, you will understand how to create different basic plots in R. Also, you will learn how to create plots for categorical variables and numeric or quantitative variables. By extension, you will learn how to plot three variables and save your plot as an image in R.

Note, you do not need to be a data scientist to be successful in this guided project, just a familiarity with basic statistics and using R suffice for this project. If you are not familiar with R and want to learn the basics, start with my previous guided projects titled “Getting Started with R” and “Calculating Descriptive Statistics in R”",,,,
Introduction to Embedded Machine Learning,https://www.coursera.org/learn/introduction-to-embedded-machine-learning,Data Science,Machine Learning,"Shawn Hymel, Alexander Fred-Ojala","Machine learning (ML) allows us to teach computers to make predictions and decisions based on data and learn from experiences. In recent years, incredible optimizations have been made to machine learning algorithms, software frameworks, and embedded hardware. Thanks to this, running deep neural networks and other complex machine learning algorithms is possible on low-power devices like microcontrollers.

This course will give you a broad overview of how machine learning works, how to train neural networks, and how to deploy those networks to microcontrollers, which is known as embedded machine learning or TinyML. You do not need any prior machine learning knowledge to take this course. Familiarity with Arduino and microcontrollers is advised to understand some topics as well as to tackle the projects. Some math (reading plots, arithmetic, algebra) is also required for quizzes and projects.

We will cover the concepts and vocabulary necessary to understand the fundamentals of machine learning as well as provide demonstrations and projects to give you hands-on experience.",23471.0,50456.0,4.8,449.0
Introduction to Genomic Technologies,https://www.coursera.org/learn/introduction-genomics,Data Science,Data Analysis,"Steven Salzberg, PhD, Jeff Leek, PhD","This course introduces you to the basic biology of modern genomics and the experimental tools that we use to measure it. We'll introduce the Central Dogma of Molecular Biology and cover how next-generation sequencing can be used to measure DNA, RNA, and epigenetic patterns. You'll also get an introduction to the key concepts in computing and data science that you'll need to understand how data from next-generation sequencing experiments are generated and analyzed.  

This is the first course in the Genomic Data Science Specialization.",82027.0,60557.0,4.6,4109.0
Introduction to Line Balancing Using Precedence Diagram,https://www.coursera.org/learn/introduction-to-line-balancing-using-precedence-diagram,Data Science,Data Analysis,Hazem Ehab,"In this 1-hour 30-minutes long project-based course, you will learn how to o define what is meant by cycle time and how to calculate it, draw a precedence diagram for your given process and calculate the idle time for this process, you will be able to calculate the efficiency of the system and the minimum number of workstations and how to assign tasks to these workstations, by applying all of these you will create a complete line balancing system.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,11.0
Introduction to Machine Learning,https://www.coursera.org/learn/machine-learning-duke,Data Science,Machine Learning,"Lawrence Carin , David Carlson, Timothy Dunn, Kevin Liang","This course will provide you a foundational understanding of machine learning models (logistic regression, multilayer perceptrons, convolutional neural networks, natural language processing, etc.) as well as demonstrate how these models can solve complex problems in a variety of industries, from medical diagnostics to image recognition to text prediction. In addition, we have designed practice exercises that will give you hands-on experience implementing these data science models on data sets. These practice exercises will teach you how to implement machine learning algorithms with PyTorch, open source libraries used by leading tech companies in the machine learning field (e.g., Google, NVIDIA, CocaCola, eBay, Snapchat, Uber and many more).",168498.0,106197.0,4.7,3174.0
Introduction to Machine Learning in Production,https://www.coursera.org/learn/introduction-to-machine-learning-in-production,Data Science,Machine Learning,"Andrew Ng, Cristian Bartolomé Arámburu","In the first course of Machine Learning Engineering for Production Specialization, you will identify the various components and design an ML production system end-to-end: project scoping, data needs, modeling strategies, and deployment constraints and requirements; and learn how to establish a model baseline, address concept drift, and prototype the process for developing, deploying, and continuously improving a productionized ML application.

Understanding machine learning and deep learning concepts is essential, but if you’re looking to build an effective AI career, you need production engineering capabilities as well. Machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production-ready skills. 

Week 1: Overview of the ML Lifecycle and Deployment
Week 2: Selecting and Training a Model
Week 3: Data Definition and Baseline",65077.0,160459.0,4.8,2103.0
Introduction to Machine Learning in Sports Analytics,https://www.coursera.org/learn/machine-learning-sports-analytics,Data Science,Data Analysis,Christopher Brooks,"In this course students will explore supervised machine learning techniques using the python scikit learn (sklearn) toolkit and real-world athletic data to understand both machine learning algorithms and how to predict athletic outcomes. Building on the previous courses in the specialization, students will apply methods such as support vector machines (SVM), decision trees, random forest, linear and logistic regression, and ensembles of learners to examine data from professional sports leagues such as the NHL and MLB as well as wearable devices such as the Apple Watch and inertial measurement units (IMUs). By the end of the course students will have a broad understanding of how classification and regression techniques can be used to enable sports analytics across athletic activities and events.",1740.0,6609.0,4.5,11.0
Introduction to Machine Learning: Supervised Learning,https://www.coursera.org/learn/introduction-to-machine-learning-supervised-learning,Data Science,Machine Learning,Geena Kim ,"In this course, you’ll be learning various supervised ML algorithms and prediction tasks applied to different data. You’ll learn when to use which model and why, and how to improve the model performances. We will cover models such as linear and logistic regression, KNN, Decision trees and ensembling methods such as Random Forest and Boosting, kernel methods such as SVM.

Prior coding or scripting knowledge is required. We will be utilizing Python extensively throughout the course. In this course, you will need to have a solid foundation in Python or sufficient previous experience coding with other programming languages to pick up Python quickly. 

We will be learning how to use data science libraries like NumPy, pandas, matplotlib, statsmodels, and sklearn. The course is designed for programmers beginning to work with those libraries. Prior experience with those libraries would be helpful but not necessary. 

College-level math skills, including Calculus and Linear Algebra, are required. Our hope for this course is that the math will be understandable but not intimidating.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",5193.0,41762.0,3.0,17.0
Introduction to Microsoft Azure Synapse Analytics,https://www.coursera.org/learn/introduction-to-microsoft-azure-synapse-analytics,Data Science,Data Analysis, Microsoft,"In this course, you will learn how Azure Synapse Analytics enables you to perform different types of analytics through its’ components that can be used to build Modern Data Warehouses through to advanced analytical solutions.  You will learn how Azure Synapse Analytics solves the issue of having a single service to fulfill the broad range of analytics requirements that organizations face today and take a tour of the core application used to interact with the various components of Azure Synapse Analytics. You will learn the various components of Azure Synapse Analytics that enable you to build your analytical solutions in one place.

This course is part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services for anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). 

This is the fourth course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",3355.0,20216.0,3.9,29.0
Introduction to Microsoft Excel,https://www.coursera.org/learn/introduction-to-microsoft-excel,Data Science,Probability and Statistics,Kim Webb,"At the end of this project, you will be able to start a simple spreadsheet in Microsoft Excel. Being able to use Microsoft Excel will allow you to simplify many of your daily tasks at work but also at home. There is no limit to what you can use Microsoft Excel for, you can use it to plan the annual budget of your business, you can use it to track business expenses but you can also use it simply to keep inventory of all the books you own.",,,,
Introduction to Neurohacking In R,https://www.coursera.org/learn/neurohacking,Data Science,Data Analysis,"Dr. Elizabeth Sweeney , Ciprian M. Crainiceanu, John Muschelli III ","Neurohacking describes how to use the R programming language (https://cran.r-project.org/) and its associated package to perform manipulation, processing, and analysis of neuroimaging data. We focus on publicly-available structural magnetic resonance imaging (MRI). We discuss concepts such as inhomogeneity correction, image registration, and image visualization.

By the end of this course, you will be able to:

Read/write images of the brain in the NIfTI (Neuroimaging Informatics Technology Initiative) format
Visualize and explore these images
Perform inhomogeneity correction, brain extraction, and image registration (within a subject and to a template).",21193.0,9725.0,4.6,279.0
Introduction to Node-red,https://www.coursera.org/learn/introduction-to-node-red,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project, you will learn the basic concepts and fundamentals of Node-red. Node-RED is an opensource flow-based development tool for visual programming in javascript it allows the programmers to interconnect physical I/O, could based-systems, databases and different APIs, in many ways. originally, it was designed to work with the Internet of Things, i.e. devices that interact and control the real world, as it has evolved, it has become useful for a range of applications. In this project, we are going to cover key-core nodes in node-red. at the final task of this project we will create a weather alert application using node-red.",,,4.7,30.0
Introduction to Predictive Modeling,https://www.coursera.org/learn/introduction-to-predictive-modeling,Data Science,Probability and Statistics,De Liu,"Welcome to Introduction to Predictive Modeling, the first course in the University of Minnesota’s Analytics for Decision Making specialization.

This course will introduce to you the concepts, processes, and applications of predictive modeling, with a focus on linear regression and time series forecasting models and their practical use in Microsoft Excel. By the end of the course, you will be able to:

-          Understand the concepts, processes, and applications of predictive modeling.
-          Understand the structure of and intuition behind linear regression models.
-          Be able to fit simple and multiple linear regression models to data, interpret the results, evaluate the goodness of fit, and use fitted models to make predictions.
-          Understand the problem of overfitting and underfitting and be able to conduct simple model selection.
-          Understand the concepts, processes, and applications of time series forecasting as a special type of predictive modeling.
-          Be able to fit several time-series-forecasting models (e.g., exponential smoothing and Holt-Winter’s method) in Excel, evaluate the goodness of fit, and use fitted models to make forecasts.
-          Understand different types of data and how they may be used in predictive models.
-          Use Excel to prepare data for predictive modeling, including exploring data patterns, transforming data, and dealing with missing values.

This is an introductory course to predictive modeling. The course provides a combination of conceptual and hands-on learning. During the course, we will provide you opportunities to practice predictive modeling techniques on real-world datasets using Excel.

To succeed in this course, you should know basic math (the concept of functions, variables, and basic math notations such as summation and indices) and basic statistics (correlation, sample mean, standard deviation, and variance). This course does not require a background in programming, but you should be familiar with basic Excel operations (e.g., basic formulas and charting). For the best experience, you should have a recent version of Microsoft Excel installed on your computer (e.g., Excel 2013, 2016, 2019, or Office 365).",4586.0,11219.0,4.8,59.0
Introduction to Probability and Data with R,https://www.coursera.org/learn/probability-intro,Data Science,Data Analysis,Mine Çetinkaya-Rundel,"This course introduces you to sampling and exploring data, as well as basic probability theory and Bayes' rule. You will examine various types of sampling methods, and discuss how such methods can impact the scope of inference. A variety of exploratory data analysis techniques will be covered, including numeric summary statistics and basic data visualization. You will be guided through installing and using R and RStudio (free statistical software), and will use this software for lab exercises and a final project. The concepts and techniques in this course will serve as building blocks for the inference and modeling courses in the Specialization.",253496.0,148889.0,4.7,5323.0
Introduction to PyMC3 for Bayesian Modeling and Inference,https://www.coursera.org/learn/introduction-to-pymc3,Data Science,Machine Learning,Dr. Srijith Rajamohan,"The objective of this course is to introduce PyMC3 for Bayesian Modeling and Inference,  The attendees will start off by learning the the basics of PyMC3 and learn how to perform scalable inference for a variety of problems. This will be the final course in a specialization of three courses .Python and Jupyter notebooks will be used throughout this course to illustrate and perform Bayesian modeling with PyMC3.. The course website is located at https://sjster.github.io/introduction_to_computational_statistics/docs/index.html. The course notebooks can be downloaded from this website by following the instructions on page https://sjster.github.io/introduction_to_computational_statistics/docs/getting_started.html.

The instructor for this course will be Dr. Srijith Rajamohan.",,3366.0,3.5,13.0
Introduction to Python Functions,https://www.coursera.org/learn/introduction-python-functions,Data Science,Data Analysis,Di Wu,"How many times have you decided to learn a programming language but got stuck somewhere along the way, grew frustrated, and gave up? This specialization is designed for learners who have little or no programming experience but want to use Python as a tool to play with data. 

In the second course, Introduction to Python Functions, you are going to learn and use functions predefined in Python and Python packages, you also are able to define functions as well. You will create and use functions to make your programs reusable and adaptive.

Are you ready? Let's go!

Logo image courtesy of Mourizal Zativa. Available on Unsplash here: https://unsplash.com/photos/gNMVpAPe3PE",,7086.0,,
Introduction to Python Fundamentals,https://www.coursera.org/learn/introduction-python-fundamentals,Data Science,Data Analysis,Di Wu,"How many times have you decided to learn a programming language but got stuck somewhere along the way, grew frustrated, and gave up? This specialization is designed for learners who have little or no programming experience but want to use Python as a tool to play with data. 

The first course will introduce you to programming languages, with Python as an example. You are going to learn how to use variables and operators, as well as input/output and flow controls to build simple Python programs. The pace will be very slow, so you will feel comfortable learning Python as quickly or as slowly as you like.  

Are you ready? Let's go!

Logo image courtesy of Mourizal Zativa. Available on Unsplash here: https://unsplash.com/photos/gNMVpAPe3PE",1724.0,22485.0,,
Introduction to R Programming and Tidyverse,https://www.coursera.org/learn/r-programming-tidyverse,Data Science,Data Analysis,Jane Wall,"This course is a gentle introduction to programming in R designed for 3 types of learners. It will be right for you, if:

•    you want to do data analysis but don’t know programming
•    you know programming but aren’t familiar with R
•    you know some R programming but want to learn the tidyverse verbs

You will learn to do data visualization and analysis in a reproducible manner and use functions that allow your code to be easily read and understood. You will use RMarkdown to create nice documents and reports that execute your code freshly every time it’s run and that capture your thoughts about the data along the way.

This course has been designed for learners from non-STEM backgrounds to help prepare them for more advanced data science courses by providing an introduction to programming and to the R language. I am excited for you to join me on the journey!

The course logo was created using images of stickers from the RStudio shop. Please visit https://swag.rstudio.com/s/shop.",2045.0,127487.0,4.7,11.0
Introduction to R Programming for Data Science,https://www.coursera.org/learn/introducton-r-programming-data-science,Data Science,Data Analysis,Yan Luo,"When working in the data science field you will definitely become acquainted with the R language and the role it plays in data analysis. This course introduces you to the basics of the R language such as data types, techniques for manipulation, and how to implement fundamental programming tasks. 

You will begin the process of understanding common data structures, programming fundamentals and how to manipulate data all with the help of the R programming language. 

The emphasis in this course is hands-on and practical learning . You will write a simple program using RStudio, manipulate data in a data frame or matrix, and complete a final project as a data analyst using Watson Studio and Jupyter notebooks to acquire and analyze data-driven insights.  
 

No prior knowledge of R, or programming is required.",15850.0,71299.0,4.4,206.0
Introduction to R: Basic R syntax,https://www.coursera.org/learn/intro-to-r-basic-syntax,Data Science,Data Analysis,Nicole Baerg,"This guided project is for beginners interested in taking their first steps with coding in the statistical language R. It assumes no previous knowledge of R, introduces the RStudio environment, and covers basic concepts, tools, and general syntax. By the end of the exercise, learners will build familiarity with RStudio and the fundamentals of the statistical coding language R.",,,4.3,20.0
Introduction to Recommender Systems:  Non-Personalized and Content-Based,https://www.coursera.org/learn/recommender-systems-introduction,Data Science,Machine Learning,"Joseph A Konstan, Michael D. Ekstrand","This course, which is designed to serve as the first course in the Recommender Systems specialization, introduces the concept of recommender systems, reviews several examples in detail, and leads you through non-personalized recommendation using summary statistics and product associations, basic stereotype-based or demographic recommendations, and content-based filtering recommendations. 

After completing this course, you will be able to compute a variety of recommendations from datasets using basic spreadsheet tools, and if you complete the honors track you will also have programmed these recommendations using the open source LensKit recommender toolkit.  

In addition to detailed lectures and interactive exercises, this course features interviews with several leaders in research and practice on advanced topics and current directions in recommender systems.",34456.0,11764.0,4.5,617.0
Introduction to Reproducibility in Cancer Informatics,https://www.coursera.org/learn/intro-reproducibility-cancer-informatics,Data Science,Data Analysis,"Candace Savonen, MS","The course is intended for students in the biomedical sciences and researchers who use informatics tools in their research and have not had training in reproducibility tools and methods.

This course is written for individuals who:  

- Have some familiarity with R or Python - have written some scripts.   
- Have not had formal training in computational methods.  
- Have limited or no familiar with GitHub, Docker, or package management tools.

Motivation

Data analyses are generally not reproducible without direct contact with the original researchers and a substantial amount of time and effort (BeaulieuJones et al, 2017). Reproducibility in cancer informatics (as with other fields) is still not monitored or incentivized despite that it is fundamental to the scientific method. Despite the lack of incentive, many researchers strive for reproducibility in their own work but often lack the skills or training to do so effectively.

Equipping researchers with the skills to create reproducible data analyses increases the efficiency of everyone involved. Reproducible analyses are more likely to be understood, applied, and replicated by others. This helps expedite the scientific process by helping researchers avoid false positive dead ends. Open source clarity in reproducible methods also saves researchers' time so they don't have to reinvent the proverbial wheel for methods that everyone in the field is already performing.

Curriculum  

This course introduces the concepts of reproducibility and replicability in the context of cancer informatics. It uses hands-on exercises to demonstrate in practical terms how to increase the reproducibility of data analyses. The course also introduces tools relevant to reproducibility including analysis notebooks, package managers, git and GitHub.

The course includes hands-on exercises for how to apply reproducible code concepts to their code. Individuals who take this course are encouraged to complete these activities as they follow along with the course material to help increase the reproducibility of their analyses.

**Goal of this course:**  
Equip learners with reproducibility skills they can apply to their existing analyses scripts and projects. This course opts for an ""ease into it"" approach. We attempt to give learners doable, incremental steps to increase the reproducibility of their analyses.

**What is not the goal**  
This course is meant to introduce learners to the reproducibility tools, but _it does not necessarily represent the absolute end-all, be-all best practices for the use of these tools_. In other words, this course gives a starting point with these tools, but not an ending point. The advanced version of this course is the next step toward incrementally ""better practices"".

How to use the course

This course is designed with busy professional learners in mind -- who may have to pick up and put down the course when their schedule allows.

Each exercise has the option for you to continue along with the example files as you've been editing them in each chapter, OR you can download fresh chapter files that have been edited in accordance with the relative part of the course. This way, if you decide to skip a chapter or find that your own files you've been working on no longer make sense, you have a fresh starting point at each exercise.",,,,
Introduction to SQL Window Functions,https://www.coursera.org/learn/introduction-to-sql-window-functions,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Introduction to SQL Window Functions. This is a hands-on project that introduces SQL users to the world of window functions. In this project, you will learn how to explore and query the project-db database extensively. We will start this hands-on project by retrieving the data in the table in the database.

By the end of this 2-hour-and-a-half-long project, you will be able to use different window functions to retrieve the desired result from a database. In this project, you will learn how to use SQL window functions like ROW_NUMBER(), LEAD(), LAG(), and FIRST_VALUE() to manipulate data in the project-db database. These window functions will be used together with the OVER() clause to query this database.",,,4.3,10.0
Introduction to Sentiment Analysis in R with quanteda,https://www.coursera.org/learn/sentiment-analysis-in-r-with-quanteda,Data Science,Data Analysis,Nicole Baerg,"In this guided project, you will learn how to import textual data stored in raw text files into R, turn these files into a corpus (a collection of textual documents), and tokenize the text all using the R software package quanteda. You will then learn how to check for words with positive or negative sentiment within the text, and how to plot the proportion of use for these words over time, while stratifying by a third variable. You will also learn how to carry out a targeted sentiment analysis by looking for words with a positive or negative sentiment that are adjacent to relevant keywords or phrases, and how to compare the results of a targeted sentiment analysis with the results of a generic analysis.",,,,
Introduction to Statistical Analysis:  Hypothesis Testing,https://www.coursera.org/learn/statistical-analysis-hypothesis-testing-sas,Data Science,Data Analysis,Jordan Bakerman,"This introductory course is for SAS software users who perform statistical analyses using SAS/STAT software. The focus is on t tests, ANOVA, and linear regression, and includes a brief introduction to logistic regression.",8434.0,39574.0,4.6,79.0
Introduction to Statistics,https://www.coursera.org/learn/stanford-statistics,Data Science,Data Analysis,Guenther Walther,"Stanford's ""Introduction to Statistics"" teaches you statistical thinking concepts that are essential for learning from data and communicating insights. By the end of the course, you will be able to perform exploratory data analysis, understand key principles of sampling, and select appropriate tests of significance for multiple contexts. You will gain the foundational skills that prepare you to pursue more advanced topics in statistical thinking and machine learning.

Topics include Descriptive Statistics, Sampling and Randomized Controlled Experiments, Probability, Sampling Distributions and the Central Limit Theorem, Regression, Common Tests of Significance, Resampling, Multiple Comparisons.",201328.0,583384.0,4.6,1692.0
Introduction to Statistics in Python,https://www.coursera.org/learn/introduction-statistics-python,Data Science,Probability and Statistics,Ekaterina Royal,"In this project, learners will get a refresher of introductory statistics, learn about different python libraries that can be used to run statistical analysis, and create visualizations to represent the results. By the end of the project, the learners will import a real world data set, run statistical analysis to find means, medians , standard deviations, correlations, and other information of the data. The learners will also create distinct graphs and plots to represent the data. 

Along the way, the learners will not only learn the frequently used statistics functions, but also learn to navigate documentations for different python libraries in order to find assistance in the implementation of those functions, and find other relevant functions as well. This will help the learners to understand the material and implement more complex functions down the road instead of simply memorizing the syntax of one solution.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Introduction to Systems and Network Mapping with Kumu,https://www.coursera.org/learn/systems-network-kumu,Data Science,Data Analysis,Danilo Oliveira Vaz,"In this 1-hour long project-based course, you will create an interactive multi-elements relationship map, as well as design visualizations for a real-world social network, based on metrics analyses.

Besides helping you to make sense of complex data, relationship maps like the ones we will build here are a great medium to visually present Causal Loop and Stock and Flow diagrams, as well as non-linear dynamics within an ecosystem.

This project will also introduce you to some of the basic concepts behind network theory, which will inform the analyses and interpretations of the maps you will create.

The art and craft of creating and communicating relationship maps is applicable to a wide range of areas, from design and software engineering, to organization consultancy and community building. And this project is an accessible opportunity for anyone to get some hands-on practice and knowledge on this subject. So let's map!

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",1748.0,,4.6,48.0
Introduction to Text Classification in R with quanteda,https://www.coursera.org/learn/text-classification-in-r,Data Science,Data Analysis,Nicole Baerg,"In this guided project you will learn how to import textual data stored in raw text files into R, turn these files into a corpus (a collection of textual documents), reshape them into paragraphs from documents and tokenize the text all using the R software package quanteda. You will then learn how to classify the texts using the Naive Bayes algorithm. 
This guided project is for beginners interested in quantitative text analysis in R. It assumes no knowledge of textual analysis and focuses on exploring textual data (US Presidential Concession Speeches). Users should have a basic understanding of the statistical programming language R.",,,,
Introduction to Topic Modelling in R,https://www.coursera.org/learn/introduction-to-topic-modelling-in-r,Data Science,Data Analysis,Nicole Baerg,"By the end of this project, you will know how to load and pre-process a data set of text documents by converting the data set into a document feature matrix and reducing it’s dimensionality. You will also know how to run an unsupervised machine learning LDA topic model (Latent Dirichlet Allocation). You will know how to plot the change in topics over time as well as explore the distribution of topic probability in each document.",,,,
"Introduction to Trading, Machine Learning & GCP",https://www.coursera.org/learn/introduction-trading-machine-learning-gcp,Data Science,Machine Learning,Jack Farmer,"In this course, you’ll learn about the fundamentals of trading, including the concept of trend, returns, stop-loss, and volatility. You will learn how to identify the profit source and structure of basic quantitative trading strategies. This course will help you gauge how well the model generalizes its learning, explain the differences between regression and forecasting, and identify the steps needed to create development and implementation backtesters. By the end of the course, you will be able to use Google Cloud Platform to build basic machine learning models in Jupyter Notebooks. 

To be successful in this course, you should have advanced competency in Python programming and familiarity with pertinent libraries for machine learning, such as Scikit-Learn, StatsModels, and Pandas. Experience with SQL is recommended. You should have a background in statistics (expected values and standard deviation, Gaussian distributions, higher moments, probability, linear regressions) and foundational knowledge of financial markets (equities, bonds, derivatives, market structure, hedging).",38369.0,35764.0,4.0,758.0
Introduction to Widgets for Data Science,https://www.coursera.org/learn/widgets-for-ds,Data Science,Data Analysis,Muhammad Saad uddin,"In this 2-hour long project-based course, you will learn what are widgets, how they can used for data science work, types of widgets, linking multiple widgets, basic dashboards of widgets and creating child widgets.",,,,
Introduction to the Tidyverse,https://www.coursera.org/learn/tidyverse,Data Science,Data Analysis,"Carrie Wright, PhD, Shannon Ellis, PhD, Stephanie Hicks, PhD, Roger D. Peng, PhD","This course introduces a powerful set of data science tools known as the Tidyverse. The Tidyverse has revolutionized the way in which data scientists do almost every aspect of their job. We will cover the simple idea of ""tidy data"" and how this idea serves to organize data for analysis and modeling. We will also cover how non-tidy can be transformed to tidy data, the data science project life cycle, and the ecosystem of Tidyverse R packages that can be used to execute a data science project. 

If you are new to data science, the Tidyverse ecosystem of R packages is an excellent way to learn the different aspects of the data science pipeline, from importing the data, tidying the data into a format that is easy to work with, exploring and visualizing the data, and fitting machine learning models. If you are already experienced in data science, the Tidyverse provides a power system for streamlining your workflow in a coherent manner that can easily connect with other data science tools. 

In this course it is important that you be familiar with the R programming language. If you are not yet familiar with R, we suggest you first complete R Programming before returning to complete this course.",2817.0,5867.0,4.2,30.0
Introduction à l'analyse de données à l'aide d'Excel,https://www.coursera.org/learn/excel-data-analysis-fr,Data Science,Data Analysis,Sharad Borle,"L'utilisation d'Excel est répandue dans l'industrie. C'est un outil d'analyse de données très puissant et presque toutes les grandes et petites entreprises utilisent Excel au quotidien. Ce cours d'introduction à l'utilisation d'Excel est conçu pour vous donner une connaissance pratique d'Excel dans le but de l'utiliser ultérieurement pour des sujets plus avancés dans le domaine des statistiques d'entreprise. Le cours est conçu en gardant à l'esprit deux types d'apprenants - ceux qui ont très peu de connaissances fonctionnelles d'Excel et ceux qui utilisent Excel régulièrement mais à un niveau moindre et souhaitent améliorer leurs compétences. Le cours vous présente des opérations de base telles que la lecture de données dans Excel en utilisant divers formats de données, l'organisation et la manipulation de données, et certaines des fonctionnalités les plus avancées d'Excel. Tout au long du cours, la fonctionnalité d’Excel est présentée à l'aide d'exemples faciles à comprendre qui sont illustrés de manière à permettre aux apprenants de les comprendre et de les appliquer.

Pour réussir les travaux du cours, les étudiants doivent avoir accès à une version Windows de Microsoft Excel 2010 ou une version ultérieure. 
________________________________________
SEMAINE 1
Module 1 : Introduction aux feuilles de calcul
Dans ce module, vous serez initié à l'utilisation des feuilles de calcul Excel et des diverses fonctions de base relatives aux données d'Excel.

Les sujets abordés sont les suivants :
•	Lecture des données dans Excel en utilisant différents formats
•	Fonctions de base dans Excel, fonctions arithmétiques ainsi que diverses fonctions logiques
•	Mise en forme des lignes et des colonnes
•	Utilisation des formules dans Excel et exécution de copier-coller à l'aide du référencement absolu et relatif
________________________________________
SEMAINE 2
Module 2 : Fonctions des feuilles de calcul pour organiser les données
Ce module présente diverses fonctions Excel permettant d’organiser et d’interroger les données. Les apprenants découvrent les fonctions SI, SI imbriquée, RECHERCHEV et RECHERCHEH d'Excel. 

Les sujets abordés sont les suivants :
•	Fonctions SI et SI imbriquée
•	RECHERCHEV et RECHERCHEH
•	La fonction ALEA.ENTRE.BORNES
________________________________________
SEMAINE 3
Module 3 : Introduction au filtrage, aux tableaux croisés dynamiques et aux graphiques
Ce module présente diverses fonctionnalités de filtrage des données d'Excel. Vous apprendrez à définir des filtres dans les données pour accéder de manière sélective aux données. Le tableau croisé dynamique, un outil de synthèse de données très puissant, est également expliqué et nous commencerons à introduire la fonction de création de graphiques d'Excel.

Les sujets abordés sont les suivants :
•	RECHERCHEV sur les feuilles de calcul
•	Filtrage des données dans Excel
•	Utilisation de tableaux croisés dynamiques avec des données catégorielles et numériques
•	Introduction à la capacité de création de graphiques d'Excel
________________________________________
SEMAINE 4
Module 4 : Graphiques et diagrammes avancés
Ce module explore diverses techniques avancées de création de graphiques et diagrammes disponibles dans Excel. Nous commencerons par divers graphiques linéaires, à barres et à secteurs, et présenterons les graphiques croisés dynamiques, les nuages de points et les histogrammes. Vous apprendrez à comprendre ces différents graphiques et à les construire par vous-même.

Les sujets abordés sont les suivants :
•	Graphiques linéaires, à barres et à secteurs
•	Graphiques croisés dynamiques
•	Nuage de points
•	Histogrammes",1942.0,6567.0,,
Introduzione alla Data Visualization con Tableau,https://www.coursera.org/learn/introduzione-data-visualization-tableau,Data Science,Data Analysis,Manuel Belgioioso,"L’obiettivo del corso è formare professionisti della Business Intelligence attraverso l’apprendimento della piattaforma Tableau, strumento leader di questo settore. La mole di dati a disposizione è sempre più grande ed estrarre informazioni utili per sfruttare queste informazioni è compito degli analisti.

Un ruolo cruciale lo riveste la data visualization: il tassello del processo analitico che permette di capire come rappresentare al meglio i propri dati per elaborare strategie data-driven.
In questo corso verranno presentate tutte le funzionalità di Tableau Desktop, il tool dedicato alla costruzione delle analisi dei dati. 
Introduciamo i diversi prodotti della suite Tableau, l’interfaccia grafica e gli ambienti di lavoro, per passare, infine, alla presentazione delle unità minime del lavoro su Tableau: dimensioni, misure e tipi di dato. Vengono illustrati i contenuti relativi ai modi e ai tipi di connessione ai dati, e le strategie di selezione e organizzazione dei dati. Infine tutti gli elementi necessari per imparare a combinare insieme i dati e lavorare con set, date e misure multiple.",,2002.0,,
Introdução a Machine Learning em uma Competição do Kaggle,https://www.coursera.org/learn/ml-basics-kaggle-competition-pt-br,Data Science,Machine Learning,Mírian Silva,"Neste curso de 1 hora, com base em projeto, você será capaz de entender como prever quais passageiros sobreviveriam ao naufrágio do Titanic e fazer sua primeira submissão em uma competição de Aprendizado de Máquina dentro da plataforma do Kaggle. Além disso, você, como iniciante em Machine Learning, irá se familiarizar e entender como iniciar um modelo preditivo usando conceitos básicos de aprendizado supervisionado. Vamos escolher classificadores para aprender, prever e testar os dados. Realizaremos uma Análise Exploratória de Dados (também chamada de EDA) para adquirir um bom entendimento sobre os dados que iremos trabalhar. Ao final, você saberá como medir o desempenho de um modelo, e será capaz de enviar seu modelo para a competição e obter uma pontuação do Kaggle.

Nota: Este curso funciona melhor para aprendizes de regiões que tem como idioma o Português. Você encontra a versão desse mesmo conteúdo disponível em inglês para aprendizes da América do Norte em: https://www.coursera.org/projects/ml-basics-kaggle-competition

Este projeto é indicado para iniciantes em Ciência de Dados que desejam fazer uma aplicação prática usando Aprendizado de Máquina e análise de dados.

Para ter sucesso neste projeto é desejado que você tenha conhecimentos básicos em linguagem Python, utilizaremos bibliotecas como Numpy e Pandas. Você também deve previamente ter uma conta Google para utilizar o Google Colab e também uma conta na plataforma Kaggle (ambas sem custo).",,,,
Introdução ao Big Data,https://www.coursera.org/learn/introducao-big-data,Data Science,Data Analysis,Alessandra  Montini,"Este curso é indicado para profissionais que desejam entender de forma fácil o que é Big Data, conhecer algumas tecnologias de Big Data, ter acesso a algumas aplicações de Analytics, Internet das Coisas - IOT e de Big Data. Ao final do curso você será capaz de participar de um projeto de Big Data contribuindo com estratégias e direcionando o projeto para a escolha da adequada técnica de análise de dados.",15341.0,2117.0,4.6,316.0
Introdução ao Workforce Management,https://www.coursera.org/learn/introducao-ao-workforce-management,Data Science,Data Analysis,Paula Suda,"Nossas boas-vindas ao Curso Introdução ao Workforce Management.

Neste curso, você aprenderá os conceitos fundamentais de Workforce Management (WFM), estruturados em uma metodologia prática e aplicável em sua realidade.

Ao final deste curso, você será capaz de conhecer, de forma detalhada, os processos de WFM nas organizações, o que permite definir as principais estratégias de RH e implementar as iniciativas de WFM. Também saberá identificar quais as principais iniciativas, boas práticas e tendências para a área.

Este curso é composto por quatro módulos, disponibilizados em semanas de aprendizagem. Cada módulo é composto por vídeos, leituras e testes de verificação de aprendizagem. Ao final de cada módulo, temos uma avaliação de verificação dos conhecimentos.

Estamos muito felizes com sua presença neste curso e esperamos que você tire o máximo de proveito dos conceitos aqui apresentados.

Bons estudos!",,,,
Introdução à Ciência e Engenharia de Dados,https://www.coursera.org/learn/introducao-a-ciencia-e-engenharia-de-dados,Data Science,Data Analysis,Anderson França,"Neste curso, você aprenderá que os dados se tornaram o principal ativo de negócios nos dias de hoje. Com o aumento do Big Data e criação de novas tecnologias, as organizações em todo o mundo estão inovando e descobrindo novas formas para analisar o potencial dos dados à sua disposição, o que ajuda no crescimento, na lucratividade, no direcionamento das operações gerais e no aumento da satisfação do cliente. Mas para que tudo isso funcione corretamente e seja possível extrair todo o potencial de forma precisa e que seja viável para o negócio, criou-se a área de ciência de dados.

Ao final deste curso, você será capaz de compreender todo o processo de ciência de dados e o uso da tecnologia em um mundo conectado, entender todo o escopo de ciência e engenharia de dados e conhecer as principais metodologias de projeto para ciência de dados. 

Este curso é composto por quatro módulos, disponibilizados em semanas de aprendizagem. Cada módulo é composto por vídeos, leituras e testes de verificação de aprendizagem. Ao final de cada módulo, temos uma avaliação de verificação dos conhecimentos.

Estamos muito felizes com sua presença neste curso e esperamos que você tire o máximo de proveito dos conceitos aqui apresentados.

Bons estudos!",,6200.0,4.2,10.0
Joining Data in R using dplyr,https://www.coursera.org/learn/joining-data-in-r-using-dplyr,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"You will need to join or merge two or more data sets at different points in your work as a data enthusiast. The dplyr package offers very sophisticated functions to help you achieve the join operation you desire. This project-based course, ""Joining Data in R using dplyr"" is for R users willing to advance their knowledge and skills. 
In this course, you will learn practical ways for data manipulation in R. We will talk about different join operations and spend a great deal of our time here joining the sales and customers data sets using the dplyr package. By the end of this 2-hour-long project, you will perform inner join, full (outer) join, right join, left join, cross join, semi join, and anti join using the merge() and dplyr functions.
This project-based course is an intermediate-level course in R. Therefore, to get the most of this project, it is essential to have prior experience using R for basic analysis. I recommend that you complete the project titled: ""Data Manipulation with dplyr in R"" before you take this current project.",,,,
Julia Scientific Programming,https://www.coursera.org/learn/julia-programming,Data Science,Data Analysis,"Juan H Klopper, Henri Laurie","This four-module course introduces users to Julia as a first language.  Julia is a high-level, high-performance dynamic programming language developed specifically for scientific computing. This language will be particularly useful for applications in physics, chemistry, astronomy, engineering, data science, bioinformatics and many more. As open source software, you will always have it available throughout your working life. It can also be used from the command line, program files or a new type of interface known as a Jupyter notebook (which is freely available as a service from JuliaBox.com).

Julia is designed to address the requirements of high-performance numerical and scientific computing while also being effective for general-purpose programming. You will be able to access all the available processors and memory, scrape data from anywhere on the web, and have it always accessible through any device you care to use as long as it has a browser.  Join us to discover new computing possibilities. Let's get started on learning Julia.

By the end of the course you will be able to:
- Programme using the Julia language by practising through assignments
- Write your own simple Julia programs from scratch
- Understand the advantages and capacities of Julia as a computing language
- Work in Jupyter notebooks using the Julia language
- Use various Julia packages such as  Plots, DataFrames and Stats

The course is delivered through video lectures, on-screen demonstrations, quizzes and practical peer-reviewed projects designed to give you an opportunity to work with the packages.",33725.0,13980.0,4.4,412.0
Julia for Beginners in Data Science,https://www.coursera.org/learn/julia-beginners-data-science,Data Science,Data Analysis,Vinita Silaparasetty,"This guided project is for those who want to learn how to use Julia for data cleaning as well as exploratory analysis. This project covers the syntax of Julia from a data science perspective. So you will not build anything during the course of this project. 

While you are watching me code, you will get a cloud desktop with all the required software pre-installed. This will allow you to code along with me. After all, we learn best with active, hands-on learning.

Special Features:

1) Work with 2 real-world datasets.
2) Detailed variable description booklets are provided in the github repository for this guided project.
3) This project provides challenges with solutions to encourage you to practice.
4) The real-world applications of each function are explained.
5) Best practices and tips are provided to ensure that you learn how to use pandas efficiently.
6) You get a copy of the jupyter notebook that you create which acts as a handy reference guide.

Please note that the version of Julia used is 1.0.4

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.3,41.0
K-Means Clustering 101: World Happiness Report,https://www.coursera.org/learn/clustering-world-happiness-report,Data Science,Data Analysis,Ryan Ahmed,"In this case study, we will train an unsupervised machine learning algorithm to cluster countries based on features such as economic production, social support, life expectancy, freedom, absence of corruption, and generosity.
The World Happiness Report determines the state of global happiness. The happiness scores and rankings data has been collected by asking individuals to rank their life from 0 (worst possible life) to 10 (best possible life).",,,4.7,10.0
Language Classification with Naive Bayes in Python,https://www.coursera.org/learn/language-classification,Data Science,Machine Learning,Ari Anastassiou,"In this 1-hour long project, you will learn how to clean and preprocess data for language classification. You will learn some theory behind Naive Bayes Modeling, and the impact that class imbalance of training data has on classification performance. You will learn how to use subword units to further mitigate the negative effects of class imbalance, and build an even better model.",6204.0,,4.5,150.0
Launching Machine Learning: Delivering Operational Success with Gold Standard ML Leadership,https://www.coursera.org/learn/launching-machine-learning-leadership,Data Science,Machine Learning,Eric Siegel,"Machine learning runs the world. It generates predictions for each individual customer, employee, voter, and suspect, and these predictions drive millions of business decisions more effectively, determining whom to call, mail, approve, test, diagnose, warn, investigate, incarcerate, set up on a date, or medicate. 

But, to make this work, you've got to bridge what is a prevalent gap between business leadership and technical know-how. Launching machine learning is as much a management endeavor as a technical one. Its success relies on a very particular business leadership practice. This means that two different species must cooperate in harmony: the business leader and the quant. 

This course will guide you to lead or participate in the end-to-end implementation of machine learning (aka predictive analytics). Unlike most machine learning courses, it prepares you to avoid the most common management mistake that derails machine learning projects: jumping straight into the number crunching before establishing and planning for a path to operational deployment.

Whether you'll participate on the business or tech side of a machine learning project, this course delivers essential, pertinent know-how. You'll learn the business-level fundamentals needed to ensure the core technology works within - and successfully produces value for - business operations. If you're more a quant than a business leader, you'll find this is a rare opportunity to ramp up on the business side, since technical ML trainings don't usually go there. But know this: The soft skills are often the hard ones.

After this course, you will be able to:

- Apply ML: Identify the opportunities where machine learning can improve marketing, sales, financial credit scoring, insurance, fraud detection, and much more.

- Plan ML: Determine the way in which machine learning will be operationally integrated and deployed, and the staffing and data requirements to get there. 

- Greenlight ML: Forecast the effectiveness of a machine learning project and then internally sell it, gaining buy-in from your colleagues.

- Lead ML: Manage a machine learning project, from the generation of predictive models to their launch.

- Prep data for ML: Oversee the data preparation, which is directly informed by business priorities.

- Evaluate ML: Report on the performance of predictive models in business terms, such as profit and ROI.

- Regulate ML: Manage ethical pitfalls, such as when predictive models reveal sensitive information about individuals, including whether they're pregnant, will quit their job, or may be arrested - aka AI ethics.

NO HANDS-ON AND NO HEAVY MATH. Rather than a hands-on training, this course serves both business leaders and burgeoning data scientists alike by contextualizing the core technology, guiding you on the end-to-end process required to successfully deploy a predictive model so that it delivers a business impact. There are no exercises involving coding or the use of machine learning software.

WHO IT'S FOR. This concentrated entry-level program is for anyone who wishes to participate in the commercial deployment of machine learning, no matter whether you'll do so in the role of enterprise leader or quant. This includes business professionals and decision makers of all kinds, such as executives, directors, line of business managers, and consultants - as well as data scientists.

LIKE A UNIVERSITY COURSE. This course is also a good fit for college students, or for those planning for or currently enrolled in an MBA program. The breadth and depth of the overall three-course specialization is equivalent to one full-semester MBA or graduate-level course.

IN-DEPTH YET ACCESSIBLE. Brought to you by industry leader Eric Siegel - a winner of teaching awards when he was a professor at Columbia University - this curriculum stands out as one of the most thorough, engaging, and surprisingly accessible on the subject of machine learning. 

VENDOR-NEUTRAL. This specialization includes illuminating software demos of machine learning in action using SAS products. However, the curriculum is vendor-neutral and universally-applicable. The contents and learning objectives apply, regardless of which machine learning software tools you end up choosing to work with. 

PREREQUISITES. Before this course, learners should take the first of this specialization's three courses, ""The Power of Machine Learning: Boost Business, Accumulate Clicks, Fight Fraud, and Deny Deadbeats.""",3643.0,2043.0,4.8,69.0
Launching into Machine Learning,https://www.coursera.org/learn/launching-machine-learning,Data Science,Machine Learning,Google Cloud Training,"The course begins with a discussion about data: how to improve data quality and perform exploratory data analysis. We describe Vertex AI AutoML and how to build, train, and deploy an ML model without writing a single line of code. You will understand the benefits of Big Query ML. We then discuss how to optimize a machine learning (ML) model and how generalization and sampling can help assess the quality of ML models for custom training.",42439.0,30273.0,4.6,4207.0
Launching into Machine Learning em Português Brasileiro,https://www.coursera.org/learn/launching-machine-learning-br,Data Science,Machine Learning,Google Cloud Training,"Começando pela história do machine learning, vamos discutir por que as redes neurais hoje funcionam com vários problemas de ciência de dados. Depois vamos definir um problema de aprendizado supervisionado e descobrir uma boa solução usando o gradiente descendente. Isso envolve criar conjuntos de dados que permitem generalização. Vamos falar sobre os métodos que devemos usar para fazer isso de modo repetível e que viabilize a experimentação.

Objetivos do curso:
 Identificar por que o aprendizado profundo é comum atualmente
 Otimizar e avaliar os modelos usando funções de perda e métricas de desempenho
 Mitigar problemas comuns que surgem no machine learning
 Criar conjuntos de dados de treinamento, avaliação e teste repetíveis e escalonáveis",,,4.5,31.0
Launching into Machine Learning en Español,https://www.coursera.org/learn/launching-machine-learning-es,Data Science,Machine Learning,Google Cloud Training,"Comenzaremos con la historia del aprendizaje automático y discutiremos por qué las redes neuronales actualmente dan tan buenos resultados para una gran variedad de problemas de la ciencia de datos. Luego, veremos cómo configurar un problema de aprendizaje supervisado y encontrar una buena solución mediante el descenso de gradientes. Para esto, será necesario crear conjuntos de datos que permitan la generalización. Hablaremos sobre los métodos para hacerlo de una forma repetible que respalde la experimentación.

Objetivos del curso:
Identificar por qué el aprendizaje profundo es popular en la actualidad
Optimizar y evaluar modelos mediante las funciones de pérdida y las métricas de rendimiento
Mitigar problemas comunes que se presentan en el aprendizaje automático
Crear conjuntos de datos repetibles y escalables para entrenamiento, evaluación y pruebas",3033.0,2689.0,4.7,97.0
Launching into Machine Learning en Français,https://www.coursera.org/learn/launching-machine-learning-fr,Data Science,Machine Learning,Google Cloud Training,"À partir de l'histoire du machine learning, nous examinons les raisons pour lesquelles les réseaux de neurones fonctionnent si bien de nos jours dans différents problèmes liés à la science des données. Nous évoquons ensuite la façon d'aborder un problème d'apprentissage supervisé et le moyen d'y répondre en utilisant la descente de gradient. Cela implique de créer des ensembles de données menant à une généralisation ; nous évoquons les méthodes pour y parvenir de façon reproductible en utilisant l'expérimentation.

Objectifs du cours :
 Identifier les raisons pour lesquelles le deep learning est actuellement en vogue
 Optimiser et évaluer les modèles à l'aide des fonctions de perte et des statistiques de performance
 Réduire les problèmes courants qui surviennent dans le machine learning
 Créer des formations, des évaluations et des ensembles de données tests répétables et évolutifs",,,4.5,11.0
Launching into Machine Learning 日本語版,https://www.coursera.org/learn/launching-machine-learning-jp,Data Science,Machine Learning,Google Cloud Training,"機械学習の歴史を皮切りに、ニューラル ネットワークがデータ サイエンスのさまざまな問題でうまく機能している理由をご紹介します。次に、教師あり学習の問題を設定し、勾配降下法を使用して適切な解決策を見つける方法について説明します。これには、一般化が可能なデータセットの作成も含まれます。実験に対応するため、繰り返し使用できるデータセットの作成方法について解説します。

コースの目標:
 ディープ ラーニングが注目を集めている理由を理解する
 損失関数とパフォーマンス指標を使用して、モデルの最適化と評価を行う
 機械学習で発生しがちな一般的な問題を軽減する
 繰り返し使用可能でスケーラブルなトレーニング用、評価用、テスト用のデータセットを作成する",,1588.0,4.4,50.0
Le nettoyage de données,https://www.coursera.org/learn/nettoyage-de-donnees,Data Science,Data Analysis,Google Career Certificates,"Il s’agit du quatrième cours du Google Data Analytics Certificate. Ces cours vous permettront d’acquérir les compétences dont vous avez besoin pour postuler les emplois d’analyste de données de niveau junior. Dans ce cours, vous continuerez à approfondir votre compréhension de l'analytique des données et des concepts et outils utilisés par les analystes de données dans leur travail. Vous apprendrez comment vérifier et nettoyer vos données à l'aide de feuilles de calcul et de SQL, ainsi que comment vérifier et créer des rapports de vos résultats de nettoyage de données. Des analystes de données actuellement chez Google vous instruiront et vous fourniront des moyens pratiques d’accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler à des emplois d’analyste de données de niveau junior. Aucune expérience préalable n’est nécessaire.

À la fin de ce cours, vous aurez :
 - Appris comment vérifier l'intégrité des données.
 - Découvert les techniques de nettoyage de données à l'aide de feuilles de calcul 
 - Développé des requêtes SQL de base pour une utilisation sur les bases de données.
 - Appliqué les fonctions SQL de base pour le nettoyage et la transformation des données.
 - Compris comment vérifier les résultats du nettoyage de données.
 - Exploré les éléments et l'importance des rapports de nettoyage de données.",,1668.0,,
Learning SAS: Creating Formats and Labels,https://www.coursera.org/learn/learning-sas-creating-formats-and-labels,Data Science,Data Analysis,Afia Owusu-Forfie,"In this 1.03-hour long project-based course, you will learn to add LABELS to variables, use FORMATS to enhance outputs, regroup values using FORMATS, discover more on FORMAT RANGES and store your FORMATS in a FORMAT LIBRARY.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
"Learning SAS: Data Types, Naming Conventions, and Resources",https://www.coursera.org/learn/learning-sas-data-types-naming-conventions-and-resources,Data Science,Data Analysis,Afia Owusu-Forfie,"By the end of this project, you will evaluate data types, apply naming conventions and integrate external resources in your SAS programs.",,,,
Learning SAS: History and SAS Studio,https://www.coursera.org/learn/learning-sas-history-and-sas-studio,Data Science,Data Analysis,Afia Owusu-Forfie,"In this 1.25-hour long project-based course, you will learn to explain the highlights of the history of SAS, how to access and explore SAS Studio and how to transfer a NOTEPAD file into SAS Studio.

 
Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Learning SAS: Reading Raw Data from Fixed Columns,https://www.coursera.org/learn/learning-sas-reading-raw-data-from-fixed-columns,Data Science,Data Analysis,Afia Owusu-Forfie,"By the end of this project, you will be able to input raw data into SAS by applying the Formatted Input as well as embed raw data directly into SAS via the DATALINES statement.",,,,
Learning SAS: Reading Raw Data with the List Input Method,https://www.coursera.org/learn/learning-sas-reading-raw-data-with-the-list-input-method,Data Science,Data Analysis,Afia Owusu-Forfie,"In this 1.04 hour long project-based course, you will be able to read in external files using an input method called list, manipulate Missing values, place the DATALINES keyword in your program as well as INFILE statements and work with a Comma Separated Values (CSV) file. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Les Expressions Régulières en Python,https://www.coursera.org/learn/les-expressions-regulieres-en-python,Data Science,Data Analysis,Emmanuel Segui,"Dans ce cours d'une heure, basé sur un projet, vous apprendrez comment (objectif d'apprentissage 1, objectif d'apprentissage 2, objectif d'apprentissage 3). Essayez de limiter ce texte à 400-500 caractères.

Remarque : ce cours fonctionne le mieux pour les étudiants basés en Amérique du Nord. Nous nous efforçons actuellement d'apporter la même expérience dans d'autres régions.",,,,
Les Statistiques Descriptives et Inférentielles en R,https://www.coursera.org/learn/statistiques-descriptives-et-inferentielles-en-r,Data Science,Data Analysis,Emmanuel Segui,"Dans ce cours d'une heure, basé sur un projet, vous apprendrez comment effectuer des statistiques descriptives et inférentielles dans R, y compris comment résumer des statistiques descriptives, calculer des corrélations et effectuer des tests d'hypothèse dans R

Remarque : ce cours fonctionne le mieux pour les étudiants basés en Amérique du Nord. Nous nous efforçons actuellement d'apporter la même expérience dans d'autres régions.",,,,
Les bases du langage PHP,https://www.coursera.org/learn/les-bases-du-langage-php,Data Science,Machine Learning,Mirna Saad,"Dans ce cours d'une heure, basé sur un projet vous apprendrez  la définition du php,la création des variables en php,la différence entre ""echo"" et ""print"" ,quelques fonctions sur les chaînes et quelques fonctions mathèmatiques.
A la fin de ce projet, vous serez capable  d'écrire un code PHP , de créer des variables en PHP et savoir quelques fonctions PHP.",,,,
Leveraging Unstructured Data with Cloud Dataproc on Google Cloud em Português Brasileiro,https://www.coursera.org/learn/leveraging-unstructured-data-dataproc-gcp-br,Data Science,Data Analysis,Google Cloud Training,"Este curso intensivo de uma semana baseia-se nos cursos anteriores da especialização Data Engineering on Google Cloud Platform. Por meio de videoaulas, demonstrações e laboratórios práticos, você aprenderá a criar e gerenciar clusters de computação para executar jobs do Hadoop, Spark, Pig e/ou Hive no Google Cloud Platform.Você também aprenderá a acessar várias opções de armazenamento em nuvem dos clusters de computação e integrar os recursos de machine learning do Google aos respectivos programas de análise.

Nos laboratórios práticos, você criará e gerenciará os clusters do Dataproc usando o console da Web e a CLI e usará o cluster para executar jobs do Spark e Pig. Depois você criará notebooks iPython que são integrados ao BigQuery e ao armazenamento e utilizará o Spark. Por fim, você integrará as APIs de machine learning à análise de dados.
 
 Pré-requisitos
 • Noções básicas de Big Data e Machine Learning do Google Cloud Platform (ou experiência equivalente)
 • Algum conhecimento de Python",,,4.6,13.0
Life Expectancy Prediction Using Machine Learning,https://www.coursera.org/learn/life-expectancy-prediction-using-machine-learning,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will train a Linear Regression model to predict life expectancy. The dataset was initially obtained from the World Health Organization (WHO) and United Nations Websites. Data contains features such as year, status, life expectancy, adult mortality, infant deaths, percentage of expenditure, and alcohol consumption.",,,,
Limpieza de datos para el procesamiento de lenguaje natural,https://www.coursera.org/learn/limpieza-de-datos-para-el-procesamiento-de-lenguaje-natural,Data Science,Machine Learning,Hernán Daniel Merlino,"Este curso te brindará los conocimientos necesarios para la extracción, limpieza y preparación de distintas fuentes de datos para ser incluidos en un proceso de NLP.

Para realizar este curso es necesario contar con conocimientos de programación de nivel básico a medio, deseablemente conocimiento básico del lenguaje Python y es recomendable conocer el entorno de Jupyter Notebooks del entorno Anaconda.

Para desarrollar aplicaciones se va a utilizar Python 3.6 o superior. Alternativamente se puede utilizar el entorno de Anaconda con la misma versión de Python.
Como editor de código, los ejemplos van a ser editados en el Notebook de Anaconda, pero el alumno puede utilizar cualquier editor de texto que reconozca notebooks de Anaconda.
Librerías que es necesario tener instaladas para realizar el curso: NLTK, Pandas, Scikit-learn y librerías de extracción de datos.",,,4.2,11.0
Line Balancing With MILP Optimization In RStudio,https://www.coursera.org/learn/line-balancing-milp-rstudio,Data Science,Data Analysis,Moses Gummadi,"By the end of this project, you will learn to use R lpSolveAPI. You will learn to:
#    Formulate Line Balancing Problem & Determine Objective Function
#    Apply Constraints On Tasks Assignment To Stations
#    Apply The Sum Of Durations Constraints On Tasks
#    Apply Task Precedence Relationship Constraints
#    Run Optimiser, Obtain & Analyse Solution",,,,
Linear Regression and Modeling,https://www.coursera.org/learn/linear-regression-model,Data Science,Data Analysis,Mine Çetinkaya-Rundel,"This course introduces simple and multiple linear regression models. These models allow you to assess the relationship between variables in a data set and a continuous response variable. Is there a relationship between the physical attractiveness of a professor and their student evaluation scores? Can we predict the test score for a child based on certain characteristics of his or her mother? In this course, you will learn the fundamental theory behind linear regression and, through data examples, learn to fit, examine, and utilize regression models to examine relationships between multiple variables, using the free statistical software R and RStudio.",85854.0,29709.0,4.7,1609.0
Linear Regression and Multiple Linear Regression in Julia,https://www.coursera.org/learn/linear-regression-julia,Data Science,Machine Learning,Vinita Silaparasetty,"This guided project is for those who want to learn how to use Julia for linear regression and multiple linear regression. You will learn what linear regression is, how to build linear regression models in Julia and how to test the performance of your model.

While you are watching me code, you will get a cloud desktop with all the required software pre-installed. This will allow you to code along with me. After all, we learn best with active, hands-on learning.

Special Features:

1) Work with real-world stock market data.
2) Best practices and tips are provided.
3) You get a copy of the jupyter notebook that you create which acts as a handy reference guide.

Please note that the version of Julia used is 1.0.4

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.1,15.0
Linear Regression for Business Statistics,https://www.coursera.org/learn/linear-regression-business-statistics,Data Science,Data Analysis,Sharad Borle,"Regression Analysis is perhaps the single most important Business Statistics tool used in the industry. Regression is the engine behind a multitude of data analytics applications used for many forms of forecasting and prediction.  

This is the fourth course in the specialization, ""Business Statistics and Analysis"". The course  introduces you to the very important tool known as Linear Regression. You will learn to apply various procedures such as dummy variable regressions, transforming variables, and interaction effects. All these are introduced and explained using easy to understand examples in Microsoft Excel.
The focus of the course is on understanding and application, rather than detailed mathematical derivations.
Note: This course uses the ‘Data Analysis’ tool box which is standard with the Windows version of Microsoft Excel. It is also standard with the 2016 or later Mac version of Excel. However, it is not standard with earlier versions of Excel for Mac. 


WEEK 1
Module 1: Regression Analysis: An Introduction
In this module you will get introduced to the Linear Regression Model. We will build a regression model and estimate it using Excel. We will use the estimated model to infer relationships between various variables and use the model to make predictions. The module also introduces the notion of errors, residuals and R-square in a regression model.

Topics covered include:
•	Introducing the Linear Regression
•	Building a Regression Model and estimating it using Excel
•	Making inferences using the estimated model
•	Using the Regression model to make predictions
•	Errors, Residuals and R-square
 

WEEK 2
Module 2: Regression Analysis: Hypothesis Testing and Goodness of Fit
This module presents different hypothesis tests you could do using the Regression output. These tests are an important part of inference and the module introduces them using Excel based examples. The p-values are introduced along with goodness of fit measures R-square and the adjusted R-square. Towards the end of module we introduce the ‘Dummy variable regression’ which is used to incorporate categorical variables in a regression. 

Topics covered include:
•	Hypothesis testing in a Linear Regression
•	‘Goodness of Fit’ measures (R-square, adjusted R-square)
•	Dummy variable Regression (using Categorical variables in a Regression)
 

WEEK 3
Module 3: Regression Analysis: Dummy Variables, Multicollinearity
This module continues with the application of Dummy variable Regression. You get to understand the interpretation of Regression output in the presence of categorical variables. Examples are worked out to re-inforce various concepts introduced. The module also explains what is Multicollinearity and how to deal with it. 

Topics covered include:
•	Dummy variable Regression (using Categorical variables in a Regression)
•	Interpretation of coefficients and p-values in the presence of Dummy variables
•	Multicollinearity in Regression Models
 

WEEK 4
Module 4: Regression Analysis: Various Extensions
The module extends your understanding of the Linear Regression, introducing techniques such as mean-centering of variables and building confidence bounds for predictions using the Regression model. A powerful regression extension known as ‘Interaction variables’ is introduced and explained using examples. We also study the transformation of variables in a regression and in that context introduce the log-log and the semi-log regression models. 

Topics covered include:
•	Mean centering of variables in a Regression model
•	Building confidence bounds for predictions using a Regression model
•	Interaction effects in a Regression
•	Transformation of variables
•	The log-log and semi-log regression models",38660.0,55079.0,4.8,1292.0
Linear Regression with NumPy and Python,https://www.coursera.org/learn/linear-regression-numpy-python,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Linear Regression with NumPy and Python. In this project, you will do all the machine learning without using any of the popular machine learning libraries such as scikit-learn and statsmodels. The aim of this project and is to implement all the machinery, including gradient descent and linear regression, of the various learning algorithms yourself, so you have a deeper understanding of the fundamentals.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, NumPy, and Seaborn pre-installed.",21984.0,,4.5,939.0
Linear Regression with Python,https://www.coursera.org/learn/linear-regression,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn how to implement Linear Regression using Python and Numpy. Linear Regression is an important, fundamental concept if you want break into Machine Learning and Deep Learning. Even though popular machine learning frameworks have implementations of linear regression available, it's still a great idea to learn to implement it on your own to understand the mechanics of optimization algorithm, and the training process.

Since this is a practical, project-based course, you will need to have a theoretical understanding of linear regression, and gradient descent. We will focus on the practical aspect of implementing linear regression with gradient descent, but not on the theoretical aspect.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",10505.0,,4.6,416.0
Linear SVM Classification(Soft Margin) -using Scikit Learn,https://www.coursera.org/learn/linear-svm-classification,Data Science,Machine Learning,Ashish Dikshit,Linear SVM Classification(Soft Margin) -using Scikit Learn,,,,
Logistic Regression 101: US Household Income Classification,https://www.coursera.org/learn/us-household-income-bracket-classification,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will train Logistic Regression and XG-Boost models to predict whether a particular person earns less than 50,000 US Dollars or more than 50,000 US Dollars annually. This data was obtained from U.S. Census database and consists of features like occupation, age, native country, capital gain, education, and work class.

By the end of this project, you will be able to: 

- Understand the theory and intuition behind Logistic Regression and XG-Boost models
- Import key Python libraries, dataset, and perform Exploratory Data Analysis like removing missing values, replacing characters, etc.
- Perform data visualization using Seaborn.
- Prepare the data to increase the predictive power of Machine Learning models by One-Hot Encoding, Label Encoding, and Train/Test Split
- Build and train Logistic Regression and XG-Boost models to classify the Income Bracket of U.S. Household.
- Assess the performance of trained model and ensure its generalization using various KPIs such as accuracy, precision and recall.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Logistic Regression for Classification using Julia,https://www.coursera.org/learn/logistic-regression-classification-julia,Data Science,Machine Learning,Vinita Silaparasetty,"This guided project is about book genre classification using logistic regression in Julia. It is ideal for beginners who do not know what logistic regression is because this project explains these concepts in simple terms.

While you are watching me code, you will get a cloud desktop with all the required software pre-installed. This will allow you to code along with me. After all, we learn best with active, hands-on learning.

Special features:

1) Simple explanations of important concepts.
2) Use of images to aid in explanation.
3) Use a real world dataset.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Logistic Regression with NumPy and Python,https://www.coursera.org/learn/logistic-regression-numpy-python,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Logistic with NumPy and Python. In this project, you will do all the machine learning without using any of the popular machine learning libraries such as scikit-learn and statsmodels. The aim of this project and is to implement all the machinery, including gradient descent, cost function, and logistic regression, of the various learning algorithms yourself, so you have a deeper understanding of the fundamentals. By the time you complete this project, you will be able to build a logistic regression model using Python and NumPy, conduct basic exploratory data analysis, and implement gradient descent from scratch. The prerequisites for this project are prior programming experience in Python and a basic understanding of machine learning theory.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, NumPy, and Seaborn pre-installed.",11770.0,,4.5,387.0
Logistic Regression with Python and Numpy,https://www.coursera.org/learn/deep-learning-fundamentals-logistic-regression,Data Science,Machine Learning,Amit Yadav,"Welcome to this project-based course on Logistic with NumPy and Python. In this project, you will do all the machine learning without using any of the popular machine learning libraries such as scikit-learn and statsmodels. The aim of this project and is to implement all the machinery, including gradient descent, cost function, and logistic regression, of the various learning algorithms yourself, so you have a deeper understanding of the fundamentals. By the time you complete this project, you will be able to build a logistic regression model using Python and NumPy, conduct basic exploratory data analysis, and implement gradient descent from scratch. The prerequisites for this project are prior programming experience in Python and a basic understanding of machine learning theory.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, NumPy, and Seaborn pre-installed.",5986.0,,4.5,146.0
"ML Parameters Optimization: GridSearch, Bayesian, Random",https://www.coursera.org/learn/ml-parameters-optimization-gridsearch-bayesian-random,Data Science,Data Analysis,Ryan Ahmed,"Hello everyone and welcome to this new hands-on project on Machine Learning hyperparameters optimization. In this project, we will optimize machine learning regression models parameters using several techniques such as grid search, random search and Bayesian optimization. Hyperparameter optimization is a key step in developing machine learning models and it works by fine tuning ML models so they can optimally perform on a given dataset.",,,,
ML Pipelines on Google Cloud,https://www.coursera.org/learn/ml-pipelines-google-cloud,Data Science,Machine Learning,Google Cloud Training,"In this course, you will be learning from ML Engineers and Trainers who work with the state-of-the-art development of ML pipelines here at Google Cloud.  The first few modules will cover about TensorFlow Extended (or TFX), which is Google’s production machine learning platform based on TensorFlow for management of ML pipelines and metadata. You will learn about pipeline components and pipeline orchestration with TFX. You will also learn how you can automate your pipeline through continuous integration and continuous deployment, and how to manage ML metadata.

Then we will change focus to discuss how we can automate and reuse ML pipelines across multiple ML frameworks such as tensorflow, pytorch, scikit learn, and xgboost.  You will also learn how to use another tool on Google Cloud, Cloud Composer, to orchestrate your continuous training pipelines. And finally, we will go over how to use MLflow for managing the complete machine learning life cycle. 

Please take note that this is an advanced level course and to get the most out of this course, ideally you have the following prerequisites:

You have a good ML background and have been creating/deploying ML pipelines
You have completed the courses in the ML with Tensorflow on GCP specialization (or at least a few courses)
You have completed the MLOps Fundamentals course.


>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",7764.0,19292.0,3.7,52.0
ML Pipelines on Google Cloud - Français,https://www.coursera.org/learn/ml-pipelines-google-cloud-fr,Data Science,Machine Learning,Google Cloud Training,"Dans ce cours, vous profiterez de l'expérience d'ingénieurs et de formateurs en ML qui développent des pipelines de ML chez Google Cloud à l'aide de technologies de pointe. Les premiers modules porteront sur TensorFlow Extended (TFX), la plate-forme Google de machine learning de production basée sur TensorFlow et conçue pour gérer des pipelines et des métadonnées de ML. Vous explorerez les composants de pipelines et apprendrez à orchestrer des pipelines avec TFX. Vous verrez également comment automatiser vos pipelines au moyen d'une intégration et d'un déploiement continus, et comment gérer des métadonnées de ML. Ensuite, nous découvrirons comment automatiser et réutiliser des pipelines de ML sur plusieurs frameworks de ML tels que TensorFlow, PyTorch, scikit-learn et XGBoost. Vous apprendrez également à utiliser Cloud Composer, un autre outil Google Cloud, pour orchestrer vos pipelines d'entraînement continu. Enfin, nous verrons comment utiliser MLflow pour gérer l'ensemble du cycle de vie du machine learning.",,,,
ML Pipelines on Google Cloud - Português,https://www.coursera.org/learn/ml-pipelines-google-cloud-pt,Data Science,Machine Learning,Google Cloud Training,"Neste curso, você vai aprender com engenheiros e instrutores de ML que trabalham com o desenvolvimento de última geração dos pipelines de ML aqui no Google Cloud. Nos primeiros módulos, vamos abordar o TensorFlow Extended (ou TFX), que é uma plataforma de machine learning do Google baseada no TensorFlow criada para gerenciar pipelines e metadados de ML. Você vai conhecer os componentes e a orquestração de um pipeline com o TFX. Também vamos abordar como é possível automatizar os pipelines usando a integração e a implantação contínuas e como gerenciar os metadados de ML. Depois disso, vamos mudar o foco para discutir como podemos automatizar e reutilizar os pipelines de ML em vários frameworks de machine learning, como tensorflow, pytorch, scikit-learn e xgboost. Você também vai aprender a usar outra ferramenta no Google Cloud, o Cloud Composer, para orquestrar seus pipelines de treinamento contínuo. Por fim, vamos mostrar como usar o MLflow para gerenciar o ciclo de vida completo do machine learning.",,,,
ML Pipelines on Google Cloud - 日本語版,https://www.coursera.org/learn/ml-pipelines-google-cloud-ja,Data Science,Machine Learning,Google Cloud Training,このコースでは、Google Cloud で最先端の ML パイプラインに携わっている ML エンジニアおよびトレーナーたちから知識を吸収することができます。 最初のいくつかのモジュールで、ML パイプラインとメタデータの管理用 TensorFlow を基盤とする Google の本番環境向け機械学習プラットフォーム TensorFlow Extended（TFX）について説明します。パイプラインのコンポーネントについて、そして TFX を使用したパイプラインのオーケストレーションについて学習します。また、継続的インテグレーションと継続的デプロイを通じたパイプラインの自動化の方法と、ML メタデータの管理方法についても学習します。その後、焦点を変えて、TensorFlow、PyTorch、Scikit Learn、XGBoost などの複数の ML フレームワーク全体にわたる ML パイプラインの自動化と再利用の方法について説明します。 さらに、Google Cloud のもう 1 つのツール、Cloud Composer を継続的なトレーニング パイプラインのオーケストレーションに活用する方法についても学習します。最後は、MLflow を使用して機械学習の完全なライフサイクルを管理する方法の解説で締めくくります。,,,,
ML Pipelines on Google Cloud - 한국어,https://www.coursera.org/learn/ml-pipelines-google-cloud-ko,Data Science,Machine Learning,Google Cloud Training,"이 과정에서는 Google Cloud에서 최신 ML 파이프라인 개발을 담당하는 ML 엔지니어와 트레이너로부터 유익한 지식을 배웁니다. 초반에 진행되는 몇 개 모듈에서는 Google의 TensorFlow 기반 프로덕션 머신러닝 플랫폼으로서 ML 파이프라인과 메타데이터를 관리할 수 있는 TensorFlow Extended(TFX)에 대해 다룹니다. 파이프라인 구성요소와 TFX를 사용한 파이프라인 조정을 알아봅니다. 지속적 통합과 지속적 배포를 통해 파이프라인을 자동화하는 방법과 ML 메타데이터를 관리하는 방법도 배웁니다. 그런 다음 주제를 전환하여 TensorFlow, PyTorch, scikit-learn, xgboost 등 여러 ML 프레임워크에서 ML 파이프라인을 자동화하고 재사용하는 방법을 설명합니다. 또한 Google Cloud의 또 다른 도구인 Cloud Composer를 사용하여 지속적 학습 파이프라인을 조정하는 방법도 알아봅니다. 마지막으로 MLflow를 사용하여 머신러닝의 전체 수명 주기를 관리하는 방법을 살펴봅니다.",,,,
ML Pipelines on Google Cloud en Español,https://www.coursera.org/learn/ml-pipelines-google-cloud-es,Data Science,Machine Learning,Google Cloud Training,"En este curso, aprenderá de los ingenieros y capacitadores de AA que trabajan en el desarrollo de vanguardia de las canalizaciones de AA en Google Cloud. En los primeros módulos, se abordará TensorFlow Extended (o TFX), la plataforma de aprendizaje automático de producción de Google basada en TensorFlow para la administración de canalizaciones y metadatos de AA. Aprenderá sobre los componentes y la organización de las canalizaciones con TFX. También aprenderá cómo automatizar su canalización mediante la integración y la implementación continuas, y cómo administrar ML Metadata. Luego, cambiaremos el enfoque para analizar cómo podemos automatizar y volver a usar las canalizaciones de AA en múltiples frameworks de AA, como TensorFlow, PyTorch, scikit-learn y XGBoost. Además, aprenderá a usar Cloud Composer, otra herramienta de Google Cloud, para organizar sus canalizaciones de entrenamiento continuo. Por último, aprenderá a usar MLflow para administrar el ciclo de vida completo del aprendizaje automático.",,,,
ML y Big Data con PySpark para la retención de clientes,https://www.coursera.org/learn/ml-bigdata-pyspark-retencion-clientes,Data Science,Data Analysis,Leire Ahedo,"Es un curso práctico y efectivo para aprender a generar modelos de Machine Learning con PySpark en un entorno de Big Data para predecir el ""Churn"" del cliente.  Te enseñaremos desde cero los fundamentos de Spark y MLlib, y acabarás desarrollando avanzados modelos de Machine Learning con MLlib y PySpark.",,,,
ML y Power BI para incrementar las ventas en Retail,https://www.coursera.org/learn/ml-powerbi-ventas-retail,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso efectivo para aprender a analizar los datos de retail y a identificar patrones que permiten maximizar las ventas. Para ello, se aprenderá todo lo necesario acerca de las reglas de asociación y a como generar dichas reglas en Power BI.",,,4.9,14.0
ML: Diagnose the presence of Breast Cancer with Python,https://www.coursera.org/learn/diagnose-breast-cancer-python,Data Science,Machine Learning,Ikechukwu Nigel Ogbuchi,"In this 1-hour long project-based course, you will learn how to set up and run your Jupyter Notebook, load, preview and visualize data, then train, test and evaluate a machine learning model that predicts if a patient has breast cancer or not.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
MLOps (Machine Learning Operations) Fundamentals,https://www.coursera.org/learn/mlops-fundamentals,Data Science,Machine Learning,Google Cloud Training,"This course introduces participants to MLOps tools and best practices for deploying, evaluating, monitoring and operating production ML systems on Google Cloud. MLOps is a discipline focused on the deployment, testing, monitoring, and automation of ML systems in production. Machine Learning Engineering professionals use tools for continuous improvement and evaluation of deployed models. They work with (or can be) Data Scientists, who develop models, to enable velocity and rigor in deploying the best performing models.

This course is primarily intended for the following participants:
Data Scientists looking to quickly go from machine learning prototype to production to deliver business impact.
Software Engineers looking to develop Machine Learning Engineering skills.
ML Engineers who want to adopt Google Cloud for their ML production projects.



>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",28400.0,40746.0,4.0,376.0
MLOps (Machine Learning Operations) Fundamentals Português,https://www.coursera.org/learn/mlops-fundamentals-br,Data Science,Machine Learning,Google Cloud Training,"Neste curso, os participantes vão conhecer as ferramentas de MLOps e as práticas recomendadas para a implantação, avaliação, monitoramento e operação de sistemas de ML de produção no Google Cloud. MLOps é uma disciplina com foco na implantação, teste, monitoramento e automação de sistemas de ML em produção. Profissionais de engenharia de machine learning usam ferramentas para fazer melhorias contínuas e avaliações de modelos implantados. Eles trabalham com (e podem até ser) cientistas de dados que desenvolvem modelos para garantir a velocidade e o rigor na implantação de modelos com melhor desempenho.",,,,
MLOps (Machine Learning Operations) Fundamentals en Français,https://www.coursera.org/learn/mlops-fundamentals-fr,Data Science,Machine Learning,Google Cloud Training,"Ce cours présente les outils et les bonnes pratiques MLOps pour déployer, évaluer, surveiller et exploiter des systèmes de production de ML sur Google Cloud. Le MLOps est une discipline axée sur le déploiement, le test, la surveillance et l'automatisation des systèmes de ML en production. Les ingénieurs en machine learning utilisent des outils pour améliorer et évaluer en permanence les modèles déployés. Ils collaborent avec des data scientists (ou peuvent occuper ce poste) qui développent des modèles permettant de déployer de manière rapide et rigoureuse les solutions de machine learning les plus performantes.",,,,
MLOps (Machine Learning Operations) Fundamentals en español,https://www.coursera.org/learn/mlops-fundamentals-es,Data Science,Machine Learning,Google Cloud Training,"En este curso, se presentan a los participantes las herramientas y prácticas recomendadas de MLOps para implementar, evaluar, supervisar y operar sistemas de AA de producción en Google Cloud. Las MLOps son una disciplina enfocada en la implementación, prueba, supervisión y automatización de sistemas de AA en producción. Los ingenieros profesionales de aprendizaje automático usan herramientas para mejorar y evaluar continuamente los modelos implementados. Trabajan con científicos de datos (o pueden serlo) que desarrollan modelos para ofrecer velocidad y rigor en la implementación de modelos con el mejor rendimiento.",,,,
MLOps (Machine Learning Operations) Fundamentals 日本語版,https://www.coursera.org/learn/mlops-fundamentals-ja,Data Science,Machine Learning,Google Cloud Training,このコースでは、Google Cloud 上で本番環境の ML システムをデプロイ、評価、モニタリング、運用するための MLOps ツールとベスト プラクティスについて説明します。MLOps は、本番環境 ML システムのデプロイ、テスト、モニタリング、自動化に重点を置いた規範です。機械学習エンジニアリングの担当者は、ツールを活用して、デプロイしたモデルの継続的な改善と評価を行います。また、データ サイエンティストと協力して、あるいは自らがデータ サイエンティストとして、最も効果的なモデルを迅速かつ正確にデプロイできるようモデルを開発します。,,,,
MLOps (Machine Learning Operations) Fundamentals 한국어,https://www.coursera.org/learn/mlops-fundamentals-ko,Data Science,Machine Learning,Google Cloud Training,"이 과정에서는 Google Cloud에서 프로덕션 ML 시스템 배포, 평가, 모니터링, 운영을 위한 MLOps 도구와 권장사항을 소개합니다. MLOps는 프로덕션에서 ML 시스템을 배포, 테스트, 모니터링, 자동화하는 방법론입니다. 머신러닝 엔지니어링 전문가들은 배포된 모델의 지속적인 개선과 평가를 위해 도구를 사용합니다. 이들이 협력하거나 때론 그 역할을 하는 데이터 과학자는 고성능 모델을 빠르고 정밀하게 배포할 수 있도록 모델을 개발합니다.",,,,
MNIST Fashion Datensatz mit Tensorflow,https://www.coursera.org/learn/mnist-fashion-datensatz-tensorflow,Data Science,Machine Learning,Jousef Murad,MNIST Fashion Datensatz mit Tensorflow programmieren.,,,,
MYSQL Workbench إنشاء و تصميم قواعد البيانات باستخدام,https://www.coursera.org/learn/database-creation-and-modeling-using-mysqlworkbench,Data Science,Data Analysis,Omnya Khaled,"فى نهاية هذا المشروع ، سوف تكون قادرًا على تحديد وفهم أساسيات workbench MYSQL وإنشاء اتصال بالسيرفر المحلي. ستتعلم أيضًا كيفية إنشاء قاعدة بيانات جديدة ومسحها وإنشاء جداول جديدة وحذفها. علاوة على ذلك ، ستتمكن من إعادة تسمية أعمدة الجدول ، وربط الجداول ببعضها البعض وإضافة البيانات إلى الجداول. وأخيرًا ستتعلم كيفية إضافة أعمدة وتطبيق بعض الميزات بشكل احترافي على هذه الأعمدة باستخدام بعض الكلمات الرئيسية مثل PRIMARY KEY و FOREIGN KEY و NOT NULL و AUTO_INCREMENT و DISTINCT وتحديث الجداول ببيانات جديدة. يتم استخدام SQL من قبل جميع الأسماء الكبيرة في مجال التكنولوجيا مثل Netflix أو Airbnb. إذا كنت تستهدف Google أو Facebook أو Amazon ، فإن لديهم بالطبع أنظمة قواعد البيانات الخاصة بهم. لكن SQL ستكون موجودة أيضًا للاستعلام عن البيانات وتحليلها.

هذا المشروع الموجه للمبتدئين في مجال تصميم البيانات وقواعد البيانات. يوفر لك أساسيات إنشاء قاعدة البيانات بأكملها. يزودك بمعرفة الخطوات الأولى في تصميم قواعد البيانات.",,,,
Machine Learning - Anomaly Detection via PyCaret,https://www.coursera.org/learn/anomaly-detection,Data Science,Machine Learning,Muhammad Saad uddin,"In this 2 hour long project-based course you will learn how to perform anomaly detection, its importance in machine learning, set up PyCaret anomaly detection, create, visualize & compare anomaly detection algorithms all this with just a few lines of code.",,,,
Machine Learning Algorithms: Supervised Learning Tip to Tail,https://www.coursera.org/learn/machine-learning-classification-algorithms,Data Science,Machine Learning,Anna Koop,"This course takes you from understanding the fundamentals of a machine learning project. Learners will understand and implement supervised learning techniques on real case studies to analyze business case scenarios where decision trees, k-nearest neighbours and support vector machines are optimally used. Learners will also gain skills to contrast the practical consequences of different data preparation steps and describe common production issues in applied ML.

To be successful, you should have at least beginner-level background in Python programming (e.g., be able to read and code trace existing code, be comfortable with conditionals, loops, variables, lists, dictionaries and arrays). You should have a basic understanding of linear algebra (vector notation) and statistics (probability distributions and mean/median/mode).

This is the second course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute.",15038.0,3687.0,4.7,404.0
Machine Learning Data Lifecycle in Production,https://www.coursera.org/learn/machine-learning-data-lifecycle-in-production,Data Science,Machine Learning,Robert Crowe,"In the second course of Machine Learning Engineering for Production Specialization, you will build data pipelines by gathering, cleaning, and validating datasets and assessing data quality; implement feature engineering, transformation, and selection with TensorFlow Extended and get the most predictive power out of your data; and establish the data lifecycle by leveraging data lineage and provenance metadata tools and follow data evolution with enterprise data schemas.

Understanding machine learning and deep learning concepts is essential, but if you’re looking to build an effective AI career, you need production engineering capabilities as well. Machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production-ready skills. 

Week 1: Collecting, Labeling, and Validating data
Week 2: Feature Engineering, Transformation, and Selection
Week 3: Data Journey and Data Storage
Week 4: Advanced Data Labeling Methods, Data Augmentation, and Preprocessing Different Data Types",26117.0,114144.0,4.3,545.0
Machine Learning Foundations for Product Managers,https://www.coursera.org/learn/machine-learning-foundations-for-product-managers,Data Science,Machine Learning,Jon Reifschneider,"In this first course of the AI Product Management Specialization offered by Duke University's Pratt School of Engineering, you will build a foundational understanding of what machine learning is, how it works and when and why it is applied.  To successfully manage an AI team or product and work collaboratively with data scientists, software engineers, and customers you need to understand the basics of machine learning technology.  This course provides a non-coding introduction to machine learning, with focus on the process of developing models, ML model evaluation and interpretation, and the intuition behind common ML and deep learning algorithms.  The course will conclude with a hands-on project in which you will have a chance to train and optimize a machine learning model on a simple real-world problem.

At the conclusion of this course, you should be able to:
1) Explain how machine learning works and the types of machine learning
2) Describe the challenges of modeling and strategies to overcome them
3) Identify the primary algorithms used for common ML tasks and their use cases
4) Explain deep learning and its strengths and challenges relative to other forms of machine learning
5) Implement best practices in evaluating and interpreting ML models",8871.0,45261.0,4.6,93.0
Machine Learning Foundations: A Case Study Approach,https://www.coursera.org/learn/ml-foundations,Data Science,Machine Learning,"Emily Fox, Carlos Guestrin","Do you have data and wonder what it can tell you?  Do you need a deeper understanding of the core ways in which machine learning can improve your business?  Do you want to be able to converse with specialists about anything from regression and classification to deep learning and recommender systems?

In this course, you will get hands-on experience with machine learning from a series of practical case-studies.  At the end of the first course you will have studied how to predict house prices based on house-level features, analyze sentiment from user reviews, retrieve documents of interest, recommend products, and search for images.  Through hands-on practice with these use cases, you will be able to apply machine learning methods in a wide range of domains.

This first course treats the machine learning method as a black box.  Using this abstraction, you will focus on understanding tasks of interest, matching these tasks to machine learning tools, and assessing the quality of the output. In subsequent courses, you will delve into the components of this black box by examining models and algorithms.  Together, these pieces form the machine learning pipeline, which you will use in developing intelligent applications.

Learning Outcomes:  By the end of this course, you will be able to:
   -Identify potential applications of machine learning in practice.  
   -Describe the core differences in analyses enabled by regression, classification, and clustering.
   -Select the appropriate machine learning task for a potential application.  
   -Apply regression, classification, clustering, retrieval, recommender systems, and deep learning.
   -Represent your data as features to serve as input to machine learning models. 
   -Assess the model quality in terms of relevant error metrics for each task.
   -Utilize a dataset to fit a model to analyze new data.
   -Build an end-to-end application that uses machine learning at its core.  
   -Implement these techniques in Python.",365644.0,100395.0,4.6,13178.0
"Machine Learning Interpretable: SHAP, PDP y permutacion",https://www.coursera.org/learn/machine-learning-interpretable-shap-p,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a generar modelos de Machine Learning interpretables. Se explican en profundidad diferentes técnicas de interpretabilidad de modelos como: SHAP, Partial Dependence Plot, Permutation importance, etc que nos permitirá entender el porqué de las predicciones.

Gracias a esto, aprenderás a entrenar modelos Glassbox que puedas entender el porqué de sus decisiones.",,,,
Machine Learning Interpretable: interpretML y LIME,https://www.coursera.org/learn/machine-learning-interpretable-lime,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a generar modelos de Machine Learning interpretables. Se explican en profundidad diferentes técnicas de interpretabilidad de modelos como: interpretML y LIME que nos permitirá entender el porqué de las predicciones.

Gracias a esto, aprenderás a entrenar modelos Glassbox que puedas entender el porqué de sus decisiones.",,,,
Machine Learning Introduction for Everyone,https://www.coursera.org/learn/machine-learning-introduction-for-everyone,Data Science,Machine Learning,"Aije Egwaikhide, Yasmine Hemmati","This three-module course introduces machine learning and data science for everyone with a foundational understanding of machine learning models. You’ll learn about the history of machine learning, applications of machine learning, the machine learning model lifecycle, and tools for machine learning. You’ll also learn about supervised versus unsupervised learning, classification, regression, evaluating machine learning models, and more. Our labs give you hands-on experience with these machine learning and data science concepts. You will develop concrete machine learning skills as well as create a final project demonstrating your proficiency. 

After completing this program, you’ll be able to realize the potential of machine learning algorithms and artificial intelligence in different business scenarios. You’ll be able to identify when to use machine learning to explain certain behaviors and when to use it to predict future outcomes. You’ll also learn how to evaluate your machine learning models and to incorporate best practices. 

In addition to receiving a certificate from Coursera, you'll also earn an IBM Badge to help you share your accomplishments with your network and potential employer. 

This Course Is Part of Multiple Programs 

You can also leverage the learning from the program to complete the remaining two courses of the six-course IBM Machine Learning Professional Certificate and power a new career in the field of machine learning.",4711.0,21878.0,4.5,59.0
Machine Learning Modeling Pipelines in Production,https://www.coursera.org/learn/machine-learning-modeling-pipelines-in-production,Data Science,Machine Learning,Robert Crowe,"In the third course of Machine Learning Engineering for Production Specialization, you will build models for different serving environments; implement tools and techniques to effectively manage your modeling resources and best serve offline and online inference requests; and use analytics tools and performance metrics to address model fairness, explainability issues, and mitigate bottlenecks.

Understanding machine learning and deep learning concepts is essential, but if you’re looking to build an effective AI career, you need production engineering capabilities as well. Machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production-ready skills.

Week 1: Neural Architecture Search
Week 2: Model Resource Management Techniques
Week 3: High-Performance Modeling
Week 4: Model Analysis
Week 5: Interpretability",17437.0,88122.0,4.4,279.0
Machine Learning Models in Science,https://www.coursera.org/learn/machine-learning-models-in-science,Data Science,Machine Learning,"Sabrina Moore, Rajvir Dua, Neelesh Tiruviluamala","This course is aimed at anyone interested in applying machine learning techniques to scientific problems. In this course, we'll learn about the complete machine learning pipeline, from reading in, cleaning, and transforming data to running basic and advanced machine learning algorithms. We'll start with data preprocessing techniques, such as PCA and LDA. Then, we'll dive into the fundamental AI algorithms: SVMs and K-means clustering. Along the way, we'll build our mathematical and programming toolbox to prepare ourselves to work with more complicated models. Finally, we'll explored advanced methods such as random forests and neural networks. Throughout the way, we'll be using medical and astronomical datasets. In the final project, we'll apply our skills to compare different machine learning models in Python.",,3078.0,,
Machine Learning Pipelines with Azure ML Studio,https://www.coursera.org/learn/azure-machine-learning-studio-pipeline,Data Science,Machine Learning,Snehan Kekre,"In this project-based course, you are going to build an end-to-end machine learning pipeline in Azure ML Studio, all without writing a single line of code! This course uses the Adult Income Census data set to train a model to predict an individual's income. It predicts whether an individual's annual income is greater than or less than $50,000. The estimator used in this project is a Two-Class Boosted Decision Tree classifier. Some of the features used to train the model are age, education, occupation, etc. Once you have scored and evaluated the model on the test data, you will deploy the trained model as an Azure Machine Learning web service. In just under an hour, you will be able to send new data to the web service API and receive the resulting predictions.

This is the second course in this series on building machine learning applications using Azure Machine Learning Studio. I highly encourage you to take the first course before proceeding. It has instructions on how to set up your Azure ML account with $200 worth of free credit to get started with running your experiments! 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",34535.0,,4.6,652.0
Machine Learning Rapid Prototyping with IBM Watson Studio,https://www.coursera.org/learn/ibm-rapid-prototyping-watson-studio-autoai,Data Science,Machine Learning,"Mark J Grover, Meredith Mante","An emerging trend in AI is the availability of technologies in which automation is used to select a best-fit model, perform feature engineering and improve model performance via hyperparameter optimization. This automation will provide rapid-prototyping of models and allow the Data Scientist to focus their efforts on applying domain knowledge to fine-tune models. This course will take the learner through the creation of an end-to-end automated pipeline built by Watson Studio’s AutoAI experiment tool, explaining the underlying technology at work as developed by IBM Research. The focus will be on working with an auto-generated Python notebook. Learners will be provided with test data sets for two use cases.

This course is intended for practicing Data Scientists. While it showcases the automated AI capabilies of IBM Watson Studio with AutoAI, the course does not explain Machine Learning or Data Science concepts. 

In order to be successful, you should have knowledge of:

Data Science workflow
Data Preprocessing 
Feature Engineering 
Machine Learning Algorithms 
Hyperparameter Optimization
Evaluation measures for models 
Python and scikit-learn library (including Pipeline class)",,1790.0,,
"Machine Learning Under the Hood: The Technical Tips, Tricks, and Pitfalls",https://www.coursera.org/learn/machine-learning-under-the-hood,Data Science,Machine Learning,Eric Siegel,"Machine learning. Your team needs it, your boss demands it, and your career loves it. After all, LinkedIn places it as one of the top few ""Skills Companies Need Most"" and as the very top emerging job in the U.S.

If you want to participate in the deployment of machine learning (aka predictive analytics), you've got to learn how it works. Even if you work as a business leader rather than a hands-on practitioner – even if you won't crunch the numbers yourself – you need to grasp the underlying mechanics in order to help navigate the overall project. Whether you're an executive, decision maker, or operational manager overseeing how predictive models integrate to drive decisions, the more you know, the better.

And yet, looking under the hood will delight you. The science behind machine learning intrigues and surprises, and an intuitive understanding is not hard to come by. With its impact on the world growing so quickly, it's time to demystify the predictive power of data – and how to scientifically tap it.

This course will show you how machine learning works. It covers the foundational underpinnings, the way insights are gleaned from data, how we can trust these insights are reliable, and how well predictive models perform – which can be established with pretty straightforward arithmetic. These are things every business professional needs to know, in addition to the quants.

And this course continues beyond machine learning standards to also cover cutting-edge, advanced methods, as well as preparing you to circumvent prevalent pitfalls that seldom receive the attention they deserve. The course dives deeply into these topics, and yet remains accessible to non-technical learners and newcomers.

With this course, you'll learn what works and what doesn't – the good, the bad, and the fuzzy: 

– How predictive modeling algorithms work, including decision trees, logistic regression, and neural networks

– Treacherous pitfalls such as overfitting, p-hacking, and presuming causation from correlations

– How to interpret a predictive model in detail and explain how it works

– Advanced methods such as ensembles and uplift modeling (aka persuasion modeling)

– How to pick a tool, selecting from the many machine learning software options

– How to evaluate a predictive model, reporting on its performance in business terms

– How to screen a predictive model for potential bias against protected classes – aka AI ethics

IN-DEPTH YET ACCESSIBLE. Brought to you by industry leader Eric Siegel – a winner of teaching awards when he was a professor at Columbia University – this curriculum stands out as one of the most thorough, engaging, and surprisingly accessible on the subject of machine learning.

NO HANDS-ON AND NO HEAVY MATH. Rather than a hands-on training, this course serves both business leaders and burgeoning data scientists alike with expansive coverage of the state-of-the-art techniques and the most pernicious pitfalls. There are no exercises involving coding or the use of machine learning software. However, for one of the assessments, you'll perform a hands-on exercise, creating a predictive model by hand in Excel or Google Sheets and visualizing how it improves before your eyes.

BUT TECHNICAL LEARNERS SHOULD TAKE ANOTHER LOOK. Before jumping straight into the hands-on, as quants are inclined to do, consider one thing: This curriculum provides complementary know-how that all great techies also need to master. It contextualizes the core technology with a strong conceptual framework and covers topics that are generally omitted from even the most technical of courses, including uplift modeling (aka persuasion modeling) and some particularly treacherous pitfalls.

VENDOR-NEUTRAL. This course includes illuminating software demos of machine learning in action using SAS products. However, the curriculum is vendor-neutral and universally-applicable. The contents and learning objectives apply, regardless of which machine learning software tools you end up choosing to work with.

PREREQUISITES. Before this course, learners should take the first two of this specialization's three courses, ""The Power of Machine Learning"" and ""Launching Machine Learning.""",3821.0,2439.0,4.9,56.0
Machine Learning Using SAS Viya,https://www.coursera.org/learn/machine-learning-sas,Data Science,Machine Learning,"Jeff Thompson, Catherine Truxillo","This course covers the theoretical foundation for different techniques associated with supervised machine learning models. In addition, a business case study is defined to guide participants through all steps of the analytical life cycle, from problem understanding to model deployment, through data preparation, feature selection, model training and validation, and model assessment. A series of demonstrations and exercises is used to reinforce the concepts and the analytical approach to solving business problems. 

This course uses Model Studio, the pipeline flow interface in SAS Viya that enables you to prepare, develop, compare, and deploy advanced analytics models. You learn to train supervised machine learning models to make better decisions on big data. The SAS applications used in this course make machine learning possible without programming or coding.",7202.0,8056.0,4.7,95.0
Machine Learning With Big Data,https://www.coursera.org/learn/big-data-machine-learning,Data Science,Machine Learning,"Mai Nguyen, Ilkay Altintas","Want to make sense of the volumes of data you have collected?  Need to incorporate data-driven decisions into your process?  This course provides an overview of machine learning techniques to explore, analyze, and leverage data.  You will be introduced to tools and algorithms you can use to create machine learning models that learn from data, and to scale those models up to big data problems.

At the end of the course, you will be able to:
•	Design an approach to leverage data using the steps in the machine learning process.
•	Apply machine learning techniques to explore and prepare data for modeling.
•	Identify the type of machine learning problem in order to apply the appropriate set of techniques.
•	Construct models that learn from data using widely available open source tools.
•	Analyze big data problems using scalable machine learning algorithms on Spark.

Software Requirements: 
Cloudera VM, KNIME, Spark",65066.0,61038.0,4.6,2412.0
Machine Learning con Azure Machine Learning Studio,https://www.coursera.org/learn/ml-azure-machine-learning-studio,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un proyecto práctico para aprender a crear modelos de ML con Azure Machine Learning Studio. Aprenderás todos los pasos para el desarrollo de un modelo de regresión y su despliegue en producción.

No necesitaras conocimientos previos pues comenzarás desde lo más básico, como conocer el entorno de Azure o los fundamentos de ML, para llegar a lo más avanzado.",,,,
Machine Learning con Pyspark aplicado al campo sanitario,https://www.coursera.org/learn/machine-learning-pyspark-aplicado-campo-sanitario,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a generar modelos de Machine Learning en un entorno de Big Data con PySpark en proyectos sanitarios. 
Te enseñaremos desde cero las bases de PySpark hasta las funciones más complejas. Y finalmente acabarás desarrollando un modelo completo y avanzado con Spark en Jupyter Notebooks.",,,,
Machine Learning con Python. Nivel Avanzado,https://www.coursera.org/learn/machine-learning-python-nivel-avanzado,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender Machine Learning con Python. Aprenderás todos los pasos de desarrollo de un modelo y a evaluar su desempeño. 
Aprenderás de manera práctica y aplicada a desarrollar un modelo completo de Machine learning, desde el pre-procesamiento de datos hasta la validación del modelo. También aprenderás a aplicar conceptos avanzados de machine learning como: pipelines, validación cruzada o XGBoost.",,,,
Machine Learning con Python. Nivel intermedio,https://www.coursera.org/learn/machine-learning-python-nivel-intermedio,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender Machine Learning con Python. Aprenderás todos los pasos de desarrollo de un modelo y a evaluar su desempeño. Al finalizar este curso, habrás generado un proyecto completo de Machine Learning desde cero.",,,,
Machine Learning con Spark (MLlib) en Databricks,https://www.coursera.org/learn/machine-learning-spark-mllib-databricks,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a generar modelos de Machine Learning en un entorno de Big Data de Spark. Te enseñaremos a utilizar la herramienta de Big Data de Databricks. Y finalmente aprenderás, desde cero los fundamentos del MLlib en Spark y acabarás desarrollando un modelo completo y avanzado con Spark en Databricks.",,,,
Machine Learning e Data Mining in R,https://www.coursera.org/learn/machine-learning-data-mining-con-r,Data Science,Data Analysis,"Antonio Lepore, Biagio Palumbo, Carlo Sansone","Il corso Machine Learning e Data Mining in R è rivolto a chiunque voglia avere una pratica panoramica delle tecniche di apprendimento automatico, dalle più interpretabili - come l’analisi di regressione, delle componenti principali e dei gruppi - a quelle più flessibili come le reti neurali artificiali, sia shallow che deep - e le più ricorrenti problematiche di analisi e modellazione di dati e problemi reali - come collinearità, overfitting, regolarizzazione e knowledge transfer.

La modalità di erogazione del corso è di tipo learning by doing, mediante una continua implementazione in R dei concetti esposti. Le diverse unità ti verranno prima illustrate a voce, per permetterti di ricordare e capire, e poi rese disponibili sotto forma di reading, per permetterti di analizzarne criticamente il contenuto. Alla fine di ogni unità, verrai messo alla prova attraverso open Lab in ambiente di sviluppo RStudio, che ti permetteranno di applicare i metodi trattati nel corso ai tanti data set reali che ti saranno forniti. Ti verrà infine richiesto di valutare i tuoi progressi mediante graded quiz contenenti domande a risposta multipla. Non rimandare: Machine Learning e Data Mining in R sono ora a portata di mano!",,2478.0,,
Machine Learning for Accounting with Python,https://www.coursera.org/learn/machine-learning-accounting-python,Data Science,Machine Learning,Linden Lu,"This course, Machine Learning for Accounting with Python, introduces machine learning algorithms (models) and their applications in accounting problems. It covers classification, regression, clustering, text analysis, time series analysis. It also discusses model evaluation and model optimization. This course provides an entry point for students to be able to apply proper machine learning models on business related datasets with Python to solve various problems.

Accounting Data Analytics with Python is a prerequisite for this course. This course is running on the same platform (Jupyter Notebook) as that of the prerequisite course. While Accounting Data Analytics with Python covers data understanding and data preparation in the data analytics process, this course covers the next two steps in the process, modeling and model evaluation. Upon completion of the two courses, students should be able to complete an entire data analytics process with Python.",7220.0,5246.0,4.6,34.0
Machine Learning for Data Analysis,https://www.coursera.org/learn/machine-learning-data-analysis,Data Science,Machine Learning,"Jen Rose, Lisa Dierker","Are you interested in predicting future outcomes using your data? This course helps you do just that! Machine learning is the process of developing, testing, and applying predictive algorithms to achieve this goal. Make sure to familiarize yourself with course 3 of this specialization before diving into these machine learning concepts. Building on Course 3, which introduces students to integral supervised machine learning concepts, this course will provide an overview of many additional concepts, techniques, and algorithms in machine learning, from basic classification to decision trees and clustering. By completing this course, you will learn how to apply, test, and interpret machine learning algorithms as alternative methods for addressing your research questions.",43106.0,11503.0,4.2,313.0
Machine Learning for Investment Professionals,https://www.coursera.org/learn/machine-learning-investment,Data Science,Machine Learning,Anastasia Diakaki,"This course is uniquely tailored to the needs of investment professionals or those with investment industry knowledge who want to develop a basic, practical understanding of machine learning techniques and how they are used in the investment process. Incorporating real-life case studies, this course covers both the technical and the “soft skills” necessary for investment professionals to stay relevant. 

In this course, you will learn how to:
-	Distinguish between supervised and unsupervised machine learning and deep learning
-	Describe how machine learning algorithm performance is evaluated
-	Describe supervised and unsupervised machine learning algorithms and determine the problems they are best suited for
-	Describe neural networks, deep learning nets, and reinforcement learning
-	Choose an appropriate machine learning algorithm
-	Describe the value of integrating machine learning and data projects in the investment process
-	Work with data scientists and investment teams to harness information and insights from within large and alternative data sets
-	Apply the CFA Institute Ethical Decision-Making Framework to machine learning dilemmas

This course is part of the Data Science for Investment Professionals Specialization offered by CFA Institute.",,13203.0,,
Machine Learning for Kyphosis Disease Classification,https://www.coursera.org/learn/machine-learning-for-kyphosis-disease-classification,Data Science,Machine Learning,Ryan Ahmed,"The objective of this project is to predict whether a patient has kyphosis or not, based on given features and diagnostic measurements such as age and number of vertebrae. Kyphosis is an abnormally excessive convex curvature of the spine. This guided project is practical and directly applicable to the healthcare industry. You can add this project to your portfolio of projects which is essential for your next job interview.",,,,
Machine Learning for Telecom Customers Churn Prediction,https://www.coursera.org/learn/telecom-customer-churn-prediction,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train several classification algorithms such as Logistic Regression, Support Vector Machine, K-Nearest Neighbors, and Random Forest Classifier to predict the churn rate of Telecommunication Customers. Machine learning help companies analyze customer churn rate based on several factors such as services subscribed by customers, tenure rate, and payment method. Predicting churn rate is crucial for these companies because the cost of retaining an existing customer is far less than acquiring a new one.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,20.0
Machine Learning in the Enterprise,https://www.coursera.org/learn/art-science-ml,Data Science,Machine Learning,Google Cloud Training,"This course encompasses a real-world practical approach to the ML Workflow: a case study approach that presents an ML team faced with several ML business requirements and use cases. This team must understand the tools required for data management and governance and consider the best approach for data preprocessing: from providing an overview of Dataflow and Dataprep to using BigQuery for preprocessing tasks.

The team is presented with three options to build machine learning models for two specific use cases. This course explains why the team would use AutoML, BigQuery ML, or custom training to achieve their objectives. A deeper dive into custom training is presented in this course. We describe custom training requirements from training code structure, storage, and loading large datasets to exporting a trained model.

You will build a custom training machine learning model, which allows you to build a container image with little knowledge of Docker.

The case study team examines hyperparameter tuning using Vertex Vizier and how it can be used to improve model performance. To understand more about model improvement, we dive into a bit of theory: we discuss regularization, dealing with sparsity, and many other essential concepts and principles. We end with an overview of prediction and model monitoring and how Vertex AI can be used to manage ML models.",25709.0,17570.0,4.6,1419.0
"Machine Learning para series temporales con ARIMA, SARIMA...",https://www.coursera.org/learn/machine-learning-series-temporales-arima-sarima,Data Science,Machine Learning,Leire Ahedo,"Proyecto aplicado y práctico para aprender a entrenar modelos de Machine Learning como: AR, MA, ARMA, ARIMA, autoARIMA, SARIMA y autoSARIMA para predecir series temporales con Python.",,,,
Machine Learning with H2O Flow,https://www.coursera.org/learn/machine-learning-h2o-flow,Data Science,Machine Learning,Snehan Kekre,"This is a hands-on, guided introduction to using H2O Flow for machine learning. By the end of this project, you will be able to train and evaluate machine learning models with H2O Flow and AutoML, without writing a single line of code! You will use the point and click, web-based interface to H2O called Flow to solve a business analytics problem with machine learning.

H2O is a leading open-source machine learning and artificial intelligence platform trusted by data scientists and machine learning practitioners. It has APIs available in R, Python, Scala, and also a web-based point and click interface called Flow. H2O's AutoML automates the process of training and tuning a large selection of models, allowing the user to focus on other aspects of the data science and machine learning pipelines such as data pre-processing, feature engineering, and model deployment.

To get the most out of this project, we recommend that you have an understanding of basic machine learning theory, and have trained machine learning models.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4005.0,,4.7,100.0
Machine Learning with Python,https://www.coursera.org/learn/machine-learning-with-python,Data Science,Machine Learning,"SAEED AGHABOZORGI, Joseph Santarcangelo","Get ready to dive into the world of Machine Learning (ML) by using Python! This course is for you whether you want to advance your Data Science career or get started in Machine Learning and Deep Learning.  

This course will begin with a gentle introduction to Machine Learning and what it is, with topics like supervised vs unsupervised learning, linear & non-linear regression, simple regression and more.  

You will then dive into classification techniques using different classification algorithms, namely K-Nearest Neighbors (KNN), decision trees, and Logistic Regression. You’ll also learn about the importance and different types of clustering such as k-means, hierarchical clustering, and DBSCAN. 

With all the many concepts you will learn, a big emphasis will be placed on hands-on learning. You will work with Python libraries like SciPy and scikit-learn and apply your knowledge through labs. In the final project you will demonstrate your skills by building, evaluating and comparing several Machine Learning models using different algorithms.  

By the end of this course, you will have job ready skills to add to your resume and a certificate in machine learning to prove your competency.",294211.0,491608.0,4.7,13316.0
Machine Learning y Regresión con PySpark. Guía paso a paso,https://www.coursera.org/learn/machine-learning-regresion-pyspark,Data Science,Data Analysis,Leire Ahedo,"Es un curso práctico y efectivo para aprender a generar modelos de regresión (Machine Learning) con PySpark en un entorno de Big Data. Te enseñaremos desde cero los fundamentos de Spark y MLlib, y acabarás desarrollando avanzados modelos de regresión en PySpark para predecir el precio de las viviendas o el número de bicis que se alquilarán por horas.",,,,
"Machine Learning:  Predict Numbers from Handwritten Digits using a Neural Network, Keras, and R",https://www.coursera.org/learn/predict-numbers-from-handwritten-digits-neuralnetwork,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to build a Neural Network Model using Keras and the MNIST Data Set.  By the end of the course you will have built a model that will recognize the digits of hand written numbers.  You will also be exposed to One Hot Encoding, Neural Network Architecture, Loss Optimizers and Testing of the Model's performance.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4767.0,,4.4,71.0
Machine Learning:  Predict Poisonous Mushrooms using a Random Forest Model and the FFTrees Package in R,https://www.coursera.org/learn/predict-poison-mushrooms-using-random-forest,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to complete a training and test set using an R function, practice looking at data distribution using R and ggplot2, Apply a Random Forest model to the data using the FFTrees package in R, and examine the results using a Confusion Matrix.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4572.0,,4.6,95.0
Machine Learning: Classification,https://www.coursera.org/learn/ml-classification,Data Science,Machine Learning,"Emily Fox, Carlos Guestrin","Case Studies: Analyzing Sentiment & Loan Default Prediction

In our case study on analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).  In our second case study for this course, loan default prediction, you will tackle financial data, and predict when a loan is likely to be risky or safe for the bank. These tasks are an examples of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification. 

In this course, you will create classifiers that provide state-of-the-art performance on a variety of tasks.  You will become familiar with  the most successful techniques, which are most widely used in practice, including logistic regression, decision trees and boosting.  In addition, you will be able to design and implement the underlying algorithms that can learn these models at scale, using stochastic gradient ascent.  You will implement these technique on real-world, large-scale machine learning tasks.  You will also address significant tasks you will face in real-world applications of ML, including handling missing data and measuring precision and recall to evaluate a classifier.  This course is hands-on, action-packed, and full of visualizations and illustrations of how these techniques will behave on real data.  We've also included optional content in every module, covering advanced topics for those who want to go even deeper! 

Learning Objectives: By the end of this course, you will be able to:
   -Describe the input and output of a classification model.
   -Tackle both binary and multiclass classification problems.
   -Implement a logistic regression model for large-scale classification.  
   -Create a non-linear model using decision trees.
   -Improve the performance of any model using boosting.
   -Scale your methods with stochastic gradient ascent.
   -Describe the underlying decision boundaries.  
   -Build a classification model to predict sentiment in a product review dataset.  
   -Analyze financial data to predict loan defaults.
   -Use techniques for handling missing data.
   -Evaluate your models using precision-recall metrics.
   -Implement these techniques in Python (or in the language of your choice, though Python is highly recommended).",116976.0,28413.0,4.7,3681.0
Machine Learning: Clustering & Retrieval,https://www.coursera.org/learn/ml-clustering-and-retrieval,Data Science,Data Analysis,"Emily Fox, Carlos Guestrin","Case Studies: Finding Similar Documents

A reader is interested in a specific news article and you want to find similar articles to recommend.  What is the right notion of similarity?  Moreover, what if there are millions of other documents?  Each time you want to a retrieve a new document, do you need to search through all other documents?  How do you group similar documents together?  How do you discover new, emerging topics that the documents cover?   

In this third case study, finding similar documents, you will examine similarity-based algorithms for retrieval.  In this course, you will also examine structured representations for describing the documents in the corpus, including clustering and mixed membership models, such as latent Dirichlet allocation (LDA).  You will implement expectation maximization (EM) to learn the document clusterings, and see how to scale the methods using MapReduce.

Learning Outcomes:  By the end of this course, you will be able to:
   -Create a document retrieval system using k-nearest neighbors.
   -Identify various similarity metrics for text data.
   -Reduce computations in k-nearest neighbor search by using KD-trees.
   -Produce approximate nearest neighbors using locality sensitive hashing.
   -Compare and contrast supervised and unsupervised learning tasks.
   -Cluster documents by topic using k-means.
   -Describe how to parallelize k-means using MapReduce.
   -Examine probabilistic clustering approaches using mixtures models.
   -Fit a mixture of Gaussian model using expectation maximization (EM).
   -Perform mixed membership modeling using latent Dirichlet allocation (LDA).
   -Describe the steps of a Gibbs sampler and how to use its output to draw inferences.
   -Compare and contrast initialization techniques for non-convex optimization objectives.
   -Implement these techniques in Python.",91129.0,21426.0,4.7,2306.0
Machine Learning: Concepts and Applications,https://www.coursera.org/learn/machine-learning-applications,Data Science,Machine Learning,Dr. Nick Feamster,"This course gives you a comprehensive introduction to both the theory and practice of machine learning. You will learn to use Python along with industry-standard libraries and tools, including Pandas, Scikit-learn, and Tensorflow, to ingest, explore, and prepare data for modeling and then train and evaluate models using a wide variety of techniques. Those techniques include linear regression with ordinary least squares, logistic regression, support vector machines, decision trees and ensembles, clustering, principal component analysis, hidden Markov models, and deep learning.

A key feature of this course is that you not only learn how to apply these techniques, you also learn the conceptual basis underlying them so that you understand how they work, why you are doing what you are doing, and what your results mean. The course also features real-world datasets, drawn primarily from the realm of public policy. It is based on an introductory machine learning course offered to graduate students at the University of Chicago and will serve as a strong foundation for deeper and more specialized study.",,9315.0,,
Machine Learning: Regression,https://www.coursera.org/learn/ml-regression,Data Science,Machine Learning,"Emily Fox, Carlos Guestrin","Case Study - Predicting Housing Prices

In our first case study, predicting house prices, you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms,...).  This is just one of the many places where regression can be applied.  Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression.

In this course, you will explore regularized linear regression models for the task of prediction and feature selection.  You will be able to handle very large sets of features and select between models of various complexity.  You will also analyze the impact of aspects of your data -- such as outliers -- on your selected models and predictions.  To fit these models, you will implement optimization algorithms that scale to large datasets.

Learning Outcomes:  By the end of this course, you will be able to:
   -Describe the input and output of a regression model.
   -Compare and contrast bias and variance when modeling data.
   -Estimate model parameters using optimization algorithms.
   -Tune parameters with cross validation.
   -Analyze the performance of the model.
   -Describe the notion of sparsity and how LASSO leads to sparse solutions.
   -Deploy methods to select between models.
   -Exploit the model to form predictions. 
   -Build a regression model to predict prices using a housing dataset.
   -Implement these techniques in Python.",149857.0,49587.0,4.8,5501.0
Machine Teaching for Autonomous AI,https://www.coursera.org/learn/machine-teaching-ai,Data Science,Machine Learning,Kence Anderson,"Just as teachers help students gain new skills, the same is true of artificial intelligence (AI). Machine learning algorithms can adapt and change, much like the learning process itself. Using the machine teaching paradigm, a subject matter expert (SME) can teach AI to improve and optimize a variety of systems and processes. The result is an autonomous AI system.  

In this course, you’ll learn how automated systems make decisions and how to approach building an AI system that will outperform current capabilities. Since 87% of machine learning systems fail in the proof-concept phase, it’s important you understand how to analyze an existing system and determine whether it’d be a good fit for machine teaching approaches. For your course project, you’ll select an appropriate use case, interview a SME about a process, and then flesh out a story for why and how you might go about building an autonomous AI system. 

At the end of this course, you’ll be able to: 
•	Describe the concept of machine teaching 
•	Explain the role that SMEs play in training advanced AI 
•	Evaluate the pros and cons of leveraging human expertise in the design of AI systems 
•	Differentiate between automated and autonomous decision-making systems 
•	Describe the limitations of automated systems and humans in real-time decision-making 
•	Select use cases where autonomous AI will outperform both humans and automated systems 
•	Propose an autonomous AI solution to a real-world problem 
•	Validate your design against existing expertise and techniques for solving problems

This course is part of a specialization called Autonomous AI for Industry, which will launch in fall 2022.",1782.0,9948.0,4.6,11.0
Machine Translation,https://www.coursera.org/learn/machinetranslation,Data Science,Machine Learning,"Alexander Waibel, Jan Niehues","Welcome to the CLICS-Machine Translation MOOC

This MOOC explains the basic principles of machine translation. Machine translation is the task of translating from one natural language to another natural language. Therefore, these algorithms can help people communicate in different languages. Such algorithms are used in common applications, from Google Translate to apps on your mobile device.

After taking this course you will be able to understand the main difficulties of translating natural languages and the principles of different machine translation approaches. A main focus of the course will be the current state-of-the-art neural machine translation technology which uses deep learning methods to model the translation process. You will be able to decide which concepts fit your machine translation application best.

This course is taught by Prof. Dr. Alexander Waibel (http://isl.anthropomatik.kit.edu/english/21_74.php) and Assistant Professor Dr. Jan Niehus (https://www.maastrichtuniversity.nl/jan.niehues).",10246.0,21673.0,4.6,107.0
Machine/Deep Learning for Mining Quality Prediction-Enhanced,https://www.coursera.org/learn/machinedeep-learning-for-mining-quality-prediction-enhanced,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train machine learning and deep learning models to predict the % of Silica Concentrate in the Iron ore concentrate per minute. This project could be practically used in Mining Industry to get the % Silica Concentrate at much faster rate compared to the traditional methods.",,,,
Malaria parasite detection using ensemble learning in Keras,https://www.coursera.org/learn/malaria-parasite-detection-ensemble-learning-keras,Data Science,Machine Learning,Sherif A. Tawfik Abbas,"In this 1-hour long project-based course, you will learn what ensemble learning is and how to implement is using python. You will create deep convolutional neural networks using the Keras library to predict the malaria parasite. You will learn various ways of assessing classification models. You will create an ensemble of deep convolutional neural networks and apply voting in order to combine the best predictions of your models.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Managing Big Data in Clusters and Cloud Storage,https://www.coursera.org/learn/cloud-storage-big-data-analysis-sql,Data Science,Data Analysis,"Ian Cook, Glynn Durham","In this course, you'll learn how to manage big datasets, how to load them into clusters and cloud storage, and how to apply structure to the data so that you can run queries on it using distributed SQL engines like Apache Hive and Apache Impala. You’ll learn how to choose the right data types, storage systems, and file formats based on which tools you’ll use and what performance you need.

By the end of the course, you will be able to
• use different tools to browse existing databases and tables in big data systems;
• use different tools to explore files in distributed big data filesystems and cloud storage;
• create and manage big data databases and tables using Apache Hive and Apache Impala; and
• describe and choose among different data types and file formats for big data systems.

To use the hands-on environment for this course, you need to download and install a virtual machine and the software on which to run it. Before continuing, be sure that you have access to a computer that meets the following hardware and software requirements:
• Windows, macOS, or Linux operating system (iPads and Android tablets will not work)
• 64-bit operating system (32-bit operating systems will not work)
• 8 GB RAM or more
• 25GB free disk space or more
• Intel VT-x or AMD-V virtualization support enabled (on Mac computers with Intel processors, this is always enabled;
on Windows and Linux computers, you might need to enable it in the BIOS)
• For Windows XP computers only: You must have an unzip utility such as 7-Zip or WinZip installed (Windows XP’s built-in unzip utility will not work)",10644.0,14624.0,4.7,272.0
Managing Big Data with MySQL,https://www.coursera.org/learn/analytics-mysql,Data Science,Data Analysis,"Daniel Egger, Jana Schaich Borg","This course is an introduction to how to use relational databases in business analysis.  You will learn how relational databases work, and how to use entity-relationship diagrams to display the structure of the data held within them.  This knowledge will help you understand how data needs to be collected in business contexts, and help you identify features you want to consider if you are involved in implementing new data collection efforts.  You will also learn how to execute the most useful query and table aggregation statements for business analysts, and practice using them with real databases. No more waiting 48 hours for someone else in the company to provide data to you – you will be able to get the data by yourself!

By the end of this course, you will have a clear understanding of how relational databases work, and have a portfolio of queries you can show potential employers. Businesses are collecting increasing amounts of information with the hope that data will yield novel insights into how to improve businesses. Analysts that understand how to access this data – this means you! – will have a strong competitive advantage in this data-smitten business world.",177770.0,59752.0,4.7,3966.0
Managing Machine Learning Projects,https://www.coursera.org/learn/managing-machine-learning-projects,Data Science,Machine Learning,Jon Reifschneider,"This second course of the AI Product Management Specialization by Duke University's Pratt School of Engineering focuses on the practical aspects of managing machine learning projects.  The course walks through the keys steps of a ML project from how to identify good opportunities for ML through data collection, model building, deployment, and monitoring and maintenance of production systems.  Participants will learn about the data science process and how to apply the process to organize ML efforts, as well as the key considerations and decisions in designing ML systems.

At the conclusion of this course, you should be able to:
1) Identify opportunities to apply ML to solve problems for users
2) Apply the data science process to organize ML projects
3) Evaluate the key technology decisions to make in ML system design
4) Lead ML projects from ideation through production using best practices",3122.0,16641.0,4.7,43.0
Managing Machine Learning Projects with Google Cloud,https://www.coursera.org/learn/machine-learning-business-professionals,Data Science,Machine Learning,Google Cloud Training,"Business professionals in non-technical roles have a unique opportunity to lead or influence machine learning projects. If you have questions about machine learning and want to understand how to use it, without the technical jargon, this course is for you. Learn how to translate business problems into machine learning use cases and vet them for feasibility and impact. Find out how you can discover unexpected use cases, recognize the phases of an ML project and considerations within each, and gain confidence to propose a custom ML use case to your team or leadership or translate the requirements to a technical team.",111576.0,13099.0,4.6,3582.0
"Managing, Describing, and Analyzing Data",https://www.coursera.org/learn/managing-describing-analyzing-data,Data Science,Probability and Statistics,Wendy Martin,"In this course, you will learn the basics of understanding the data you have and why correctly classifying data is the first step to making correct decisions. You will describe data both graphically and numerically using descriptive statistics and R software. You will learn four probability distributions commonly used in the analysis of data. You will analyze data sets using the appropriate probability distribution. Finally, you will learn the basics of sampling error, sampling distributions, and errors in decision-making.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",2747.0,8224.0,4.5,22.0
Manipulate R data frames using SQL in RStudio,https://www.coursera.org/learn/manipulate-r-data-frames-using-sql-rstudio,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Have you ever wondered how SQL queries work in R? Have you ever thought about whether it is possible to use or write SQL queries in R? Then, you are in the right place. This project-based course Manipulate R data frames using SQL in RStudio is for people who are learning R and who may be well-versed in SQL or even for experienced R programmers who seek useful ways for data manipulation in R. It is for people who are interested in advancing their knowledge and skills in using SQL in R. In this project, we will write very nice queries to manipulate the gapminder and UCBAdmissions R data frames using the sqldf package in RStudio. This project is extremely important for you as an R and SQL user. You will understand how the SQL SELECT statement works to interact with R to get the desired result. We will start this hands-on project by installing and importing the required packages and data sets for this project. Be rest assured that you will learn a ton of good work here.
By the end of this 2-hour-long project, you will be able to use SELECT statements together with the WHERE clause to set conditions on data retrieved from R data frames.  Also, you will understand how to use the WHERE clause together with other SQL operators like AND, OR, IN, NOT IN, BETWEEN- AND, NOT BETWEEN- AND, and other comparison operators to retrieve data from the data frames. Going forward, we will consider how to use wildcard characters with the LIKE and NOT LIKE operators for pattern matching. By extension, we will learn how to create data summaries or aggregates using SQL aggregate functions.
In this project, we will move systematically by first introducing the SELECT statements using simple examples. Then, we will write slightly complex queries to solve some SQL challenges. Therefore, to complete this project, it is required that you have prior experience with using SQL and R. I recommend that you should complete the projects titled: “Getting Started with R” and “Querying Databases using SQL SELECT statements” before you take this current project. These introductory projects in using SQL and R will provide every necessary foundation to complete this current project. However, if you are comfortable writing queries in SQL, please join me on this wonderful ride! Let’s get our hands dirty!",,,,
Master Data Analysis with Pandas: Learning Path 1 (Enhanced),https://www.coursera.org/learn/master-data-analysis-with-pandas-learning-path-1-enhanced,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on guided project, we will master the fundamentals of data analysis and manipulation with Pandas and Python. Pandas is a super powerful, fast, flexible and easy to use open-source data analysis and manipulation tool. This guided project is the first of a series of multiple guided projects (learning path) that is designed for anyone who wants to master data analysis with pandas.",,,,
Mastering Data Analysis in Excel,https://www.coursera.org/learn/analytics-excel,Data Science,Data Analysis,"Jana Schaich Borg, Daniel Egger","Important: The focus of this course is on math - specifically, data-analysis concepts and methods - not on Excel for its own sake. We use Excel to do our calculations, and all math formulas are given as Excel Spreadsheets, but we do not attempt to cover Excel Macros, Visual Basic, Pivot Tables, or other intermediate-to-advanced Excel functionality.

This course will prepare you to design and implement realistic predictive models based on data. In the Final Project (module 6) you will assume the role of a business data analyst for a bank, and develop two different predictive models to determine which applicants for credit cards should be accepted and which rejected. Your first model will focus on minimizing default risk, and your second on maximizing bank profits. The two models should demonstrate to you in a practical, hands-on way the idea that your choice of business metric drives your choice of an optimal model.

The second big idea this course seeks to demonstrate is that your data-analysis results cannot and should not aim to eliminate all uncertainty. Your role as a data-analyst is to reduce uncertainty for decision-makers by a financially valuable increment, while quantifying how much uncertainty remains. You will learn to calculate and apply to real-world examples the most important uncertainty measures used in business, including classification error rates, entropy of information, and confidence intervals for linear regression.

All the data you need is provided within the course, all assignments are designed to be done in MS Excel, and you will learn enough Excel to complete all assignments. The course will give you enough practice with Excel to become fluent in its most commonly used business functions, and you’ll be ready to learn any other Excel functionality you might need in the future (module 1).

The course does not cover Visual Basic or Pivot Tables and you will not need them to complete the assignments. All advanced concepts are demonstrated in individual Excel spreadsheet templates that you can use to answer relevant questions. You will emerge with substantial vocabulary and practical knowledge of how to apply business data analysis methods based on binary classification (module 2), information theory and entropy measures (module 3), and linear regression (module 4 and 5), all using no software tools more complex than Excel.",330277.0,58096.0,4.2,3864.0
Mastering Data Analysis with Pandas,https://www.coursera.org/learn/learning-path-data-analysis-with-pandas,Data Science,Data Analysis,Ryan Ahmed,"In this structured series of hands-on guided projects, we will master the fundamentals of data analysis and manipulation with Pandas and Python. Pandas is a super powerful, fast, flexible and easy to use open-source data analysis and manipulation tool. This guided project is the first of a series of multiple guided projects (learning path) that is designed for anyone who wants to master data analysis with pandas.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4486.0,,4.6,103.0
Mastering Data Analysis with Pandas: Learning Path Part 2,https://www.coursera.org/learn/mastering-data-analysis-with-pandas-learning-path-part-2,Data Science,Data Analysis,Ryan Ahmed,"In this structured series of hands-on guided projects, we will master the fundamentals of data analysis and manipulation with Pandas and Python. Pandas is a super powerful, fast, flexible and easy to use open-source data analysis and manipulation tool. This guided project is the second of a series of multiple guided projects (learning path) that is designed for anyone who wants to master data analysis with pandas.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.7,17.0
Mastering Data Analysis with Pandas: Learning Path Part 3,https://www.coursera.org/learn/mastering-data-analysis-with-pandas-learning-path-part-3,Data Science,Data Analysis,Ryan Ahmed,"In this structured series of hands-on guided projects, we will master the fundamentals of data analysis and manipulation with Pandas and Python. Pandas is a super powerful, fast, flexible and easy to use open-source data analysis and manipulation tool. This guided project is the third of a series of multiple guided projects (learning path) that is designed for anyone who wants to master data analysis with pandas.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Mastering Data Analysis with Pandas: Learning Path Part 4,https://www.coursera.org/learn/mastering-data-analysis-with-pandas-learning-path-part-4,Data Science,Data Analysis,Ryan Ahmed,"In this structured series of hands-on guided projects, we will master the fundamentals of data analysis and manipulation with Pandas and Python. Pandas is a super powerful, fast, flexible and easy to use open-source data analysis and manipulation tool. This guided project is the fourth of a series of multiple guided projects (learning path) that is designed for anyone who wants to master data analysis with pandas.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Mastering Data Analysis with Pandas: Learning Path Part 5,https://www.coursera.org/learn/mastering-data-analysis-with-pandas-learning-path-part-5,Data Science,Data Analysis,Ryan Ahmed,"In this structured series of hands-on guided projects, we will master the fundamentals of data analysis and manipulation with Pandas and Python. Pandas is a super powerful, fast, flexible and easy to use open-source data analysis and manipulation tool. This guided project is the fifth of a series of multiple guided projects (learning path) that is designed for anyone who wants to master data analysis with pandas.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Mastering SQL Joins,https://www.coursera.org/learn/mastering-sql-joins,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"In this 2-hour long project-based course, you will understand how to use SQL joins like INNER JOIN, LEFT JOIN, and RIGHT JOIN to get a desired result set. In addition, you will learn how to use SQL Joins with the WHERE clause and with aggregate functions. By extension, you will learn how to join more than two tables in the database.

Note: You do not need to be a data administrator or data analyst expert to be successful in this guided project, just you have to be familiar with querying databases using SQL SELECT statement to get the most of this project. If you are not familiar with SQL and want to learn the basics, start with my previous guided projects titled “Performing Data definition and Manipulation in SQL"", “Querying Databases using SQL SELECT statement” and “Performing Data Aggregation using SQL Aggregate Functions”",4403.0,,4.3,86.0
Mastering Software Development in R Capstone,https://www.coursera.org/learn/r-capstone,Data Science,Data Analysis,"Roger D. Peng, PhD, Brooke Anderson",R Programming Capstone,1743.0,,4.0,43.0
Math behind Moneyball,https://www.coursera.org/learn/mathematics-sport,Data Science,Data Analysis,Professor Wayne Winston,"Learn how probability, math, and statistics can be used to help baseball, football and basketball teams improve, player and lineup selection as well as in game strategy.",15262.0,11444.0,4.4,94.0
Mathematical Biostatistics Boot Camp 2,https://www.coursera.org/learn/biostatistics-2,Data Science,Probability and Statistics,"Brian Caffo, PhD","Learn fundamental concepts in data analysis and statistical inference, focusing on one and two independent samples.",18661.0,6918.0,4.3,116.0
Mathematics for Machine Learning: Linear Algebra,https://www.coursera.org/learn/linear-algebra-machine-learning,Data Science,Machine Learning,"David Dye, Samuel J. Cooper, A. Freddie Page","In this course on Linear Algebra we look at what linear algebra is and how it relates to vectors and matrices. Then we look through what vectors and matrices are and how to work with them, including the knotty problem of eigenvalues and eigenvectors, and how to use these to solve problems. Finally  we look at how to use these to do fun things with datasets - like how to rotate images of faces and how to extract eigenvectors to look at how the Pagerank algorithm works.

Since we're aiming at data-driven applications, we'll be implementing some of these ideas in code, not just on pencil and paper. Towards the end of the course, you'll write code blocks and encounter Jupyter notebooks in Python, but don't worry, these will be quite short, focussed on the concepts, and will guide you through if you’ve not coded before.

At the end of this course you will have an intuitive understanding of vectors and matrices that will help you bridge the gap into linear algebra problems, and how to apply these concepts to machine learning.",305257.0,343798.0,4.7,11148.0
Mathematics for Machine Learning: PCA,https://www.coursera.org/learn/pca-machine-learning,Data Science,Machine Learning,Marc Peter Deisenroth,"This intermediate-level course introduces the mathematical foundations to derive Principal Component Analysis (PCA), a fundamental dimensionality reduction technique. We'll cover some basic statistics of data sets, such as mean values and variances, we'll compute distances and angles between vectors using inner products and derive orthogonal projections of data onto lower-dimensional subspaces. Using all these tools, we'll then derive PCA as a method that minimizes the average squared reconstruction error between data points and their reconstruction.

At the end of this course, you'll be familiar with important mathematical concepts and you can implement PCA all by yourself. If you’re struggling, you'll find a set of jupyter notebooks that will allow you to explore properties of the techniques and walk you through what you need to do to get on track. If you are already an expert, this course may refresh some of your knowledge.

The lectures, examples and exercises require:
1. Some ability of abstract thinking
2. Good background in linear algebra (e.g., matrix and vector algebra, linear independence, basis)
3. Basic background in multivariate calculus (e.g., partial derivatives, basic optimization)
4. Basic knowledge in python programming and numpy

Disclaimer: This course is substantially more abstract and requires more programming than the other two courses of the specialization. However, this type of abstract thinking, algebraic manipulation and programming is necessary if you want to understand and develop machine learning algorithms.",72469.0,72646.0,4.0,2863.0
MatplotLib Python باستخدام  plots إنشاء ال,https://www.coursera.org/learn/creating-plots-using-matplotlib-python-ar,Data Science,Data Analysis,Omnya Khaled,"في نهاية هذا المشروع ، ستتمكن من إضافة البيانات الموجودة في ملف csv إلى Pandas data frame ، ورسم    graphمع  تغيير نوع marker ولونها. ستتمكن أيضًا من تطبيق labels وتغيير حجم الخط وإضافة grid lines وlegends. أخيرًا ، ستتمكن من إنشاء boxplot وحفظ graph  كصورة باستخدام مكتبات matplotlib و seaborn  ، وهم أهم مكتبات في لغة python الذين يستخدمون  فى ال Data Visualization.

هذا المشروع الإرشادى مخصص للأشخاص في مجال تحليل البيانات. الأشخاص الذين يرغبون في تعلم Python و Pandas. يوفر لك الخطوات المهمة لتكون محلل بيانات. ايضا  ، فإنه يزودك بالمعرفة في هياكل البيانات الأصلية لpython",,,,
Matrix Factorization and Advanced Techniques,https://www.coursera.org/learn/matrix-factorization,Data Science,Machine Learning,"Michael D. Ekstrand, Joseph A Konstan","In this course you will learn a variety of matrix factorization and hybrid machine learning techniques for recommender systems.  Starting with basic matrix factorization, you will understand both the intuition and the practical details of building recommender systems based on reducing the dimensionality of the user-product preference space.  Then you will learn about techniques that combine the strengths of different algorithms into powerful hybrid recommenders.",14392.0,3879.0,4.3,184.0
Meaningful Predictive Modeling,https://www.coursera.org/learn/meaningful-predictive-modeling,Data Science,Data Analysis,"Julian McAuley, Ilkay Altintas","This course will help us to evaluate and compare the models we have developed in previous courses. So far we have developed techniques for regression and classification, but how low should the error of a classifier be (for example) before we decide that the classifier is ""good enough""? Or how do we decide which of two regression algorithms is better?

By the end of this course you will be familiar with diagnostic techniques that allow you to evaluate and compare classifiers, as well as performance measures that can be used in different regression and classification scenarios. We will also study the training/validation/test pipeline, which can be used to ensure that the models you develop will generalize well to new (or ""unseen"") data.",5627.0,3593.0,4.4,46.0
Measurement Systems Analysis,https://www.coursera.org/learn/measurement-systems-analysis,Data Science,Probability and Statistics,Wendy Martin,"In this course, you will learn to analyze measurement systems for process stability and capability and why having a stable measurement process is imperative prior to performing any statistical analysis. You will analyze continuous measurement systems and statistically characterize both accuracy and precision using R software. You will perform measurement systems analysis for potential, short-term and long-term statistical control and capability. Additionally, you will learn how to assess a discrete measurement and perform analyses for internal consistency, concordance between assessors, and concordance with a standard. Finally, you will learn how to make decisions on measurement systems process improvement.

This specialization can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",,2106.0,,
Measurement – Turning Concepts into Data,https://www.coursera.org/learn/measurement-turning-concepts-data,Data Science,Data Analysis,"Jennifer Bachner, PhD","This course provides a framework for how analysts can create and evaluate quantitative measures.  Consider the many tricky concepts that are often of interest to analysts, such as health, educational attainment and trust in government.  This course will explore various approaches for quantifying these concepts.  The course begins with an overview of the different levels of measurement and ways to transform variables.  We’ll then discuss how to construct and build a measurement model.  We’ll next examine surveys, as they are one of the most frequently used measurement tools.  As part of this discussion, we’ll cover survey sampling, design and evaluation.  Lastly, we’ll consider different ways to judge the quality of a measure, such as by its level of reliability or validity.  By the end of this course, you should be able to develop and critically assess measures for concepts worth study.  After all, a good analysis is built on good measures.",1872.0,3027.0,4.8,59.0
Measuring Total Data Quality,https://www.coursera.org/learn/measuring-total-data-quality,Data Science,Data Analysis,"Brady T. West, James Wagner, Jinseok Kim, Trent D Buskirk","By the end of this second course in the Total Data Quality Specialization, learners will be able to:

1. Learn various metrics for evaluating Total Data Quality (TDQ) at each stage of the TDQ framework.
2. Create a quality concept map that tracks relevant aspects of TDQ from a particular application or data source.
3. Think through relative trade-offs between quality aspects, relative costs and practical constraints imposed by a particular project or study.
4. Identify relevant software and related tools for computing the various metrics.
5. Understand metrics that can be computed for both designed and found/organic data.
6. Apply the metrics to real data and interpret their resulting values from a TDQ perspective.

This specialization as a whole aims to explore the Total Data Quality framework in depth and provide learners with more information about the detailed evaluation of total data quality that needs to happen prior to data analysis. The goal is for learners to incorporate evaluations of data quality into their process as a critical component for all projects. We sincerely hope to disseminate knowledge about total data quality to all learners, such as data scientists and quantitative analysts, who have not had sufficient training in the initial steps of the data science process that focus on data collection and evaluation of data quality. We feel that extensive knowledge of data science techniques and statistical analysis procedures will not help a quantitative research study if the data collected/gathered are not of sufficiently high quality.

This specialization will focus on the essential first steps in any type of scientific investigation using data: either generating or gathering data, understanding where the data come from, evaluating the quality of the data, and taking steps to maximize the quality of the data prior to performing any kind of statistical analysis or applying data science techniques to answer research questions. Given this focus, there will be little material on the analysis of data, which is covered in myriad existing Coursera specializations. The primary focus of this specialization will be on understanding and maximizing data quality prior to analysis.",,1710.0,,
Medical Diagnosis using Support Vector Machines,https://www.coursera.org/learn/medical-diagnosis-support-vector-machines,Data Science,Machine Learning,Daniel Romaniuk,"In this one hour long project-based course, you will learn the basics of support vector machines using Python and scikit-learn.  The dataset we are going to use comes from the National Institute of Diabetes and Digestive and Kidney Diseases, and contains anonymized diagnostic measurements for a set of female patients.  We will train a support vector machine to predict whether a new patient has diabetes based on such measurements. By the end of this course, you will be able to model an existing dataset with the goal of making predictions about new data.  This is a first step on the path to mastering machine learning.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2091.0,,4.5,61.0
Medical Insurance Premium Prediction with Machine Learning,https://www.coursera.org/learn/medical-insurance-premium-prediction-with-machine-learning,Data Science,Machine Learning,Ryan Ahmed,"In this 1-hour long project-based course, you will learn how to predict medical insurance cost with machine learning. The objective of this case study is to predict the health insurance cost incurred by Individuals based on their age, gender, Body Mass Index (BMI), number of children, smoking habits, and geo-location.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Mempersiapkan Data untuk Eksplorasi,https://www.coursera.org/learn/mempersiapkan-data-untuk-eksplorasi,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi ketiga dalam program Sertifikat Analitik Data Google (Google Data Analytics Certificate). Materi ini akan membekali Anda dengan keterampilan yang Anda butuhkan untuk melamar pekerjaan analis data tingkat pemula. Selagi Anda terus membangun pemahaman tentang topik-topik pada dua materi pertama, Anda juga akan diperkenalkan dengan topik baru yang akan membantu Anda mendapatkan keterampilan praktis analitik data. Anda akan mempelajari cara menggunakan alat seperti spreadsheet dan SQL untuk mengekstrak dan menggunakan data yang tepat untuk tujuan Anda dan cara mengatur dan melindungi data Anda. Para analis data Google akan mengajarkan dan memberi tahu Anda berbagai cara untuk menyelesaikan tugas umum analis data dengan menggunakan peralatan dan sumber daya terbaik.

Peserta didik yang menyelesaikan program sertifikasi ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak membutuhkan pengalaman apa pun.

Di akhir materi ini, Anda akan:
 - Mencari tahu bagaimana analis memutuskan data mana yang akan dikumpulkan untuk analisis.
 - Mempelajari tentang data terstruktur dan tidak terstruktur, tipe data, dan format data.
 - Mengetahui cara mengidentifikasi berbagai jenis bias dalam data untuk membantu memastikan kredibilitas data. 
 - Mengeksplorasi bagaimana analis menggunakan spreadsheet dan SQL dengan database dan dataset.
 - Memeriksa open data dan hubungan antara dan pentingnya etika data dan privasi data.
 - Mendapatkan pemahaman tentang cara mengakses database dan mengekstrak, menyaring, dan mengurutkan data yang ada di sana.
 - Mempelajari praktik terbaik untuk mengatur data dan menjaganya agar tetap aman.",3803.0,479709.0,4.9,182.0
Memproses Data dari Kotor ke Bersih,https://www.coursera.org/learn/memproses-data-dari-kotor-ke-bersih,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi pertama dalam program Sertifikat Analitik Data Google. Materi ini akan membekali Anda dengan keterampilan yang Anda butuhkan untuk melamar pekerjaan analis data tingkat pemula. Dalam materi ini, Anda akan terus meningkatkan pemahaman tentang analitis data dan konsep dan peralatan yang digunakan para analis data dalam pekerjaan mereka. Anda akan mempelajari cara memeriksa dan membersihkan data menggunakan spreadsheet dan SQL serta cara memverifikasi dan melaporkan hasil pembersihan data Anda. Para analis data Google akan mengajarkan dan memberi tahu Anda berbagai cara untuk menyelesaikan tugas umum analis data dengan menggunakan peralatan dan sumber daya terbaik.

Pembelajar yang menyelesaikan program sertifikat ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak dibutuhkan pengalaman apa pun.

Pada akhir materi ini, Anda akan mampu:
 - Mempelajari cara memeriksa integritas data.
 - Mengetahui teknik pembersihan data menggunakan spreadsheet. 
 - Mengembangkan kueri SQL sederhana untuk digunakan pada database.
 - Menerapkan fungsi SQL sederhana untuk membersihkan dan mengubah data.
 - Memahami cara memverifikasi hasil pembersihan data.
 - Mengeksplorasi elemen-elemen dan arti penting laporan pembersihan data.",3242.0,414450.0,4.9,131.0
Menganalisis Data untuk Menjawab Pertanyaan,https://www.coursera.org/learn/menganalisis-data-untuk-menjawab-pertanyaan,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi kelima dalam program Google Data Analytics Certificate. Materi ini akan membekali Anda dengan keterampilan yang dibutuhkan untuk melamar pekerjaan analis data tingkat pemula. Dalam pelatihan ini, Anda akan menjelajahi fase ""analisis"" dari proses analisis data. Terapkan apa yang telah dipelajari sejauh ini pada analisis Anda untuk memahami data yang telah Anda kumpulkan. Anda akan belajar cara mengatur dan memformat data menggunakan spreadsheet dan SQL untuk membantu melihat dan memikirkan data dengan cara yang berbeda. Anda juga akan mengetahui cara melakukan perhitungan kompleks pada data untuk menyelesaikan tujuan bisnis. Anda akan belajar cara menggunakan formula, fungsi, dan kueri SQL saat melakukan analisis. Para analis data Google akan mengajarkan dan memberi tahu Anda berbagai cara untuk menyelesaikan tugas umum analis data dengan menggunakan peralatan dan sumber daya terbaik.

Pembelajar yang menyelesaikan program sertifikat ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak membutuhkan pengalaman apa pun.

Di akhir materi ini, Anda akan:
 - Mempelajari cara mengatur data untuk analisis.
 - Memahami proses untuk memformat dan menyesuaikan data. 
 - Memperoleh pemahaman tentang cara mengumpulkan data dalam spreadsheet dan dengan menggunakan SQL.
 - Menggunakan formula dan fungsi dalam spreadsheet untuk perhitungan data.
 - Mempelajari cara menyelesaikan perhitungan menggunakan kueri SQL.",2806.0,413501.0,4.9,98.0
"Merge, Sort and Filter Data in Python Pandas",https://www.coursera.org/learn/python-pandas-merge-sort-filter,Data Science,Data Analysis,David Dalsveen,"Visualizing data patterns often involves re-arrangement and elimination to determine patterns. For example, in a list of data with yearly rainfall amounts, to quickly determine the years with the most rainfall, the data can be sorted according to rainfall in descending order. A filter could be used to limit the amount of data observed, for example, to only show rainfall amounts greater than an inch. A merge can be used to join two datasets together, for example rainfall and temperature data from two different sources. The ability to sort, merge and filter data has always existed using SQL with database data, now it can be done in application memory space using Python.

In this course, you will create an application that reads data from two CSV files. You will learn how to merge, sort, and filter the data to ultimately produce a regression plot to determine a possible correlation between two data sets.",3733.0,,4.5,100.0
Metodologia de Ciência de Dados,https://www.coursera.org/learn/data-science-methodology-pt,Data Science,Data Analysis,"Alex Aklson, Polong Lin","Apesar do recente aumento do poder da computação e do acesso a dados nas últimas décadas, nossa capacidade de usar os dados em um processo de decisão é frequentemente perdida ou não maximizada. Não temos uma compreensão sólida da pergunta que está sendo feita e como aplicar os dados corretamente à questão.

Este curso busca compartilhar uma metodologia que possa ser usada dentro da ciência de dados, para garantir que os dados usados em resoluções de problemas sejam relevantes e devidamente operados.

Assim, neste curso, você aprenderá:
    - As principais etapas da resolução de problemas de ciência de dados.
    - As principais etapas da prática da ciência de dados, desde a formação de um negócio concreto ou problema de pesquisa, à coleta e análise de dados, construção de um modelo, e ao entendimento de feedback após a implementação do modelo.
    - Como cientistas de dados pensam!

OFERTA POR TEMPO LIMITADO: inscrições por apenas US$ 39 por mês com acesso a materiais avaliados e um certificado.",,,,
Metodología de la ciencia de datos,https://www.coursera.org/learn/metodologia-de-la-ciencia-de-datos,Data Science,Data Analysis,"Alex Aklson, Polong Lin","A pesar del reciente aumento de la potencia informática y el acceso a los datos durante las últimas dos décadas, nuestra capacidad para utilizar los datos en el proceso de toma de decisiones se pierde o no se maximiza con demasiada frecuencia, no tenemos una comprensión sólida de las preguntas que se hacen y cómo aplicar los datos correctamente al problema en cuestión.

Este curso tiene un propósito, y es compartir una metodología que se pueda utilizar dentro de la ciencia de datos, para garantizar que los datos utilizados en la resolución de problemas sean relevantes y se manipulen adecuadamente para abordar la cuestión en cuestión.

En consecuencia, en este curso aprenderá:
    - Los principales pasos necesarios para abordar un problema de ciencia de datos.
    - Los principales pasos involucrados en la práctica de la ciencia de datos, desde la formación de un negocio concreto o un problema de investigación, hasta la recopilación y análisis de datos, la construcción de un modelo y la comprensión de los comentarios después de la implementación del modelo.
    - ¡Cómo piensan los científicos de datos!

OFERTA POR TIEMPO LIMITADO: La suscripción cuesta solo $ 39 USD por mes para acceder a materiales calificados y un certificado.",2463.0,100600.0,4.8,92.0
Microsoft Azure Databricks for Data Engineering,https://www.coursera.org/learn/microsoft-azure-databricks-for-data-engineering,Data Science,Data Analysis, Microsoft,"In this course, you will learn how to harness the power of Apache Spark and powerful clusters running on the Azure Databricks platform to run large data engineering workloads in the cloud.

You will discover the capabilities of Azure Databricks and the Apache Spark notebook for processing huge files. You will come to understand the Azure Databricks platform and identify the types of tasks well-suited for Apache Spark. You will also be introduced to the architecture of an Azure Databricks Spark Cluster and Spark Jobs. You will work with large amounts of data from multiple sources in different raw formats.  you will learn how Azure Databricks supports day-to-day data-handling functions, such as reads, writes, and queries.

This course is part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services for anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). You will take a practice exam that covers key skills measured by the certification exam.

This is the eighth course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",5509.0,59846.0,4.6,36.0
Microsoft Azure Machine Learning,https://www.coursera.org/learn/microsoft-azure-machine-learning,Data Science,Machine Learning, Microsoft,"Machine learning is at the core of artificial intelligence, and many modern applications and services depend on predictive machine learning models. Training a machine learning model is an iterative process that requires time and compute resources. Automated machine learning can help make it easier. In this course, you will learn how to use Azure Machine Learning to create and publish models without writing code.

This course will help you prepare for Exam AI-900: Microsoft Azure AI Fundamentals. This is the second course in a five-course program that prepares you to take the AI-900 certification exam. This course teaches you the core concepts and skills that are assessed in the AI fundamentals exam domains.  This beginner course is suitable for IT personnel who are just beginning to work with Microsoft Azure and want to learn about Microsoft Azure offerings and get hands-on experience with the product. Microsoft Azure AI Fundamentals can be used to prepare for other Azure role-based certifications like Microsoft Azure Data Scientist Associate or Microsoft Azure AI Engineer Associate, but it is not a prerequisite for any of them.

This course is intended for candidates with both technical and non-technical backgrounds. Data science and software engineering experience is not required; however, some general programming knowledge or experience would be beneficial.  To be successful in this course, you need to have basic computer literacy and proficiency in the English language. You should be familiar with basic computing concepts and terminology,  general technology concepts, including concepts of machine learning and artificial intelligence.",5432.0,18312.0,4.7,114.0
Microsoft Azure Machine Learning for Data Scientists,https://www.coursera.org/learn/microsoft-azure-machine-learning-for-data-scientist,Data Science,Machine Learning, Microsoft,"Machine learning is at the core of artificial intelligence, and many modern applications and services depend on predictive machine learning models. Training a machine learning model is an iterative process that requires time and compute resources. Automated machine learning can help make it easier. In this course, you will learn how to use Azure Machine Learning to create and publish models without writing code.

This is the second course in a five-course program that prepares you to take the DP-100: Designing and Implementing a Data Science Solution on Azurecertification exam.

The certification exam is an opportunity to prove knowledge and expertise operate machine learning solutions at a cloud-scale using Azure Machine Learning. This specialization teaches you to leverage your existing knowledge of Python and machine learning to manage data ingestion and preparation, model training and deployment, and machine learning solution monitoring in Microsoft Azure. Each course teaches you the concepts and skills that are measured by the exam. 

This Specialization is intended for data scientists with existing knowledge of Python and machine learning frameworks like Scikit-Learn, PyTorch, and Tensorflow, who want to build and operate machine learning solutions in the cloud. It teaches data scientists how to create end-to-end solutions in Microsoft Azure. Students will learn how to manage Azure resources for machine learning; run experiments and train models; deploy and operationalize machine learning solutions, and implement responsible machine learning. They will also learn to use Azure Databricks to explore, prepare, and model data; and integrate Databricks machine learning processes with Azure Machine Learning.",3075.0,21236.0,4.6,41.0
Microsoft Azure for Data Engineering,https://www.coursera.org/learn/microsoft-azure-dp-203-data-engineering,Data Science,Data Analysis, Microsoft,"The world of data has evolved and the advent of cloud technologies is providing new opportunities for businesses to explore. In this course, you will learn the various data platform technologies available, and how a Data Engineer can take advantage of this technology to an organization's benefit.

This course part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). 

This is the first course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",13121.0,64846.0,4.5,243.0
Migrating an application and data from Apache Cassandra™ to DataStax Enterprise,https://www.coursera.org/learn/googlecloud-migrating-an-application-and-data-from-apache-cassandra-tm-to-tnrgn,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Mining Quality Prediction Using Machine & Deep Learning,https://www.coursera.org/learn/mining-quality-prediction,Data Science,Machine Learning,Ryan Ahmed,"In this 1.5-hour long project-based course, you will be able to:
- Understand the theory and intuition behind Simple and Multiple Linear Regression.
- Import Key python libraries, datasets and perform data visualization
- Perform exploratory data analysis and standardize the training and testing data.
- Train and Evaluate different regression models using Sci-kit Learn library.
- Build and train an Artificial Neural Network to perform regression.
- Understand the difference between various regression models KPIs such as MSE, RMSE, MAE, R2, and adjusted R2.
- Assess the performance of regression models and visualize the performance of the best model using various KPIs.",4451.0,,4.8,49.0
Modelaje y Análisis con información georreferenciada,https://www.coursera.org/learn/modelaje-anlisis-informacin-georreferenciada,Data Science,Data Analysis,"Germán Enrique Bravo Córdoba, Andrés Ernesto Guhl Corpas","El curso modelaje y análisis con información georreferenciada busca que comprendas la diversidad y el potencial de los datos geográficos. En el curso podrás utilizarlos en ejemplos básicos para modelar, procesar y analizar problemas donde la ubicación juega un rol importante. Todo esto con el fin de encontrar soluciones que te permiten un primer acercamiento práctico para el procesamiento de este tipo de datos no tradicionales.

El curso está dirigido a personas con intereses relacionados a explorar la información geográfica, uso de plataformas para el manejo de información de observación de la tierra, que tengan buen nivel de comprensión lectora en inglés, sepan leer mapas y tengan conocimiento básico sobre programación. El lenguaje utilizado es Python y se proveen tutoriales básicos que permiten entender y desarrollar las actividades planteadas.

Este curso requiere de la instalación de un programa especial, es recomendable que el equipo cuente con las siguientes especificaciones minimas:

Computador con mínimo 8 GB de Memoria RAM.  
Sistema Operativo Windows 10  
Espacio en disco disponible 20 GB  
Conexión a internet estable para descargar información geográfica",,,,
Modeling Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-modelling-data,Data Science,Data Analysis,"Carrie Wright, PhD, Shannon Ellis, PhD, Stephanie Hicks, PhD, Roger D. Peng, PhD","Developing insights about your organization, business, or research project depends on effective modeling and analysis of the data you collect. Building effective models requires understanding the different types of questions you can ask and how to map those questions to your data. Different modeling approaches can be chosen to detect interesting patterns in the data and identify hidden relationships.

This course covers the types of questions you can ask of data and the various modeling approaches that you can apply. Topics covered include hypothesis testing, linear regression, nonlinear modeling, and machine learning. With this collection of tools at your disposal, as well as the techniques learned in the other courses in this specialization, you will be able to make key discoveries from your data for improving decision-making throughout your organization.

In this specialization we assume familiarity with the R programming language. If you are not yet familiar with R, we suggest you first complete R Programming before returning to complete this course.",,3186.0,,
Modeling Time Series and Sequential Data,https://www.coursera.org/learn/modeling-time-series-and-sequential-data,Data Science,Data Analysis,"Chip Wells, Ari Zitin, Danny Modlin","In this course you learn to build, refine, extrapolate, and, in some cases, interpret models designed for a single, sequential series. There are three modeling approaches presented. The traditional, Box-Jenkins approach for modeling time series is covered in the first part of the course. This presentation moves students from models for stationary data, or ARMA, to models for trend and seasonality, ARIMA, and concludes with information about specifying transfer function components in an ARIMAX, or time series regression, model. A Bayesian approach to modeling time series is considered next. The basic Bayesian framework is extended to accommodate autoregressive variation in the data as well as dynamic input variable effects. Machine learning algorithms for time series is the third approach. Gradient boosting and recurrent neural network algorithms are particularly well suited for accommodating nonlinear relationships in the data. Examples are provided to build intuition on the effective use of these algorithms. 

The course concludes by considering how forecasting precision can be improved by combining the strengths of the different approaches. The final lesson includes demonstrations on creating combined (or ensemble) and hybrid model forecasts.

This course is appropriate for analysts interested in augmenting their machine learning skills with analysis tools that are appropriate for assaying, modifying, modeling, forecasting, and managing data that consist of variables that are collected over time. 

This course uses a variety of different software tools. Familiarity with Base SAS, SAS/ETS, SAS/STAT, and SAS Visual Forecasting, as well as open-source tools for sequential data handling and modeling, is helpful but not required. The lessons on Bayesian analysis and machine learning models assume some prior knowledge of these topics. One way that students can acquire this background is by completing these SAS Education courses: Bayesian Analyses Using SAS and Machine Learning Using SAS Viya.",,2544.0,,
Modelling with WARP PLS,https://www.coursera.org/learn/warp-pls,Data Science,Data Analysis,Shalini Gopalkrishnan ,"In this 1-hour long project-based course, you will learn how to  create path models using Smartpls. We will take a project on changing behavior and check if attitudes or subjective norms impact behavior the most.
 We will learn how to launch this new software, create the model and run it. We will then show you how to interpret the same. We will also learn how to create models for different groups such as males and females and if there is a difference between them.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Modelos predictivos con aprendizaje automático,https://www.coursera.org/learn/modelos-predictivos-con-aprendizaje-automatico,Data Science,Machine Learning,Haydemar Nuñez Castro ,"Este curso te va a brindar conocimientos, tanto teóricos como prácticos, para que puedas construir modelos predictivos utilizando técnicas de aprendizaje automático (en inglés, machine learning). Estos modelos nos permiten anticipar en alguna medida eventos futuros y, en consecuencia, pueden ser utilizados para apoyar la toma de decisiones en las organizaciones y, en general, en cualquier dominio de aplicación.   

El curso consta de 4 módulos, cada uno de una semana, en los cuales vas a tener la oportunidad de conocer y analizar diferentes casos de estudio con el objetivo de que tengas un panorama amplio de las aplicaciones de los modelos predictivos.  

En el primer módulo estudiaremos algunos fundamentos del aprendizaje automático y te mostraremos ejemplos de proyectos que pueden ser realizados con estas técnicas. El segundo módulo lo dedicaremos a la tarea de regresión y cómo construir modelos de predicción numérica con algoritmos lineales. A continuación, en el tercer módulo, estudiaremos algunos conceptos importantes en el aprendizaje supervisado, como la complejidad de modelos y la capacidad de generalización. Veremos entonces algunas técnicas que te permitirán mejorar el rendimiento de tus modelos. Por último, en el cuarto módulo, estudiaremos la tarea de clasificación y cómo construir modelos predictivos con algoritmos basados en árboles de decisión. 

Este curso está pensado para personas de diferentes disciplinas que quieran adentrarse en el mundo del aprendizaje automático y sus aplicaciones en el análisis de información, que estén iniciando estudios universitarios o con un título profesional. El aspirante a tomar este curso puede provenir de cualquier campo del conocimiento y estar incorporado en cualquier ámbito industrial, empresarial o académico.   

Este curso requiere la instalación de un programa especial (Anaconda/Jupyter Notebook). Es recomendable que el equipo cuente con más de 4GB de RAM y espacio en disco duro superior a 1GB.",,6612.0,4.8,13.0
Modern Regression Analysis in R,https://www.coursera.org/learn/modern-regression-analysis-in-r,Data Science,Probability and Statistics,Brian Zaharatos,"This course will provide a set of foundational statistical modeling tools for data science. In particular, students will be introduced to methods, theory, and applications of linear statistical models, covering the topics of parameter estimation, residual diagnostics, goodness of fit, and various strategies for variable selection and model comparison. Attention will also be given to the misuse of statistical models and ethical implications of such misuse.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Logo adapted from photo by Vincent Ledvina on Unsplash",3245.0,28911.0,4.2,17.0
Modèles de séquence,https://www.coursera.org/learn/nlp-sequence-models-fr,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Cette formation vous apprendra à construire des modèles pour le langage naturel, l’audio et les autres données de séquence. Grâce à l’apprentissage profond, les algorithmes de séquence fonctionnent beaucoup mieux qu’il y a deux ans ; nous disposons donc de nombreuses applications très intéressantes en matière de reconnaissance vocale, de synthèse musicale, de chatbots, de traduction automatique, de compréhension naturelle du langage, etc.

Vous allez:
- Comprendre comment construire et former des réseaux neuronaux récurrents (RNN) et des variantes couramment utilisées telles que les GRU et les LSTM.
-  Être capable d’appliquer des modèles de séquence à des problèmes de langage naturel, y compris la synthèse de texte.
-  Pouvoir appliquer des modèles de séquence à des applications audio, incluant la reconnaissance vocale et la synthèse musicale.

C’est le cinquième et dernier cours de la spécialisation Apprentissage profond.

deeplearning.ai travaille également en partenariat avec le NVIDIA Deep Learning Institute (DLI) dans le cours 5, Modèles de séquence, afin de fournir une affectation de programmation sur la traduction automatique avec l’apprentissage en profondeur. Vous aurez la possibilité de construire un projet d’apprentissage en profondeur avec un contenu de pointe, pertinent pour l’industrie.",,,,
Moneyball and Beyond,https://www.coursera.org/learn/moneyball-and-beyond,Data Science,Data Analysis,Stefan Szymanski,"The book Moneyball triggered a revolution in the analysis of performance statistics in professional sports, by showing that data analytics could be used to increase team winning percentage. This course shows how to program data using Python to test the claims that lie behind the Moneyball story, and to examine the evolution of Moneyball statistics since the book was published. The learner is led through the process of calculating baseball performance statistics from publicly available datasets. The course progresses from the analysis of on base percentage and slugging percentage to more advanced measures derived using the run expectancy matrix, such as wins above replacement (WAR). By the end of this course the learner will be able to use these statistics to conduct their own team and  player analyses.",1961.0,7492.0,4.7,35.0
MongoDB Aggregation Framework,https://www.coursera.org/learn/mongodb-aggregation-framework,Data Science,Data Analysis,"Nathan Leniz, Kirby Kohlmorgen","This course will teach you how to perform data analysis using MongoDB's powerful Aggregation Framework.

You'll begin this course by building a foundation of essential aggregation knowledge. By understanding these features of the Aggregation Framework you will learn how to ask complex questions of your data. This will lay the groundwork for the remainder of the course where you'll dive deep and learn about schema design, relational data migrations, and machine learning with 
MongoDB.

By the end of this course you'll understand how to best use MongoDB and its Aggregation Framework in your own data science workflow.",9394.0,6497.0,4.5,51.0
Multiple Linear Regression with scikit-learn,https://www.coursera.org/learn/scikit-learn-multiple-linear-regression,Data Science,Machine Learning,Snehan Kekre,"In this 2-hour long project-based course, you will build and evaluate multiple linear regression models using Python. You will use scikit-learn to calculate the regression, while using pandas for data management and seaborn for data visualization. The data for this project consists of the very popular Advertising dataset to predict sales revenue based on advertising spending through media such as TV, radio, and newspaper. 

By the end of this project, you will be able to:

- Build univariate and multivariate linear regression models using scikit-learn
- Perform Exploratory Data Analysis (EDA) and data visualization with seaborn
- Evaluate model fit and accuracy using numerical measures such as R² and RMSE
- Model interaction effects in regression using basic feature engineering techniques

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, this means instant access to a cloud desktop with Jupyter Notebooks and Python 3.7 with all the necessary libraries pre-installed.

Notes:
- You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7696.0,,4.5,342.0
Music Recommender System Using Pyspark,https://www.coursera.org/learn/musics-recommender-system-using-pyspark,Data Science,Data Analysis,Ahmad Varasteh,"Nowadays, recommender systems are everywhere. for example, Amazon uses recommender systems to suggest some products that you might be interested in based on the products you've bought earlier. Or Spotify will suggest new tracks based on the songs you use to listen to every day. Most of these recommender systems use some algorithms which are based on Matrix factorization such as NMF( NON NEGATIVE MATRIX FACTORIZATION) or ALS (Alternating Least Square).

So in this Project, we are going to use ALS Algorithm to create a Music Recommender system to suggest new tracks to different users based upon the songs they've been listening to. As a very important prerequisite of this course, I suggest you study a little bit about ALS Algorithm because in this course we will not cover any theoretical concepts.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,20.0
NLP Modelos y Algoritmos,https://www.coursera.org/learn/nlp-modelos-y-algoritmos,Data Science,Machine Learning,Hernán Daniel Merlino,"Este curso te brindará los conocimientos necesarios para la implementación de algoritmos de NLP. Mediante el uso de los últimos algoritmos más populares en NLP se procederá a dar solución a un conjunto de problemas propios del área.

Para realizar este curso es necesario contar con conocimientos de programación de nivel básico a medio, deseablemente conocimiento básico del lenguaje Python y es recomendable conocer los Jupyter Notebooks en el entorno Anaconda.

Para desarrollar aplicaciones se va a utilizar Python 3.6 o superior. Alternativamente se puede utilizar el entorno de Anaconda con la misma versión de Python.
Como editor de código, los ejemplos van a ser editados en el Notebook de Anaconda, pero el alumno puede utilizar cualquier editor de texto que reconozca notebooks de Anaconda.
Librerías que es necesario tener instaladas para realizar el curso: NLTK, Scikit-learn, Spacy y TensorFlow.",,,,
NLP System Architecture and Dev-Ops,https://www.coursera.org/learn/nlp-system-architecture-and-dev-ops,Data Science,Machine Learning,Hernán Daniel Merlino,"Este curso te brindará los conocimientos necesarios para la implementación de algoritmos de NLP. Mediante el uso de los últimos algoritmos más populares en NLP se procederá a dar solución a un conjunto de problemas propios del área.

Para realizar este curso es necesario contar con conocimientos de programación de nivel básico a medio, deseablemente conocimiento básico del lenguaje Python y es recomendable conocer los Jupyter Notebooks en el entorno Anaconda.

Para desarrollar aplicaciones se va a utilizar Python 3.6 o superior. Alternativamente se puede utilizar el entorno de Anaconda con la misma versión de Python.
Como editor de código, los ejemplos van a ser editados en el Notebook de Anaconda, pero el alumno puede utilizar cualquier editor de texto que reconozca notebooks de Anaconda.
Librerías que es necesario tener instaladas para realizar el curso: NLTK, Scikit-learn, Spacy y TensorFlow.",,,,
NLP: Twitter Sentiment Analysis,https://www.coursera.org/learn/twitter-sentiment-analysis,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train a Naive Bayes classifier to predict sentiment from thousands of Twitter tweets. This project could be practically used by any company with social media presence to automatically predict customer's sentiment (i.e.: whether their customers are happy or not). The process could be done automatically without having humans manually review thousands of tweets and customer reviews. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9960.0,,4.6,332.0
Naive Bayes 101: Resume Selection with Machine Learning,https://www.coursera.org/learn/resume-selector-using-naive-bayes,Data Science,Data Analysis,Ryan Ahmed,"In this project, we will build a Naïve Bayes Classifier to predict whether a given resume text is flagged or not. Our training data consist of 125 resumes with 33 flagged resumes and 92 non flagged resumes. This project could be practically used to screen resumes in companies.",,,4.5,11.0
Named Entity Recognition using LSTMs with Keras,https://www.coursera.org/learn/named-entity-recognition-lstm-keras-tensorflow,Data Science,Machine Learning,Snehan Kekre,"In this 1-hour long project-based course, you will use the Keras API with TensorFlow as its backend to build and train a bidirectional LSTM neural network model to recognize named entities in text data. Named entity recognition models can be used to identify mentions of people, locations, organizations, etc. Named entity recognition is not only a standalone tool for information extraction, but it also an invaluable preprocessing step for many downstream natural language processing applications like machine translation, question answering, and text summarization. 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Keras pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",5717.0,,4.3,169.0
Natural Language Processing and Capstone Assignment,https://www.coursera.org/learn/natural-language-processing-captsone-assignment,Data Science,Data Analysis,"Dursun Delen, Julie Pai","Welcome to Natural Language Processing and Capstone Assignment. In this course we will begin with an Recognize how technical and business techniques can be used to deliver business insight, competitive intelligence, and consumer sentiment. The course concludes with a capstone assignment in which you will apply a wide range of what has been covered in this specialization.",1572.0,2798.0,4.6,21.0
Natural Language Processing in Microsoft Azure,https://www.coursera.org/learn/nlp-microsoft-azure,Data Science,Machine Learning, Microsoft,"Natural language processing supports applications that can see, hear, speak with, and understand users. Using text analytics, translation, and language understanding services, Microsoft Azure makes it easy to build applications that support natural language.

In this course, you will learn how to use the Text Analytics service for advanced natural language processing of raw text for sentiment analysis, key phrase extraction, named entity recognition, and language detection. You will learn how to recognize and synthesize speech by using Azure Cognitive Services. You will gain an understanding of how automated translation capabilities in an AI solution enable closer collaboration by removing language barriers. You will be introduced to the Language Understanding service, and shown how to create applications that understand language.

This course will help you prepare for Exam AI-900: Microsoft Azure AI Fundamentals. This is the fourth course in a five-course program that prepares you to take the AI-900 certification exam. This course teaches you the core concepts and skills that are assessed in the AI fundamentals exam domains.  

This beginner course is suitable for IT personnel who are just beginning to work with Microsoft Azure and want to learn about Microsoft Azure offerings and get hands-on experience with the product. Microsoft Azure AI Fundamentals can be used to prepare for other Azure role-based certifications like Microsoft Azure Data Scientist Associate or Microsoft Azure AI Engineer Associate, but it is not a prerequisite for any of them.

This course is intended for candidates with both technical and non-technical backgrounds. Data science and software engineering experience is not required; however, some general programming knowledge or experience would be beneficial.  To be successful in this course, you need to have basic computer literacy and proficiency in the English language. You should be familiar with basic computing concepts and terminology,  general technology concepts, including machine learning and artificial intelligence concepts.",2598.0,7998.0,4.7,45.0
Natural Language Processing in TensorFlow,https://www.coursera.org/learn/natural-language-processing-tensorflow,Data Science,Machine Learning,Laurence Moroney,"If you are a software developer who wants to build scalable AI-powered algorithms, you need to understand how to use the tools to build them. This Specialization will teach you best practices for using TensorFlow, a popular open-source framework for machine learning.

In Course 3 of the deeplearning.ai TensorFlow Specialization, you will build natural language processing systems using TensorFlow. You will learn to process text, including tokenizing and representing sentences as vectors, so that they can be input to a neural network. You’ll also learn to apply RNNs, GRUs, and LSTMs in TensorFlow. Finally, you’ll get to train an  LSTM on existing text to create original poetry!

The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization.",111556.0,169785.0,4.6,6052.0
Natural Language Processing on Google Cloud,https://www.coursera.org/learn/sequence-models-tensorflow-gcp,Data Science,Machine Learning,Google Cloud Training,"This course is an introduction to sequence models and their applications, including an overview of sequence model architectures and how to handle inputs of variable length.

• Predict future values of a time-series
• Classify free form text
• Address time-series and text problems with recurrent neural networks
• Choose between RNNs/LSTMs and simpler models
• Train and reuse word embeddings in text problems

You will get hands-on practice building and optimizing your own text classification and sequence models on a variety of public datasets in the labs we’ll work on together.  

Prerequisites: Basic SQL, familiarity with Python and TensorFlow",15605.0,8145.0,4.4,477.0
Natural Language Processing with Attention Models,https://www.coursera.org/learn/attention-models-in-nlp,Data Science,Machine Learning,"Younes Bensouda Mourri, Łukasz Kaiser, Eddy Shyu","In Course 4 of the Natural Language Processing Specialization, you will:

a) Translate complete English sentences into German using an encoder-decoder attention model,
b) Build a Transformer model to summarize text, 
c) Use T5 and BERT models to perform question-answering, and
d) Build a chatbot using a Reformer model. 


By the end of this Specialization, you will have designed NLP applications that perform question-answering and sentiment analysis, created tools to translate languages and summarize text, and even built a chatbot!   

Learners should have a working knowledge of machine learning, intermediate Python including experience with a deep learning framework (e.g., TensorFlow, Keras), as well as proficiency in calculus, linear algebra, and statistics. Please make sure that you’ve completed course 3 - Natural Language Processing with Sequence Models - before starting this course.
   
This Specialization is designed and taught by two experts in NLP, machine learning, and deep learning. Younes Bensouda Mourri is an Instructor of AI at Stanford University who also helped build the Deep Learning Specialization. Łukasz Kaiser is a Staff Research Scientist at Google Brain and the co-author of Tensorflow, the Tensor2Tensor and Trax libraries, and the Transformer paper.",45121.0,95015.0,4.3,809.0
Natural Language Processing with Classification and Vector Spaces,https://www.coursera.org/learn/classification-vector-spaces-in-nlp,Data Science,Machine Learning,"Younes Bensouda Mourri, Łukasz Kaiser, Eddy Shyu","In Course 1 of the Natural Language Processing Specialization, you will:   

a) Perform sentiment analysis of tweets using logistic regression and then naïve Bayes, 
b) Use vector space models to discover relationships between words and use PCA to reduce the dimensionality of the vector space and visualize those relationships, and
c) Write a simple English to French translation algorithm using pre-computed word embeddings and locality-sensitive hashing to relate words via approximate k-nearest neighbor search.  
    
  
By the end of this Specialization, you will have designed NLP applications that perform question-answering and sentiment analysis, created tools to translate languages and summarize text, and even built a chatbot!   
   
This Specialization is designed and taught by two experts in NLP, machine learning, and deep learning. Younes Bensouda Mourri is an Instructor of AI at Stanford University who also helped build the Deep Learning Specialization. Łukasz Kaiser is a Staff Research Scientist at Google Brain and the co-author of Tensorflow, the Tensor2Tensor and Trax libraries, and the Transformer paper.",118829.0,243109.0,4.6,3676.0
Natural Language Processing with Probabilistic Models,https://www.coursera.org/learn/probabilistic-models-in-nlp,Data Science,Machine Learning,"Younes Bensouda Mourri, Łukasz Kaiser, Eddy Shyu","In Course 2 of the Natural Language Processing Specialization, you will:

a) Create a simple auto-correct algorithm using minimum edit distance and dynamic programming,
b) Apply the Viterbi Algorithm for part-of-speech (POS) tagging, which is vital for computational linguistics,
c) Write a better auto-complete algorithm using an N-gram language model, and 
d) Write your own Word2Vec model that uses a neural network to compute word embeddings using a continuous bag-of-words model.


By the end of this Specialization, you will have designed NLP applications that perform question-answering and sentiment analysis, created tools to translate languages and summarize text, and even built a chatbot!

This Specialization is designed and taught by two experts in NLP, machine learning, and deep learning. Younes Bensouda Mourri is an Instructor of AI at Stanford University who also helped build the Deep Learning Specialization. Łukasz Kaiser is a Staff Research Scientist at Google Brain and the co-author of Tensorflow, the Tensor2Tensor and Trax libraries, and the Transformer paper.",50909.0,125529.0,4.7,1436.0
Natural Language Processing with PyCaret,https://www.coursera.org/learn/nlp-with-pycaret,Data Science,Machine Learning,Muhammad Saad uddin,"In this project you will learn how to set up PyCaret for your natural language processing tasks, compare and create models effectively, visualize your models and corpus. All this with just a few lines of code.",,,,
Natural Language Processing with Sequence Models,https://www.coursera.org/learn/sequence-models-in-nlp,Data Science,Machine Learning,"Younes Bensouda Mourri, Łukasz Kaiser, Eddy Shyu","In Course 3 of the Natural Language Processing Specialization, you will:

a) Train a neural network with GLoVe word embeddings to perform sentiment analysis of tweets,
b) Generate synthetic Shakespeare text using a Gated Recurrent Unit (GRU) language model,
c) Train a recurrent neural network to perform named entity recognition (NER) using LSTMs with linear layers, and 
d) Use so-called ‘Siamese’ LSTM models to compare questions in a corpus and identify those that are worded differently but have the same meaning.


By the end of this Specialization, you will have designed NLP applications that perform question-answering and sentiment analysis, created tools to translate languages and summarize text, and even built a chatbot!

This Specialization is designed and taught by two experts in NLP, machine learning, and deep learning. Younes Bensouda Mourri is an Instructor of AI at Stanford University who also helped build the Deep Learning Specialization. Łukasz Kaiser is a Staff Research Scientist at Google Brain and the co-author of Tensorflow, the Tensor2Tensor and Trax libraries, and the Transformer paper.",43905.0,76286.0,4.5,953.0
Nearest Neighbor Collaborative Filtering,https://www.coursera.org/learn/collaborative-filtering,Data Science,Machine Learning,"Joseph A Konstan, Michael D. Ekstrand","In this course, you will learn the fundamental techniques for making personalized recommendations through nearest-neighbor techniques.  First you will learn user-user collaborative filtering, an algorithm that identifies other people with similar tastes to a target user and combines their ratings to make recommendations for that user.  You will explore and implement variations of the user-user algorithm, and will explore the benefits and drawbacks of the general approach.  Then you will learn the widely-practiced item-item collaborative filtering algorithm, which identifies global product associations from user ratings, but uses these product associations to provide personalized recommendations based on a user's own product ratings.",13633.0,3847.0,4.3,299.0
Nettoyer vos données avec Python,https://www.coursera.org/learn/nettoyer-donnees-python,Data Science,Data Analysis,Thierno Ibrahima Diop,"Dans ce projet guidé, vous allez charger, nettoyer et explorer des données de produits alimentaires issues de la base de données Open Food Facts. Vous allez d’abord vous familiariser avec Jupyter, lire les données, analyser les valeurs manquantes, nettoyer les données en se basant sur les connaissances métiers mais aussi sur des techniques statistiques, vous allez ensuite remplir les valeurs manquantes.

Pour réaliser cette analyse, vous allez utiliser JupyterLab avec les librairies data science en python telles que Pandas, Matplotlib, SeaBorn et missigno.",,,,
Network Analysis for Marketing Analytics,https://www.coursera.org/learn/network-analysis-for-marketing-analytics,Data Science,Data Analysis,"Chris J. Vargo, Scott Bradley","Network analysis is a long-standing methodology used to understand the relationships between words and actors in the broader networks in which they exist. This course covers network analysis as it pertains to marketing data, specifically text datasets and social networks. Learners walk through a conceptual overview of network analysis and dive into real-world datasets through instructor-led tutorials in Python. The course concludes with a major project.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",,3495.0,,
Network Data Science with NetworkX and Python,https://www.coursera.org/learn/networkx,Data Science,Data Analysis,Danilo Lessa Bernardineli,"In this 1-hour long project-based course, you are going to be able to perform centrality network analysis and visualization on educational datasets, to generate different kinds of random graphs which represents social networks, and to manipulate the graph and subgraph structures, allowing you to break and get insights on complex structures.

This guided project is for people who want to incorporate network data science skills into their technology portfolio. This is a topic of interest to researchers, marketers, consultants and practitioners associated with the knowledge areas of social science, marketing, social media, operational research and complexity science.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",5267.0,,4.3,83.0
Neural Network Visualizer Web App with Python,https://www.coursera.org/learn/neural-network-visualizer,Data Science,Machine Learning,Amit Yadav,"In this 2 hour long project-based course, you will learn to create a Neural Network Visualizer web application using Streamlit, and a simple model server using Keras and Flask. You will also use Keras to train a Neural Network model, and use Keras' functional API to create a model with multiple outputs. We will create a web application that will visualize the outputs of all the nodes of all the layers of the neural network for a given input image.

In order to complete this project successfully, you will need prior programming experience with Python, understanding of the theory behind neural networks, and familiarity with Keras.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6573.0,,4.5,231.0
Neural Network from Scratch in TensorFlow,https://www.coursera.org/learn/neural-network-tensorflow,Data Science,Machine Learning,Amit Yadav,"In this 2-hours long project-based course, you will learn how to implement a Neural Network model in TensorFlow using its core functionality (i.e. without the help of a high level API like Keras). You will also implement the gradient descent algorithm with the help of TensorFlow's automatic differentiation. While it’s easier to get started with TensorFlow with the Keras API, it’s still worth understanding how a slightly lower level implementation might work in tensorﬂow, and this project will give you a great starting point.

In order to be successful in this project, you should be familiar with python programming, TensorFlow basics, conceptual understanding of Neural Networks and gradient descent. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9894.0,,4.5,272.0
Neural Networks and Deep Learning,https://www.coursera.org/learn/neural-networks-deep-learning,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","In the first course of the Deep Learning Specialization, you will study the foundational concept of neural networks and deep learning. 

By the end, you will be familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",1125787.0,1168756.0,4.9,116634.0
Neural Networks and Random Forests,https://www.coursera.org/learn/neural-networks-random-forests,Data Science,Machine Learning,"Rajvir Dua, Neelesh Tiruviluamala","In this course, we will build on our knowledge of basic models and explore advanced AI techniques. We’ll start with a deep dive into neural networks, building our knowledge from the ground up by examining the structure and properties. Then we’ll code some simple neural network models and learn to avoid overfitting, regularization, and other hyper-parameter tricks. After a project predicting likelihood of heart disease given health characteristics, we’ll move to random forests. We’ll describe the differences between the two techniques and explore their differing origins in detail. Finally, we’ll complete a project predicting similarity between health patients using random forests.",,2031.0,,
Neural Style Transfer with TensorFlow,https://www.coursera.org/learn/neural-style-transfer,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn the basics of Neural Style Transfer with TensorFlow. Neural Style Transfer is a technique to apply stylistic features of a Style image onto a Content image while retaining the Content's overall structure and complex features. We will see how to create content and style models, compute content and style costs and ultimately run a training loop to optimize a proposed image which retains content features while imparting stylistic features from another image.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Tensorflow pre-installed.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4258.0,,4.6,111.0
Neuronale Netze und Deep Learning,https://www.coursera.org/learn/neural-networks-deep-learning-de,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Wenn auch Sie topaktuelle KI für sich nutzen möchten, sind Sie mit diesem Kurs auf dem richtigen Weg. Deep Learning-Pioniere sind vielgefragt und wenn Sie Deep Learning einmal gemeistert haben, stehen Ihnen zahlreiche Karrieremöglichkeiten offen. Deep Learning ist eine neue „Superkraft“, mit der Sie KI-Systeme entwickeln können, die so vor ein paar Jahren gar nicht möglich gewesen wären.

Mit diesem Kurs eignen Sie sich die grundlegenden Kenntnisse zu Deep Learning an. Am Ende des Kurses werden Sie die folgenden Fähigkeiten erlangt haben:
– Verständnis der wesentlichen Techniktrends, die Deep Learning vorantreiben
– Erstellen, Trainieren und Anwenden lückenloser, tiefer neuronaler Netze
– Wissen, wie Sie effiziente (vektorisierte) neuronale Netze implementieren
– Verständnis der wichtigsten Parameter in der Architektur eines neuronalen Netzes

In diesem Kurs erfahren Sie zudem, wie Deep Learning eigentlich funktioniert, da das Konzept hier nicht nur flüchtig oder oberflächlich beschrieben wird Nach Abschluss des Kurses werden Sie in der Lage sein, Deep Learning für Ihre eigenen Anwendungen zu nutzen. Wenn Sie eine berufliche Laufbahn im Bereich KI anstreben, werden Sie nach diesem Kurs zudem grundlegende Fragen in einem Bewerbungsgespräch beantworten können.

Dies ist der erste Kurs der Deep Learning-Spezialisierung",,1959.0,,
NoSQL systems,https://www.coursera.org/learn/nosql-databases,Data Science,Data Analysis,María del Pilar Ángeles,"Welcome to the specialization course of NoSQL Systems. 

This course will be completed on six weeks, it will be supported with videos and exercises that will allow you to identify the differences between the relational and NoSQL databases. 
As part of these alternative technologies the student will learn the main characteristics and how to implement the typical NoSQL databases, such as Key-value, columnar, document and graph. 
Let's start!

After completing this course, a learner will be able to
●	Identify what type of NoSQL database to implement based on business requirements (key-value, document, full text, graph, etc.)
●	Apply NoSQL data modeling from application specific queries
●	Use Atomic Aggregates and denormalization as data modelling techniques to optimize query processing

Software to download:
MongoDB
Neo4j
SAPIQ
Cassandra

In case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).",10554.0,5754.0,4.3,154.0
Non Linear SVM Classification -using SCKIT learn,https://www.coursera.org/learn/non-linear-svm-classification-using-sckit-learn,Data Science,Machine Learning,Ashish Dikshit,Non Linear SVM Classification -using SCKIT learn,,,,
Non parametric Tests using R Cmdr,https://www.coursera.org/learn/non-parametric-tests-rcmdr,Data Science,Data Analysis,Shalini Gopalkrishnan ,"In this project , you will learn how to conduct non parametric tests using Rcmdr. Non parametric tests are powerful tests which are conducted when underlying assumptions are not met in the data . After completing the project, you will be able to apply the appropriate test for the right data set. You will also learn how to do it in an easy to use Rcmdr.",,,,
Nursing Informatics Leadership Theory and Practice,https://www.coursera.org/learn/nursing-informatics-leaders,Data Science,Data Analysis,"Daniel J. Pesut, Ph.D., RN, FAAN","“By the end of this Course, you will be able to…” 

•	Evaluate effective leadership styles for leadership in nursing informatics in clinical or academic contexts to improve leadership success.
•	Discover core values that support effective nursing informatics leadership in academic and clinical contexts to inform development of a personal leadership mission statement.
•	Discover competing values and polarities related to knowledge leadership and management to promote successful leadership collaboration.
•	Determine your personal informatics leadership style based on results from the Minnesota Informatics Leadership Inventory to inform successful leadership practice. 
•	Discuss the value and importance of foresight leadership in nursing informatics to anticipate trends and consequences that are likely to transform the learning health care system",2049.0,,4.7,41.0
O que é ciência de dados?,https://www.coursera.org/learn/what-is-datascience-pt,Data Science,Data Analysis,"Rav Ahuja, Alex Aklson","A arte de revelar os insights e as tendências dos dados existe desde a antiguidade. Os antigos egípcios usavam os dados do censo para aumentar a eficiência da cobrança de impostos e previam com precisão a cheia do Nilo todos os anos. Desde então, as pessoas que trabalham com a ciência de dados vêm desenvolvendo uma área de atuação distinta e específica. Essa área é a ciência de dados. Neste curso, conheceremos alguns profissionais da ciência de dados e apresentaremos uma visão geral da ciência de dados na atualidade.",,,,
Object Detection Using Facebook's Detectron2,https://www.coursera.org/learn/object-detection-facebook-detectron2,Data Science,Machine Learning,Mohammed Murtuza Qureshi,"In this 2-hour long project-based course, you will learn how to train an Object Detection Model using Facebook's Detectron2. Detectron2 is a research platform and a production library for deep learning, built by Facebook AI Research (FAIR). We will be building an Object Detection Language Identification Model to identify English and Hindi texts written which can be extended to different use cases. We will look at the entire cycle of Model Development and Evaluation in Detectron2. We will first look at how to load a dataset, visualize it and prepare it as an input to the Deep Learning Model. 

We will then look at how we can build a Faster R-CNN model in Detectron2 and customize it. We will then configure the parameters & hyperparameters of the model. We will then move on to training the Model and subsequently to model inference and evaluation.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.3,11.0
Object Detection with Amazon Sagemaker,https://www.coursera.org/learn/object-detection-sagemaker,Data Science,Machine Learning,Amit Yadav,"Please note: You will need an AWS account to complete this course. Your AWS account will be charged as per your usage. Please make sure that you are able to access Sagemaker within your AWS account. If your AWS account is new, you may need to ask AWS support for access to certain resources. You should be familiar with python programming, and AWS before starting this hands on project. We use a Sagemaker P type instance in this project, and if you don't have access to this instance type, please contact AWS support and request access.

In this 2-hour long project-based course, you will learn how to train and deploy an object detector using Amazon Sagemaker. Sagemaker provides a number of machine learning algorithms ready to be used for solving a number of tasks. We will use the SSD Object Detection algorithm from Sagemaker to create, train and deploy a model that will be able to localize faces of dogs and cats from the popular IIIT-Oxford Pets Dataset.

Since this is a practical, project-based course, we will not dive in the theory behind deep learning based SSD or Object Detection, but will focus purely on training and deploying a model with Sagemaker. You will also need to have some experience with Amazon Web Services (AWS).

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7235.0,,4.5,97.0
Object Localization with TensorFlow,https://www.coursera.org/learn/object-localization-tensorflow,Data Science,Machine Learning,Amit Yadav,"Welcome to this 2 hour long guided project on creating and training an Object Localization model with TensorFlow. In this guided project, we are going to use TensorFlow's Keras API to create a convolutional neural network which will be trained to classify as well as localize emojis in images. Localization, in this context, means the position of the emojis in the images. This means that the network will have one input and two outputs. Think of this task as a simpler version of Object Detection. In Object Detection, we might have multiple objects in the input images, and an object detection model predicts the classes as well as bounding boxes for all of those objects. In Object Localization, we are working with the assumption that there is just one object in any given image, and our CNN model will classify and localize that object.

Please note that you will need prior programming experience in Python. You will also need familiarity with TensorFlow. This is a practical, hands on guided project for learners who already have theoretical understanding of Neural Networks, Convolutional Neural Networks, and optimization algorithms like Gradient Descent but want to understand how to use use TensorFlow to solve computer vision tasks like Object Localization.",4813.0,,4.4,91.0
Operational Analytics with Microsoft Azure Synapse Analytics,https://www.coursera.org/learn/operational-analytics-with-microsoft-azure-synapse-analytics,Data Science,Data Analysis, Microsoft,"In this course, you will learn how to perform operational analytics against Azure Cosmos DB using the Azure Synapse Link feature within Azure Synapse Analytics.

You will learn how hybrid transactional and analytical processing can help you perform operational analytics with Azure Synapse Analytics. You will also learn how to configure and enable Azure Synapse Link to interact with Azure Cosmos DB and how you can perform analytics against Azure Cosmos DB using Azure Synapse Link.

This course is part of a Specialization intended for Data engineers and developers who want to demonstrate their expertise in designing and implementing data solutions that use Microsoft Azure data services for anyone interested in preparing for the Exam DP-203: Data Engineering on Microsoft Azure (beta). You will take a practice exam that covers key skills measured by the certification exam.

This is the seventh course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",1550.0,8329.0,,
Optimization for Decision Making,https://www.coursera.org/learn/optimization-for-decision-making,Data Science,Data Analysis,Soumya Sen,"In this data-driven world, companies are often interested in knowing what is the ""best"" course of action, given the data. For example, manufacturers need to decide how many units of a product to produce given the estimated demand and raw material availability? Should they make all the products in-house or buy some from a third-party to meet the demand? Prescriptive Analytics is the branch of analytics that can provide answers to these questions. It is used for prescribing data-based decisions. The most important method in the prescriptive analytics toolbox is optimization. This course will introduce students to the basic principles of linear optimization for decision-making. Using practical examples, this course teaches how to convert a problem scenario into a mathematical model that can be solved to get the best business outcome. We will learn to identify decision variables, objective function, and constraints of a problem, and use them to formulate and solve an optimization problem using Excel solver and spreadsheet.",2184.0,7267.0,4.6,22.0
Optimize ML Models and Deploy Human-in-the-Loop Pipelines,https://www.coursera.org/learn/ml-models-human-in-the-loop-pipelines,Data Science,Machine Learning,"Antje Barth, Shelbee Eigenbrode, Sireesha Muppala, Chris Fregly","In the third course of the Practical Data Science Specialization, you will learn a series of performance-improvement and cost-reduction techniques to automatically tune model accuracy, compare prediction performance, and generate new training data with human intelligence.  After tuning your text classifier using Amazon SageMaker Hyper-parameter Tuning (HPT), you will deploy two model candidates into an A/B test to compare their real-time prediction performance and automatically scale the winning model using Amazon SageMaker Hosting. Lastly, you will set up a human-in-the-loop pipeline to fix misclassified predictions and generate new training data using Amazon Augmented AI and Amazon SageMaker Ground Truth.

Practical data science is geared towards handling massive datasets that do not fit in your local hardware and could originate from multiple sources. One of the biggest benefits of developing and running data science projects in the cloud is the agility and elasticity that the cloud offers to scale up and out at a minimum cost.

The Practical Data Science Specialization helps you develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ML workflow using Amazon SageMaker. This Specialization is designed for data-focused developers, scientists, and analysts familiar with the Python and SQL programming languages and want to learn how to build, train, and deploy scalable, end-to-end ML pipelines - both automated and human-in-the-loop - in the AWS cloud.",5580.0,10098.0,4.7,85.0
Optimize TensorFlow Models For Deployment with TensorRT,https://www.coursera.org/learn/tensorflow-tensorrt,Data Science,Machine Learning,Snehan Kekre,"This is a hands-on, guided project on optimizing your TensorFlow models for inference with NVIDIA's TensorRT. By the end of this 1.5 hour long project, you will be able to optimize Tensorflow models using the TensorFlow integration of NVIDIA's TensorRT (TF-TRT), use TF-TRT to optimize several deep learning models at FP32, FP16, and INT8 precision, and observe how tuning TF-TRT parameters affects performance and inference throughput. 

Prerequisites:
In order to successfully complete this project, you should be competent in Python programming, understand deep learning and what inference is, and have experience building deep learning models in TensorFlow and its Keras API.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3816.0,,4.6,58.0
Optimizing Machine Learning Performance,https://www.coursera.org/learn/optimize-machine-learning-model-performance,Data Science,Machine Learning,Anna Koop,"This course synthesizes everything your have learned in the applied machine learning specialization. You will now walk through a complete machine learning project to prepare a machine learning maintenance roadmap. You will understand and analyze how to deal with changing data. You will also be able to identify and interpret potential unintended effects in your project. You will understand and define procedures to operationalize and maintain your applied machine learning model. By the end of this course you will have all the tools and understanding you need to confidently roll out a machine learning project and prepare to optimize it in your business context. 

To be successful, you should have at least beginner-level background in Python programming (e.g., be able to read and code trace existing code, be comfortable with conditionals, loops, variables, lists, dictionaries and arrays). You should have a basic understanding of linear algebra (vector notation) and statistics (probability distributions and mean/median/mode).

This is the final course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute (Amii).",6097.0,2801.0,4.4,45.0
Optimizing Performance of LookML Queries,https://www.coursera.org/learn/googlecloud-optimizing-performance-of-lookml-queries-8ht7a,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Overview of Data Visualization,https://www.coursera.org/learn/overview-data-visualization,Data Science,Data Analysis,Judy Richardson,"In this project, you will develop an understanding and appreciation for data visualization. You will review the benefits of data visualization as you examine existing examples of data that is displayed in a variety of visual formats. In addition, you will gain some hands-on experience in building your own data visualization examples by aggregating data and generating simple charts in Google Sheets.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4889.0,,4.6,102.0
Overview of Data Visualization in Microsoft Excel,https://www.coursera.org/learn/overview-of-data-visualization-in-microsoft-excel,Data Science,Data Analysis,Nadine Rodriguez,"After finishing this project, you will have learned some basic rules about data visualization and can apply them whenever you create charts. In present times, one can find data visualization in a wide range of fields. Businesses show graphs to report on revenue, police departments create maps of crimes in their jurisdiction, and on the website for the city hall, you can likely find visual comparisons of people who moved to the city and those who left the city. For this reason, it is important for a lot of people to know the basics of data visualization.",,,,
Partager des données grâce à l'art de la visualisation,https://www.coursera.org/learn/partager-des-donnees-grace-a-lart-de-la-visualisation,Data Science,Data Analysis,Google Career Certificates,"Il s’agit du sixième cours du Google Data Analytics Certificate.. Ces cours vous permettront d’acquérir les compétences dont vous avez besoin pour postuler les emplois d’analyste de données de niveau junior. Vous apprendrez à visualiser et à présenter vos résultats des données au fur et à mesure que vous terminez le processus d’analyse des données. Ce cours vous montrera comment les visualisations des données, telles que les tableaux de bord visuels, peuvent vous aider à donner vie à vos données. Vous examinerez également Tableau, une plateforme de visualisation des données qui vous aidera à créer des visualisations efficaces pour vos présentations. Des analystes de données actuellement chez Google vous instruiront et vous fourniront des moyens pratiques d’accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler à des emplois d’analyste de données de niveau junior. Aucune expérience préalable n’est nécessaire.

D’ici la fin de ce cours, vous :
 - Examinerez l’importance de la visualisation des données.
 - Apprendrez à former un récit convaincant à travers des histoires de données.
 - Comprendrez comment utiliser Tableau pour créer des tableaux de bord et des filtres de tableau de bord.
 - Découvrirez comment utiliser Tableau pour créer des visualisations efficaces. 
 - Découvrirez les principes et les pratiques impliqués dans des présentations efficaces.
 - Apprendrez à tenir compte des limitations potentielles associées aux données de vos présentations.
 - Comprendrez comment appliquer les meilleures pratiques à une séance de questions-réponses avec votre public.",,,,
Pattern Discovery in Data Mining,https://www.coursera.org/learn/data-patterns,Data Science,Data Analysis,Jiawei Han,"Learn the general concepts of data mining along with basic methodologies and applications. Then dive into one subfield in data mining: pattern discovery. Learn in-depth concepts, methods, and applications of pattern discovery in data mining. We will also introduce methods for data-driven phrase mining and some interesting applications of pattern discovery. This course provides you the opportunity to learn skills and content to practice and engage in scalable pattern discovery methods on massive transactional data, discuss pattern evaluation measures, and study methods for mining diverse kinds of patterns, sequential patterns, and sub-graph patterns.",37913.0,26968.0,4.3,309.0
Perform Feature Analysis with Yellowbrick,https://www.coursera.org/learn/feature-analysis-yellowbrick,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Performing Feature Analysis with Yellowbrick. In this course, we are going to use visualizations to steer machine learning workflows. The problem we will tackle is to predict whether rooms in apartments are occupied or unoccupied based on passive sensor data such as temperature, humidity, light and CO2 levels. With an emphasis on visual steering of our analysis, we will cover the following topics in our machine learning workflow: feature analysis using methods such as scatter plots, RadViz, parallel coordinates plots, feature ranking, and manifold visualization.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, Yellowbrick, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2602.0,,4.8,56.0
Perform Sentiment Analysis with scikit-learn,https://www.coursera.org/learn/scikit-learn-logistic-regression-sentiment-analysis,Data Science,Machine Learning,Snehan Kekre,"In this project-based course, you will learn the fundamentals of sentiment analysis, and build a logistic regression model to classify movie reviews as either positive or negative. We will use the popular IMDB data set. Our goal is to use a simple logistic regression estimator from scikit-learn for document classification.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9731.0,,4.5,406.0
Performing Confirmatory Data Analysis in R,https://www.coursera.org/learn/performing-confirmatory-data-analysis-in-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course Performing Confirmatory Data Analysis in R. In this project, you will learn how to perform extensive confirmatory data analysis, which is similar to performing inferential statistics in R.

By the end of this 2-hour long project, you will understand how to perform chi-square tests, which includes, the goodness of fit test, test for independence, and test for homogeneity. Also, you will learn how to calculate correlation for numeric variables and perform regression analysis. Also, you will learn how to interpret the results of a test and make viable decisions. By extension, you will learn how to explore some built-in R datasets to perform the different tests.

Note, you do not need to be a data scientist or statistical analyst to be successful in this guided project, just a familiarity with basic statistics and performing hypothesis test in R suffice for this project. A fundamental prerequisite is having a good understanding of the theory of hypothesis test. So, I recommend that you should take the Hypothesis Testing in R project before taking this project.",,,,
Performing Data Aggregation using SQL Aggregate Functions,https://www.coursera.org/learn/performing-data-aggregation-using-sql-aggregate-functions,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"In this 2-hour long project-based course, you will learn how to retrieve data from tables in a database using SQL SELECT statement with SQL Aggregate functions. The aggregate functions we will consider in this project are COUNT, SUM, MIN, MAX and AVG. Aggregate functions are used to summarize data from rows of a table into a single value. In addition, you will learn how to set conditions on the output of an aggregate function using the HAVING clause. Finally, you will learn how to tidy up the result set of aggregate functions using the ROUND function.

Note: You do not need to be a data administrator or data analyst to be successful in this guided project, just a familiarity with querying databases using SQL SELECT statement suffice for this project. If you are not familiar with SQL and want to learn the basics, start with my previous guided projects titled “Performing Data definition and Manipulation in SQL.""  and “Querying Databases using SQL SELECT statement”",3006.0,,4.8,65.0
Performing Data Definition and Manipulation in SQL,https://www.coursera.org/learn/performing-data-definition-and-manipulation-in-sql,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"In this 2-hour long project-based course, you will learn how to use SQL data definition statements for various data definition tasks and how to use SQL data manipulation statements for data manipulation tasks such as updating records in a table. In addition, you will learn how to upload a CSV file into a database using PostgreSQL.",2719.0,,4.6,103.0
"Performing Network, Path, and Text Analyses in SAS Visual Analytics",https://www.coursera.org/learn/network-path-text-analyses-sas-va,Data Science,Data Analysis,Nicole Ball,"In this course, you learn about the data structure needed for network, path, and text analytics and how to create network analysis, path analysis, and text analytics in SAS Visual Analytics.",7886.0,7806.0,4.7,183.0
Performing regression tasks using decision tree & PCA basics,https://www.coursera.org/learn/performing-regression-tasks-using-decision-tree--pca-basics,Data Science,Machine Learning,Ashish Dikshit,"In this 1-hour long project-based course, you will learn how to perform regression tasks using decision tree & some PCA fundamental coding.
you will get expertise in acing following tasks- 
Predicting two decision tree regression model
Drawing Decision tree for regression
Regularize a decision tree regressor
Setting up the environment for dimensional reduction 
Coding for Projection methods in Dimensionality  reduction
Coding for PCA using SVD decomposition and SCIKIT learn",,,,
Plots Creation using Matplotlib Python,https://www.coursera.org/learn/plots-creation-using-matplotlib-python,Data Science,Data Analysis,Omnya Khaled,"By the end of this project, you will be able to add the data in the CSV file to Pandas data frame, plot the graph, and set marker type and color. You will also be able to apply labels, change font size, add grid lines and legends. Finally, you will be able to create the boxplot and save the graph as an image using the matplotlib and seaborn libraries, which are the most important libraries in python that are used for Data Visualization. You can create bar-plots, scatter-plots, histograms, and a lot more with them.

This guided project is for people in the field of data and data analysis. people who want to learn python and Pandas library. It provides you with the important steps to be a data analyst. Moreover, it equips you with the knowledge of python's native data structures",,,,
Pneumonia Classification using PyTorch,https://www.coursera.org/learn/pneumonia-classification-using-pytorch,Data Science,Machine Learning,Parth Dhameliya,"In this 2-hour guided project, you are going to use EfficientNet model and train it on Pneumonia Chest X-Ray dataset. The dataset consist of nearly 5600 Chest X-Ray images and two categories (Pneumonia/Normal). Our main aim for this project is to build a pneumonia classifier which can classify Chest X-Ray scan that belong to one of the two classes. You will load and fine tune the pretrained EffiecientNet model and also to create a simple pytorch trainer to train the model.

In order to be successful in this project, you should be familiar with python, convolutional neural network, basic pytorch. This is a hands on, practical project that focuses primarily on implementation, and not on the theory behind Convolutional Neural Networks.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Population Health: Predictive Analytics,https://www.coursera.org/learn/population-health-predictive-analytics,Data Science,Data Analysis,"Ewout W. Steyerberg, David van Klaveren","Predictive analytics has a longstanding tradition in medicine. Developing better prediction models is a critical step in the pursuit of improved health care: we need these tools to guide our decision-making on preventive measures, and individualized treatments. In order to effectively use and develop these models, we must understand them better. In this course, you will learn how to make accurate prediction tools, and how to assess their validity. First, we will discuss the role of predictive analytics for prevention, diagnosis, and effectiveness. Then, we look at key concepts such as study design, sample size and overfitting.

Furthermore, we comprehensively discuss important modelling issues such as missing values, non-linear relations and model selection. The importance of the bias-variance tradeoff and its role in prediction is also addressed. Finally, we look at various way to evaluate a model - through performance measures, and by assessing both internal and external validity. We also discuss how to update a model to a specific setting.

Throughout the course, we illustrate the concepts introduced in the lectures using R. You need not install R on your computer to follow the course: you will be able to access R and all the example datasets within the Coursera environment. We do however make references to further packages that you can use for certain type of analyses – feel free to install and use them on your computer.

Furthermore, each module can also contain practice quiz questions. In these, you will pass regardless of whether you provided a right or wrong answer. You will learn the most by first thinking about the answers themselves and then checking your answers with the correct answers and explanations provided.

This course is part of a Master's program Population Health Management at Leiden University (currently in development).",3701.0,3068.0,4.5,22.0
Population Health: Responsible Data Analysis,https://www.coursera.org/learn/responsible-data-analysis,Data Science,Data Analysis,"Mar Rodriguez Girondo, Jelle Goeman, Saskia le Cessie","In most areas of health, data is being used to make important decisions.  As a health population manager, you will have the opportunity to use data to answer interesting questions. In this course, we will discuss data analysis from a responsible perspective, which will help you to extract useful information from data and enlarge your knowledge about specific aspects of interest of the population. 

First, you will learn how to obtain, safely gather, clean and explore data. Then, we will discuss that because data are usually obtained from a sample of a limited number of individuals, statistical methods are needed to make claims about the whole population of interest. You will discover how statistical inference, hypothesis testing and regression techniques will help you to make the connection between samples and populations.

A final important aspect is interpreting and reporting. How can we transform information into knowledge? How can we separate trustworthy information from noise? In the last part of the course, we will cover the critical assessment of the results, and we will discuss challenges and dangers of data analysis in the era of big data and massive amounts of information.  

In this course, we will emphasize the concepts and we will also teach you how to effectively perform your analysis using R. You do not need to install R on your computer to follow the course, you will be able to access R and all the example data sets within the Coursera environment.  

This course will become part of the to-be-developed  Leiden University master program Population Health Management. If you wish to find out more about this program see the last reading of this Course!",4406.0,4549.0,4.6,30.0
Poser des questions pour prendre des décisions basées sur les données,https://www.coursera.org/learn/poser-des-questions-pour-prendre-des-decisions-basees-sur-les-donnees,Data Science,Data Analysis,Google Career Certificates,"Il s’agit du deuxième cours du Google Data Analytics Certificate. Ces cours vous permettront d’acquérir les compétences dont vous avez besoin pour postuler à des emplois d’analyste de données de niveau junior. Vous vous appuierez sur votre compréhension des sujets qui ont été introduits dans le premier cours du Google Data Analytics Certificate. Le matériel vous aidera à apprendre à poser des questions efficaces pour prendre des décisions basées sur les données, tout en vous connectant aux besoins des partenaires. Des analystes de données actuellement chez Google vous instruiront et vous fourniront des moyens pratiques d’accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler à des emplois d’analyste de données de niveau junior. Aucune expérience préalable n’est nécessaire.

D’ici la fin de ce cours, vous :
- apprendrez des techniques de questionnement efficaces qui peuvent aider à guider l’analyse. 
- acquerrez une compréhension de la prise de décision basée sur les données et de la façon dont les analystes de données présentent les résultats.
- explorerez une variété de scénarios commerciaux du monde réel pour soutenir une compréhension du questionnement et de la prise de décision.
- découvrirez comment et pourquoi les tableurs sont un outil important pour les analystes de données.
- examinerez les idées clés associées à la pensée structurée et comment elles peuvent aider les analystes à mieux comprendre les problèmes et à développer des solutions.
- apprendrez des stratégies pour gérer les attentes des partenaires tout en établissant une communication claire avec une équipe d’analytique des données pour atteindre les objectifs de l’entreprise.",,1658.0,,
Power BI  الحصول على البيانات وشكلها ودمجها باستخدام,https://www.coursera.org/learn/manipulate-data-using-power-bi-desktop,Data Science,Data Analysis,Omnya Khaled,"في نهاية هذا المشروع, سوف تتمكن من تحديد أساسيات power BI وكيفية استخدامها.و إنشاء modelو إدخال البيانات من أنواع مختلفة من مصادر البيانات. و سوف أيضًا سوف  تتمكن من معالجة البيانات: تقليل عدد البيانات ، ودمج الأعمدة ، واستبدال القيم ، وتغيير أنواع البيانات ، وأخيراً استخدام statistical and standard functions. بالإضافة إلى تعلم كيفية وضع عمود index جديد ، وضم queries مع كل منهم ، و ترتيب مجموعة البيانات وتنظيفها. وأخيرًا ، كيفية تطبيق union و inset و except ودمج بيانات جدولين وإضافة النتائج في جدول جديد.

هذا المشروع الإرشادى مخصص للأشخاص في مجال تحليل البيانات والبيانات. الأشخاص الذين يرغبون في تعلم Power BI. يزودك  بالخطوات المهمة لتكون  business intelligence specialist.",,,,
Power BI para Business Intelligence,https://www.coursera.org/learn/power-bi-business-intelligence,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a analizar los datos asociados a las ventas con la herramienta de Power BI Desktop. Se explicara paso a paso todo el proceso de desarrollo de los informes de ventas. Desde la importación de los datos y modelado, hasta el desarrollo de los KPIs y visuales de analítica avanzada con inteligencia artificial. 
Gracias a ello, al finalizar el curso sabremos generar nuestros propios análisis de los datos de ventas con Power BI y podremos tomar decisiones en base a los datos.",1664.0,,4.7,40.0
Power BI لوحة بيانات مبيعات باستخدام برنامج,https://www.coursera.org/learn/power-bi-iawhat-bayanat-mabieat-biaistikhdam-barnamaj,Data Science,Data Analysis,Ahmed Hashem,مع نهاية المشروع ده هتقدر تعمل لوحة بيانات مبيعات باستخدام برنامج Power BIهنمشي مع بعض خطوة بخطوة خلال المشروع عشان نقدر نحدد  الdata model  و تختار العرض الصحيح للبيانات و نحدد  الأسئلة اللي توجهها للdata عشان  يبقى التقرير مفيدهتقدر كمان تنضف البيانات من الشوائب و تبني التقرير بشكل احترافي يتبع أسلوب السرد القصصي.كمان هتقدر تستخدم لغة الDAX في عمل معادلات تحسب مؤشرات الأداء المطلوبة.المشروع ده للمهتمين بمجال تحليل البيانات data analysis باستخدام لغة ال Power BI ، والمشروع ده  للمستوى المتوسط اللي عارفين اساسيات البرنامج و حابين يبتدوا يعملوا تقرير متكامل. بعد المشروع هتقدر انك تتعامل مع أي تقرير مطلوب منك  باختلاف مصادر البيانات.في المشروع ده ، هنستخدم Microsoft Power BI و هنستخدم لغة الـ DAX -Data Analysis Expression وهي لغة قوية هتساعدك في انشاء المعادلات المعقدة,,,,
Power BI وتقارير باستخدام Visualizations   إنشاء,https://www.coursera.org/learn/creating-visualizations-and-reports-using-power-bi,Data Science,Data Analysis,Omnya Khaled,"فى نهاية هذا المشروع ، ستتمكن من إنشاء تقارير وvisualizations لبياناتك باستخدام Power BI. ستتمكن من تحميل البيانات من ملفات CSV إلى Power BI Desktop ، وإنشاء text visualizations وتنسيقها ، وتحليل البيانات باستخدام charts. ستتمكن أيضًا من تطبيق Q & A visual وتصفية البيانات في visuals. وأخيرًا ، ستقوم  بإنشاء تقارير تستجيب لmobile layout.

تستخدم العديد من الشركات Power BI لتوصيل البيانات وتحويلها  ، وأيضًا إنشاء charts, graphs وتقارير وdashboards ، وهي مجموعات من visuals، وأخيراً مشاركة التقارير مع الآخرين باستخدام Power BI.

هذا المشروع الأرشادى مخصص للأشخاص في مجال تحليل البيانات والبيانات. الأشخاص الذين يرغبون في تعلم Power BI. يزودك بالخطوات المهمة لتكون متخصصًا في business intelligence.",,,,
Power and Sample Size for Multilevel and Longitudinal Study Designs,https://www.coursera.org/learn/power-sample-size,Data Science,Probability and Statistics,Albert Ritzhaupt,"Power and Sample Size for Longitudinal and Multilevel Study Designs, a five-week, fully online course covers innovative, research-based power and sample size methods, and software for multilevel and longitudinal studies.  The power and sample size methods and software taught in this course can be used for any health-related, or more generally, social science-related (e.g., educational research) application.  All examples in the course videos are from real-world studies on behavioral and social science employing multilevel and longitudinal designs. The course philosophy is to focus on the conceptual knowledge to conduct power and sample size methods. The goal of the course is to teach and disseminate methods for accurate sample size choice, and ultimately, the creation of a power/sample size analysis for a relevant research study in your professional context. 

Power and sample size selection is one of the most important ethical questions researchers face. Interventional studies that are too large expose human volunteer research participants to possible, and needless, harm from research. Interventional studies that are too small will fail to reach their scientific objective, again bringing possible harm to research participants, without the possibility of concomitant gain from the increase in knowledge. For observational studies in which there are no possible harms to the participants, such as observational studies, proper power ensures good stewardship of both time and money.

Most National Institutes of Health (NIH) study sections will only fund a grant if the grantee has written a compelling and accurate power and sample size analysis. The Institute of Education Sciences (IES), the statistics, research, and evaluation arm of the U.S. Department of Education, also offers competitive grants requiring a compelling and accurate power and sample size analysis (Goal 3: Efficacy and Replication and Goal 4: Effectiveness/Scale-Up). 

At the end of the online course, learners will be able to: 
•	Use a framework and strategy for study planning 
•	Write study aims as testable hypotheses
•	Describe a longitudinal and multilevel study design
•	Write a statistical analysis plan 
•	Plan a sampling design for subgroups, e.g. racial and ethnic
•	Demonstrate the feasibility of recruitment
•	Describe expected missing data and dropout
•	Write a power and sample size analysis that is aligned with the planned statistical analysis

This is a five-week intensive and interactive online course. We will use a mix of instructional videos, software demonstration videos, online readings, quizzes, and exercise assignments. The final course project is a peer-reviewed research study you design for future power or sample size analysis.",5070.0,4201.0,4.3,34.0
Practical Data Wrangling with Pandas,https://www.coursera.org/learn/practical-data-wrangling-with-pandas,Data Science,Data Analysis,Ryan Ahmed,"In this project, we will analyze life expectancy data by performing data wrangling & exploratory data analysis (EDA). Pandas is a powerful open source data analysis tools in python. Exploratory Data Analysis (EDA) is a process of analyzing data to gain valuable insights such as statistical summary & visualizations.",,,,
Practical Decision-Making Using No-code ML on AWS,https://www.coursera.org/learn/no-code-ml-aws,Data Science,Machine Learning,Jared Heywood,"In this course, you will discover how to solve business problems with machine learning, no coding required. You will explore Amazon SageMaker Canvas, a visual point-and-click interface that allows you to generate accurate ML predictions without requiring any machine learning experience or having to write a single line of code. At the end of the course, you will walk away understanding how to make better business decisions using no-code machine learning.",,17878.0,,
Practical Machine Learning,https://www.coursera.org/learn/practical-machine-learning,Data Science,Machine Learning,"Jeff Leek, PhD, Roger D. Peng, PhD, Brian Caffo, PhD","One of the most common tasks performed by data scientists and data analysts are prediction and machine learning. This course will cover the basic components of building and applying prediction functions with an emphasis on practical applications. The course will provide basic grounding in concepts such as training and tests sets, overfitting, and error rates. The course will also introduce a range of model based and algorithmic machine learning methods including regression, classification trees, Naive Bayes, and random forests. The course will cover the complete process of building prediction functions including data collection, feature creation, algorithms, and evaluation.",146200.0,33798.0,4.5,3214.0
Practical Machine Learning on H2O,https://www.coursera.org/learn/machine-learning-h2o,Data Science,Machine Learning,Darren Cook,"In this course, we will learn all the core techniques needed to make effective use of H2O. Even if you have no prior experience of machine learning, even if your math is weak, by the end of this course you will be able to make machine learning models using a variety of algorithms. We will be using linear models, random forest, GBMs and of course deep learning, as well as some unsupervised learning algorithms. You will also be able to evaluate your models and choose the best model to suit not just your data but the other business restraints you may be under.",7850.0,4265.0,4.5,71.0
Practical Predictive Analytics: Models and Methods,https://www.coursera.org/learn/predictive-analytics,Data Science,Data Analysis,Bill Howe,"Statistical experiment design and analytics are at the heart of data science.  In this course you will design statistical experiments and analyze the results using modern methods.  You will also explore the common pitfalls in interpreting statistical arguments, especially those associated with big data.  Collectively, this course will help you internalize a core set of practical and effective machine learning methods and concepts, and apply them to solve some real world problems.

Learning Goals: After completing this course, you will be able to:
1. Design effective experiments and analyze the results
2. Use resampling methods to make clear and bulletproof statistical arguments without invoking esoteric notation
3. Explain and apply a core set of classification methods of increasing complexity (rules, trees, random forests), and associated optimization methods (gradient descent and variants)
4. Explain and apply a set of unsupervised learning concepts and methods
5. Describe the common idioms of large-scale graph analytics, including structural query, traversals and recursive queries, PageRank, and community detection",35067.0,6435.0,4.1,309.0
Practical SAS Programming and Certification Review,https://www.coursera.org/learn/sas-programming-certification-review,Data Science,Data Analysis,Stacey Syphus,In this course you have the opportunity to use the skills you acquired in the two SAS programming courses to solve realistic problems. This course is also designed to give you a thorough review of SAS programming concepts so you are prepared to take the SAS Certified Specialist: Base Programming Using SAS 9.4 Exam.,14006.0,4888.0,4.9,354.0
Practical Time Series Analysis,https://www.coursera.org/learn/practical-time-series-analysis,Data Science,Probability and Statistics,"Tural Sadigov, William Thistleton","Welcome to Practical Time Series Analysis!

Many of us are ""accidental"" data analysts. We trained in the sciences, business, or engineering and then found ourselves confronted with data for which we have no formal analytic training.  This course is designed for people with some technical competencies who would like more than a ""cookbook"" approach, but who still need to concentrate on the routine sorts of presentation and analysis that deepen the understanding of our professional topics. 

In practical Time Series Analysis we look at data sets that represent sequential information, such as stock prices, annual rainfall, sunspot activity, the price of agricultural products, and more.  We look at several mathematical models that might be used to describe the processes which generate these types of data. We also look at graphical representations that provide insights into our data. Finally, we also learn how to make forecasts that say intelligent things about what we might expect in the future.

Please take a few minutes to explore the course site. You will find video lectures with supporting written materials as well as quizzes to help emphasize important points. The language for the course is R, a free implementation of the S language. It is a professional environment and fairly easy to learn.

You can discuss material from the course with your fellow learners. Please take a moment to introduce yourself!

Time Series Analysis can take effort to learn- we have tried to present those ideas that are ""mission critical"" in a way where you understand enough of the math to fell satisfied while also being immediately productive. We hope you enjoy the class!",73054.0,52724.0,4.6,1550.0
Practicing for the SAS Programming Certification Exam,https://www.coursera.org/learn/practicing-sas-programming-certification,Data Science,Data Analysis,Peter Styliadis,In this course you have the opportunity to use the skills you acquired in the two SAS programming courses to solve realistic problems. This course is also designed to give you a thorough review of SAS programming concepts so you are prepared to take the SAS Certified Specialist: Base Programming Using SAS 9.4 Exam.,2996.0,5741.0,4.9,62.0
Predicción de Ventas Pronosticando Tendencias,https://www.coursera.org/learn/prediccion-de-ventas-pronosticando-tendencias-en-google-sheets,Data Science,Machine Learning,Paula Del Rey,"En este curso basado en un proyecto y de 2 horas de duración, aprenderás a realizar pronósticos de tendencia y a entender cómo los pronósticos apoyan la toma de decisiones. Aprenderás a utilizar hojas de cálculo para  visualizar y realizar un examen estadístico de datos analizando la pendiente de la línea de regresión y creando una gráfica de línea. Al final del curso entenderás cómo evaluar los modelos y cuándo utilizar técnicas de ingeniería para mejorar la exactitud de la previsión.

Nota: Este curso es de mayor utilidad para estudiantes que residen en la región de América del Norte. Actualmente, estamos trabajando para proporcionar la misma experiencia en otras regiones",2478.0,,4.5,69.0
Predicción del fraude bancario con autoML y Pycaret,https://www.coursera.org/learn/prediccion-fraude-automl-pycaret,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender todo lo que necesitas saber acerca de autoML y Pycaret. Aprenderemos a generar un modelo predictivo de clasificación capaz de predecir el fraude bancario. Para ello, aprenderemos a generar múltiples modelos de ML y metamodelos, a evaluar su eficiencia, a desplegarlos en producción y a guardarlos en MlFlow, etc.",,,,
Predict Ad Clicks Using Logistic Regression and XG-Boost,https://www.coursera.org/learn/predict-ad-clicks-using-logistic-regression-and-xg-boost,Data Science,Machine Learning,Ryan Ahmed,"In this project, we will predict Ads clicks using logistic regression and XG-boost algorithms. In this project, we will assume that you have been hired as a consultant to a start-up that is running a targeted marketing ad campaign on Facebook. The company wants to analyze customer behavior by predicting which customer clicks on the advertisement.",,,,
Predict Career Longevity for NBA Rookies using Scikit-learn,https://www.coursera.org/learn/predict-career-longevity,Data Science,Machine Learning,Mohanad Ayman Affify,"By the end of this project, you will be able to apply data analysis to predict career longevity for NBA Rookie using python. Determining whether a player’s career will flourish or not became a science based on the player’s stats.  Throughout the project, you will be able to analyze players’ stats and  build your own binary classification model using Scikit-learn to predict if the NBA rookie will last for 5 years in the league if provided with some stats such as Games played, assists, steals and turnovers …. etc. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Predict Diabetes with a Random Forest using R,https://www.coursera.org/learn/predict-diabetes-with-a-random-forest-using-r,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to (complete a training and test set using an R function, practice looking at data distribution using R and ggplot2, Apply a Random Forest model to the data, and examine the results using RMSE and a Confusion Matrix). 


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3015.0,,4.5,109.0
Predict Employee Turnover with scikit-learn,https://www.coursera.org/learn/employee-turnover-scikit-learn,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Predicting Employee Turnover with Decision Trees and Random Forests using scikit-learn. In this project, you will use Python and scikit-learn to grow decision trees and random forests, and apply them to an important business problem. Additionally, you will learn to interpret decision trees and random forest models using feature importance plots. Leverage Jupyter widgets to build interactive controls, you can change the parameters of the models on the fly with graphical controls, and see the results in real time!

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.",7938.0,,4.4,251.0
Predict Future Product Prices Using Facebook Prophet,https://www.coursera.org/learn/prophet-timeseries-prediction,Data Science,Machine Learning,Ryan Ahmed,"In this 1-hour long project-based course, you will be able to:
- Understand the theory and intuition behind Facebook times series forecasting tool
- Import Key libraries, dataset and visualize dataset
- Build a time series forecasting model using Facebook Prophet to predict future product prices
- Compile and fit time series forecasting model to training data 
- Assess trained model performance

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",8135.0,,4.4,400.0
Predict Gas Guzzlers using a Neural Net Model on the MPG Data Set,https://www.coursera.org/learn/predict-gas-guzzlers-neural-net,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to (complete a training and test set using an R function, practice looking at data distribution using R and ggplot2, Apply a Neural Net model to the data, and examine the results using a Confusion Matrix.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,32.0
Predict Housing Prices with Tensorflow and AI Platform,https://www.coursera.org/learn/googlecloud-predict-housing-prices-with-tensorflow-and-ai-platform-wbgwf,Data Science,Machine Learning,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Predict Ideal Diamonds over Good Diamonds using a Random Forest using R,https://www.coursera.org/learn/predict-ideal-diamonds-with-a-random-forest-using-r,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to (complete a training and test set using an R function, practice looking at data distribution using R and ggplot2, Apply a Random Forest model to the data, and examine the results using RMSE and a Confusion Matrix). 


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",1530.0,,4.8,33.0
Predict Sales Revenue with scikit-learn,https://www.coursera.org/learn/scikit-learn-simple-linear-regression,Data Science,Machine Learning,Snehan Kekre,"In this 2-hour long project-based course, you will build and evaluate a simple linear regression model using Python. You will employ the scikit-learn module for calculating the linear regression, while using pandas for data management, and seaborn for plotting. You will be working with the very popular Advertising data set to predict sales revenue based on advertising spending through mediums such as TV, radio, and newspaper. 

By the end of this course, you will be able to:
- Explain the core ideas of linear regression to technical and non-technical audiences
- Build a simple linear regression model in Python with scikit-learn
- Employ Exploratory Data Analysis (EDA) to small data sets with seaborn and pandas
- Evaluate a simple linear regression model using appropriate metrics

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Jupyter and Python 3.7 with all the necessary libraries pre-installed.

Notes:
- You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",5869.0,,4.5,229.0
Predict Sales and Forecast Trends in Google Sheets,https://www.coursera.org/learn/predict-sales-forecast-trends-in-google-sheets,Data Science,Data Analysis,Tricia Bagley,"By the end of this project, you will understand use cases for conducting forecasts in your workplace and be able to confidently conduct a trend forecast in any spreadsheet software. You will also understand when it is necessary to refine a model to improve the accuracy of forecasted trends.

There are many times when having a crystal ball might be useful and it’s natural to leverage trusted predictions of future outcomes to prepare and drive best results. Predictions come our way in the form of the forecasted data we consume regularly in our personal and business lives. This data covers everything from the weather to projected investment returns. At work we use forecasted data for a multitude of purposes including developing strategies, budgets, to provide the right amount of resources to meet demand, and to create the best customer experience possible. In this course, you will build baseline prediction skills with statistical forecasting by designing, creating, and interpreting a sales trend forecast. You will do this as we work side-by-side in the free-to-use software Google Sheets.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3060.0,,4.4,26.0
Predicting Credit Card Fraud with R,https://www.coursera.org/learn/predicting-credit-fraud-with-r,Data Science,Data Analysis,John Garcia,"Welcome to Predicting Credit Card Fraud with R. In this project-based course, you will learn how to use R to identify fraudulent credit card transactions with a variety of classification methods and use R to generate synthetic samples to address the common problem of classification bias for highly imbalanced datasets—the class of interest (fraud) represents less than 1% of the observations. 

Class imbalance can make it difficult to detect the effect independent variables have on fraud, ultimately leading to higher misclassification rates. Fixing the imbalance allows the minority class (fraud) to be better learned by the classifier algorithms.

After completing the project, you will be able to apply the methods introduced in the project to a wide range of classification problems that typically confront class imbalance, including predicting loan default, customer churn, cancer diagnosis, early high school dropout risk, and malware detection.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,27.0
Predicting House Prices with Regression using TensorFlow,https://www.coursera.org/learn/tensorflow-beginner-predicting-house-prices-regression,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn the basics of using Keras with TensorFlow as its backend and you will learn to use it to solve a basic regression problem. By the end of this project, you will have created, trained, and evaluated a neural network model that, after the training, will be able to predict house prices with a high degree of accuracy.

Notes:
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",11621.0,,4.5,485.0
Predicting Salaries with Decision Trees,https://www.coursera.org/learn/predicting-salaries-decision-trees,Data Science,Machine Learning,Daniel Romaniuk,"In this 1.5 hour long project-based course, you will tackle a real-world prediction problem using machine learning.  The dataset we are going to use comes from the U.S. Census Bureau; they recorded a number of attributes such as gender and occupation as well as the salary range for a sample of more than 32,000 Americans.  We will fit a decision tree to this data, and try to predict the salary for a person we haven’t seen before.

By the end of this project, you will have created a machine learning model using industry standard tools, including Python and sklearn. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Predicting Salaries with Simple Linear Regression in R,https://www.coursera.org/learn/linear-regression-predicting-salaries,Data Science,Data Analysis,Mo Rebaie,"In this 1-hour long project-based course, you will learn how to create a simple linear regression algorithm and use it to solve a basic regression problem. By the end of this project, you will have built, trained, tested, and visualized a Regression model that will be able to accurately predict the salary of a data scientist if provided with some information about years of experience.

In order to be successful in this project, you should just know the basics of R and linear regression.",7372.0,,4.3,199.0
Predicting the Weather with Artificial Neural Networks,https://www.coursera.org/learn/predicting-weather-artificial-neural-networks,Data Science,Machine Learning,Daniel Romaniuk,"In this one hour long project-based course, you will tackle a real-world prediction problem using machine learning.  The dataset we are going to use comes from the Australian government.  They recorded daily weather observations from a number of Australian weather stations.  We will use this data to train an artificial neural network to predict whether it will rain tomorrow.

By the end of this project, you will have created a machine learning model using industry standard tools, including Python and sklearn. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,3.9,10.0
Prediction Models with Sports Data,https://www.coursera.org/learn/prediction-models-sports-data,Data Science,Data Analysis,"Youngho Park, Stefan Szymanski","In this course the learner will be shown how to generate forecasts of game results in professional sports using Python. The main emphasis of the course is on teaching the method of logistic regression as a way of modeling game results, using data on team expenditures. The learner is taken through the process of modeling past results, and then using the model to forecast the outcome games not yet played. The course will show the learner how to evaluate the reliability of a model using data on betting odds. The analysis is applied first to the English Premier League, then the NBA and NHL. The course also provides an overview of the relationship between data analytics and gambling, its history and the social issues that arise in relation to sports betting, including the personal risks.",2650.0,9665.0,4.6,21.0
Prediction and Control with Function Approximation,https://www.coursera.org/learn/prediction-control-function-approximation,Data Science,Machine Learning,"Martha White, Adam White","In this course, you will learn how to solve problems with large, high-dimensional, and potentially infinite state spaces. You will see that estimating value functions can be cast as a supervised learning problem---function approximation---allowing you to build agents that carefully balance generalization and discrimination in order to maximize reward. We will begin this journey by investigating how our policy evaluation or prediction methods like Monte Carlo and TD can be extended to the function approximation setting. You will learn about feature construction techniques for RL, and representation learning via neural networks and backprop. We conclude this course with a deep-dive into policy gradient methods; a way to learn policies directly without learning a value function. In this course you will solve two continuous-state control tasks and investigate the benefits of policy gradient methods in a continuous-action environment. 

Prerequisites: This course strongly builds on the fundamentals of Courses 1 and 2, and learners should have completed these before starting this course.  Learners should also be comfortable with probabilities & expectations, basic linear algebra, basic calculus, Python 3.0 (at least 1 year), and  implementing algorithms from pseudocode.

By the end of this course, you will be able to: 

-Understand how to use supervised learning approaches to approximate value functions
-Understand objectives for prediction (value estimation) under function approximation
-Implement TD with function approximation (state aggregation), on an environment with an infinite state space (continuous state space)
-Understand fixed basis and neural network approaches to feature construction 
-Implement TD with neural network function approximation in a continuous state environment
-Understand new difficulties in exploration when moving to function approximation
-Contrast discounted problem formulations for control versus an average reward problem formulation
-Implement expected Sarsa and Q-learning with function approximation on a continuous state control task
-Understand objectives for directly estimating policies (policy gradient objectives)
-Implement a policy gradient method (called Actor-Critic) on a discrete state environment",19419.0,33504.0,4.8,743.0
Predictive Analytics for Business with H2O in R,https://www.coursera.org/learn/predictive-analytics-business-h2o-r,Data Science,Machine Learning,Snehan Kekre,"This is a hands-on, guided project on Predictive Analytics for Business with H2O in R. By the end of this project, you will be able apply machine learning and predictive analytics to solve a business problem, explain and describe automatic machine learning, perform automatic machine learning (AutoML) with H2O in R. We will take a data-driven approach to predict the success of bank telemarketing.

H2O's AutoML automates the process of training and tuning a large selection of models, allowing the user to focus on other aspects of the data science and machine learning pipeline such as data pre-processing, feature engineering and model deployment.

To successfully complete the project, we recommend that you have prior experience with programming in R, basic machine learning theory, and have trained ML models in R. We will not be exploring how any particular model works nor dive into the math behind them. Instead, we assume you have this foundational knowledge and want to learn to use H2O in R for predictive analytics.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2853.0,,4.9,49.0
Predictive Modeling and Analytics,https://www.coursera.org/learn/predictive-modeling-analytics,Data Science,Data Analysis,Dan Zhang,"Welcome to the second course in the Data Analytics for Business specialization! 

This course will introduce you to some of the most widely used predictive modeling techniques and their core principles. By taking this course, you will form a solid foundation of predictive analytics, which refers to tools and techniques for building statistical or machine learning models to make predictions based on data. You will learn how to carry out exploratory data analysis to gain insights and prepare data for predictive modeling, an essential skill valued in the business. 

You’ll also learn how to summarize and visualize datasets using plots so that you can present your results in a compelling and meaningful way. We will use a practical predictive modeling software, XLMiner, which is a popular Excel plug-in. This course is designed for anyone who is interested in using data to gain insights and make better business decisions. The techniques discussed are applied in all functional areas within business organizations including accounting, finance, human resource management, marketing, operations, and strategic planning. 

The expected prerequisites for this course include a prior working knowledge of Excel, introductory level algebra, and basic statistics.",31092.0,16705.0,3.6,564.0
Predictive Modeling and Machine Learning with MATLAB,https://www.coursera.org/learn/predictive-modeling-machine-learning,Data Science,Machine Learning,"Heather Gorr, Michael Reardon, Maria Gavilan-Alfonso, Brandon Armstrong, Brian Buechel, Isaac Bruss, Matt Rich, Nikola Trica, Adam Filion, Erin Byrne, Sam Jones","In this course, you will build on the skills learned in Exploratory Data Analysis with MATLAB and Data Processing and Feature Engineering with MATLAB to increase your ability to harness the power of MATLAB to analyze data relevant to the work you do.

These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background. To be successful in this course, you should have some background in basic statistics (histograms, averages, standard deviation, curve fitting, interpolation) and have completed courses 1 through 2 of this specialization. 

By the end of this course, you will use MATLAB to identify the best machine learning model for obtaining answers from your data. You will prepare your data, train a predictive model, evaluate and improve your model, and understand how to get the most out of your models.",12467.0,13970.0,4.8,101.0
Predictive Modeling with Logistic Regression using SAS,https://www.coursera.org/learn/sas-predictive-modeling-using-logistic-regression,Data Science,Data Analysis,"Michael J Patetta, Marc Huber","This course covers predictive modeling using SAS/STAT software with emphasis on the LOGISTIC procedure. This course also discusses selecting variables and interactions, recoding categorical variables based on the smooth weight of evidence, assessing models, treating missing values, and using efficiency techniques for massive data sets. You learn to use logistic regression to model an individual's behavior as a function of known inputs, create effect plots and odds ratio plots, handle missing data values, and tackle multicollinearity in your predictors. You also learn to assess model performance and compare models.",3792.0,33801.0,4.6,39.0
"Predictive Modeling, Model Fitting, and Regression Analysis",https://www.coursera.org/learn/predictive-modeling-model-fitting-regression-analysis,Data Science,Data Analysis,"Dursun Delen, Julie Pai","Welcome to Predictive Modeling, Model Fitting, and Regression Analysis. In this course, we will explore different approaches in predictive modeling, and discuss how a model can be either supervised or unsupervised. We will review how a model can be fitted, trained and scored to apply to both historical and future data in an effort to address business objectives. Finally, this course includes a hands-on activity to develop a linear regression model.",2354.0,2179.0,4.4,46.0
Predictive Modelling with Azure Machine Learning Studio,https://www.coursera.org/learn/predictive-modelling-azure-machine-learning-studio,Data Science,Machine Learning,Snehan Kekre,"In this project, we will use Azure Machine Learning Studio to build a predictive model without writing a single line of code! Specifically, we will predict flight delays using weather data provided by the US Bureau of Transportation Statistics and the National Oceanic and Atmospheric Association (NOAA).  You will be provided with instructions on how to set up your Azure Machine Learning account with $200 worth of free credit to get started with running your experiments! 

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",9773.0,,4.5,236.0
Preparar datos para la exploración,https://www.coursera.org/learn/preparar-datos-para-la-exploracion,Data Science,Data Analysis,Google Career Certificates,"Este es el tercer curso del Certificado de análisis computacional de datos de Google. En estos cursos obtendrás las habilidades necesarias para solicitar empleos de analista de datos de nivel introductorio. A medida que continúes con tu comprensión de los temas de los dos primeros cursos, también se te presentarán nuevos temas que te ayudarán a obtener habilidades prácticas de análisis computacional de datos. Aprenderás a utilizar herramientas como hojas de cálculo y SQL para extraer y utilizar los datos adecuados para tus objetivos y a organizar y proteger tus datos. Los analistas de datos actuales de Google seguirán dándote instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, habrás hecho lo siguiente:
 - Descubrir cómo deciden los analistas qué datos recopilar para el análisis.
 - Aprender sobre datos estructurados y no estructurados, tipos de datos y formatos de datos.
 - Descubrir cómo identificar diferentes tipos de sesgo en los datos para ayudar a garantizar su credibilidad. 
 - Explorar cómo utilizan los analistas las hojas de cálculo y el SQL con las bases de datos y los conjuntos de datos.
 - Examinar los datos abiertos y la relación e importancia de la ética y la privacidad de los datos.
 - Comprender cómo acceder a las bases de datos y extraer, filtrar y ordenar los datos que contienen.
 - Aprender las mejores prácticas para organizar los datos y mantenerlos seguros.",6072.0,336556.0,4.7,257.0
Preparar os Dados para Exploração,https://www.coursera.org/learn/preparar-os-dados-para-exploracao,Data Science,Data Analysis,Google Career Certificates,"Este é o primeiro curso do Certificado do Google Data Analytics Estes cursos darão a você as habilidades necessárias para se candidatar a cargos empregos de analista de dados de nível introdutório. Conforme você continua a desenvolver sua compreensão dos tópicos dos dois primeiros cursos, também será apresentado a novos tópicos que o ajudarão a adquirir habilidades práticas de análise de dados. Você aprenderá como usar ferramentas como planilhas e SQL para extrair e fazer uso dos dados certos para seus objetivos e como organizar e proteger seus dados. Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível introdutório para analista de dados. Nenhuma experiência anterior é necessária.

Ao final deste curso, você poderá:
 - Descobrir como os analistas decidem quais dados coletar para análise.
 - Aprender sobre dados estruturados e não estruturados, tipos de dados e formatos de dados.
 - Descobrir como identificar diferentes tipos de distorção nos dados para ajudar a garantir a credibilidade dos dados. 
 - Explorar como os analistas usam planilhas e SQL com bancos de dados e conjuntos de dados.
 - Examinar os dados abertos e a relação e a importância da ética dos dados e da privacidade dos dados.
 - Obter uma compreensão de como acessar bancos de dados e extrair, filtrar e classificar os dados que eles contêm.
 - Aprender as melhores práticas para organizar dados e mantê-los seguros.",2491.0,159292.0,4.8,75.0
Prepare Data for Exploration,https://www.coursera.org/learn/data-preparation,Data Science,Data Analysis,Google Career Certificates,"This is the third course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. As you continue to build on your understanding of the topics from the first two courses, you’ll also be introduced to new topics that will help you gain practical data analytics skills. You’ll learn how to use tools like spreadsheets and SQL to extract and make use of the right data for your objectives and how to organize and protect your data. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
 - Find out how analysts decide which data to collect for analysis.
 - Learn about structured and unstructured data, data types, and data formats.
 - Discover how to identify different types of bias in data to help ensure data credibility. 
 - Explore how analysts use spreadsheets and SQL with databases and data sets.
 - Examine open data and the relationship between and importance of data ethics and data privacy.
 - Gain an understanding of how to access databases and extract, filter, and sort the data they contain.
 - Learn the best practices for organizing data and keeping it secure.",347209.0,4655921.0,4.8,11565.0
Prepare for DP-203: Data Engineering on Microsoft Azure Exam,https://www.coursera.org/learn/microsoft-dp-203-practice-exam,Data Science,Data Analysis, Microsoft,"Microsoft certifications give you a professional advantage by providing globally recognized and industry-endorsed evidence of mastering skills in digital and cloud businesses.​​ In this course, you will prepare to take the DP-203 Microsoft Azure Data Fundamentals certification exam. 

You will refresh your knowledge of how to use various Azure data services and languages to store and produce cleansed and enhanced datasets for analysis. You will test your knowledge in a practice exam​ mapped to all the main topics covered in the DP-203 exam, ensuring you’re well prepared for certification success. 

You will also get a more detailed overview of the Microsoft certification program and where you can go next in your career. You’ll also get tips and tricks, testing strategies, useful resources, and information on how to sign up for the DP-203 proctored exam. By the end of this course, you will be ready to sign-up for and take the DP-203 exam.​

This is the last course in a program of 10 courses to help prepare you to take the exam so that you can have expertise in designing and implementing data solutions that use Microsoft Azure data services. The Data Engineering on Microsoft Azure exam is an opportunity to prove knowledge expertise in integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions that use Microsoft Azure data services. Each course teaches you the concepts and skills that are measured by the exam. 

By the end of this Specialization, you will be ready to take and sign-up for the Exam DP-203: Data Engineering on Microsoft Azure (beta).",2440.0,9026.0,4.4,26.0
"Prepare, Clean, Transform, and Load Data using Power BI",https://www.coursera.org/learn/prepare-clean-transform-and-load-data-using-powerbi,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Usually, tidy data is a mirage in a real-world setting. Additionally, before quality analysis can be done, data need to be in a proper format. This project-based course, ""Prepare, Clean, Transform, and Load Data using Power BI"" is for beginner and intermediate Power BI users willing to advance their knowledge and skills. 
In this course, you will learn practical ways for data cleaning and transformation using Power BI. We will talk about different data cleaning and transformation tasks like splitting, renaming, adding, removing columns. By the end of this 2-hour-long project, you will change data types, merge and append data sets. By extension, you will learn how to import data from the web and unpivot data.
This project-based course is a beginner to an intermediate-level course in Power BI. Therefore, to get the most of this project, it is essential to have a basic understanding of using a computer before you take this project.",16605.0,,4.6,405.0
Preparing Data for Machine Learning Models,https://www.coursera.org/learn/preparing-data-for-machine-learning-models,Data Science,Machine Learning,Yara Yasser,"By the end of this project, you will extract colors pixels as training dataset into a form where you can feed it to your Machine Learning Model using numpy arrays.

In this project we will work with images, you will get introduced to computer vision basic concepts.
Moreover, you will be able to properly handle arrays and preprocess your training dataset and label it. 

Extracting features and preparing data is a very crucial task as it influences your model. 
So you will start to learn the basics of handling the data into the format where it would be accepted by a Machine Learning algorithm as Training Dataset.",,,,
Preparing for AI-900: Microsoft Azure AI Fundamentals exam,https://www.coursera.org/learn/microsoft-ai-900-exam-prep,Data Science,Machine Learning, Microsoft,"Microsoft certifications give you a professional advantage by providing globally recognized and industry-endorsed evidence of mastering skills in digital and cloud businesses.​​ In this course, you will prepare to take the AI-900 Microsoft Azure AI Fundamentals certification exam. 

You will refresh your knowledge of fundamental principles of machine learning on Microsoft Azure. You will go back over the main consideration of AI workloads and the features of computer vision, Natural Language Processing (NLP), and conversational AI workloads on Azure. In short, you will recap all the core concepts and skills that are measured by the exam.

You will test your knowledge in a series of practice exams​ mapped to all the main topics covered in the AI-900 exam, ensuring you’re well prepared for certification success. You will prepare to pass the certification exam by taking practice tests with similar formats and content.

You will also get a more detailed overview of the Microsoft certification program and where you can go next in your career. You’ll also get tips and tricks, testing strategies, useful resources, and information on how to sign up for the AI-900 proctored exam. By the end of this course, you will be ready to sign-up for and take the AZ-900 exam.​

This course is intended for candidates with both technical and non-technical backgrounds. Data science and software engineering experience is not required; however, some general programming knowledge or experience would be beneficial.  To be successful in this course, you need to have basic computer literacy and proficiency in the English language. You should be familiar with basic computing concepts and terminology,  general technology concepts, including concepts of machine learning and artificial intelligence.",2713.0,8029.0,4.9,41.0
Preparing for the SAS Programming Certification Exam,https://www.coursera.org/learn/preparing-sas-programming-certification,Data Science,Data Analysis,Stacey Syphus,In this course you have the opportunity to use the skills you acquired in the two SAS programming courses to solve realistic problems. This course is also designed to give you a thorough review of SAS programming concepts so you are prepared to take the SAS Certified Specialist: Base Programming Using SAS 9.4 Exam.,3646.0,24086.0,4.8,85.0
Preparing for the SAS® Viya® Programming Certification Exam,https://www.coursera.org/learn/sas-viya-programming-certification-prep,Data Science,Data Analysis,"Stacey Syphus, Peter Styliadis","Welcome to the Preparing for the SAS Viya Programming Certification Exam course. This is the third and final course in the Coursera SAS Programmer specialization. You will apply what you have learned in the first two courses by writing code to execute in SAS Cloud Analytic Services and practicing for the SAS certification exams. 

This is an advanced course, intended for learners who have completed the first two courses in the Coursera SAS Programmer specialization: SAS Programming for Distributed Computing in SAS Viya and CASL Programming for Distributed Computing in SAS Viya. 

By the end of the course, you be prepared to take either of these SAS credential exams:
- SAS® Viya® Programming Associate
- SAS® Viya® Programming Specialist",,,,
Principal Component Analysis with NumPy,https://www.coursera.org/learn/principal-component-analysis-numpy,Data Science,Machine Learning,Snehan Kekre,"Welcome to this 2 hour long project-based course on Principal Component Analysis with NumPy and Python. In this project, you will do all the machine learning without using any of the popular machine learning libraries such as scikit-learn and statsmodels. The aim of this project and is to implement all the machinery of the various learning algorithms yourself, so you have a deeper understanding of the fundamentals. By the time you complete this project, you will be able to implement and apply PCA from scratch using NumPy in Python, conduct basic exploratory data analysis, and create simple data visualizations with Seaborn and Matplotlib. The prerequisites for this project are prior programming experience in Python and a basic understanding of machine learning theory.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, NumPy, and Seaborn pre-installed.",8815.0,,4.6,286.0
Principles of fMRI 1,https://www.coursera.org/learn/functional-mri,Data Science,Data Analysis,"Martin Lindquist, PhD, MSc, Tor Wager, PhD","Functional Magnetic Resonance Imaging (fMRI) is the most widely used technique for investigating the living, functioning human brain as people perform tasks and experience mental states. It is a convergence point for multidisciplinary work from many disciplines. Psychologists, statisticians, physicists, computer scientists, neuroscientists, medical researchers, behavioral scientists, engineers, public health researchers, biologists, and others are coming together to advance our understanding of the human mind and brain.  This course covers the design, acquisition, and analysis of Functional Magnetic Resonance Imaging (fMRI) data, including psychological inference, MR Physics, K Space, experimental design, pre-processing of fMRI data, as well as Generalized Linear Models (GLM’s).  A book related to the class can be found here: https://leanpub.com/principlesoffmri.",35749.0,16040.0,4.6,767.0
Principles of fMRI 2,https://www.coursera.org/learn/functional-mri-2,Data Science,Data Analysis,"Martin Lindquist, PhD, MSc, Tor Wager, PhD","Functional Magnetic Resonance Imaging (fMRI) is the most widely used technique for investigating the living, functioning human brain as people perform tasks and experience mental states. It is a convergence point for multidisciplinary work from many disciplines. Psychologists, statisticians, physicists, computer scientists, neuroscientists, medical researchers, behavioral scientists, engineers, public health researchers, biologists, and others are coming together to advance our understanding of the human mind and brain.  This course covers the analysis of Functional Magnetic Resonance Imaging (fMRI) data.  It is a continuation of the course “Principles of fMRI, Part 1”.",14084.0,7403.0,4.7,220.0
Probabilistic Deep Learning with TensorFlow 2,https://www.coursera.org/learn/probabilistic-deep-learning-with-tensorflow2,Data Science,Machine Learning,Dr Kevin Webster,"Welcome to this course on Probabilistic Deep Learning with TensorFlow!

This course builds on the foundational concepts and skills for TensorFlow taught in the first two courses in this specialisation, and focuses on the  probabilistic approach to deep learning. This is an increasingly important area of deep learning that aims to quantify the noise and uncertainty that is often present in real world datasets. This is a crucial aspect when using deep learning models in applications such as autonomous vehicles or medical diagnoses; we need the model to know what it doesn't know.

You will learn how to develop probabilistic models with TensorFlow, making particular use of the TensorFlow Probability library, which is designed to make it easy to combine probabilistic models with deep learning. As such, this course can also be viewed as an introduction to the TensorFlow Probability library.

You will learn how probability distributions can be represented and incorporated into deep learning models in TensorFlow, including Bayesian neural networks, normalising flows and variational autoencoders. You will learn how to develop models for uncertainty quantification, as well as generative models that can create new samples similar to those in the dataset, such as images of celebrity faces.

You will put concepts that you learn about into practice straight away in practical, hands-on coding tutorials, which you will be guided through by a graduate teaching assistant. In addition there is a series of automatically graded programming assignments for you to consolidate your skills.

At the end of the course, you will bring many of the concepts together in a Capstone Project, where you will develop a variational autoencoder algorithm to produce a generative model of a synthetic image dataset that you will create yourself.

This course follows on from the previous two courses in the specialisation, Getting Started with TensorFlow 2 and Customising Your Models with TensorFlow 2. The additional prerequisite knowledge required in order to be successful in this course is a solid foundation in probability and statistics. In particular, it is assumed that you are familiar with standard probability distributions, probability density functions, and concepts such as maximum likelihood estimation, change of variables formula for random variables, and the evidence lower bound (ELBO) used in variational inference.",10633.0,21017.0,4.7,84.0
Probabilistic Graphical Models 1: Representation,https://www.coursera.org/learn/probabilistic-graphical-models,Data Science,Machine Learning,Daphne Koller,"Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the first in a sequence of three. It describes the two basic PGM representations: Bayesian Networks, which rely on a directed graph; and Markov networks, which use an undirected graph. The course discusses both the theoretical properties of these representations as well as their use in practice. The (highly recommended) honors track contains several hands-on assignments on how to represent some real-world problems. The course also presents some important extensions beyond the basic PGM representation, which allow more complex models to be encoded compactly.",83653.0,45074.0,4.6,1396.0
Probabilistic Graphical Models 2: Inference,https://www.coursera.org/learn/probabilistic-graphical-models-2-inference,Data Science,Machine Learning,Daphne Koller,"Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the second in a sequence of three. Following the first course, which focused on representation, this course addresses the question of probabilistic inference: how a PGM can be used to answer questions. Even though a PGM generally describes a very high dimensional distribution, its structure is designed so as to allow questions to be answered efficiently. The course presents both exact and approximate algorithms for different types of inference tasks, and discusses where each could best be applied. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of the most commonly used exact and approximate algorithms are implemented and applied to a real-world problem.",23334.0,16226.0,4.6,475.0
Probabilistic Graphical Models 3: Learning,https://www.coursera.org/learn/probabilistic-graphical-models-3-learning,Data Science,Machine Learning,Daphne Koller,"Probabilistic graphical models (PGMs) are a rich framework for encoding probability distributions over complex domains: joint (multivariate) distributions over large numbers of random variables that interact with each other. These representations sit at the intersection of statistics and computer science, relying on concepts from probability theory, graph algorithms, machine learning, and more. They are the basis for the state-of-the-art methods in a wide variety of applications, such as medical diagnosis, image understanding, speech recognition, natural language processing, and many, many more. They are also a foundational tool in formulating many machine learning problems. 

This course is the third in a sequence of three. Following the first course, which focused on representation, and the second, which focused on inference, this course addresses the question of learning: how a PGM can be learned from a data set of examples. The course discusses the key problems of parameter estimation in both directed and undirected models, as well as the structure learning task for directed models. The (highly recommended) honors track contains two hands-on programming assignments, in which key routines of two commonly used learning algorithms are implemented and applied to a real-world problem.",19653.0,15261.0,4.6,295.0
Probability Theory: Foundation for Data Science,https://www.coursera.org/learn/probability-theory-foundation-for-data-science,Data Science,Probability and Statistics,"Anne Dougherty, Jem Corcoran","Understand the foundations of probability and its relationship to statistics and data science.  We’ll learn what it means to calculate a probability, independent and dependent outcomes, and conditional events.  We’ll study discrete and continuous random variables and see how this fits with data collection.  We’ll end the course with Gaussian (normal) random variables and the Central Limit Theorem and understand its fundamental importance for all of statistics and data science.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder

Logo adapted from photo by Christopher Burns on Unsplash.",11508.0,148429.0,4.4,88.0
Probability and Statistics: To p or not to p?,https://www.coursera.org/learn/probability-statistics,Data Science,Probability and Statistics,Dr James Abdey,"We live in an uncertain and complex world, yet we continually have to make decisions in the present with uncertain future outcomes.  Indeed, we should be on the look-out for ""black swans"" - low-probability high-impact events.

To study, or not to study?  To invest, or not to invest?  To marry, or not to marry?

While uncertainty makes decision-making difficult, it does at least make life exciting!  If the entire future was known in advance, there would never be an element of surprise.  Whether a good future or a bad future, it would be a known future.

In this course we consider many useful tools to deal with uncertainty and help us to make informed (and hence better) decisions - essential skills for a lifetime of good decision-making.

Key topics include quantifying uncertainty with probability, descriptive statistics, point and interval estimation of means and proportions, the basics of hypothesis testing, and a selection of multivariate applications of key terms and concepts seen throughout the course.",70831.0,40906.0,4.6,1370.0
Problem Solving with Excel,https://www.coursera.org/learn/excel-analysis,Data Science,Data Analysis,Alex Mannella,"This course explores Excel as a tool for solving business problems. In this course you will learn the basic functions of excel through guided demonstration. Each week you will build on your excel skills and be provided an opportunity to practice what you’ve learned. Finally, you will have a chance to put your knowledge to work in a final project.  Please note, the content in this course was developed using a Windows version of Excel 2013.  

This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",125382.0,85004.0,4.7,5101.0
Procesamiento del lenguaje natural con Python y Power BI,https://www.coursera.org/learn/nlp-python-powerbi,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender acerca del Procesamiento Natural del Lenguaje, centrándote en la parte de Topic Modelling. Aprenderas a como analizar tus textos mediante Python y Pycaret. También aprenderás a añadir capacidades de NLP a tus dashboards en Power BI.",,,,
Proceso de datos sucios a datos limpios,https://www.coursera.org/learn/proceso-de-datos-sucios-a-datos-limpios,Data Science,Data Analysis,Google Career Certificates,"Este es el cuarto curso del certificado de análisis computacional de datos de Google. En estos cursos obtendrás las habilidades necesarias para solicitar empleos de analista de datos de nivel introductorio. En este curso seguirás aprendiendo sobre el análisis de datos y los conceptos y las herramientas con los que trabajan los analistas de datos. Aprenderás cómo controlar y limpiar datos utilizando hojas de cálculo y SQL, y cómo verificar e informar los resultados de tu limpieza de datos. Los analistas de datos actuales de Google seguirán dándote instrucciones y te proporcionarán formas prácticas de llevar a cabo las tareas comunes de los analistas de datos con las mejores herramientas y recursos.

Los alumnos que completen este programa de certificados estarán listos para solicitar trabajos de nivel introductorio como analistas de datos. No se requiere experiencia previa.

Al final de este curso, serás capaz de:
 - Controlar la integridad de los datos.
 - Descubrir las técnicas de limpieza de datos utilizando hojas de cálculo. 
 - Desarrollar consultas básicas en SQL para su uso con bases de datos.
 - Aplicar funciones básicas de SQL para limpiar y transformar variables de datos.
 - Aprender cómo verificar los resultados de la limpieza de datos.
 - Explorar los elementos y la importancia de los informes sobre limpieza de datos.",4325.0,220586.0,4.7,127.0
Process Data from Dirty to Clean,https://www.coursera.org/learn/process-data,Data Science,Data Analysis,Google Career Certificates,"This is the fourth course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. In this course, you’ll continue to build your understanding of data analytics and the concepts and tools that data analysts use in their work. You’ll learn how to check and clean your data using spreadsheets and SQL as well as how to verify and report your data cleaning results. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will be able to do the following:
 - Learn how to check for data integrity.
 - Discover data cleaning techniques using spreadsheets. 
 - Develop basic SQL queries for use on databases.
 - Apply basic SQL functions for cleaning and transforming data.
 - Gain an understanding of how to verify the results of cleaning data.
 - Explore the elements and importance of data cleaning reports.",284116.0,3471838.0,4.8,8530.0
Process Mining: Data science in Action,https://www.coursera.org/learn/process-mining,Data Science,Data Analysis,Wil van der Aalst,"Process mining is the missing link between model-based process analysis and data-oriented analysis techniques. Through concrete data sets and easy to use software the course provides data science knowledge that can be applied directly to analyze and improve processes in a variety of domains.

Data science is the profession of the future, because organizations that are unable to use (big) data in a smart way will not survive. It is not sufficient to focus on data storage and data analysis. The data scientist also needs to relate data to process analysis. Process mining bridges the gap between traditional model-based process analysis (e.g., simulation and other business process management techniques) and data-centric analysis techniques such as machine learning and data mining. Process mining seeks the confrontation between event data (i.e., observed behavior) and process models (hand-made or discovered automatically). This technology has become available only recently, but it can be applied to any type of operational processes (organizations and systems). Example applications include: analyzing treatment processes in hospitals, improving customer service processes in a multinational, understanding the browsing behavior of customers using booking site, analyzing failures of a baggage handling system, and improving the user interface of an X-ray machine. All of these applications have in common that dynamic behavior needs to be related to process models. Hence, we refer to this as ""data science in action"".

The course explains the key analysis techniques in process mining. Participants will learn various process discovery algorithms. These can be used to automatically learn process models from raw event data. Various other process analysis techniques that use event data will be presented. Moreover, the course will provide easy-to-use software, real-life data sets, and practical skills to directly apply the theory in a variety of application domains.

This course starts with an overview of approaches and technologies that use event data to support decision making and business process (re)design. Then the course focuses on process mining as a bridge between data mining and business process modeling. The course is at an introductory level with various practical assignments.

The course covers the three main types of process mining.

1. The first type of process mining is discovery. A discovery technique takes an event log and produces a process model without using any a-priori information. An example is the Alpha-algorithm that takes an event log and produces a process model (a Petri net) explaining the behavior recorded in the log.

2. The second type of process mining is conformance. Here, an existing process model is compared with an event log of the same process. Conformance checking can be used to check if reality, as recorded in the log, conforms to the model and vice versa.

3. The third type of process mining is enhancement. Here, the idea is to extend or improve an existing process model using information about the actual process recorded in some event log. Whereas conformance checking measures the alignment between model and reality, this third type of process mining aims at changing or extending the a-priori model. An example is the extension of a process model with performance information, e.g., showing bottlenecks. Process mining techniques can be used in an offline, but also online setting. The latter is known as operational support. An example is the detection of non-conformance at the moment the deviation actually takes place. Another example is time prediction for running cases, i.e., given a partially executed case the remaining processing time is estimated based on historic information of similar cases.

Process mining provides not only a bridge between data mining and business process management; it also helps to address the classical divide between ""business"" and ""IT"". Evidence-based business process management based on process mining helps to create a common ground for business process improvement and information systems development.

The course uses many examples using real-life event logs to illustrate the concepts and algorithms. After taking this course, one is able to run process mining projects and have a good understanding of the Business Process Intelligence field.

After taking this course you should:
- have a good understanding of Business Process Intelligence techniques (in particular process mining),
- understand the role of Big Data in today’s society,
- be able to relate process mining techniques to other analysis techniques such as simulation, business intelligence, data mining, machine learning, and verification,
- be able to apply basic process discovery techniques to learn a process model from an event log (both manually and using tools),
- be able to apply basic conformance checking techniques to compare event logs and process models (both manually and using tools),
- be able to extend a process model with information extracted from the event log (e.g., show bottlenecks),
- have a good understanding of the data needed to start a process mining project,
- be able to characterize the questions that can be answered based on such event data,
- explain how process mining can also be used for operational support (prediction and recommendation), and
- be able to conduct process mining projects in a structured manner.",70584.0,83158.0,4.7,1118.0
Processar os dados para limpá-los,https://www.coursera.org/learn/processar-os-dados-para-limpa-los,Data Science,Data Analysis,Google Career Certificates,"Este é o quarto curso do Certificado de Data Analytics do Google. Estes cursos darão a você as habilidades necessárias para se candidatar a cargos empregos de analista de dados de nível inicial. Neste curso, você continuará a ampliar seu conhecimento sobre Data Analytics e os conceitos e ferramentas que os analistas de dados usam no trabalho. Você aprenderá como checar e limpar os dados usando planilhas e SQL, além de verificar e gerar relatórios dos resultados da limpeza de dados. Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível inicial para analista de dados. Nenhuma experiência anterior é necessária.

Veja do que você será capaz ao final deste curso:
 - Verificar a integridade dos dados.
 - Aplicar técnicas de limpeza de dados usando planilhas. 
 - Desenvolver consultas SQL básicas para serem usadas em bancos de dados.
 - Aplicar funções básicas de SQL para limpar e transformar os dados.
 - Entender como verificar os resultados da limpeza de dados.
 - Explorar os elementos e a importância dos relatórios de limpeza de dados.",1562.0,72918.0,4.3,31.0
Production Machine Learning Systems,https://www.coursera.org/learn/gcp-production-ml-systems,Data Science,Machine Learning,Google Cloud Training,"This course covers how to implement the various flavors of production ML systems— static, dynamic, and continuous training; static and dynamic inference; and batch and online processing. You delve into TensorFlow abstraction levels, the various options for doing distributed training, and how to write distributed training models with custom estimators.",23434.0,19127.0,4.6,925.0
Projet Capstone du Certificat d'analytique des données de Google : Terminer une étude de cas,https://www.coursera.org/learn/projet-capstone-du-certificat-danalytique-des-donnees-de-google,Data Science,Data Analysis,Google Career Certificates,"Ce cours est le huitième du Google Data Analytics Certificate. Vous aurez la possibilité de mener une étude de cas facultative, qui vous aidera à vous préparer à la recherche d'un emploi en analytique des données. Les études de cas sont couramment utilisées par les employeurs afin d’évaluer les compétences analytiques. Pour votre étude de cas, vous choisirez un scénario basé sur des analyses. Vous poserez ensuite des questions, préparerez, traiterez, analyserez, visualiserez et utiliserez les données du scénario. Vous apprendrez également d'autres compétences utiles en matière de recherche d'emploi grâce à des vidéos contenant des questions d'entretien d'embauche courantes avec des réponses, des documents utiles afin de créer un portfolio en ligne, et bien plus encore. Des analystes de données actuellement chez Google vous instruiront et vous fourniront des moyens pratiques d'accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler à des emplois d'analyste de données de niveau d’entrée. Aucune expérience préalable n'est nécessaire.

D'ici la fin de ce cours, vous aurez :
 - découvert les avantages et les utilisations des études de cas et des portfolios dans la recherche d'emploi ;
 - examiné des scénarios d'entretien d'embauche réels et des questions d'entretien courantes ;
 - découvert comment les études de cas peuvent faire partie du processus d'entretien d'embauche ; 
 - examiné et évalué différents scénarios d'études de cas ; 
 - eu la possibilité de terminer votre propre étude de cas pour votre portfolio.",,,,
Projeto final de Data Analytics do Google: conclua um estudo de caso,https://www.coursera.org/learn/projeto-final-conclua-um-estudo-de-caso,Data Science,Data Analysis,Google Career Certificates,"Este é o oitavo curso do Certificado de Data Analytics do Google. Você terá a oportunidade de completar um estudo de caso opcional, que ajudará você a se preparar para a busca de emprego em Data Analytics. Os estudos de caso normalmente são usados pelos empregadores para avaliar as habilidades analíticas. Para o seu estudo de caso, escolha um cenário baseado em análises. Depois, faça perguntas, prepare, processe, analise, visualize e aja de acordo com os dados desse cenário. Você também aprenderá outras habilidades úteis para os processos seletivos por meio de vídeos com perguntas e respostas comuns nas entrevistas, materiais úteis para criar um portfólio online e muito mais. Os analistas de dados do Google vão instruir e oferecer maneiras práticas de realizar tarefas comuns de analistas de dados com as melhores ferramentas e recursos.

Os alunos que concluírem este programa de certificação poderão se candidatar a empregos de nível inicial para analista de dados. Nenhuma experiência anterior é necessária.

Ao final deste curso, você poderá:
 - Conhecer os benefícios e os usos de estudos de caso e portfólios ao procurar um trabalho.
 - Explorar situações reais de entrevistas de trabalho e perguntas comuns nas entrevistas.
 - Descobrir como os estudos de caso podem fazer parte do processo seletivo. 
 - Examinar e considerar diferentes cenários de estudo de caso. 
 - Criar seu próprio estudo de caso para seu portfólio.",,9122.0,4.8,20.0
Promote the Ethical Use of Data-Driven Technologies,https://www.coursera.org/learn/promote-ethical-data-driven-technologies,Data Science,Machine Learning,"Renée Cummings, Aaron Hui, Megan Smith Branch, Eleanor 'Nell' Watson, Tania De Gasperis","The greatest risk in emerging technology is the perpetuation of bias in automated technologies dependent upon data sets. Solutions created with racial, gender or demographic bias, whether unintentional or not can perpetuate tragic inequities socially and economically.  This is the first of five courses within the Certified Ethical Emerging Technologist (CEET) professional certificate and it is designed for learners seeking to advocate and promote the ethical use of data-driven technologies. Students will learn what emerging technologies are and how they can be used to create data driven solutions. You will learn types of bias and common ethical theories and how they can be applied to emerging technology, and examine legal and ethical privacy concepts as they relate to technologies such as artificial intelligence, machine learning and data science fields. Throughout the course learners begin to distinguish which types of bias may cause the greatest risk and which principles to apply to strategically respond to ethical considerations.",10960.0,37606.0,4.7,157.0
Proyecto Final de Analítica de Datos,https://www.coursera.org/learn/proyecto-final-de-analitica-de-datos,Data Science,Data Analysis,"Rav Ahuja, Ramesh Sannareddy","En este curso se aplicarán diversas habilidades y técnicas de Data Analytics que ha aprendido como parte de los cursos anteriores del Certificado Profesional de IBM Data Analyst. Asumirá el papel de Analista de datos asociado que se ha incorporado recientemente a la organización y se enfrentará a un reto empresarial que requiere que el análisis de datos se realice en conjuntos de datos del mundo real.

Se encargará de las tareas de recoger datos de múltiples fuentes, realizar análisis de datos exploratorios, la preparación y discusión de datos, el análisis estadístico y la extracción de datos, la creación de gráficos y diagramas para visualizar los datos, y la construcción de un tablero interactivo. El proyecto culminará con la presentación de su informe de análisis de datos, con un resumen ejecutivo para los diversos interesados en la organización. Se evaluará tanto su trabajo en las diversas etapas del proceso de análisis de datos como el producto final. 

Este proyecto es una gran oportunidad para mostrar sus habilidades de análisis de datos, y demostrar su competencia a los posibles empleadores.",,1953.0,,
Proyek Akhir Analitis Data Google: Selesaikan Sebuah Studi Kasus,https://www.coursera.org/learn/proyek-akhir-analitis-data-google-selesaikan-sebuah-studi-kasus,Data Science,Data Analysis,Google Career Certificates,"Ini adalah materi kedelapan dalam program Google Data Analytics Certificate (Sertifikat Analisis Data Google). Anda akan berkesempatan untuk menyelesaikan studi kasus yang sifatnya opsional, yang akan membantu mempersiapkan diri Anda dalam mencari pekerjaan di bidang analitis data. Studi kasus biasanya digunakan oleh pemberi kerja untuk menilai keterampilan analitis. Di studi kasus ini, Anda akan memilih sebuah skenario berbasis analitis. Anda kemudian akan mengajukan pertanyaan, mempersiapkan, memproses, menganalisis, memvisualisasikan, dan bertindak berdasarkan data dari skenario tersebut. Anda juga akan mempelajari keterampilan lain yang berguna untuk mencari pekerjaan melalui video berisi pertanyaan dan jawaban yang umum dalam suatu wawancara, bahan yang bermanfaat untuk menyusun portofolio secara online, dan banyak lagi. Para analis data Google akan mengajarkan dan memberi tahu Anda berbagai cara untuk menyelesaikan tugas umum analis data dengan menggunakan peralatan dan referensi materi terbaik.

Pembelajar yang menyelesaikan program sertifikat ini akan memiliki bekal yang cukup untuk melamar kerja sebagai analis data tingkat pemula. Tidak perlu pengalaman apa pun.

Di akhir materi ini, Anda akan:
 - Mempelajari manfaat dan kegunaan studi kasus dan portofolio dalam pencarian kerja.
 - Mengeksplorasi skenario wawancara kerja di dunia nyata dan pertanyaan yang umum di suatu wawancara.
 - Mengetahui bagaimana studi kasus dapat menjadi bagian dari proses wawancara kerja. 
 - Memeriksa dan mempertimbangkan skenario studi kasus yang berbeda-beda. 
 - Berkesempatan untuk menyelesaikan studi kasus Anda sendiri untuk portofolio Anda.",2180.0,140533.0,5.0,124.0
Préparer les données pour l'exploration,https://www.coursera.org/learn/preparer-les-donnees-pour-exploration,Data Science,Data Analysis,Google Career Certificates,"Il s'agit du troisième cours du Google Data Analytics Certificate. Ces cours vous permettront d’acquérir les compétences dont vous avez besoin pour postuler à des emplois d’analyste de données de niveau junior. Au fur et à mesure que vous approfondissez votre compréhension des sujets des deux premiers cours, vous découvrirez de nouveaux sujets qui vous aideront à acquérir des compétences pratiques en analytique des données. Vous apprendrez à utiliser des outils tels que des feuilles de calcul et SQL pour extraire et utiliser les bonnes données pour vos objectifs et à organiser et protéger vos données. Des analystes de données actuellement chez Google vous instruiront et vous fourniront des moyens pratiques d’accomplir les tâches courantes des analystes de données, avec les meilleurs outils et ressources.

Les participants qui terminent cette formation certifiante seront préparés à postuler à des emplois d’analyste de données de niveau junior. Aucune expérience préalable n’est nécessaire.

D’ici la fin de ce cours, vous :
 - Découvrez comment les analystes décident quelles données collecter pour analyse.
 - Découvrez les données structurées et non structurées, les types de données et les formats de données.
 - Découvrez comment identifier différents types de partialité dans les données et assurer leur crédibilité. 
 - Découvrez comment les analystes utilisent les feuilles de calcul et SQL avec les bases de données et les jeux de données.
 - Examinez les données ouvertes et la relation entre l'importance de l'éthique des données et la confidentialité des données.
 - Comprenez comment accéder aux bases de données et extraire, filtrer et trier les données qu'elles contiennent.
 - Apprenez les meilleures pratiques pour organiser les données et les sécuriser.",,2173.0,,
Publication-Ready Tables in R,https://www.coursera.org/learn/publication-ready-tables-r-programming,Data Science,Data Analysis,Emmanuel Segui,"Learn how to create Publication-Ready Tables in R for descriptive statistics, contingency tables, correlation tables, model summary tables and survival probabilities tables",,,,
Publishing Visualizations in R with Shiny and flexdashboard,https://www.coursera.org/learn/data-viz-shiny-dashboards,Data Science,Data Analysis,Collin Paschall,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance.

This course is the fourth in the Specialization ""Data Visualization and Dashboarding in R."" Learners will come to this course with a strong background in making visualization in R using ggplot2. To build on those skills, this course covers creating interactive visualization using Shiny, as well as combining different kinds of figures made in R into interactive dashboards.",3307.0,8303.0,4.9,45.0
PyCaret: Anatomy of Classification,https://www.coursera.org/learn/pycaret-classification,Data Science,Data Analysis,Muhammad Saad uddin,"In this 2 hour 10 mins long project-based course, you will learn how to set up PyCaret Environment and become familiar with the variety of data preparing tasks done during setup, be able to create, see and compare performance of several models, learn how to tune your model without doing an exhaustive search, create impressive visuals of models, feature importance and much more.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,12.0
PyCaret: Anatomy of Regression,https://www.coursera.org/learn/pycaret-regression,Data Science,Machine Learning,Muhammad Saad uddin,"In this 2 hour and 15 mins long project-based course, you will learn how to ow to set up PyCaret Environment and become familiar with the variety of data preparing tasks done during setup, be able to create, see and compare the performance of several models, learn how to tune your model without doing an exhaustive search, create impressive visuals of models, interpret models with the wrapper around SHAP Library and much more & all this with just a few lines of code.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.4,10.0
Python Optical Character Recognition using Pytorch,https://www.coursera.org/learn/python-optical-character-recognition-using-pytorch,Data Science,Machine Learning,Vinita Silaparasetty,"Note: The rhyme platform currently does not support webcams, so this is not a live project. 

This guided project is about optical character recognition using Pythorch, a Python library.  This comes under the computer vision domain. 

While you are watching me code, you will get a cloud desktop with all the required software pre-installed. This will allow you to code along with me. After all, we learn best with active, hands-on learning.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Python Packages for Data Science,https://www.coursera.org/learn/python-packages-data-science,Data Science,Data Analysis,Di Wu,"How many times have you decided to learn a programming language but got stuck somewhere along the way, grew frustrated, and gave up? This specialization is designed for learners who have little or no programming experience but want to use Python as a tool to play with data. 

Now that you have mastered the fundamentals of Python and Python functions, you will turn your attention to Python packages specifically used for Data Science, such as Pandas, Numpy, Matplotlib, and Seaborn.

Are you ready? Let's go!

Logo image courtesy of Mourizal Zativa. Available on Unsplash here: https://unsplash.com/photos/gNMVpAPe3PE",,9690.0,,
Python Project for Data Science,https://www.coursera.org/learn/python-project-for-data-science,Data Science,Data Analysis,"Azim Hirjani, Joseph Santarcangelo","This mini-course is intended to for you to demonstrate foundational Python skills for working with data. The completion of this course involves working on a hands-on project where you will develop a simple dashboard using Python.

This course is part of the IBM Data Science Professional Certificate and the IBM Data Analytics Professional Certificate.

PRE-REQUISITE: **Python for Data Science, AI and Development** course from IBM is a pre-requisite for this project course. Please ensure that before taking this course you have either completed the Python for Data Science, AI and Development course from IBM or have equivalent proficiency in working with Python and data.

NOTE: This course is not intended to teach you Python and does not have too much instructional content. It is intended for you to apply prior Python knowledge.",92090.0,254075.0,4.5,2593.0
Python and Pandas for Data Engineering,https://www.coursera.org/learn/python-and-pandas-for-data-engineering-duke,Data Science,Data Analysis,"Kennedy Behrman, Alfredo Deza, Noah Gift","In this first course of the Python, Bash and SQL Essentials for Data Engineering Specialization, you will learn how to set up a version-controlled Python working environment which can utilize third party libraries. You will learn to use Python and the powerful Pandas library for data analysis and manipulation. Additionally, you will also be introduced to Vim and Visual Studio Code, two popular tools for writing software. This course is valuable for beginning and intermediate students in order to begin transforming and manipulating data as a data engineer.",6051.0,57412.0,4.4,59.0
Python for Data Analysis: Pandas & NumPy,https://www.coursera.org/learn/python-for-data-analysis-numpy,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will understand the fundamentals of data analysis in Python and we will leverage the power of two important python libraries known as Numpy and pandas. NumPy and Pandas are two of the most widely used python libraries in data science. They offer high-performance, easy to use structures and data analysis tools. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7277.0,,4.4,183.0
"Python for Data Science, AI & Development",https://www.coursera.org/learn/python-for-applied-data-science-ai,Data Science,Data Analysis,Joseph Santarcangelo,"Kickstart your learning of Python for data science, as well as programming in general, with this beginner-friendly introduction to Python. Python is one of the world’s most popular programming languages, and there has never been greater demand for professionals with the ability to apply Python fundamentals to drive business solutions across industries. 

This course will take you from zero to programming in Python in a matter of hours—no prior programming experience necessary! You will learn Python fundamentals, including data structures and data analysis, complete hands-on exercises throughout the course modules, and create a final project to demonstrate your new skills. 

By the end of this course, you’ll feel comfortable creating basic programs, working with data, and solving real-world problems in Python. You’ll gain a strong foundation for more advanced learning in the field, and develop skills to help advance your career. 

This course can be applied to multiple Specialization or Professional Certificate programs. Completing this course will count towards your learning in any of the following programs: 

IBM Applied AI Professional Certificate 

Applied Data Science Specialization 

IBM Data Science Professional Certificate 

Upon completion of any of the above programs, in addition to earning a Specialization completion certificate from Coursera, you’ll also receive a digital badge from IBM recognizing your expertise in the field.",474319.0,1640991.0,4.6,29467.0
Python for Data Visualization: Matplotlib & Seaborn,https://www.coursera.org/learn/python-for-data-visualization-seaborn,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will understand the fundamentals of data visualization with Python and leverage the power of two important python libraries known as Matplotlib and seaborn. We will learn how to generate line plots, scatterplots, histograms, distribution plot, 3D plots, pie charts, pair plots, countplots and many more! 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2080.0,,4.6,42.0
Python for Data Visualization:Matplotlib & Seaborn(Enhanced),https://www.coursera.org/learn/python-for-data-visualization-matplotlib-and-seaborn,Data Science,Data Analysis,Ryan Ahmed,"In this hands-on project, we will understand the fundamentals of data visualization with Python and leverage the power of two important python libraries known as Matplotlib and seaborn. We will learn how to generate line plots, scatterplots, histograms, distribution plot, 3D plots, pie charts, pair plots, countplots and many more! 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Python for Genomic Data Science,https://www.coursera.org/learn/python-genomics,Data Science,Data Analysis,"Mihaela Pertea, PhD, Steven Salzberg, PhD",This class provides an introduction to the Python programming language and the iPython notebook. This is the third course in the Genomic Big Data Science Specialization from Johns Hopkins University.,50406.0,48752.0,4.3,1515.0
Python para Ciencia de Datos,https://www.coursera.org/learn/python-para-ciencia-de-datos,Data Science,Data Analysis,Alejandro Cataldo,"Resultados de aprendizaje:

●	Comprender y analizar las herramientas básicas de Python.
●	Utilizar herramientas de Python para el desarrollo de técnicas para el manejo y análisis de datos como apoyo a la toma de mejores decisiones, identificando las posibilidades y oportunidades en las organizaciones.
●	Identificar las oportunidades y posibilidades que ofrece el uso de la Ciencia de Datos a las organizaciones.

Las aplicaciones de técnicas de análisis de datos están siendo cada día más demandadas, debido a su utilización en las organizaciones y a la tendencia mundial de mejorar los procesos de toma de decisiones en base a la evidencia que se puede obtener del análisis de la enorme cantidad de información disponible. Así, la pertinencia del curso está relacionada con la necesaria aplicación de diversos métodos para analizar estos datos. Todo ello, para mejorar diferentes procesos de decisión de corto, mediano y largo plazo de los distintos sistemas dentro de una organización. 

Este curso busca que profesionales de diversas áreas y con distintas motivaciones logren comprender cómo el uso de adecuado y eficiente de Python como herramienta computacional para el análisis de datos puede mejorar su toma de decisiones dentro de su organización. Para ello se introducirán los conceptos básicos y generales del análisis de datos, se revisará la importancia de visualizar e identificar valor en los datos y cómo los distintos métodos descriptivos, predictivos, y prescriptivos permiten evidenciar oportunidades y justificar decisiones. Para ejemplificar estos conceptos y su desarrollo a través de Python, se verán casos prácticos en industrias como el retail, medicina y logística, entre otras.",,13469.0,,
Python para Data Science y AI,https://www.coursera.org/learn/python-para-data-science-y-ai,Data Science,Data Analysis,Joseph Santarcangelo,"En este curso aprenderá cómo comenzar rápida y fácilmente con la Inteligencia Artificial utilizando IBM Watson. Comprenderá cómo funciona Watson, se familiarizará con sus casos de uso y ejemplos de clientes de la vida real, y se le presentarán varios de los servicios de inteligencia artificial de Watson de IBM que permiten a cualquiera aplicar fácilmente la inteligencia artificial y crear aplicaciones inteligentes. También trabajará con varios servicios de Watson para demostrar la IA en acción.

Este curso no requiere ninguna experiencia en programación o ciencias de la computación y está diseñado para cualquier persona, ya sea que tenga una formación técnica o no.

Esta es una traducción al español de un curso que se creó originalmente en inglés. Muchos de los componentes del curso se han traducido al español, incluidos títulos de lecciones, transcripciones de videos, lecturas, instrucciones de laboratorio y cuestionarios. Sin embargo, algunos componentes del curso, incluidos los videos originales y su narración, todavía están en inglés.",4054.0,33128.0,4.8,85.0
Python para a Ciência de Dados e IA,https://www.coursera.org/learn/python-for-applied-data-science-ai-pt,Data Science,Data Analysis,Joseph Santarcangelo,"Inicie seu estudo de Python para ciência de dados e de programação em geral com esta introdução ao Python feita especialmente para iniciantes. Python é uma das linguagens de programação mais populares do mundo e nunca houve tanta demanda por profissionais com a habilidade de aplicar os princípios básicos de Python para impulsionar soluções de negócios em vários setores. 

Neste curso, você aprenderá do zero a programar com Python em questão de horas, sem precisar ter experiência prévia em programação! Você aprenderá os fundamentos básicos de Python, incluindo estruturas e análise de dados, exercícios práticos em todo os módulos do curso e criará um projeto final para demonstrar suas novas habilidades. 

Até o final deste curso, você vai se sentir confiante para criar programas básicos, trabalhar com dados e resolver problemas do mundo real com Python. Você terá uma base de conhecimento forte para fazer estudos mais avançados na área e desenvolverá habilidades para ajudar a subir na sua carreira. 

Este curso pode ser aplicado em várias especializações ou programas de certificação profissional. Concluir este curso contará para o seu aprendizado em qualquer um dos programas a seguir: 

Certificado Profissional de IA Aplicada da IBAM 

Especialização em Ciências de Dados Aplicada 

Certificado Profissional em Ciência de Dados da IBM 

Após a conclusão de um dos programas acima, além de ganhar um certificado de conclusão de especialização da Coursera, você também receberá um selo digital da IBM reconhecendo a sua competência na área.",1870.0,3509.0,,
Python para el análisis de datos: Pandas y NumPy,https://www.coursera.org/learn/python-para-el-anlisis-de-datos-pandas-y-numpy,Data Science,Data Analysis,Daniel David Benavides Sánchez,"Al final de este proyecto guiado, podrás manipular datos usando las librerías NumPy y Pandas de Python. 

NumPy es una biblioteca de Python utilizada para trabajar con matrices.
En Python, se puede trabajar con listas que actúan como arreglos, pero el procesamiento es lento. Con NumPy la manipulación de una matriz es mucho más rápido que las listas tradicionales de Python.
Por otro lado, Pandas es una herramienta de análisis y manipulación de datos de código abierto rápida, potente, flexible y fácil de usar, construida sobre el lenguaje de programación Python.

A lo largo de este proyecto desarrollaremos un caso estudio, que te permitirá comprender y aplicar los conceptos necesarios para el análisis de datos con las librerías Pandas y Numpy.

Iniciaremos este proyecto con la revisión de la biblioteca NumPy, haciendo referencia a la creación de arreglos de una y dos dimensiones. Aprenderás a acceder a los valores de los arreglos y harás uso de los métodos para manipular y transformar los datos.
Posteriormente con pandas, aprenderás a leer datos de un dataset, seleccionar y realizar operaciones con funciones. 

Este proyecto es de nivel básico y está diseñado para desarrolladores y personas que deseen aprender Python para el análisis de datos haciendo uso de Pandas y NumPy.
 
Cada tarea del proyecto te ayudará a colocar en práctica los conocimientos adquiridos de forma fácil. 

Adquirir conocimientos de Python para el análisis de datos, te llevará a ser más atractivo al momento de aplicar en ofertas laborales.",,,,
Python per la Data Science,https://www.coursera.org/learn/python-per-la-data-science,Data Science,Data Analysis,Carlo Sansone,"Python per la Data Science è un corso cruciale per qualsiasi professionista che voglia analizzare grandi quantità di dati attraverso le più recenti tecniche di machine Learning e Deep learning. 

Il core del corso è rappresentato dall’utilizzo dei notebook: una nuova forma di fruizione dei contenuti didattici in cui testo e teoria sono affiancati a numerosi codici eseguibili e modificabili.  Il formato è visivamente simile ad un  file PDF a cui si aggiunge l’interattività tipica dei prodotti software. Il risultato? Un corso fortemente interattivo a vocazione pratica in cui, codice dopo codice, si manipolano dati fino a giungere ad esempi avanzati di image processing.
Non ti resta altro da fare che iscriverti al Corso e metterti alla prova con “Python per la Data Science”: ti aspetto!


Questo corso fa parte della Specialization in Data Science con Python e R, cui sarà possibile iscriversi non appena il corso sarà partito.",,1693.0,,
Python معالجة مسبقة للبيانات و تحليلها بواسطة,https://www.coursera.org/learn/data-wrangling-using-python,Data Science,Data Analysis,Omnya Khaled,"فى نهاية هذا المشروع ، ستكون قادرًا على تحليل بيانات Quandl من خلال معالجة مسبقة للبيانات وهي عملية جمع البيانات واختيارها وتحويلها للإجابة على أسئلة  باستخدام Python. في هذا المشروع ، ستتمكن من جمع البيانات لعام 2020 بأكملها والاستعلام عنها من موقع Quandl باستخدام واجهة برمجة التطبيقات الخاصة بها (API). إنه موقع مجاني للبيانات. ستتمكن من تحويل بيانات JSON التي تم إرجاعها إلى قاموس Python. وستكون قادرًا على تحليل هذه البيانات لحساب أعلى وأدنى الأسعار في هذه الفترة ، التغيير الأكبر بناءً على السعر المرتفع والمنخفض خلال هذا العام ، وأخيرًا متوسط التغير خلال هذا العام.

هذا المشروع مخصص للأشخاص في مجال الأعمال وتحليل البيانات. الأشخاص الذين يرغبون في مناقشة و معالجة البيانات  وتوضيح حالة الاستخدام والتنبؤ بالعلاقات بين بيانات المصدر. و يوفر لك الخطوات المهمة لتكون محلل بيانات. علاوة على ذلك ، فإنه يزودك بالمعرفة في أساسيات Python فى البيانات.",,,,
Python: Istruzioni per l’uso,https://www.coursera.org/learn/python-istruzioni-per-uso,Data Science,Machine Learning,Flora Amato,"Il Corso fornisce i principi di programmazione, le tecniche e gli strumenti di Python, linguaggio interpretato orientato agli oggetti molto utilizzato in molteplici contesti scientifici ed aziendali.

Python è un linguaggio di programmazione di alto livello, supporta diversi paradigmi di programmazione, come il paradigma object-oriented (con supporto all'ereditarietà multipla), imperativo e funzionale. Ha ottenuto un enorme successo nelle comunità dei programmatori grazie al connubio unico tra la semplicità di apprendimento e la potenza offerta dalle sue librerie.


Questo corso fa parte della Specialization in Data Science con Python e R, cui sarà possibile iscriversi non appena il corso sarà partito.",,3237.0,4.1,24.0
Python: обработка и анализ данных и ИИ,https://www.coursera.org/learn/python-for-applied-data-science-ai-ru,Data Science,Data Analysis,Joseph Santarcangelo,"Этот курс для начинающих поможет на начальных этапах изучения Python для обработки и анализа данных, а также программирования в целом. Python — один из самых популярных языков программирования в мире, и сегодня очень востребованы специалисты, умеющие применять основы Python для создания бизнес-решений в различных сферах.

Представленный курс позволит за считанные часы научиться программировать на Python с нуля! Вы ознакомитесь с основами Python, в том числе структурами и анализом данных, выполните практические упражнения в рамках модулей курса и создадите финальный проект для проверки полученных навыков.

По завершении курса вы будете уверенно создавать базовые программы, работать с данными и решать реальные задачи с помощью Python. Вы получите существенную базу для дальнейшего практического изучения языка и необходимые навыки для профессионального и карьерного роста.

Этот курс входит в ряд программ аттестации на получение специализированных и профессиональных сертификатов. Когда вы завершите этот курс, ваши результаты будут учитываться при обучении в следующих программах:
\Прикладной ИИ (профессиональная сертификация IBM)

Прикладной анализ и обработка данных (специализация)

Обработка и анализ данных (профессиональная сертификация IBM)

После завершения любой из перечисленных выше программ, кроме сертификата о завершении специального курса Coursera, вы также получите цифровой значок IBM, подтверждающий вашу квалификацию в соответствующей сфере.",,2888.0,,
Quantifying Relationships with Regression Models,https://www.coursera.org/learn/quantifying-relationships-regression-models,Data Science,Data Analysis,"Jennifer Bachner, PhD","This course will introduce you to the linear regression model, which is a powerful tool that researchers can use to measure the relationship between multiple variables.  We’ll begin by exploring the components of a bivariate regression model, which estimates the relationship between an independent and dependent variable.  Building on this foundation, we’ll then discuss how to create and interpret a multivariate model, binary dependent variable model and interactive model.  We’ll also consider how different types of variables, such as categorical and dummy variables, can be appropriately incorporated into a model.  Overall, we’ll discuss some of the many different ways a regression model can be used for both descriptive and causal inference, as well as the limitations of this analytical tool.  By the end of the course, you should be able to interpret and critically evaluate a multivariate regression analysis.",1817.0,4660.0,4.7,15.0
Quantitative Text Analysis and Evaluating Lexical Style in R,https://www.coursera.org/learn/quantitative-text-analysis-and-evaluating-lexical-style-in-r,Data Science,Data Analysis,Nicole Baerg,"By the end of this project, you will learn about the concept of lexical style in textual analysis in R. You will know how to load and pre-process a data set of text documents by converting the data set into a corpus and document feature matrix. You will know how to calculate the type to token ration which evaluates the level of complexity of a text, and know how to isolate terms of particular lexical interest in a text and visualize the variation in frequency of such terms in texts over time.",,,,
Quantitative Text Analysis and Measures of Readability in R,https://www.coursera.org/learn/quantitative-text-analysis-and-measures-of-readability-in-r,Data Science,Data Analysis,Nicole Baerg,"By the end of this project, you will be able to load textual data into R and turn it into a corpus object. You will also understand the concept of measures of readability in textual analysis. You will know how to estimate the level of readability of a text document or corpus of documents using a number of different readability metrics and  how to plot the variation in readability levels in a text document corpus over time at the document and paragraph level.

This project is aimed at beginners who have a basic familiarity with the statistical programming language R and the RStudio environment, or people with a small amount of experience who would like to learn how to measure the readability of textual data.",,,,
Quantitative Text Analysis and Scaling in R,https://www.coursera.org/learn/quantitative-text-analysis-and-scaling-in-r,Data Science,Data Analysis,Nicole Baerg,"By the end of this project, you will learn about the concept of document scaling in textual analysis in R. You will know how to load and pre-process a data set of text documents by converting the data set into a corpus and document feature matrix. You will know how to run an unsupervised document scaling model and explore and plot the scaling outcome.",,,,
Quantitative Text Analysis and Textual Similarity in R,https://www.coursera.org/learn/quantitative-text-analysis-and-textual-similarity-in-r,Data Science,Data Analysis,Nicole Baerg,"By the end of this project, you will learn about the concept of document similarity in textual analysis in R. You will know how to load and pre-process a data set of text documents by converting the data set into a corpus and document feature matrix. You will know how to calculate the cosine similarity between documents and explore and plot the output of your calculation.",,,,
Quelques instructions en PHP,https://www.coursera.org/learn/quelques-instructions-en-php,Data Science,Machine Learning,Fatima Youssef,"Dans ce cours d'une heure, basé sur un projet vous apprendrez à faciliter le stockage de nombreuses informations et à définir les conditions pour l'exécution d'un code spécifique, et à l'exécuter un certain nombre de fois.
A la fin de ce projet, vous serez capable d'utiliser les intructions conditionnelles, la commutateur, les boucles, les fonctions, et les tableaux en PHP.",,,,
Querying Databases Using SQL SELECT statement,https://www.coursera.org/learn/querying-databases-using-sql-select-statement,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"In this 2-hour long project-based course, you will learn how to retrieve data from tables in a database using SQL SELECT statement. In addition, this project will expose you to how to use different SQL operators together with the WHERE clause to set conditions on tables in a database for database manipulation. In order to reinforce the use of SQL SELECT statement to query a database for database insights, you will work on different tasks as the concepts are being introduced to you.

Note: You do not need to be a data administrator or data analyst to be successful in this guided project, just a familiarity with SQL is required. If you are not familiar with SQL and want to learn the basics, start with my previous guided project titled “Performing Data Definition and Manipulation in SQL”.",5055.0,,4.7,155.0
R Programming,https://www.coursera.org/learn/r-programming,Data Science,Data Analysis,"Roger D. Peng, PhD, Jeff Leek, PhD, Brian Caffo, PhD","In this course you will learn how to program in R and how to use R for effective data analysis. You will learn how to install and configure software necessary for a statistical programming environment and describe generic programming language concepts as they are implemented in a high-level statistical language. The course covers practical issues in statistical computing which includes programming in R, reading data into R, accessing R packages, writing R functions, debugging, profiling R code, and organizing and commenting R code. Topics in statistical data analysis will provide working examples.",670096.0,389693.0,4.5,21866.0
R Programming and Tidyverse Capstone Project,https://www.coursera.org/learn/r-programming-tidyverse-capstone-project,Data Science,Data Analysis,Jane Wall,"In this third and final course of the ""Expressway to Data Science: R Programming and Tidyverse"" specialization you will reinforce and display your R and tidyverse skills by completing an analysis of COVID-19 data! Here is a chance to apply your skills to a real-world dataset that has effected all of us.  

Throughout the capstone, you will import COVID-19 data; clean, tidy, and join datasets; and develop visualizations. You will also provide some analysis and interpretation to your results, preparing you for your journey into data science. By the end of the course, you will have developed a report that you can add to or use to begin a data science portfolio.

The course logo was created using images of stickers from the RStudio shop. Please visit https://swag.rstudio.com/s/shop.",,,,
R أساسيات لغة البرمجة,https://www.coursera.org/learn/intro-to-r-language-ar,Data Science,Data Analysis,Amani Abbas,"في هذه الدورة التدريبية القائمة على المشروع والتي تستغرق ساعة ونصف تقريباً، ستتعلم أساسيات لغة البرمجة آر، ستتعرف على كيفية التعامل مع آر ستوديو، كما ستتعلم كيفية التعامل مع الملفات، قرائتها، وتنفيذ أساسيات التحليل الاستكشافي على البيانات الموجودة بداخلها.

هذا المشروع للمبتدئين تماماً في مجال البرمجة ولا يتطلب وجود خبرة مسبقة بالتعامل مع لغة البرمجة آر، سنقوم معاً بتعلم الأساسيات خطوة بخطوة مع وجود بعض التمارين التي ستقوم بتنفيذها كجزء من المشروع لتتمكن من اكتساب المهارات المطلوبة.

يتضمن المشروع التعرف على آر ستوديو، والتعرف على كيفية تنفيذ العمليات الحسابية، والتعرف على كيفية إنشاء المتغيرات وتعديلها. التعرف على أنواع البيانات في آر، والتعرف على هياكل البيانات الخاصة بلغة آر، والتعرف على بعض الدوال المهمة للتعامل مع البيانات في آر، والتعرف على كيفية التعامل مع الملفات والمجلدات الموجودة على جهازك باستخدام لغة آر، والتعرف على كيفية التعامل مع البيانات وتنفيذ بعض أوامر التحليل الاستكشافي.",,,,
R البرمجة باستخدام لغة,https://www.coursera.org/learn/r-programming-ar,Data Science,Data Analysis,"Roger D. Peng, PhD, Jeff Leek, PhD, Brian Caffo, PhD",ستتعلم في هذه الدورة كيفية البرمجة بلغة R وكيفية استخدامها لتحليل البيانات بصورة فعالة. ستتعلم كيفية تثبيت البرامج اللازمة لبيئة البرمجة الإحصائية وتكوينها وكيفية وصف مفاهيم لغة البرمجة العامة إذ يتم تطبيقها بلغة إحصائية عالية المستوى. تتناول الدورة المشكلات العملية في الحوسبة الإحصائية التي تشمل البرمجة في لغة R، وقراءة البيانات في لغة البرمجة R، والوصول إلى حزم R، وكتابة دوال R، وتصحيح الأخطاء، وتحديد التعليمات البرمجية R، وتنظيم التعليمات البرمجية R والتعليق عليها. ستعرض الموضوعات في تحليل البيانات الإحصائية أمثلة عملية.,,1987.0,,
R 프로그래밍,https://www.coursera.org/learn/r-programming-ko,Data Science,Data Analysis,"Jeff Leek, PhD","이 과정에서는 R로 프로그래밍하는 방법과 효과적인 데이터 분석을 위해 R을 사용하는 방법을 배웁니다. 통계 프로그래밍 환경에 필요한 소프트웨어를 설치 및 구성하는 방법과 고급 통계 언어로 구현되는 일반적인 프로그래밍 언어 개념을 설명합니다. 이 과정은 R 프로그래밍, R로 데이터 읽기, R 패키지 액세스, R 함수 작성, 디버깅, R 코드 프로파일링, R 코드 구성 및 주석 달기를 포함하는 통계 컴퓨팅의 실제 문제를 다룹니다. 통계 데이터 분석의 주제는 실제 사례를 제공합니다.",,,,
R-Programmierung zur Datenanalyse,https://www.coursera.org/learn/r-programmierung-zur-datenanalyse,Data Science,Data Analysis,Google Career Certificates,"Dies ist der siebte Kurs im Google Data Analytics Certificate. In diesen Kursen lernen Sie alles, was Sie für eine Einstiegsposition in der Datenanalyse benötigen. In diesem Kurs lernen Sie die Programmiersprache R kennen. Sie erfahren, wie Sie RStudio verwenden, und lernen die Umgebung kennen, in der Sie mit R arbeiten können. In diesem Kurs werden auch die speziellen Softwareanwendungen und Tools von R behandelt, wie z. B. R-Pakete. Sie erfahren, wie Sie mit R Daten auf neue und leistungsfähigere Weisen bereinigen, organisieren, analysieren, visualisieren und Berichte über sie erstellen können.  Bei Google tätige Fachleute für die Datenanalyse werden Sie weiterhin anleiten und Ihnen praktische Möglichkeiten zeigen, wie Sie häufige Datenanalyseaufgaben mithilfe der besten Tools und Ressourcen erledigen können.

Nach Abschluss dieses Zertifikatsprogramms sind Lernende bestens gerüstet, um sich auf Einstiegspositionen in der Datenanalyse zu bewerben. Es sind keine Vorkenntnisse erforderlich.

Im Verlauf dieses Kurses werden Sie:
 - die Vorteile der Verwendung der Programmiersprache R untersuchen
 - erfahren, wie Sie RStudio verwenden, um R auf Ihre Analysen anzuwenden 
 - die grundlegenden Konzepte untersuchen, die mit der Programmierung in R verbunden sind 
 - den Inhalt und die Komponenten von R-Paketen kennenlernen, einschließlich des Tidyverse-Pakets
 - ein Verständnis von Dataframes und deren Verwendung in R erlangen
 - die Möglichkeiten zum Generieren von Visualisierungen in R entdecken
 - R Markdown zum Dokumentieren der R-Programmierung kennenlernen",,1736.0,,
"RH, Dados e Inteligência Artificial",https://www.coursera.org/learn/rh-dados-e-inteligencia-artificial,Data Science,Data Analysis,Anderson França,"Nossas boas-vindas ao Curso RH, Dados e Inteligência Artificial.

Neste curso, você aprenderá que a transformação digital na área de Recursos Humanos é a reorganização e a remodelagem das funções de gestão de pessoas, utilizando a tecnologia para recriar sistemas operacionais e processos eficientes, que inclui substituir ou não os sistemas tradicionais para todas as áreas. 

Podemos resumir como: uma mudança de mentalidade que as empresas passam com o objetivo de se tornarem mais modernas e acompanharem os avanços tecnológicos que não param de surgir, como Internet das Coisas (IoT), computação em nuvem, Big Data, Inteligência Artificial e os robôs.

O curso aborda os principais temas do mercado de dados aplicado à área de Recursos Humanos.

Ao final deste curso, você será capaz de entender temas como:
- Transformação digital em RH;
- As etapas para se tornar orientado por dados;
- Desafios do RH orientado por dados;
- Fundamentos de Inteligência Artificial;
- Aprendizado de máquina;
- Aplicações de modelos.

Este curso é composto por quatro módulos, disponibilizados em semanas de aprendizagem. Cada módulo é composto por vídeos, leituras e testes de verificação de aprendizagem. Ao final de cada módulo, temos uma avaliação de verificação dos conhecimentos.

Estamos muito felizes com sua presença neste curso e esperamos que você tire o máximo de proveito dos conceitos aqui apresentados.

Bons estudos!",,,,
"Random Models, Nested and Split-plot Designs",https://www.coursera.org/learn/random-models-nested-split-plot-designs,Data Science,Probability and Statistics,Douglas C. Montgomery,"Many experiments involve factors whose levels are chosen at random. A well-know situation is the study of measurement systems to determine their capability.  This course presents the design and analysis of these types of experiments, including modern methods for estimating the components of variability in these systems. The course also covers experiments with nested factors, and experiments with hard-to-change factors that require split-plot designs. We also provide an overview of designs for experiments with response distributions from nonnormal response distributions and experiments with covariates.",2406.0,3661.0,4.6,28.0
Real-time data visualization dashboard using Node-red,https://www.coursera.org/learn/realtime-data-visualization-dashboard-using-node-red,Data Science,Data Analysis,Ahmad Varasteh,"At the end of this project you are going learn how to create an real-time data visualization dashboard using node-red. so in this project we are going to use openAQ API which is an open source API sharing real-time air quality data related to different cities around the globe. we are going to fetch this 
data, preprocess it and visualize it using node-red. Therefor, as a very important prerequisite you should have a basic knowledge of node-red. if you don’t have any experience using node-red I recommend to attend my guided project course on introduction to node-red on Coursera.",,,4.6,10.0
Recognizing Facials and Objects with Amazon Rekognition,https://www.coursera.org/learn/recognizing-facials-objects-amazon-rekognition,Data Science,Machine Learning,Rogerio Guimaraes,"In this two hours project, you understand how Amazon Rekognition works and will learn how to use the AWS SDK to Analyze Faces, detect objects and labels in image scenes, moderate images, identify celebrities and recognize and compare faces using Artificial Intelligence.

Amazon Rekognition is one of the most used Artificial Intelligence services in AWS and popular to analyze images with huge confidence and low costs.

Once you're done with this project, you will be able to use Amazon Rekognition to analyze your own images in just a few steps.",,,,
Recommendation Systems with TensorFlow on GCP,https://www.coursera.org/learn/recommendation-models-gcp,Data Science,Machine Learning,Google Cloud Training,"In this course, you apply your knowledge of classification models and embeddings to build a ML pipeline that functions as a recommendation engine.

This is the fifth and final course of the Advanced Machine Learning on Google Cloud series.",15772.0,10198.0,4.5,453.0
Recommender Systems,https://www.coursera.org/learn/recommender-systems-ml,Data Science,Data Analysis,Jae-kwang KIM,"In this course you will:

a) understand the basic concept of recommender systems. b) understand the Collaborative Filtering.
c) understand the Recommender System with Deep Learning. d) understand the Further Issues of Recommender Systems.
Please make sure that you’re comfortable programming in Python and have a basic knowledge of mathematics including matrix multiplications, conditional probability, and basic machine learning algorithms.",,,,
Recommender Systems Capstone,https://www.coursera.org/learn/recommeder-systems-capstone,Data Science,Machine Learning,"Michael D. Ekstrand, Joseph A Konstan","This capstone project course for the Recommender Systems Specialization brings together everything you've learned about recommender systems algorithms and evaluation into a comprehensive recommender analysis and design project.  You will be given a case study to complete where you have to select and justify the design of a recommender system through analysis of recommender goals and algorithm performance.  

Learners in the honors track will focus on experimental evaluation of the algorithms against medium sized datasets.  The standard track will include a mix of provided results and spreadsheet exploration.

Both groups will produce a capstone report documenting the analysis, the selected solution, and the justification for that solution.",1830.0,1505.0,4.2,27.0
Recommender Systems:  Evaluation and Metrics,https://www.coursera.org/learn/recommender-metrics,Data Science,Machine Learning,"Michael D. Ekstrand, Joseph A Konstan","In this course you will learn how to evaluate recommender systems.  You will gain familiarity with several families of metrics, including ones to measure prediction accuracy, rank accuracy, decision-support, and other factors such as diversity, product coverage, and serendipity.  You will learn how different metrics relate to different user goals and business goals.  You will also learn how to rigorously conduct offline evaluations (i.e., how to prepare and sample data, and how to aggregate results).  And you will learn about online (experimental) evaluation.  At the completion of this course you will have the tools you need to compare different recommender system alternatives for a wide variety of uses.",12221.0,3397.0,4.4,225.0
Reconhecimento Facial e de Objetos com o Amazon Rekognition,https://www.coursera.org/learn/reconhecimento-facial-objetos-aws-amazon-rekognition,Data Science,Machine Learning,Rogerio Guimaraes,"Neste projeto de duas horas, você entenderá como o Amazon Rekognition funciona e aprenderá como usar o AWS SDK para analisar rostos, detectar objetos e rótulos em cenas de imagem, moderar imagens, identificar celebridades e reconhecer e comparar rostos usando inteligência artificial.

O Amazon Rekognition é um dos serviços de Inteligência Artificial mais usados ​​na AWS e popular para analisar imagens com grande confiança e baixo custo.

Depois de concluir este projeto, você poderá usar o Amazon Rekognition para analisar suas próprias imagens em apenas algumas etapas.",,,,
Redes Ecológicas,https://www.coursera.org/learn/redesecologicas,Data Science,Data Analysis,Marco A. R. Mello,"Todos os seres vivos estão conectados entre si por interações ecológicas, formando a “colina emaranhada” de Darwin, metáfora inspirada pela “teia da vida” de Humboldt. Desemaranhar essa complexidade é uma tarefa desafiadora, mas factível, desde que você use ferramentas adequadas. A ciência de redes nos ajuda com excelentes ferramentas conceituais e operacionais. 

Você aceita este chamado para a aventura? Então venha comigo aprender os fundamentos sobre redes ecológicas!

Seguindo esse espírito, este curso visa ajudar pessoas interessadas em dar seus primeiros passos na análise de redes aplicada à Ecologia. Este é um curso introdutório, focado especialmente em redes de interações. Redes sociais e redes espaciais também são mencionadas, mas não de forma aprofundada, nas diversas atividades do curso.

Dedicando-se a essas atividades durante quatro semanas, ao final deste curso você terá adquirido uma visão geral sobre as teorias que orientam o estudo de redes ecológicas. Além disso, você será capaz de analisar gráfica- e numericamente, além de interpretar, dados de redes usando a linguagem de programação R.

Dessa forma, para aproveitar bem este curso você deve dominar habilidades básicas na linguagem R, além de ter familiaridade com conceitos básicos em Ecologia em nível de graduação. Mais concretamente, é importante que você já saiba como importar dados para o R, além de usar pacotes e rodar funções. Não é necessário saber construir funções personalizadas (UDFs). 

Para ir além, aproveitando o conteúdo extra sugerido para aprofundamento posterior ao curso, é recomendável saber ler em inglês. Vale lembrar também que a ajuda dos pacotes e funções do R é toda escrita em inglês, então dominar a leitura nesse idioma também é importante para analisar dados com mais desenvoltura.

Também é importante mencionar que diversos conceitos estatísticos são mencionados no curso. Portanto, ter conhecimento básico sobre probabilidade, distribuições de dados, medidas de tendência central e medidas de dispersão ajuda muito.

Se você ainda não domina os fundamentos da linguagem R, recomendo que primeiro faça um dos excelentes cursos introdutórios disponíveis aqui na Coursera, como ""R Programming"" ou ""The R Programming Environment"". Há também aqui excelentes cursos introdutórios de estatística que podem lhe ensinar o básico sobre análise de dados.",,3699.0,5.0,24.0
Redes neuronales convolucionales con Keras,https://www.coursera.org/learn/redes-neuronales-convolucionales-keras,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a generar redes neuronales convolucionales con Python y Keras. Aprenderás desde cero los fundamentos del Deep Learning y a como crear este tipo de redes.

Gracias a este curso aprenderás a programar tus propias redes convolucionales capaces de clasificar objetos de imágenes como el tipo de ropa o el número de la imagen.",,,,
Regresión (ML) en la vida real con PyCaret,https://www.coursera.org/learn/regresion-vida-real-pycaret,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender todo lo que necesitas saber acerca de los problemas de regresión con Pycaret. Aprenderemos a generar un modelo predictivo de regresión capaz de predecir el valor de los diamantes. Para ello, aprenderemos, de manera práctica, a generar múltiples modelos de ML y metamodelos, a evaluar su eficiencia, a desplegarlos en producción y a guardarlos en MlFlow.",,,,
Regression Analysis with Yellowbrick,https://www.coursera.org/learn/machine-learning-regression-yellowbrick,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Regression Analysis with Yellowbrick. In this project, we will build a machine learning model to predict the compressive strength of high performance concrete (HPC). Although, we will use linear regression, the emphasis of this project will be on using visualization techniques to steer our machine learning workflow. Visualization plays a crucial role throughout the analytical process. It is indispensable for any effective analysis, model selection, and evaluation. This project will make use of a diagnostic platform called Yellowbrick. It allows data scientists and machine learning practitioners to visualize the entire model selection process to steer towards better, more explainable models.Yellowbrick hosts several datasets from the UCI Machine Learning Repository. We’ll be working with the concrete dataset that is well suited for regression tasks. The dataset contains 1030 instances and 8 real valued attributes with a continuous target. 

We we will cover the following topics in our machine learning workflow: exploratory data analysis (EDA), feature and target analysis, regression modelling, cross-validation, model evaluation, and hyperparamter tuning.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, Yellowbrick, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3091.0,,4.6,78.0
Regression Modeling Fundamentals,https://www.coursera.org/learn/regression-modeling-sas,Data Science,Data Analysis,Jordan Bakerman,"This introductory course is for SAS software users who perform statistical analyses using SAS/STAT software. The focus is on t tests, ANOVA, and linear regression, and includes a brief introduction to logistic regression.",3446.0,31123.0,4.8,36.0
Regression Modeling in Practice,https://www.coursera.org/learn/regression-modeling-practice,Data Science,Probability and Statistics,"Jen Rose, Lisa Dierker","This course focuses on one of the most important tools in your data analysis arsenal: regression analysis. Using either SAS or Python, you will begin with linear regression and then learn how to adapt when two variables do not present a clear linear relationship. You will examine multiple predictors of your outcome and be able to identify confounding variables, which can tell a more compelling story about your results. You will learn the assumptions underlying regression analysis, how to interpret regression coefficients, and how to use regression diagnostic plots and other tools to evaluate the quality of your regression model. Throughout the course, you will share with others the regression models you have developed and the stories they tell you.",33638.0,4792.0,4.4,272.0
Regression Models,https://www.coursera.org/learn/regression-models,Data Science,Probability and Statistics,"Brian Caffo, PhD, Roger D. Peng, PhD, Jeff Leek, PhD","Linear models, as their name implies, relates an outcome to a set of predictors of interest using linear assumptions.  Regression models, a subset of linear models, are the most important statistical analysis tool in a data scientist’s toolkit. This course covers regression analysis, least squares and inference using regression models. Special cases of the regression model, ANOVA and ANCOVA will be covered as well. Analysis of residuals and variability will be investigated. The course will cover modern thinking on model selection and novel uses of regression models including scatterplot smoothing.",137013.0,44566.0,4.4,3312.0
Regression and Classification,https://www.coursera.org/learn/regression-and-classification,Data Science,Data Analysis,James Bird,"Introduction to Statistical Learning will explore concepts in statistical modeling, such as when to use certain models, how to tune those models, and if other options will provide certain trade-offs. We will cover Regression, Classification, Trees, Resampling, Unsupervised techniques, and much more!

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Photo by Nicholas Cappello on Unsplash",,4622.0,,
Regression with Automatic Differentiation in TensorFlow,https://www.coursera.org/learn/regression-automatic-differentiation-tensorflow,Data Science,Machine Learning,Amit Yadav,"In this 1.5 hour long project-based course, you will learn about constants and variables in TensorFlow, you will learn how to use automatic differentiation, and you will apply automatic differentiation to solve a linear regression problem. By the end of this project, you will have a good understanding of how machine learning algorithms can be implemented in TensorFlow. 

In order to be successful in this project, you should be familiar with Python, Gradient Descent, Linear Regression.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4381.0,,4.7,63.0
Regular Expressions in Python,https://www.coursera.org/learn/regular-expressions-in-python,Data Science,Data Analysis,Emmanuel Segui,"In this 1-hour long project-based course, you will learn how to construct regex patterns, validate passwords and user input in web forms and extract patterns and replace strings with regex.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4300.0,,4.2,63.0
Reinforcement Learning for Trading Strategies,https://www.coursera.org/learn/trading-strategies-reinforcement-learning,Data Science,Machine Learning,Jack Farmer,"In the final course from the Machine Learning for Trading specialization, you will be introduced to reinforcement learning (RL) and the benefits of using reinforcement learning in trading strategies. You will learn how RL has been integrated with neural networks and review LSTMs and how they can be applied to time series data. By the end of the course, you will be able to build trading strategies using reinforcement learning, differentiate between actor-based policies and value-based policies, and incorporate RL into a momentum trading strategy.

To be successful in this course, you should have advanced competency in Python programming and familiarity with pertinent libraries for machine learning, such as Scikit-Learn, StatsModels, and Pandas. Experience with SQL is recommended. You should have a background in statistics (expected values and standard deviation, Gaussian distributions, higher moments, probability, linear regressions) and foundational knowledge of financial markets (equities, bonds, derivatives, market structure, hedging).",13011.0,11110.0,3.6,200.0
Reinforcement Learning in Finance,https://www.coursera.org/learn/reinforcement-learning-in-finance,Data Science,Machine Learning,Igor Halperin,"This course aims at introducing the fundamental concepts of Reinforcement Learning (RL), and develop use cases for applications of RL for option valuation, trading, and asset management. 

By the end of this course, students will be able to
- Use reinforcement learning to solve classical problems of Finance such as portfolio optimization, optimal trading, and option pricing and risk management.
- Practice on valuable examples such as famous Q-learning using financial problems.
- Apply their knowledge acquired in the course to a simple model for market dynamics that is obtained using reinforcement learning as the course project.

Prerequisites are the courses ""Guided Tour of Machine Learning in Finance"" and ""Fundamentals of Machine Learning in Finance"". Students are expected to know the lognormal process and how it can be simulated. Knowledge of option pricing is not assumed but desirable.",17750.0,9992.0,3.6,120.0
Relational Database Support for Data Warehouses,https://www.coursera.org/learn/dwrelational,Data Science,Data Analysis,"Michael Mannino, A.W. Lukens","Relational Database Support for Data Warehouses is the third course in the Data Warehousing for Business Intelligence specialization. In this course, you'll use analytical elements of SQL for answering business intelligence questions. You'll learn features of relational database management systems for managing summary data commonly used in business intelligence reporting. Because of the importance and difficulty of managing implementations of data warehouses, we'll also delve into storage architectures, scalable parallel processing, data governance, and big data impacts. In the assignments in this course, you can use either Oracle or PostgreSQL.",27778.0,6311.0,4.6,580.0
Relational Databases - MySQL - قواعد البيانات العلائقية,https://www.coursera.org/learn/qawaeid-albayanat-alealayiqiat-mysql,Data Science,Data Analysis,Amani Abbas,"في هذه الدورة التدريبية القائمة على المشروع والتي تستغرق ساعة واحدة، ستتعلم كيفية استخدام لغة الاستعلام البنائية SQL للحصول على معلومات من قاعدة البيانات.

سنقوم باستخدام MySQL في هذا المشروع وسنتعلم كيفية عرض البيانات من الجداول الموجودة في قاعدة البيانات، كيفية الحصول على إذخالات بشكل غير متكرر، كيفية الحصول على نتائج بحسب شروط معينة وبحسب ترتيب تصاعدي أو تنازلي،  كما ستتعلم كيفية ربط الجداول ببعضها في قاعدة البيانات للحصول على نتائج من عدة جداول باستخدام استعلام واحد فقط، ستتعلم أيضا كيفية إنشاء جدول وإضافته لقاعدة البيانات، إضافة بيانات للجدول الجديد، وكيفية مسح جدول من قاعدة البيانات.

هذا المشروع هو للمبتدئين تماماً في مجال قواعد البيانات العلائقية",,,,
Relational database systems,https://www.coursera.org/learn/relational-database,Data Science,Data Analysis,María del Pilar Ángeles,"Welcome to the specialization course Relational Database Systems. This course will be completed on six weeks, it will be supported with videos and various documents that will allow you to learn in a very simple way how several types of information systems and databases are available to solve different problems and needs of the companies. 

Objective:

A learner will be able to design, test, and implement analytical, transactional or NoSQL database systems according to business requirements by programming reliable, scalable and maintainable applications and resources using SQL and Hadoop ecosystem.

Programming languages:

For course 1 you will use the MYSQL language.

Software to download:
MySQL
Workbench 

In case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).",21584.0,13896.0,4.4,425.0
Reproducible Research,https://www.coursera.org/learn/reproducible-research,Data Science,Data Analysis,"Roger D. Peng, PhD, Jeff Leek, PhD, Brian Caffo, PhD","This course focuses on the concepts and tools behind reporting modern data analyses in a reproducible manner. Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them.  The need for reproducibility is increasing dramatically as data analyses become more complex, involving larger datasets and more sophisticated computations. Reproducibility allows for people to focus on the actual content of a data analysis, rather than on superficial details reported in a written summary. In addition, reproducibility makes an analysis more useful to others because the data and code that actually conducted the analysis are available. This course will focus on literate statistical analysis tools which allow one to publish data analyses in a single document that allows others to easily execute the same analysis to obtain the same results.",98669.0,19807.0,4.6,4130.0
Reproducible Templates for Analysis and Dissemination,https://www.coursera.org/learn/reproducible-templates-analysis,Data Science,Data Analysis,Melinda Higgins,"This course will assist you with recreating work that a previous coworker completed, revisiting a project you abandoned some time ago, or simply reproducing a document with a consistent format and workflow. Incomplete information about how the work was done, where the files are, and which is the most recent version can give rise to many complications. This course  focuses on the proper documentation creation process, allowing you and your colleagues to easily reproduce the components of your workflow. Throughout this course, you'll receive helpful demonstrations of RStudio and the R Markdown language and engage in active learning opportunities to help you build a professional online portfolio.",2044.0,3064.0,4.6,17.0
Research Data Management and Sharing,https://www.coursera.org/learn/data-management,Data Science,Data Analysis,"Helen Tibbo, Sarah Jones","This course will provide learners with an introduction to research data management and sharing. After completing this course, learners will understand the diversity of data and their management needs across the research data lifecycle, be able to identify the components of good data management plans, and be familiar with best practices for working with data including the organization, documentation, and storage and security of data. Learners will also understand the impetus and importance of archiving and sharing data as well as how to assess the trustworthiness of repositories. 

Today, an increasing number of funding agencies, journals, and other stakeholders are requiring data producers to share, archive, and plan for the management of their data. In order to respond to these requirements, researchers and information professionals will need the data management and curation knowledge and skills that support the long-term preservation, access, and reuse of data. Effectively managing data can also help optimize research outputs, increase the impact of research, and support open scientific inquiry. After completing this course, learners will be better equipped to manage data throughout the entire research data lifecycle from project planning to the end of the project when data ideally are shared and made available within a trustworthy repository.

This course was developed by the Curating Research Assets and Data Using Lifecycle Education (CRADLE) Project in collaboration with EDINA at the University of Edinburgh. 

This course was made possible in part by the Institute of Museum and Library Services under award #RE-06-13-0052-13. The views, findings, conclusions or recommendations expressed in this Research Data Management and Sharing MOOC do not necessarily represent those of the Institute of Museum and Library Services.

Hashtag: #RDMSmooc",31467.0,20588.0,4.7,626.0
"Response Surfaces, Mixtures, and Model Building",https://www.coursera.org/learn/response-surfaces-mixtures-model-building,Data Science,Probability and Statistics,Douglas C. Montgomery,"Factorial experiments are often used in factor screening.; that is, identify the subset of factors in a process or system that are of primary important to the response. Once the set of important factors are identified interest then usually turns to optimization; that is, what levels of the important factors produce the best values of the response.  This course provides design and optimization tools to answer that questions using the response surface framework.  Other related topics include design and analysis of computer experiments, experiments with mixtures, and experimental strategies to reduce the effect of uncontrollable factors on unwanted variability in the response.",3017.0,7630.0,4.7,49.0
"Reverse and complement nucleic acid sequences (DNA, RNA) using Python",https://www.coursera.org/learn/reverse-and-complement-nucleic-acid-sequences-using-python,Data Science,Data Analysis,Usama A. F. Khalil,"In this 1-hour long project-based course, you will learn the basic building blocks in the Python language and how to Develop a Python program that constructs reverse, complement, and reverse-complement nucleic acid sequences (DNA, RNA). Also, you will make your code read a file that has a long DNA sequence and deal with one of the complete genomes for the novel coronavirus.",,,4.4,32.0
"Reverse and complement nucleic acid sequences (DNA, RNA) using R",https://www.coursera.org/learn/reverse-and-complement-nucleic-acid-sequences-using-r,Data Science,Data Analysis,Usama A. F. Khalil,"In this 1-hour long project-based course, you will learn the basic building blocks in the R language and how to Develop an R program that constructs reverse, complement, and reverse-complement nucleic acid sequences (DNA, RNA). Also, you will make your code read a file that has a long DNA sequence and deal with one of the complete genomes for the novel coronavirus.",1915.0,,4.4,48.0
Réseaux neuronaux convolutifs,https://www.coursera.org/learn/convolutional-neural-networks-fr,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Ce cours vous apprendra à créer des réseaux neuronaux convolutifs et à les appliquer aux données d'image. Grâce à l'apprentissage en profondeur, la vision par ordinateur fonctionne beaucoup mieux qu'il y a seulement deux ans, ce qui permet de nombreuses applications passionnantes allant de la conduite autonome en toute sécurité, à la reconnaissance faciale précise, à la lecture automatique des images radiologiques.

Vous allez:
-  Comprendre comment créer un réseau neuronal convolutif, notamment les variations récentes telles que les réseaux résiduels.
-  Savoir appliquer les réseaux convolutifs aux tâches de détection et de reconnaissance visuelles.
- Savoir utiliser le transfert de style neuronal pour générer de l'art.
- Être à même d'appliquer ces algorithmes à une variété d'images, de vidéos et d'autres données 2D ou 3D.

Il s'agit du quatrième cours de spécialisation d'apprentissage approfondi.",,2362.0,,
Réseaux neuronaux et Deep Learning,https://www.coursera.org/learn/neural-networks-deep-learning-fr,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Vous souhaitez vous lancer dans l’IA de pointe ? Ce cours est là pour vous y aider. Les ingénieurs en Deep Learning sont très convoités et la maîtrise de ce domaine vous ouvrira de nombreuses opportunités professionnelles. Le Deep Learning est également un nouveau « superpouvoir » qui vous permettra de développer des systèmes d’IA qui n’étaient même pas envisageables il y a encore quelques années.

Vous découvrirez dans ce cours les bases du Deep Learning. Une fois que vous l’aurez terminé, vous serez en mesure de :
- comprendre les grandes tendances technologiques sur lesquelles repose le Deep Learning ;
- développer, entraîner et utiliser des réseaux neuronaux profonds entièrement connectés ;
- mettre en œuvre des réseaux neuronaux efficaces (vectorisés) ;
- comprendre les principaux paramètres de l’architecture d’un réseau neuronal.

Ce cours ne se limitera pas à une description rapide ou superficielle du Deep Learning, mais vous expliquera également son fonctionnement. Une fois que vous l’aurez terminé, vous serez donc en mesure de l’utiliser dans vos propres applications. En outre, si vous recherchez un poste dans l’IA, vous aurez la capacité de répondre à des questions de base posées lors d’entretiens.

Il s’agit du premier cours de la Spécialisation Deep Learning.",,3548.0,4.8,13.0
R을 사용한 확률 및 데이터 소개,https://www.coursera.org/learn/probability-intro-ko,Data Science,Data Analysis,Mine Çetinkaya-Rundel,"이 과정에서는 데이터 표본 추출 및 탐색, 기본 확률 이론 및 베이즈 정리를 소개합니다. 다양한 유형의 표본 추출 방법을 검토하고 이러한 방법이 추론 범위에 어떤 영향을 미칠 수 있는지 논의합니다. 수치 요약 통계 및 기본 데이터 시각화를 포함하여 다양한 탐색적 데이터 분석 기술을 다룹니다. R 및 RStudio(무료 통계 소프트웨어)를 설치하고 사용하는 방법을 안내하고 이 소프트웨어를 실습 및 최종 프로젝트에 사용합니다. 이 과정의 개념과 기술은 전문화 과정의 추론 및 모델링 과정을 위한 빌딩 블록 역할을 합니다.",,,,
SARS-CoV-2 Protein Modeling and Drug Docking,https://www.coursera.org/learn/sars-cov-2-protein-modeling-and-drug-docking,Data Science,Data Analysis,Bhagesh Hunakunti,"In this 1-hour long project-based course, you will construct a 3D structure of a SARS-CoV-2 protein sequence using homology modeling and perform molecular docking of drugs against this protein molecule and infer protein-drug interaction. We will accomplish it in by completing each task in the project which includes

- Model protein structures from sequence data
- Process proteins and ligands for docking procedure
- Molecular docking of drugs against protein molecules

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.7,69.0
SAS® Programming for Distributed Computing in SAS® Viya®,https://www.coursera.org/learn/sas-viya-programming-distributed-computing,Data Science,Data Analysis,"Stacey Syphus, Peter Styliadis","Welcome to the SAS Programming for Distributed Computing in SAS Viya course. SAS Viya is an AI, analytic and data management platform running on a scalable, distributed, cloud-native architecture. In this course you will learn how to modify existing Base SAS programs to execute in SAS Viya. The programs you create will leverage the power of SAS Cloud Analytic Services (CAS) to access, manage, and analyze in-memory tables. 

This is an advanced course, intended for learners with SAS programming experience. To be successful,  you should be able to access data via SAS libraries, read and prepare data with the DATA step, query data using PROC SQL, and summarize data with the MEANS and FREQ procedures. This foundational knowledge can be acquired in the Coursera SAS Programmer specialization.

By the end of the course, you will be able to:
- Load data into SAS Cloud Analytic Services
- Modify DATA step and SQL procedure code to execute in CAS
- Use CAS-enabled procedures
- Write CASL code to execute CAS actions",,2652.0,,
SQL  تأكيد صحة البيانات فى,https://www.coursera.org/learn/takid-sihat-albayanat-faa-sql,Data Science,Data Analysis,Abdelrahman Tarek Hafez,"فى نهاية المشروع، تقدر تتأكد من صحة بياناتك بطريقة سهلة و فعالة باستخدام جمل SQL . . ده هو من اهم الاجزاء فى مهمة معالجة البيانات سواء كان فى مجال جمع  البيانات او عرضها وتحليلها. فإننا نتأكد من صحة البيانات , هيدينا الدقة و التفاصيل و الوضوح . و ده هيخلينا نتجنب المشاكل  او المخاطر فى اى مشروع. 
خلال المشروع،تقدر تتأكد من صحة البيانات من خلال 13 query و باستخدام أوامر مختلفة . هتقدر تحدد تفاصيل الجدول والبيانات.  تقدر تربط بين جدولين او أكثر و تحسب عدد الصفوف الناتجة من اى query. هتقدر ترتب البيانات و تحط جمل شرطية فى ال query .ونتجنب الـ case sensitive بتاعة الحروف. و هتقدر تجيب البيانات المنفردة من غير اى تكرار وتستبعد بيانات من الناتج. تقدر تخرج الصفوف من خلال جزء من جملة أو كلمة و تخرج الناتج لكل مجموعة و تحدد الصفوف المكررة. و اخيرا هتقدر تجيب طول البيانات باستخدام LENGTH. المشروع مخصص للأشخاص المبتدئين فى مجال نمذجة البيانات او ال data modelling و التأكد من صحة البيانات. المشروع ده هيساعدك تبدأ اول خطواتك كمحلل بيانات او مهندس بيانات لانه من المهام الأساسية لنمذجة البيانات او ال data modelling.",,,,
SQL CASE Statements,https://www.coursera.org/learn/sql-case-statements,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course, SQL CASE Statements. In this project, you will learn how to use SQL CASE statements to query tables in a database.
By the end of this 2-hour long project, you will be able to write simple CASE statements to retrieve the desired result from a database. Then, we will move systematically to write more complex SQL CASE statements. Furthermore, we will see how to use the CASE clause together with aggregate functions, and SQL joins to get the desired result you want from tables in a database. Also, you will learn how to use the CASE clause to transpose the result of a query.

Also, for this hands-on project, we will use PostgreSQL as our preferred database management system (DBMS). Therefore, to complete this project, it is required that you have prior experience with using PostgreSQL. Similarly, this project is an advanced SQL concept; so, a good foundation for writing SQL queries, and performing joins in SQL is vital to complete this project.
If you are not familiar with writing queries in SQL and SQL joins and want to learn these concepts, start with my previous guided projects titled “Querying Databases using SQL SELECT statement"", “Performing Data Aggregation using SQL Aggregate Functions” and “Mastering SQL Joins”. I taught these guided projects using PostgreSQL. So, taking these projects will give the needed requisite to complete this project on SQL CASE Statements. However, if you are comfortable writing queries in PostgreSQL, please join me on this wonderful ride! Let’s get our hands dirty!",,,4.4,20.0
SQL Date Time Functions,https://www.coursera.org/learn/sql-date-time-functions,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course, SQL Date Time Functions. In this project, you will learn how to use SQL Date Time Functions to manipulate tables with data datatypes in a database.

By the end of this 2-and-a-half-hour-long project, you will be able to use different Date Time Functions to retrieve the desired result from a database. In this project, you will learn how to use SQL Date Time Functions like CURRENT_DATE, CURRENT_TIME, CURRENT_TIMESTAMP, AGE, EXTRACT, TO_CHAR, TO_DATE to manipulate date-like data in the employees table. In this project, we will move systematically by first introducing the functions using a simple example. Then, we will write more complex queries using the Date Time Functions in real-life applications. Also, you will learn how to convert a date to a string and vice versa.

Also, for this hands-on project, we will use PostgreSQL as our preferred database management system (DBMS). Therefore, to complete this project, it is required that you have prior experience with using PostgreSQL. Similarly, this project is an advanced SQL concept; so, a good foundation for writing SQL queries is vital to complete this project.

If you are not familiar with writing queries in SQL and SQL joins and want to learn these concepts, start with my previous guided projects titled “Querying Databases using SQL SELECT statement,"" “Performing Data Aggregation using SQL Aggregate Functions,” and “Mastering SQL Joins.” I taught these guided projects using PostgreSQL. So, taking these projects will give the needed requisite to complete this SQL Date Time Functions project. However, if you are comfortable writing queries in PostgreSQL, please join me on this wonderful ride! Let’s get our hands dirty!",,,4.4,14.0
SQL Mathematical Functions,https://www.coursera.org/learn/sql-mathematical-functions,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course, SQL Mathematical Functions. In this project, you will learn how to use SQL Mathematical Functions to manipulate tables in a database.
By the end of this 2-hour-long project, you will be able to use different Mathematical Functions to retrieve the desired result from a database. In this project, you will learn how to use SQL Mathematical Functions like CEIL(), FLOOR(), RANDOM(), SETSEED(), ROUND(), TRUNC(), SQRT(), CBRT(), and POWER() to manipulate data in the employees database. In this project, we will move systematically by first introducing the functions using a simple example. Then, we will write slightly complex queries using the Mathematical Functions in real-life applications.
Also, for this hands-on project, we will use PostgreSQL as our preferred database management system (DBMS). Therefore, to complete this project, it is required that you have prior experience with using PostgreSQL. Similarly, this project is an intermediate SQL concept; so, a good foundation for writing SQL queries is vital to complete this project.
If you are not familiar with writing queries in SQL and want to learn these concepts, start with my previous guided projects titled “Querying Databases using SQL SELECT statement,"" and “Performing Data Aggregation using SQL Aggregate Functions.” I taught these guided projects using PostgreSQL. So, taking these projects will give the needed requisite to complete this SQL Mathematical Functions project. However, if you are comfortable writing queries in PostgreSQL, please join me on this wonderful ride! Let’s get our hands dirty!",,,,
SQL Window Functions for Analytics,https://www.coursera.org/learn/sql-window-functions-for-analytics,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course SQL Window Functions for Analytics. This is a hands-on project that will help SQL users use window functions extensively for database insights. In this project, you will learn how to explore and query the project-db database extensively. We will start this hands-on project by retrieving the data in the table in the database.
By the end of this 2-hour-and-a-half-long project, you will be able to use different window functions to retrieve the desired result from a database. In this project, you will learn how to use SQL window functions like ROW_NUMBER(), RANK(), DENSE_RANK(), NTILE(), and LAST_VALUE() to manipulate data in the project-db database. Also, we will consider how to use aggregate window functions. These window functions will be used together with the OVER() clause to query this database. By extension, we will use grouping functions like GROUPING SETS(), ROLLUP(), and CUBE() to retrieve sublevel and grand totals.",,,4.8,16.0
SQL for Data Science,https://www.coursera.org/learn/sql-for-data-science,Data Science,Data Analysis,Sadie St. Lawrence,"As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. This is a data scientist, “part mathematician, part computer scientist, and part trend spotter” (SAS Institute, Inc.). According to Glassdoor, being a data scientist is the best job in America; with a median base salary of $110,000 and thousands of job openings at a time. The skills necessary to be a good data scientist include being able to retrieve and work with data, and to do that you need to be well versed in SQL, the standard language for communicating with database systems.

This course is designed to give you a primer in the fundamentals of SQL and working with data so that you can begin analyzing it for data science purposes. You will begin to ask the right questions and come up with good answers to deliver valuable insights for your organization. This course starts with the basics and assumes you do not have any knowledge or skills in SQL. It will build on that foundation and gradually have you write both simple and complex queries to help you select data from tables.  You'll start to work with different types of data like strings and numbers and discuss methods to filter and pare down your results. 

You will create new tables and be able to move data into them. You will learn common operators and how to combine the data. You will use case statements and concepts like data governance and profiling. You will discuss topics on data, and practice using real-world programming assignments. You will interpret the structure, meaning, and relationships in source data and use SQL as a professional to shape your data for targeted analysis purposes. 

Although we do not have any specific prerequisites or software requirements to take this course, a simple text editor is recommended for the final project. So what are you waiting for? This is your first step in landing a job in the best occupation in the US and soon the world!",464692.0,855183.0,4.6,13966.0
SQL for Data Science Capstone Project,https://www.coursera.org/learn/sql-data-science-capstone,Data Science,Data Analysis,Don Noxon,"Data science is a dynamic and growing career field that demands knowledge and skills-based in SQL to be successful. This course is designed to provide you with a solid foundation in applying SQL skills to analyze data and solve real business problems.

Whether you have successfully completed the other courses in the Learn SQL Basics for Data Science Specialization or are taking just this course, this project is your chance to apply the knowledge and skills you have acquired to practice important SQL  querying and solve problems with data. You will participate in your own personal or professional journey to create a portfolio-worthy piece from start to finish. You will choose a dataset and develop a project proposal. You will explore your data and perform some initial statistics you have learned through this specialization. You will uncover analytics for qualitative data and consider new metrics that make sense from the patterns that surface in your analysis. You will put all of your work together in the form of a presentation where you will tell the story of your findings. Along the way, you will receive feedback through the peer-review process. This community of fellow learners will provide additional input to help you refine your approach to data analysis with SQL and present your findings to clients and management.",25986.0,52439.0,4.2,158.0
SQL for Data Science with R,https://www.coursera.org/learn/sql-data-science-r,Data Science,Data Analysis,Rav Ahuja,"Much of the world's data resides in databases. SQL (or Structured Query Language) is a powerful language which is used for communicating with and extracting data from databases. A working knowledge of databases and SQL is a must if you want to become a data scientist.

The purpose of this course is to introduce relational database concepts and help you learn and apply foundational knowledge of the SQL and R languages. It is also intended to get you started with performing SQL access in a data science environment.  

The emphasis in this course is on hands-on and practical learning. As such, you will work with real databases, real data science tools, and real-world datasets. You will create a database instance in the cloud. Through a series of hands-on labs, you will practice building and running SQL queries. You will also learn how to access databases from Jupyter notebooks using SQL and R.

No prior knowledge of databases, SQL, R, or programming is required.

Anyone can audit this course at no charge. If you choose to take this course and earn the Coursera course certificate, you can also earn an IBM digital badge upon successful completion of the course.",6647.0,41450.0,4.2,60.0
SQL für Data Science,https://www.coursera.org/learn/sql-for-data-science-de,Data Science,Data Analysis,Sadie St. Lawrence,"As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. This is a data scientist, “part mathematician, part computer scientist, and part trend spotter” (SAS Institute, Inc.). According to Glassdoor, being a data scientist is the best job in America; with a median base salary of $110,000 and thousands of job openings at a time. The skills necessary to be a good data scientist include being able to retrieve and work with data, and to do that you need to be well versed in SQL, the standard language for communicating with database systems.

This course is designed to give you a primer in the fundamentals of SQL and working with data so that you can begin analyzing it for data science purposes. You will begin to ask the right questions and come up with good answers to deliver valuable insights for your organization. This course starts with the basics and assumes you do not have any knowledge or skills in SQL. It will build on that foundation and gradually have you write both simple and complex queries to help you select data from tables.  You'll start to work with different types of data like strings and numbers and discuss methods to filter and pare down your results. 

You will create new tables and be able to move data into them. You will learn common operators and how to combine the data. You will use case statements and concepts like data governance and profiling. You will discuss topics on data, and practice using real-world programming assignments. You will interpret the structure, meaning, and relationships in source data and use SQL as a professional to shape your data for targeted analysis purposes. 

Although we do not have any specific prerequisites or software requirements to take this course, a simple text editor is recommended for the final project. So what are you waiting for? This is your first step in landing a job in the best occupation in the US and soon the world!",3293.0,18958.0,,
SQL para el desarrollo web,https://www.coursera.org/learn/sql-para-desarrollo-web,Data Science,Data Analysis,Rubén Baez,"En este curso aprenderemos todo lo básico y necesario para incorporar base de datos relacionales a nuestros desarrollos Web.  

Los objetivos son:
- Poder incorporar una base de datos a nuestro desarrollo Web, conformando las tablas necesarias para soportar el modelo de negocio de nuestras e incorporando las consultas básicas para poder obtener datos, cargar datos y modificarlos.",,3768.0,,
"SVM Regression, prediction and losses",https://www.coursera.org/learn/svm-regression,Data Science,Machine Learning,Ashish Dikshit,"In this 1-hour long project-based course, you will learn how to
Train SVM regression model- with large & small margin, second degree polynomial kernel, make prediction using Linear SVM classifier; how a small weight vector results in a large margin? and finally
pictorial representation for Hinge loss. This project gives you easy access to the invaluable learning techniques used by experts in machine learning. 
Using these approaches, no matter what your skill levels in topics you would like to master, you can change your thinking and change your understanding to thoroughness in machine learning.",,,,
Sample-based Learning Methods,https://www.coursera.org/learn/sample-based-learning-methods,Data Science,Machine Learning,"Martha White, Adam White","In this course, you will learn about several algorithms that can learn near optimal policies based on trial and error interaction with the environment---learning from the agent’s own experience. Learning from actual experience is striking because it requires no prior knowledge of the environment’s dynamics, yet can still attain optimal behavior. We will cover intuitively simple but powerful Monte Carlo methods, and temporal difference learning methods including Q-learning. We will wrap up this course investigating how we can get the best of both worlds: algorithms that can combine model-based planning (similar to dynamic programming) and temporal difference updates to radically accelerate learning.

By the end of this course you will be able to:
 
- Understand Temporal-Difference learning and Monte Carlo as two strategies for estimating value functions from sampled experience
- Understand the importance of exploration, when using sampled experience rather than dynamic programming sweeps within a model
- Understand the connections between Monte Carlo and Dynamic Programming and TD. 
- Implement and apply the TD algorithm, for estimating value functions
- Implement and apply Expected Sarsa and Q-learning (two TD methods for control) 
- Understand the difference between on-policy and off-policy control
- Understand planning with simulated experience (as opposed to classic planning strategies)
- Implement a model-based approach to RL, called Dyna, which uses simulated experience 
- Conduct an empirical study to see the improvements in sample efficiency when using Dyna",24682.0,51094.0,4.8,1131.0
"Save, Load and Export Models with Keras",https://www.coursera.org/learn/save-load-export-keras-models,Data Science,Machine Learning,Amit Yadav,"In this 1 hour long project based course, you will learn to save, load and restore models with Keras. In Keras, we can save just the model weights, or we can save weights along with the entire model architecture. We can also export the models to TensorFlow's Saved Mode format which is very useful when serving a model in production, and we can load models from the Saved Model format back in Keras as well. 

In order to be successful in this project, you should be familiar with python programming, and basics of neural networks. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3696.0,,4.6,94.0
Scalable Machine Learning on Big Data using Apache Spark,https://www.coursera.org/learn/machine-learning-big-data-apache-spark,Data Science,Machine Learning,Romeo Kienzler,"This course will empower you with the skills to scale data science and machine learning (ML) tasks on Big Data sets using Apache Spark. Most real world machine learning work involves very large data sets that go beyond the CPU, memory and storage limitations of a single computer. 

Apache Spark is an open source framework that leverages cluster computing and distributed storage to process extremely large data sets in an efficient and cost effective manner. Therefore an applied knowledge of working with Apache Spark is a great asset and potential differentiator for a Machine Learning engineer.

After completing this course, you will be able to:
- gain a practical understanding of Apache Spark, and apply it to solve machine learning problems involving both small and big data
- understand how parallel code is written, capable of running on thousands of CPUs. 
- make use of large scale compute clusters to apply machine learning algorithms on Petabytes of data using Apache SparkML Pipelines. 
- eliminate out-of-memory errors generated by traditional machine learning frameworks when data doesn’t fit in a computer's main memory
- test thousands of different ML models in parallel to find the best performing one – a technique used by many successful Kagglers
- (Optional) run SQL statements on very large data sets using Apache SparkSQL and the Apache Spark DataFrame API.

Enrol now to learn the machine learning techniques for working with Big Data that have been successfully applied by companies like Alibaba, Apple, Amazon, Baidu, eBay, IBM, NASA, Samsung, SAP, TripAdvisor, Yahoo!, Zalando and many others.

NOTE: You will practice running machine learning tasks hands-on on an Apache Spark cluster provided by IBM at no charge during the course which you can continue to use afterwards.

Prerequisites:
- basic python programming
- basic machine learning (optional introduction videos are provided in this course as well)
- basic SQL skills for optional content

The following courses are recommended before taking this class (unless you already have the skills)
https://www.coursera.org/learn/python-for-applied-data-science or similar
https://www.coursera.org/learn/machine-learning-with-python or similar
https://www.coursera.org/learn/sql-data-science for optional lectures",20834.0,6445.0,3.8,1241.0
Scatter Plot for Data Scientists & Big Data Analysts-Visuals,https://www.coursera.org/learn/scatter-plot-data-scientists-big-data-analysts-visuals,Data Science,Data Analysis,Ashish Dikshit,"This project gives you easy access to the invaluable learning techniques used by experts for visualization in statistics. We’ll learn about how to use wolfram language to draw curve in easiest way. We’ll also cover illustration and best practices shown by research to be most effective in helping you master plotting curves.
Using these approaches, no matter what your skill levels in topics you would like to master, you can change your thinking and change your life. If you’re already an expert, this peep under the mental hood will give you ideas for turbocharging successful learning, including counter-intuitive test-taking tips and insights that will help you make the best use of your time on homework and problem sets. If you’re struggling, you’ll see a structured treasure trove of practical techniques that walk you through what you need to do to get on track. If you’ve ever wanted to become better at anything, this project will help serve as your guide.
In this project  we will take some illustrations and be able to Visualize the data by Scatter Plot using Wolfram Mathematica.
By the end of this project learners will:
Be able to plot basic examples (list of y values and x y pair)& several data items with legends (labeling each Plot and each data item)
Be able to plot values including 'units' and using individual 'color' for each point
Be able to plot the range where the data is non real are excluded & function ranges where it is selected automatically.",,,,
Scikit-Learn For Machine Learning Classification Problems,https://www.coursera.org/learn/scikit-learn-for-machine-learning-classification-problems,Data Science,Machine Learning,Ryan Ahmed,"Hello everyone and welcome to this new hands-on project on Scikit-Learn Library for solving machine learning classification problems. In this project, we will learn how to build and train classifier models using Scikit-Learn library. Scikit-learn is a free machine learning library developed for python. Scikit-learn offers several algorithms for classification, regression, and clustering. Several famous machine learning models are included such as support vector machines, random forests, gradient boosting, and k-means.",,,,
Scripting with Python and SQL for Data Engineering,https://www.coursera.org/learn/scripting-with-python-sql-for-data-engineering-duke,Data Science,Data Analysis,"Alfredo Deza, Kennedy Behrman, Noah Gift","In this third course of the Python, Bash and SQL Essentials for Data Engineering Specialization, you will explore techniques to work effectively with Python and SQL. We will go through useful data structures in Python scripting and connect to databases like MySQL. Additionally, you will learn how to use a modern text editor to connect and run SQL queries against a real database, performing operations to load and extract data. Finally, you will use extracted data from websites using scraping techniques. These skills will allow you to work effectively when data is not readily available, or when spatial queries are required to extract useful information from databases.",3457.0,24829.0,4.6,37.0
Semantic Segmentation with Amazon Sagemaker,https://www.coursera.org/learn/semantic-segmentation-sagemaker,Data Science,Machine Learning,Amit Yadav,"Please note: You will need an AWS account to complete this course. Your AWS account will be charged as per your usage. Please make sure that you are able to access Sagemaker within your AWS account. If your AWS account is new, you may need to ask AWS support for access to certain resources. You should be familiar with python programming, and AWS before starting this hands on project. We use a Sagemaker P type instance in this project, and if you don't have access to this instance type, please contact AWS support and request access.

In this 2-hour long project-based course, you will learn how to train and deploy a Semantic Segmentation model using Amazon Sagemaker. Sagemaker provides a number of machine learning algorithms ready to be used for solving a number of tasks. We will use the semantic segmentation algorithm from Sagemaker to create, train and deploy a model that will be able to segment images of dogs and cats from the popular IIIT-Oxford Pets Dataset into 3 unique pixel values. That is, each pixel of an input image would be classified as either foreground (pet), background (not a pet), or unclassified (transition between foreground and background).

Since this is a practical, project-based course, we will not dive in the theory behind deep learning based semantic segmentation, but will focus purely on training and deploying a model with Sagemaker. You will also need to have some experience with Amazon Web Services (AWS).",6497.0,,4.6,79.0
Sentiment Analysis with Deep Learning using BERT,https://www.coursera.org/learn/sentiment-analysis-bert,Data Science,Machine Learning,Ari Anastassiou,"In this 2-hour long project, you will learn how to analyze a dataset for sentiment analysis. You will learn how to read in a PyTorch BERT model, and adjust the architecture for multi-class classification. You will learn how to adjust an optimizer and scheduler for ideal training and performance. In fine-tuning this model, you will learn how to design a train and evaluate loop to monitor model performance as it trains, including saving and loading models. Finally, you will build a Sentiment Analysis model that leverages BERT's large-scale language knowledge.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",12805.0,,4.4,371.0
Sentimental Analysis on COVID-19 Tweets using python,https://www.coursera.org/learn/sentimental-anlysis-on-covid-19-tweets-using-python,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project you will learn how to preprocess your text data for sentimental analysis. 
So in this project we are going to use a Dataset consisting of data related to the tweets from the 24th of July, 2020 to the 30th of August 2020 with COVID19 hashtags. We are going to use python to apply sentimental analysis on the tweets to see people's reactions to the pandemic during the mentioned period. We are going to label the tweets as Positive, Negative, and neutral. After that, we are going to visualize the result to see the people's reactions on Twitter.

Note: This project works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,48.0
Sequence Models,https://www.coursera.org/learn/nlp-sequence-models,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","In the fifth course of the Deep Learning Specialization, you will become familiar with sequence models and their exciting applications such as speech recognition, music synthesis, chatbots, machine translation, natural language processing (NLP), and more. 

By the end, you will be able to build and train Recurrent Neural Networks (RNNs) and commonly-used variants such as GRUs and LSTMs; apply RNNs to Character-level Language Modeling; gain experience with natural language processing and Word Embeddings; and use HuggingFace tokenizers and transformer models to solve different NLP tasks such as NER and Question Answering.

The Deep Learning Specialization is a foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to take the definitive step in the world of AI by helping you gain the knowledge and skills to level up your career.",345068.0,393377.0,4.8,28837.0
"Sequences, Time Series and Prediction",https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction,Data Science,Machine Learning,Laurence Moroney,"If you are a software developer who wants to build scalable AI-powered algorithms, you need to understand how to use the tools to build them. This Specialization will teach you best practices for using TensorFlow, a popular open-source framework for machine learning.

In this fourth course, you will learn how to build time series models in TensorFlow. You’ll first implement best practices to prepare time series data. You’ll also explore how RNNs and 1D ConvNets can be used for prediction. Finally, you’ll apply everything you’ve learned throughout the Specialization to build a sunspot prediction model using real-world data!

The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization.",103654.0,150454.0,4.7,4644.0
Series Temporales con Pycaret y Python,https://www.coursera.org/learn/series-temporales-con-pycaret-python,Data Science,Machine Learning,Leire Ahedo,"En este proyecto aplicado y práctico aprenderás a entrenar modelos capaces de predecir series temporales. Para ello utilizaremos la librería de Pycaret con Python y entrenaremos modelos como: XGBoost, Catboost o Random forest. También aprenderemos a generar modelos más avanzados con lñas diferentes técnicas de ensamblado de modelos.
Al finalizar este curso habrás aprendido a entrenar tus propios modelos y a aplicarlos en tus propios proyectos.",,,,
"Series temporales con Deep Learning (RNN, LSTM) y Prophet",https://www.coursera.org/learn/series-temporales-con-deep-learning-rnn-lstm-prophet,Data Science,Machine Learning,Leire Ahedo,"En este proyecto aplicado y práctico aprenderás a entrenar redes neuronales recurrentes (RNN y LSTM) y modelos de Prophet  para predecir series temporales. Tanto las redes LSTM como Prophet son algunos de los modelos más avanzados para predecir valores futuros en base a series de tiempo. Por ello, te enseñaremos a como pre-procesar y preparar tus datos, a entrenar los modelos, a evaluarlos, a optimizarlos y a utilizarlos para predecir datos futuros.

Al finalizar este curso habrás aprendido a entrenar tus propios modelos y a aplicarlos en tus propios proyectos.",,,4.8,10.0
Series temporales con Facebook’ Prophet y NeuralProphet,https://www.coursera.org/learn/series-temporales-facebook-prophet-neuralprophet,Data Science,Machine Learning,Leire Ahedo,"En este proyecto aplicado y práctico aprenderás a utilizar Prophet y neuralProphet. 
Prophet es una de las librerías más avanzadas para predecir series temporales desarrollada por Facebook. Te enseñaremos a como entrenar un modelo con Prophet, a añadir regresores adicionales como periodos vacacionales y variables adicionales, a optimizarlo y a utilizarlo para realizar predicciones futuras. 
También aprenderemos a utilizar neuralProphet, que esta basada en modelos de deep learning.

Al finalizar este curso habrás aprendido a entrenar tus propios modelos y a aplicarlos en tus propios proyectos.",,,,
Serverless Data Processing with Dataflow: Develop Pipelines,https://www.coursera.org/learn/developing-pipelines-on-dataflow,Data Science,Data Analysis,Google Cloud Training,"In this second installment of the Dataflow course series, we are going to be diving deeper on developing pipelines using the Beam SDK. We start with a review of Apache Beam concepts. Next, we discuss processing streaming data using windows, watermarks and triggers. We then cover options for sources and sinks in your pipelines, schemas to express your structured data, and how to do stateful transformations using State and Timer APIs. We move onto reviewing best practices that help maximize your pipeline performance. Towards the end of the course, we introduce SQL and Dataframes to represent your business logic in Beam and how to iteratively develop pipelines using Beam notebooks.",2658.0,12612.0,4.0,33.0
Serverless Data Processing with Dataflow: Develop Pipelines em Português Brasileiro,https://www.coursera.org/learn/developing-pipelines-on-dataflow-pt,Data Science,Data Analysis,Google Cloud Training,"In this second installment of the Dataflow course series, we are going to be diving deeper on developing pipelines using the Beam SDK. We start with a review of Apache Beam concepts. Next, we discuss processing streaming data using windows, watermarks and triggers. We then cover options for sources and sinks in your pipelines, schemas to express your structured data, and how to do stateful transformations using State and Timer APIs. We move onto reviewing best practices that help maximize your pipeline performance. Towards the end of the course, we introduce SQL and Dataframes to represent your business logic in Beam and how to iteratively develop pipelines using Beam notebooks.",,,,
Serverless Data Processing with Dataflow: Develop Pipelines en Español,https://www.coursera.org/learn/developing-pipelines-on-dataflow-es,Data Science,Data Analysis,Google Cloud Training,"En esta segunda parte de la serie de cursos sobre Dataflow, analizaremos en profundidad el desarrollo de canalizaciones con el SDK de Beam. Comenzaremos con un repaso de los conceptos de Apache Beam. A continuación, analizaremos el procesamiento de datos de transmisión con ventanas, marcas de agua y activadores. Luego, revisaremos las opciones de fuentes y receptores en sus canalizaciones, los esquemas para expresar datos estructurados y cómo realizar transformaciones con estado mediante las API de State y de Timer. Después, revisaremos las prácticas recomendadas que ayudan a maximizar el rendimiento de las canalizaciones. Al final del curso, presentaremos SQL y Dataframes para representar su lógica empresarial en Beam y cómo desarrollar canalizaciones de forma iterativa con notebooks de Beam.",,,,
Serverless Data Processing with Dataflow: Foundations,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-foundations,Data Science,Data Analysis,Google Cloud Training,"This course is part 1 of a 3-course series on Serverless Data Processing with Dataflow. In this first course, we start with a refresher of what Apache Beam is and its relationship with Dataflow. Next, we talk about the Apache Beam vision and the benefits of the Beam Portability framework. The Beam Portability framework achieves the vision that a developer can use their favorite programming language with their preferred execution backend. We then show you how Dataflow allows you to separate compute and storage while saving money, and how identity, access, and management tools interact with your Dataflow pipelines. Lastly, we look at how to implement the right security model for your use case on Dataflow. 

Prerequisites:
The Serverless Data Processing with Dataflow course series builds on the concepts covered in the Data Engineering specialization. We recommend the following prerequisite courses:
(i)Building batch data pipelines on Google Cloud : covers core Dataflow principles
(ii)Building Resilient Streaming Analytics Systems on Google Cloud : covers streaming basics concepts like windowing, triggers, and watermarks 

>>> By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service <<<",4518.0,7900.0,4.2,65.0
Serverless Data Processing with Dataflow: Foundations em Português Brasileiro,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-foundations-pt,Data Science,Data Analysis,Google Cloud Training,"Este é o primeiro de uma série de três cursos sobre processamento de dados sem servidor com o Dataflow. Nele, vamos relembrar o que é o Apache Beam e qual é a relação entre ele e o Dataflow. Depois, falaremos sobre a visão do Apache Beam e os benefícios do framework de portabilidade desse modelo de programação. Com esse processo, o desenvolvedor pode usar a linguagem de programação favorita com o back-end de execução que quiser. Em seguida, mostraremos como o Dataflow permite a separação entre a computação e o armazenamento para economizar dinheiro. Além disso, você vai aprender como as ferramentas de identidade, acesso e gerenciamento interagem com os pipelines do Dataflow. Por fim, vamos ver como implementar o modelo de segurança ideal para seu caso de uso no Dataflow.",,,,
Serverless Data Processing with Dataflow: Operations,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-operations,Data Science,Data Analysis,Google Cloud Training,"In the last installment of the Dataflow course series, we will introduce the components of the Dataflow operational model. We will examine tools and techniques for troubleshooting and optimizing pipeline performance. We will then review testing, deployment, and reliability best practices for Dataflow pipelines. We will conclude with a review of Templates, which makes it easy to scale Dataflow pipelines to organizations with hundreds of users. These lessons will help ensure that your data platform is stable and resilient to unanticipated circumstances.",,4947.0,3.5,11.0
Serverless Data Processing with Dataflow: Operations em Português Brasileiro,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-operations-pt,Data Science,Data Analysis,Google Cloud Training,"Na última parte da série de cursos do Dataflow, vamos abordar os componentes do modelo operacional do Dataflow. Veremos ferramentas e técnicas para solucionar problemas e otimizar o desempenho do pipeline. Depois analisaremos as práticas recomendadas de teste, implantação e confiabilidade para pipelines do Dataflow. Por fim, faremos uma revisão dos modelos, que facilitam o escalonamento dos pipelines do Dataflow para organizações com centenas de usuários. Essas lições garantem que a plataforma de dados seja estável e resiliente a circunstâncias imprevistas.",,,,
Serverless Data Processing with Dataflow: Operations en Español,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-operations-es,Data Science,Data Analysis,Google Cloud Training,"En esta última parte de la serie de cursos de Dataflow, presentaremos los componentes del modelo operativo de Dataflow. Examinaremos las herramientas y técnicas que permiten solucionar problemas y optimizar el rendimiento de las canalizaciones. Luego, revisaremos las prácticas recomendadas de las pruebas, la implementación y la confiabilidad en relación con las canalizaciones de Dataflow. Concluiremos con una revisión de las plantillas, que facilitan el ajuste de escala de las canalizaciones de Dataflow para organizaciones con cientos de usuarios. Estas clases asegurarán que su plataforma de datos sea estable y resiliente ante circunstancias inesperadas.",,,,
Serverless Data Processing with Dataflow:Foundations Español,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-foundations-es,Data Science,Data Analysis,Google Cloud Training,"Este curso corresponde a la 1ª parte de una serie de 3 cursos llamada Serverless Data Processing with Dataflow. Para comenzar, en el primer curso haremos un repaso de qué es Apache Beam y cómo se relaciona con Dataflow. Luego, hablaremos sobre la visión de Apache Beam y los beneficios que ofrece su framework de portabilidad. Dicho framework hace posible que un desarrollador pueda usar su lenguaje de programación favorito con su backend de ejecución preferido. Después, le mostraremos cómo Dataflow le permite separar el procesamiento y el almacenamiento y, a la vez, ahorrar dinero. También le explicaremos cómo las herramientas de identidad, acceso y administración interactúan con sus canalizaciones de Dataflow. Por último, veremos cómo implementar el modelo de seguridad adecuado en Dataflow según su caso de uso.",,,,
Serverless Machine Learning with Tensorflow on Google Cloud auf Deutsch,https://www.coursera.org/learn/serverless-machine-learning-gcp-de,Data Science,Machine Learning,Google Cloud Training,"***Wir möchten Sie darüber informieren, dass die Spezialisierung ""Data Engineer, Big Data and ML on Google Cloud auf Deutsch"" am 10. November 2020 geschlossen und nicht mehr angeboten wird.***

In diesem einwöchigen On-Demand-Intensivkurs erhalten Teilnehmer eine praxisorientierte Einführung in das Entwerfen und Erstellen von Modellen für das maschinelle Lernen (ML) mithilfe der Google Cloud Platform. In Präsentationen, Demos und praxisorientierten Labs lernen die Teilnehmer ML- und TensorFlow-Konzepte kennen und entwickeln ML-Modelle, die sie anschließend auswerten und produktionsreif machen.
 
 ZIELE
 
 In diesem Kurs werden die folgenden Fähigkeiten vermittelt:
 
 ● Anwendungsfälle für maschinelles Lernen erkennen
 
 ● ML-Modelle mit TensorFlow erstellen
 
 ● Skalier- und bereitstellbare ML-Modelle mit Cloud ML erstellen
 
 ● Bedeutung der Datenvorverarbeitung und der Kombination von Features verstehen
 
 ● Fortgeschrittene ML-Konzepte in Modelle einbinden
 
 ● Trainierte ML-Modelle produktionsreif machen
 
 
 VORAUSSETZUNGEN
 
 Für maximale Lernerfolge sollten die Teilnehmer folgende Voraussetzungen erfüllen:
 
 ● Abschluss des Kurses ""Google Cloud Platform Fundamentals: Big Data & Machine Learning"" ODER entsprechende Erfahrung auf dem Gebiet
 
 ● Grundkenntnisse in gängigen Abfragesprachen wie SQL
 
 ● Kenntnisse in Datenmodellierung, Extraktion, Transformation und Ladeaktivitäten
 
 ● Entwicklung von Anwendungen mit einer gängigen Programmiersprache wie Python
 
 ● Vertrautheit mit maschinellem Lernen und/oder Statistik
 
 Hinweis zum Google-Konto:
 • In China sind Google-Dienste derzeit nicht verfügbar.",,,,
Serverless Machine Learning with Tensorflow on Google Cloud em Português Brasileiro,https://www.coursera.org/learn/serverless-machine-learning-gcp-br,Data Science,Machine Learning,Google Cloud Training,"Este curso intensivo sob demanda de quatro dias oferece aos participantes uma introdução sobre como projetar e criar sistemas de machine learning no Google Cloud Platform. Por meio de apresentações, demonstrações e laboratórios práticos, os participantes aprenderão os conceitos de machine learning (ML) e do TensorFlow, além de habilidades de desenvolvimento, avaliação e produção de modelos de ML.

OBJETIVOS
 
 Neste curso, os participantes aprenderão as seguintes habilidades:
 
 ● Identificar casos de uso de machine learning
 
 ● Criar um modelo de ML usando o TensorFlow
 
 ● Criar modelos de ML escalonáveis e implantáveis usando o Cloud ML
 
 ● Saber a importância do pré-processamento e da combinação de atributos
 
 ● Incorporar conceitos avançados de ML aos modelos
 
 ● Produzir modelos de ML treinados
 
 
 PRÉ-REQUISITOS
 
 Para aproveitar ao máximo este curso, os participantes precisam cumprir os seguintes requisitos:
 
 ● Ter concluído o curso Google Cloud Platform Big Data and Machine Learning Fundamentals OU experiência equivalente
 
 ● Proficiência básica em linguagem de consulta comum, como SQL
 
 ● Experiência com atividades de modelagem, extração, transformação e carregamento de dados
 
 ● Desenvolvimento de aplicativos usando uma linguagem de programação comum, como Python
 
 ● Conhecimento de machine learning e/ou estatísticas
 
 Notas da Conta do Google:
 • No momento, os serviços do Google não estão disponíveis na China.",,,4.4,13.0
Share Data Through the Art of Visualization,https://www.coursera.org/learn/visualize-data,Data Science,Data Analysis,Google Career Certificates,"This is the sixth course in the Google Data Analytics Certificate. These courses will equip you with the skills needed to apply to introductory-level data analyst jobs. You’ll learn how to visualize and present your data findings as you complete the data analysis process. This course will show you how data visualizations, such as visual dashboards, can help bring your data to life. You’ll also explore Tableau, a data visualization platform that will help you create effective visualizations for your presentations. Current Google data analysts will continue to instruct and provide you with hands-on ways to accomplish common data analyst tasks with the best tools and resources.

Learners who complete this certificate program will be equipped to apply for introductory-level jobs as data analysts. No previous experience is necessary.

By the end of this course, you will:
 - Examine the importance of data visualization.
 - Learn how to form a compelling narrative through data stories.
 - Gain an understanding of how to use Tableau to create dashboards and dashboard filters.
 - Discover how to use Tableau to create effective visualizations. 
 - Explore the principles and practices involved with effective presentations.
 - Learn how to consider potential limitations associated with the data in your presentations.
 - Understand how to apply best practices to a Q&A with your audience.",216826.0,2596960.0,4.6,5100.0
Siamese Network with Triplet Loss in Keras,https://www.coursera.org/learn/siamese-network-triplet-loss-keras,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn how to implement a Triplet Loss function, create a Siamese Network, and train the network with the Triplet Loss function. With this training process, the network will learn to produce Embedding of different classes from a given dataset in a way that Embedding of examples from different classes will start to move away from each other in the vector space.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Prerequisites:
In order to be successful in this project, you should be familiar with Python, Keras, Neural Networks. 

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3789.0,,4.6,109.0
Simple Linear Regression for the Absolute Beginner,https://www.coursera.org/learn/simple-linear-regression-for-the-absolute-beginner,Data Science,Machine Learning,Ryan Ahmed,"Hello everyone and welcome to this hands-on guided project on simple linear regression for the absolute beginner. In simple linear regression, we predict the value of one variable Y based on another variable X. X is called the independent variable and Y is called the dependent variable. This guided project is practical and directly applicable to many industries. You can add this project to your portfolio of projects which is essential for your next job interview.",,,4.5,10.0
Simple Nearest Neighbors Regression and Classification,https://www.coursera.org/learn/simple-nearest-neighbors-regression-and-classification,Data Science,Machine Learning,Charles Ivan Niswander II,"In this 2-hour long project-based course, we will explore the basic principles behind the K-Nearest Neighbors algorithm, as well as learn how to implement KNN for decision making in Python. 

A simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems is the k-nearest neighbors (KNN) algorithm. The fundamental principle is that you enter a known data set, add an unknown data point, and the algorithm will tell you which class corresponds to that unknown data point. The unknown is characterized by a straightforward neighborly vote, where the ""winner"" class is the class of near neighbors. It is most commonly used for predictive decision-making. For instance,:

Is a consumer going to default on a loan or not?
Will the company make a profit?
Should we extend into a certain sector of the market?

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Simple Parallel Coordinates Plot using d3 js,https://www.coursera.org/learn/simple-parallel-coordinates-plot-pcp-d3-js,Data Science,Data Analysis,Ahmad Varasteh,Throughout this guided project we are going to create a simple Parallel Coordinates Plot (PCP) using d3 js. PCP is one of the most common data visualization techniques used to visualize high-dimensional datasets. In this guided project you will create a simple PCP step by step. We will also cover some important topics in data visualization such as Linear and Ordinal scaling to best visualize our data. Having the knowledge of javascript programming language and the basics of d3 js are the two most important prerequisites to get the most out of this guided project.,,,,
Simple Recurrent Neural Network with Keras,https://www.coursera.org/learn/simple-recurrent-neural-network-keras,Data Science,Machine Learning,Amit Yadav,"In this hands-on project, you will use Keras with TensorFlow as its backend to create a recurrent neural network model and train it to learn to perform addition of simple equations given in string format. You will learn to create synthetic data for this problem as well. By the end of this 2-hour long project, you will have created, trained, and evaluated a sequence to sequence RNN model in Keras. Computers are already pretty good at math, so this may seem like a trivial problem, but it’s not! We will give the model string data rather than numeric data to work with. This means that the model needs to infer the meaning of various characters from a sequence of text input and then learn addition from the given data.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Tensorflow pre-installed. 

Please note that you will need some experience in Python programming, and a theoretical understanding of Neural Networks to be able to finish this project successfully.

Notes:
- You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",5598.0,,4.5,117.0
Simulation Models for Decision Making,https://www.coursera.org/learn/simulation-models-for-decision-making,Data Science,Probability and Statistics,Alok Gupta,"This course is primarily aimed at third- and fourth-year undergraduate students or graduate students interested in learning simulation techniques to solve business problems.  

The course will introduce you to take everyday and complex business problems that have no one correct answer due to uncertainties that exist in business environments.  Simulation modeling allows us to explore various outcomes and protect personal or business interests against unwanted outcomes.  We can model uncertainties by using the concepts of probability and stepwise thinking.  Stepwise thinking allows us to break down the problem in smaller components, explore dependencies between related events and allows us to focus on aspects of problem that are prone to changes due to future uncertainties.

The course will introduce you to advanced Excel techniques to model and execute simulation models.  Many of the Excel techniques learned in the course will be useful beyond simulation modeling.  We will learn both Monte Carlo simulation techniques where overall outcome is of primary interest and discrete event simulation where intermediate dependencies between related events might be of interest.  The course will introduce you to several practical issues in simulation modeling that are normally not covered in textbooks.  The course uses a few running examples throughout the course to demonstrate concepts and provide concrete modeling examples.  

After taking the course a student will be able to develop fairly advanced simulation models to explore fairly broad range of business environments and outcomes.",2417.0,7166.0,4.4,25.0
Simulation of Call Centre Operations Using R Simmer,https://www.coursera.org/learn/simulation-call-centre-operations,Data Science,Data Analysis,Moses Gummadi,"Introduction To Call Centre Simulation Process 
Create Statistical Variables Required For Simulation
Define Trajectories for Call Centre Departments 
Define Teams, Resources & Arrivals of Calls
Run Call Centre Simulation & Store Results
Plot Charts & Interpret Simulation Results",,,,
Simulation of Drum-Buffer-Rope Control Using R Simmer,https://www.coursera.org/learn/simulation-drum-buffer-rope,Data Science,Data Analysis,Moses Gummadi,"Welcome to ""Simulation of Drum-Buffer-Rope Production Control Using R-Simmer"". This is a project-based course which should take about 2 hours to finish. Before diving into the project, please take a look at the course objectives and structure. By the end of this project, you will gain introductiory knowledge of Drum-Buffer-Rope Production Control, Discrete Event Simulation, be able to use R Studio and Simmer library,  create statistical variables required for simulation, define process trajectory, define and assign resources, define arrivals (eg. incoming customers / work units), run simulation in R, store results in data frames, plot charts and interpret the results.",,,,
Simulation of KANBAN Production Control Using R Simmer,https://www.coursera.org/learn/kanban-control-simulation,Data Science,Data Analysis,Moses Gummadi,"Understand Kanban Production Control
Model Discrete Event Simulations Using R Simmer
Capture Simulation Data, Plot Charts & Interpret Results",,,,
Sistemas difusos,https://www.coursera.org/learn/sistemas-difusos,Data Science,Data Analysis,Oscar Germán Duarte Velasco,"Los sistemas difusos permiten efectuar cálculos cuando hay información con incertidumbre, o cuando se debe combinar información tanto cuantitativa como cualitativa. Se trata de una aproximación matemática para modelar esas situaciones. Este curso está diseñado para ayudar a entender y explicar cómo funcionan dichos sistemas.

El curso tiene una aproximación teórica y práctica. Los principios matemáticos son de un nivel bajo y están al alcance de un público muy amplio. El curso cuenta con varios laboratorios para aprender a utilizar las herramientas de software que usan esos principios. Este componente práctico requiere una comprensión mínima de programación.",,6072.0,5.0,23.0
Social Media Data Analytics,https://www.coursera.org/learn/social-media-data-analytics,Data Science,Data Analysis,Chirag Shah,"Learner Outcomes: After taking this course, you will be able to:

- Utilize various Application Programming Interface (API) services to collect data from different social media sources such as YouTube, Twitter, and Flickr.
- Process the collected data - primarily structured - using methods involving correlation, regression, and classification to derive insights about the sources and people who generated that data.
- Analyze unstructured data - primarily textual comments - for sentiments expressed in them.
- Use different tools for collecting, analyzing, and exploring social media data for research and development purposes.

Sample Learner Story: Data analyst wanting to leverage social media data.
Isabella is a Data Analyst working as a consultant for a multinational corporation. She has experience working with Web analysis tools as well as marketing data. She wants to now expand into social media arena, trying to leverage the vast amounts of data available through various social media channels. Specifically, she wants to see how their clients, partners, and competitors view their products/services and talk about them. She hopes to build a new workflow of data analytics that incorporates traditional data processing using Web and marketing tools, as well as newer methods of using social media data.

Sample Job Roles requiring these skills: 
- Social Media Analyst
- Web Analyst
- Data Analyst
- Marketing and Public Relations 

Final Project Deliverable/ Artifact: The course will have a series of small assignments or mini-projects that involve data collection, analysis, and presentation involving various social media sources using the techniques learned in the class.

The course was developed by Dr. Chirag Shah while he was a faculty member at Rutgers University. He is currently a faculty member at University of Washington.",38509.0,11168.0,4.1,280.0
Social Network Analysis,https://www.coursera.org/learn/social-network-analysis,Data Science,Data Analysis,Martin Hilbert,"This course is designed to quite literally ‘make a science’ out of something at the heart of society: social networks. Humans are natural network scientists, as we compute new network configurations all the time, almost unaware, when thinking about friends and family (which are particular forms of social networks), about colleagues and organizational relations (other, overlapping network structures), and about how to navigate delicate or opportunistic network configurations to save guard or advance in our social standing (with society being one big social network itself). While such network structures always existed, computational social science has helped to reveal and to study them more systematically. In the first part of the course we focus on network structure. This looks as static snapshots of networks, which can be intricate and reveal important aspects of social systems. In our hands-on lab, you will also visualize and analyze a network with a software yourself, which will help to appreciate the complexity social networks can take on. During the second part of the course, we will look at how networks evolve in time. We ask how we can predict what kind of network will form and if and how we could influence network dynamics.",12244.0,16510.0,4.7,193.0
Solve Business Problems with AI and Machine Learning,https://www.coursera.org/learn/solve-problems-ai-machine-learning,Data Science,Machine Learning,Renée Cummings,"Artificial intelligence (AI) and machine learning (ML) have become an essential part of the toolset for many organizations. When used effectively, these tools provide actionable insights that drive critical decisions and enable organizations to create exciting, new, and innovative products and services.

This is the first of four courses in the Certified Artificial Intelligence Practitioner (CAIP) professional certification. This course is meant as an entry point into the world of AI/ML. You'll learn about the business problems that AI/ML can solve, as well as the specific AI/ML technologies that can solve them. In addition, you'll get an overview of the general workflow involved in machine learning, as well as the tools and other resources that support it. This course also promotes the importance of ethics in AI/ML, and provides you with techniques for addressing ethical challenges.

Ultimately, this course will get you thinking about the ""why?"" of AI/ML, and it will ensure that your more technical work in later courses is done with clear business goals in mind.",2567.0,4625.0,4.5,20.0
Solving ML Regression Problems with AWS AutoGluon,https://www.coursera.org/learn/solving-ml-regression-problem-with-aws-autogluon,Data Science,Machine Learning,Ryan Ahmed,"Hello everyone and welcome to this new hands-on project on Machine Learning Regression with Amazon Web Services (AWS) AutoGluon.
In this project, we will train several regression models using a super powerful library known as AutoGluon. AutoGluon is the library behind AWS SageMaker autopilot and it allows for quick prototyping of several powerful models using a few lines of code.",,,,
Sourcing Analytics,https://www.coursera.org/learn/sourcinganalytics,Data Science,Data Analysis,Yao Zhao,"It is easy to spend money, but hard to get the value.

From 2007 to 2010, Apple made $27 billion from iPhone with a profit of $15.6 billion. Apple could not achieve this success without its global sourcing strategy. However, one of Apple’s key suppliers, Samsung Electronics, became a competitor and used its cost advantage to over-take Apple in the global market. Meanwhile, many new suppliers and products are emerging constantly. To continue the success, Apple must explore the global markets to identify and select new suppliers that are capable, inexpensive and financially robust. The question is, how to do it right for this year?

What Apple experienced is typical in practice, as a company may have thousands of suppliers, and numerous new suppliers and products / services emerge constantly and globally, which requires a frequent adjustment of the supply base.

In this course, you will learn sourcing analytics which applies data analytics and business intelligence to supplier development and management. Specifically, you will learn market intelligence, bargain power analysis, and supplier analysis, to identify and select suppliers with the objective of getting more value with less spend.",,1795.0,,
Spatial Data Science and Applications,https://www.coursera.org/learn/spatial-data-science,Data Science,Data Analysis,Joon Heo,"Spatial (map) is considered as a core infrastructure of modern IT world, which is substantiated by business transactions of major IT companies such as Apple, Google, Microsoft, Amazon, Intel, and Uber, and even motor companies such as Audi, BMW, and Mercedes. Consequently, they are bound to hire more and more spatial data scientists.  Based on such business trend, this course is designed to present a firm understanding of spatial data science to the learners, who would have a basic knowledge of data science and data analysis, and eventually to make their expertise differentiated from other nominal data scientists and data analysts.  Additionally, this course could make learners realize the value of spatial big data and the power of open source software's to deal with spatial data science problems.

This course will start with defining spatial data science and answering why spatial is special from three different perspectives - business, technology, and data in the first week.  In the second week, four disciplines related to spatial data science - GIS, DBMS, Data Analytics, and Big Data Systems, and the related open source software's - QGIS, PostgreSQL, PostGIS, R, and Hadoop tools are introduced together.  During the third, fourth, and fifth weeks, you will learn the four disciplines one by one from the principle to applications.  In the final week, five real world problems and the corresponding solutions are presented with step-by-step procedures in environment of open source software's.",21486.0,16447.0,4.4,454.0
Specialized Models: Time Series and Survival Analysis,https://www.coursera.org/learn/time-series-survival-analysis,Data Science,Machine Learning,"Mark J Grover, Miguel Maldonado","This course introduces you to additional topics in Machine Learning that complement essential tasks, including forecasting and analyzing censored data. You will learn how to find analyze data with a time component and censored data that needs outcome inference. You will learn a few techniques for Time Series Analysis and Survival Analysis. The hands-on section of this course focuses on using best practices and verifying assumptions derived from Statistical Learning.

By the end of this course you should be able to:
Identify common modeling challenges with time series data
Explain how to decompose Time Series data: trend, seasonality, and residuals
Explain how autoregressive, moving average, and ARIMA models work
Understand how to select and implement various Time Series models
Describe hazard and survival modeling approaches
Identify types of problems suitable for survival analysis

Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience with Time Series Analysis and Survival Analysis.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Calculus, Linear Algebra, Supervised Machine Learning, Unsupervised Machine Learning, Probability, and Statistics.",9971.0,16510.0,4.5,103.0
Sprachtechnologie in den Digital Humanities,https://www.coursera.org/learn/digital-humanities,Data Science,Data Analysis,"Martin Volk, Noah Bubenhofer, Simon Clematide","AKTUELL:

Am 20.05.2019 startet die vorläufig letzte Runde des MOOCs ""Sprachtechnologie in den Digital Humanities"". Anschliessend wird der Kurs auf der Plattform Coursera pausiert, d.h. Einschreibungen in den Kurs werden ab diesem Datum nicht mehr möglich sein. Die Videos bleiben aber nach wie vor über unseren YouTube-Kanal (https://www.youtube.com/channel/UChb3Rd5vo3WEgMSy99VInaw) bzw. den SwitchTube-Kanal der Uni Zürich (https://tube.switch.ch/channels/bb3adc02) sichtbar. Die Pausierung dient primär zur Aktualisierung und Erweiterung der Kursinhalte und Lernmaterialien.

KURS-BESCHREIBUNG:
Sie möchten wissen, was genau die Digitalisierung von Texten beinhaltet? Sie haben sich schon immer gefragt, wie Texte in einem Korpus optimal durchsuchbar gemacht werden?  Sie wundern sich, wie Texte mit linguistischen Informationen angereichert werden können?
Dann sind Sie in diesem Kurs genau richtig!! Er bietet einen Überblick über die wichtigsten Konzepte und Probleme bei der Digitalisierung und Annotation von geschriebenen Texten. In sechs thematischen Modulen verteilt auf sechs Wochen lernen Sie relevante Technologien und Werkzeuge kennen. Jedes Modul beinhaltet zwei bis drei Videos (10-20 Minuten), ein Quiz oder ein Peer-Assessment sowie kurze Hintergrundtexte und weiterführende Links zu ausgewählten Themen.

Für wen ist dieser Kurs interessant:
Dieser Kurs richtet sich an Korpuslinguist/-innen, an Geisteswissenschaftler/-innen und Sprachinteressierte, die von einer rein sprachwissenschaftlichen Perspektive ausgehend auch ein paar Schritte in die Welt der Digitalisierung von Texten wagen und die dahinterstehenden Technologien kennenlernen möchten. 
Für diesen Kurs brauchen Sie keine Programmierkenntnisse. Mit Interesse an der Digitalisierung und Annotation von Texten sind Sie bestens gerüstet für diesen Kurs.

Wir freuen uns, mit Ihnen diese digitalen Wege zu beschreiten, die in den Geisteswissenschaften immer wichtiger werden.",2549.0,,4.8,22.0
Stability and Capability in Quality Improvement,https://www.coursera.org/learn/stability-and-capability-in-quality-improvement,Data Science,Probability and Statistics,Wendy Martin,"In this course, you will learn to analyze data in terms of process stability and statistical control and why having a stable process is imperative prior to perform statistical hypothesis testing. You will create statistical process control charts for both continuous and discrete data using R software. You will analyze data sets for statistical control using control rules based on probability. Additionally, you will learn how to assess a process with respect to how capable it is of meeting specifications, either internal or external, and make decisions about process improvement.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",,5346.0,,
Statistical Analysis using Python Numpy,https://www.coursera.org/learn/statistical-analysis-using-python-numpy,Data Science,Data Analysis,David Dalsveen,"By the end of this project you will use the statistical capabilities of the Python Numpy package and other packages to find the statistical significance of student test data from two student groups.

The T-Test is well known in the field of statistics. It is used to test a hypothesis using a set of data sampled from the population. To perform the T-Test, the population sample size, the mean, or average, of each population, and the standard deviation are all required.  These will all be calculated in this project.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.5,13.0
Statistical Forecasting Techniques in Google Sheets,https://www.coursera.org/learn/statistical-forecasting-techniques-in-google-sheets,Data Science,Data Analysis,Tricia Bagley,"We consume forecasted data regularly in our personal and business lives, covering everything from the weather to projected investment returns. At work we use forecasted data for a multitude of purposes including developing strategies, budgets, and to provide the right amount of resources to meet demand. In this course, you will get your feet wet with statistical forecasting by designing, creating, and interpreting a growth forecast. You will do this as we work side-by-side in the free-to-use software Google Sheets.

By the end of this course, you will understand use cases for conducting forecasts in your workplace and be able to confidently conduct a growth forecast in any spreadsheet software. You will also understand when it is necessary to refine a model to improve the accuracy of forecasted projections.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2139.0,,4.5,26.0
Statistical Inference,https://www.coursera.org/learn/statistical-inference,Data Science,Probability and Statistics,"Brian Caffo, PhD, Roger D. Peng, PhD, Jeff Leek, PhD","Statistical inference is the process of drawing conclusions about populations or scientific truths from data. There are many modes of performing inference including statistical modeling, data oriented strategies and explicit use of designs and randomization in analyses. Furthermore, there are broad theories (frequentists, Bayesian, likelihood, design based, …) and numerous complexities (missing data, observed and unobserved confounding, biases) for performing inference. A practitioner can often be left in a debilitating maze of techniques, philosophies and nuance. This course presents the fundamentals of inference in a practical approach for getting things done. After taking this course, students will understand the broad directions of statistical inference and use this information for making informed choices in analyzing data.",168238.0,55469.0,4.2,4377.0
Statistical Inference and Hypothesis Testing in Data Science Applications,https://www.coursera.org/learn/statistical-inference-and-hypothesis-testing-in-data-science-applications,Data Science,Probability and Statistics,Jem Corcoran,"This course will focus on theory and implementation of hypothesis testing, especially as it relates to applications in data science. Students will learn to use hypothesis tests to make informed decisions from data. Special attention will be given to the general logic of hypothesis testing, error and error rates, power, simulation, and the correct computation and interpretation of p-values. Attention will also be given to the misuse of testing concepts, especially p-values, and the ethical implications of such misuse.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",2289.0,30507.0,4.7,21.0
Statistical Inference for Estimation in Data Science,https://www.coursera.org/learn/statistical-inference-for-estimation-in-data-science,Data Science,Probability and Statistics,Jem Corcoran,"This course introduces statistical inference, sampling distributions,  and confidence intervals. Students will learn how to define and construct  good estimators, method of moments estimation, maximum likelihood estimation, and methods of constructing confidence intervals that will extend to more general settings.  

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.

Logo adapted from photo by Christopher Burns on Unsplash.",2792.0,39587.0,4.3,32.0
"Statistical Thinking for Industrial Problem Solving, presented by JMP",https://www.coursera.org/learn/statistical-thinking-applied-statistics,Data Science,Data Analysis,"Mia Stephens, Ledi Trutna","Statistical Thinking for Industrial Problem Solving is an applied statistics course for scientists and engineers offered by JMP, a division of SAS. By completing this course, students will understand the importance of statistical thinking, and will be able to use data and basic statistical methods to solve many real-world problems. Students completing this course will be able to:

•	Explain the importance of statistical thinking in solving problems
•	Describe the importance of data, and the steps needed to compile and prepare data for analysis
•	Compare core methods for summarizing, exploring and analyzing data, and describe when to apply these methods
•	Recognize the importance of statistically designed experiments in understanding cause and effect",5486.0,44596.0,4.8,64.0
Statistics For Data Science,https://www.coursera.org/learn/statistics-data-science,Data Science,Probability and Statistics,Muhammad Saad uddin,This is a hands-on project to give you an overview of how to use statistics in data science.,,,4.7,10.0
Statistics for Data Science with Python,https://www.coursera.org/learn/statistics-for-data-science-python,Data Science,Probability and Statistics,"Murtaza Haider, Aije Egwaikhide","This Statistics for Data Science course is designed to introduce you to the basic principles of statistical methods and procedures used for data analysis. After completing this course you will have practical knowledge of crucial topics in statistics including  - data gathering, summarizing data using descriptive statistics, displaying and visualizing data, examining relationships between variables, probability distributions, expected values, hypothesis testing, introduction to ANOVA (analysis of variance), regression and correlation analysis. You will take a hands-on approach to statistical analysis using Python and Jupyter Notebooks – the tools of choice for Data Scientists and Data Analysts. 

At the end of the course, you will complete a project to apply various concepts in the course to a Data Science problem involving a real-life inspired scenario and demonstrate an understanding of the foundational statistical thinking and reasoning. The focus is on developing a clear understanding of the different 
approaches for different data types, developing an intuitive understanding, making appropriate assessments of the proposed methods, using Python to analyze our data, and interpreting the output accurately. 

This course is suitable for a variety of professionals and students intending to start their journey in data and statistics-driven roles such as Data Scientists, Data Analysts, Business Analysts, Statisticians, and Researchers. It does not require any computer science or statistics background.  We strongly recommend taking the Python for Data Science course before starting this course to get familiar with the Python programming language,  Jupyter notebooks, and libraries. An optional refresher on Python is also provided.

After completing this course, a learner will be able to:
✔Calculate and apply measures of central tendency and measures of dispersion to grouped and ungrouped data.
✔Summarize, present, and visualize data in a way that is clear, concise, and provides a practical insight for non-statisticians needing the results.
✔Identify appropriate hypothesis tests to use for common data sets.
✔Conduct hypothesis tests, correlation tests, and regression analysis.
✔Demonstrate proficiency in statistical analysis using Python and Jupyter Notebooks.",17882.0,83792.0,4.6,248.0
Statistics for Genomic Data Science,https://www.coursera.org/learn/statistical-genomics,Data Science,Probability and Statistics,"Jeff Leek, PhD",An introduction to the statistics behind the most popular genomic data science projects. This is the sixth course in the Genomic Big Data Science Specialization from Johns Hopkins University.,30909.0,18048.0,4.2,326.0
Statistics with SAS,https://www.coursera.org/learn/sas-statistics,Data Science,Data Analysis,Jordan Bakerman,"This introductory course is for SAS software users who perform statistical analyses using SAS/STAT software. The focus is on t tests, ANOVA, and linear regression, and includes a brief introduction to logistic regression.",29039.0,32327.0,4.7,267.0
Stock Analysis:  Create a Buy Signal Filter using R and the Quantmod Package,https://www.coursera.org/learn/create-buy-signal-filter-using-r-quantmod-package,Data Science,Data Analysis,Chris Shockley,"In this 1-hour long project-based course, you will learn how to pull down Stock Data using the R quantmod package.   You will also learn how to perform analytics and pass financial risk functions to the data.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4042.0,,4.7,81.0
Storytelling With Data,https://www.coursera.org/learn/storytelling-with-data,Data Science,Data Analysis,Shalini Gopalkrishnan ,"We all love stories, so why don't we use more of them at work? In this project we will help you learn some tools of good storytelling and create one for a freely available data set from KIVA, the microloan organization.",,,4.3,31.0
Structural Equation Model and its Applications | 结构方程模型及其应用 (普通话),https://www.coursera.org/learn/jiegou-fangcheng-moxing,Data Science,Data Analysis,Prof. Kit Tai Hau 侯傑泰,在社会学、心理学、教育学、经济学、管理学、市场学等研究领域的数据分析中，结构方程建模是当前最前沿的统计方法中应用最广、研究最多的一个。它包含了方差分析、回归分析、路径分析和因子分析，弥补了传统回归分析和因子分析的不足，可以分析多因多果的联系、潜变量的关系，还可以处理多水平数据和纵向数据，是非常重要的多元数据分析工具。本课程系统地介绍结构方程模型和LISREL软件的应用，内容包括：结构方程分析（包括验证性因子分析）的基本概念、统计原理、在社会科学研究中的应用、常用模型及其LISREL程序、结果的解释和模型评价。学员应具备基本的统计知识（如：标准差、t-检验、相关系数），理解回归分析和因子分析的概念。 注：本课程配套教材为《结构方程模型及其应用》（以LISREL软件为例）。,8502.0,4968.0,4.8,86.0
Structural Equation Model and its Applications | 结构方程模型及其应用 (粤语),https://www.coursera.org/learn/structural-equation-model-cantonese,Data Science,Data Analysis,Prof. Kit Tai Hau 侯傑泰,"课程介绍：

在社会学、心理学、教育学、经济学、管理学、市场学等研究领域的数据分析中，结构方程建模是当前最前沿的统计方法中应用最广、研究最多的一个。它包含了方差分析、回归分析、路径分析和因子分析，弥补了传统回归分析和因子分析的不足，可以分析多因多果的联系、潜变量的关系，还可以处理多水平数据和纵向数据，是非常重要的多元数据分析工具。本课程系统地介绍结构方程模型和LISREL软件的应用，内容包括：结构方程分析（包括验证性因子分析）的基本概念、统计原理、在社会科学研究中的应用、常用模型及其LISREL程序、结果的解释和模型评价。学员应具备基本的统计知识（如：标准差、t-检验、相关系数），理解回归分析和因子分析的概念。 注：本课程配套教材为《结构方程模型及其应用》（以LISREL软件为例）。


修课背景要求：

讲学语言：普通话及广东话 / 简体中文
这是一个艰深的高阶课程，学员应有下述的知识及训练：(i) 使用SPSS, SAS或其他类似软件包；(ii) 回归；和(iii) 因子分析(探索性因子分析)。


课程目标：

完成课程之后，学生的预期学习成果是：

1. 能够说出与传统的ANOVA和回归分析法相比，结构方程模型的优点；
2. 能够在仪器上进行验证性因子分析；
3. 能够用结构方程模型分析简单的全模型；
4. 通过计算出各种拟合指数和运用其他评估标准，能够比较并选出适合的模型；
5. 能够基于相应的参数统计修改模型；",2824.0,2019.0,4.8,21.0
Structured Query Language (SQL) using SAS,https://www.coursera.org/learn/sas-sql,Data Science,Data Analysis,Peter Styliadis,"Course Description

In this course, you learn about Structured Query Language (SQL) and how it can be used in SAS programs to create reports and query your data.   

“By the end of this course, a learner will be able to…”
●	Query and subset data.
●	Summarize and present data.
●	Combine tables using joins and set operators.
●	Create and modify tables and views.
●	Create data-driven macro variables using a query.
●	Access DBMS data with SAS/ACCESS technology.",10041.0,45008.0,4.9,202.0
Structurer des projets d’apprentissage automatique,https://www.coursera.org/learn/machine-learning-projects-fr,Data Science,Data Analysis,"Andrew Ng, Younes Bensouda Mourri, Kian Katanforoosh","Vous allez apprendre à mener à bien un projet d’apprentissage automatique. Si vous souhaitez devenir un leader technique en IA et que vous savez comment orienter le travail de votre équipe, ce cours va vous montrer la marche à suivre.

Une grande partie de ce contenu n’a jamais été enseignée ailleurs ; elle est tirée de mon expérience dans la construction et l’expédition de nombreux produits d’apprentissage profond. Cette formation comprend également deux ""simulateurs de vol"" qui vous permettront de pratiquer la prise de décision comme chef de projet d’apprentissage automatique.  Cela vous fournira une ""expérience industrielle"" que vous ne pourriez seulement obtenir d’une autre manière qu’après des années d’expérience de travail d'apprentissage automatique (AA).

Après 2 semaines, vous: 
- Comprendrez comment diagnostiquer les erreurs d’un système d’apprentissage automatique, et
- Pourrez choisir les priorités sur les orientations les plus prometteuses dans la réduction d’erreurs
-  Comprendrez les paramètres AA complexes, tels que les ensembles ou jeux d'entraînement/tests inadéquats, et comparer et/ou surpasser les performances humaines
- Saurez appliquer l’apprentissage, l’apprentissage de transfert et l’apprentissage multitâche de bout en bout

J'ai vu des équipes perdre des mois, voire des années, à ne pas comprendre les principes qui sont enseignés dans ce cours. J’espère que cette formation de deux semaines vous fera donc gagner des mois.

C’est un cours autonome ; vous pouvez le suivre aussi longtemps que vous avez des connaissances de base en apprentissage automatique. C’est le troisième cours de spécialisation en apprentissage en profondeur.",,,,
Structuring Machine Learning Projects,https://www.coursera.org/learn/machine-learning-projects,Data Science,Data Analysis,"Andrew Ng, Younes Bensouda Mourri, Kian Katanforoosh","In the third course of the Deep Learning Specialization, you will learn how to build a successful machine learning project and get to practice decision-making as a machine learning project leader. 

By the end, you will be able to diagnose errors in a machine learning system; prioritize strategies for reducing errors; understand complex ML settings, such as mismatched training/test sets, and comparing to and/or surpassing human-level performance; and apply end-to-end learning, transfer learning, and multi-task learning.

This is also a standalone course for learners who have basic machine learning knowledge. This course draws on Andrew Ng’s experience building and shipping many deep learning products. If you aspire to become a technical leader who can set the direction for an AI team, this course provides the ""industry experience"" that you might otherwise get only after years of ML work experience.
 
The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",392619.0,174431.0,4.8,48737.0
Styles HTML - CSS,https://www.coursera.org/learn/styles-html-css,Data Science,Machine Learning,Mirna Saad,"Dans ce cours d'une heure, basé sur un projet vous apprendrez  la définition des feuilles de style en cascade  ""CSS"" ,comment on peut ajouter CSS  aux documents HTML et  vous apprendrez quelques propriétés  CSS comme les bordures ,la couleur,la taille ...
A la fin de ce projet, vous serez capable d'écrire une page HTML  en ajoutant CSS de trois manières  et d'utiliser les propriétés: CSS Bordure,CSS Couleur...",,,,
Supervised Machine Learning: Classification,https://www.coursera.org/learn/supervised-machine-learning-classification,Data Science,Machine Learning,"Mark J Grover, Yan Luo, Svitlana (Lana) Kramar, Joseph Santarcangelo, Miguel Maldonado","This course introduces you to one of the main types of modeling families of supervised Machine Learning: Classification. You will learn how to train predictive models to classify categorical outcomes and how to use error metrics to compare across different models. The hands-on section of this course focuses on using best practices for classification, including train and test splits, and handling data sets with unbalanced classes.

By the end of this course you should be able to:
-Differentiate uses and applications of classification and classification ensembles
-Describe and use logistic regression models
-Describe and use decision tree and tree-ensemble models
-Describe and use other ensemble methods for classification
-Use a variety of error metrics to compare and select the classification model that best suits your data
-Use oversampling and undersampling as techniques to handle unbalanced classes in a data set
 
Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience with Supervised Machine Learning Classification techniques in a business setting.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Calculus, Linear Algebra, Probability, and Statistics.",12256.0,58178.0,4.9,191.0
Supervised Machine Learning: Regression,https://www.coursera.org/learn/supervised-machine-learning-regression,Data Science,Machine Learning,"Mark J Grover, Miguel Maldonado","This course introduces you to one of the main types of modelling families of supervised Machine Learning: Regression. You will learn how to train regression models to predict continuous outcomes and how to use error metrics to compare across different models. This course also walks you through best practices, including train and test splits, and regularization techniques.

By the end of this course you should be able to:
Differentiate uses and applications of classification and regression in the context of supervised machine learning 
Describe and use linear regression models
Use a variety of error metrics to compare and select a linear regression model that best suits your data
Articulate why regularization may help prevent overfitting
Use regularization regressions: Ridge, LASSO, and Elastic net
 
Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience  with Supervised Machine Learning Regression techniques in a business setting.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Calculus, Linear Algebra, Probability, and Statistics.",15499.0,62314.0,4.7,312.0
Supervised Machine Learning: Regression and Classification,https://www.coursera.org/learn/machine-learning,Data Science,Machine Learning,"Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig","In the first course of the Machine Learning Specialization, you will:

• Build machine learning models in Python using popular machine learning libraries NumPy and scikit-learn.
• Build and train supervised machine learning models for prediction and binary classification tasks, including linear regression and logistic regression

The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. In this beginner-friendly program, you will learn the fundamentals of machine learning and how to use these techniques to build real-world AI applications. 

This Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.

This 3-course Specialization is an updated and expanded version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012. 

It provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)

By the end of this Specialization, you will have mastered key concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.",156865.0,2418602.0,4.9,4757.0
Supervised Text Classification for Marketing Analytics,https://www.coursera.org/learn/supervised-text-classification-for-marketing-analytics,Data Science,Data Analysis,"Chris J. Vargo, Scott Bradley","Marketing data often requires categorization or labeling. In today’s age, marketing data can also be very big, or larger than what humans can reasonably tackle. In this course, students learn how to use supervised deep learning to train algorithms to tackle text classification tasks. Students walk through a conceptual overview of supervised machine learning and dive into real-world datasets through instructor-led tutorials in Python. The course concludes with a major project.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",,4835.0,,
Supply Chain Network Optimization Using MILP on RStudio,https://www.coursera.org/learn/supply-chain-network-optimization,Data Science,Data Analysis,Moses Gummadi,Supply Chain Network Optimization,,,,
Support Vector Machine Classification in Python,https://www.coursera.org/learn/support-vector-machine-classification-python,Data Science,Machine Learning,Mo Rebaie,"In this 1-hour long guided project-based course,  you will learn how to use Python to implement a Support Vector Machine algorithm for classification. This type of algorithm classifies output data and makes predictions. The output of this model is a set of visualized scattered plots separated with a straight line.

You will learn the fundamental theory and practical illustrations behind Support Vector Machines and learn to fit, examine, and utilize supervised Classification models using SVM to classify data, using Python.

We will walk you step-by-step into Machine Learning supervised problems. With every task in this project, you will expand your knowledge, develop new skills, and broaden your experience in Machine Learning.

Particularly, you will build a Support Vector Machine algorithm, and by the end of this project, you will be able to build your own SVM classification model with amazing visualization.

In order to be successful in this project, you should just know the basics of Python and classification algorithms.",6069.0,,4.4,143.0
"Support Vector Machines in Python, From Start to Finish",https://www.coursera.org/learn/support-vector-machines-in-python,Data Science,Data Analysis,Josh Starmer,"In this lesson we will built this Support Vector Machine for classification using scikit-learn and the Radial Basis Function (RBF) Kernel. Our training data set contains continuous and categorical data from the UCI Machine Learning Repository to predict whether or not a patient has heart disease.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your Internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with (e.g. Python, Jupyter, and Tensorflow) pre-installed.

Prerequisites:
In order to be successful in this project, you should be familiar with programming in Python and the concepts behind Support Vector Machines, the Radial Basis Function, Regularization, Cross Validation and Confusion Matrices.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4798.0,,4.6,147.0
Support Vector Machines with scikit-learn,https://www.coursera.org/learn/support-vector-machines-scikit-learn,Data Science,Machine Learning,Snehan Kekre,"In this project, you will learn the functioning and intuition behind a powerful class of supervised linear models known as support vector machines (SVMs). By the end of this project, you will be able to apply SVMs using scikit-learn and Python to your own classification tasks, including building a simple facial recognition model.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7661.0,,4.3,305.0
Tables Statistiques Pour la Publication dans R,https://www.coursera.org/learn/tables-statistiques-pour-la-publication-dans-r,Data Science,Data Analysis,Emmanuel Segui,"Apprenez à créer des tableaux prêts pour la publication dans R pour des statistiques descriptives, des tableaux de contingence, des tableaux de corrélation, des tableaux récapitulatifs de modèles et des tableaux de probabilités de survie",,,,
Take a Swing at Baseball Analytics: Explore Player Careers,https://www.coursera.org/learn/baseball-analytics,Data Science,Data Analysis,"Brandon Armstrong, Matt Kata","Former Major League Baseball (MLB) player Matt Kata joins MathWorks to introduce you to data analysis using baseball statistics. By analyzing historic batting statistics, you will explore player careers and answer the question: When do great hitters peak in their career?   

In this project, you will work in MATLAB, a programming environment used by millions of engineers and scientists, and now MLB players! You’ll have access to pitching, batting, and defensive statistics dating back to 1871, enabling you to explore and answer a wide variety of questions. You will compute statistics like On-base Plus Slugging (OPS), visualize results, and filter data to highlight players that meet criteria you specify, such as the number of home runs.  

 Whether you’re analyzing sports data, financial markets, or electric engine performance, you can apply the data analysis skills you learn in this project to many other fields and applications. So, step up to the plate and take a swing at MATLAB for data analysis.",,,,
TensorFlow 2 시작하기,https://www.coursera.org/learn/getting-started-with-tensor-flow2-ko,Data Science,Machine Learning,Dr Kevin Webster,"TensorFlow 2 시작하기 과정에 오신 것을 환영합니다!

이 과정에서는 순차 API를 사용한 모델 구축, 훈련, 평가 및 예측, 모델 검증, 정규화, 콜백 구현, 모델 저장 및 로딩 등 Tensorflow를 사용하여 딥 러닝 모델을 개발하기 위한 완벽한 엔드-투-엔드 워크플로우를 배우게 됩니다. 

배운 개념을 실용적인 실습형 코딩 자습서에서 바로 연습할 것이며 이는 대학원 조교에게 안내를 받게 될 것입니다. 또한 기술을 통합할 수 있는 일련의 자동 채점 프로그래밍 과제가 있습니다.\n\n과정이 끝나면 이미지 분류기 딥 러닝 모델을 처음부터 개발하는 Capstone 프로젝트에 많은 개념을 통합할 것입니다.

Tensorflow는 오픈 소스 머신 라이브러리이며 딥 러닝에 가장 널리 사용되는 프레임워크 중 하나입니다. Tensorflow 2의 출시는 초심자에서 고급 수준에 이르기까지 모든 사용자의 사용 편의성에 중점을 둔 제품 개발의 단계적 변화를 나타냅니다. 이 과정은 Tensorflow 1.x에 대한 경험이 있는 사용자뿐만 아니라 경험이 없는 사용자 모두를 대상으로 합니다.

이 과정에서 성공하기 위해서는 파이썬 프로그래밍 언어(이 과정에서는 파이썬 3 사용), 일반적인 머신 러닝 개념(예: 과적합/과소적합, 지도 학습 작업, 검증, 정규화 및 모델 선택), 전형적인 모델 아키텍처(MLP/피드포워드 및 컨볼루션 신경망), 활성화 함수, 출력 레이어 및 최적화를 포함한 딥 러닝 분야의 실무 지식을 갖추고 있어야 합니다.",,,,
TensorFlow Serving with Docker for Model Deployment,https://www.coursera.org/learn/tensorflow-serving-docker-model-deployment,Data Science,Machine Learning,Snehan Kekre,"This is a hands-on, guided project on deploying deep learning models using TensorFlow Serving with Docker. In this 1.5 hour long project, you will train and export TensorFlow models for text classification, learn how to deploy models with TF Serving and Docker in 90 seconds, and build simple gRPC and REST-based clients in Python for model inference.

With the worldwide adoption of machine learning and AI by organizations, it is becoming increasingly important for data scientists and machine learning engineers to know how to deploy models to production. While DevOps groups are fantastic at scaling applications, they are not the experts in ML ecosystems such as TensorFlow and PyTorch. This guided project gives learners a solid, real-world foundation of pushing your TensorFlow models from development to production in no time!

Prerequisites:
In order to successfully complete this project, you should be familiar with Python, and have prior experience with building models with Keras or TensorFlow.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",4562.0,,4.8,51.0
TensorFlow for AI: Applying Image Convolution,https://www.coursera.org/learn/tensorflow-for-ai-applying-image-convolution,Data Science,Machine Learning,Mo Rebaie,"This guided project course is part of the ""Tensorflow for AI"" series, and this series presents material that builds on the first course of DeepLearning.AI TensorFlow Developer Professional Certificate, which will help learners reinforce their skills and build more projects with Tensorflow.

In this 1.5-hour long project-based course, you will discover convolutions, apply filters to images, apply pooling layers, and try out the convolution and pooling techniques on real images to learn about how convolutions work. At the end of the project, you will get a bonus deep learning project implemented with Tensorflow. By the end of this project, you will have learned how convolutions work and how to create convolutional layers to prepare for your own deep learning projects using convolutional neural networks.

This class is for learners who want to use Python for building convolutional neural networks with TensorFlow, and for learners who are currently taking a basic deep learning course or have already finished a deep learning course and are searching for a knowledge-based course about convolutions in images with TensorFlow. Also, this project provides learners with needed knowledge about building convolutional neural networks and improves their skills in applying filters to images which helps them in fulfilling their career goals by adding this project to their portfolios.",,,4.6,13.0
TensorFlow for AI: Get to Know Tensorflow,https://www.coursera.org/learn/tensorflow-for-ai-get-to-know-tensorflow,Data Science,Machine Learning,Mo Rebaie,"This guided project course is part of the ""Tensorflow for AI"" series, and this series presents material that builds on the first course of DeepLearning.AI TensorFlow Developer Professional Certificate offered at Coursera, which will help learners reinforce their skills and build more projects with Tensorflow.

In this 1-hour long project-based course, you will get to know the basics and main components of Tensorflow through hands-on exercises, and you will learn how to define, compile and train a neural network with Tensorflow, and you will get a bonus practical deep learning project implemented with Tensorflow. By the end of this project, you will have developed a deeper understanding of Tensorflow, learned how to build a neural network with Tensorflow, and learned practically how to use Tensorflow to implement AI projects so that you can start building and applying scalable models to real-world problems.

This class is for learners who want to use Python for building AI models with TensorFlow, and for learners who are currently taking a basic deep learning course or have already finished a deep learning course and are searching for a practical deep learning with TensorFlow project. Also, this project provides learners with deeper knowledge about the basics of Tensorflow and its main components and improves their skills in Tensorflow which helps them in fulfilling their career goals by adding this project to their portfolios.",4054.0,,4.2,54.0
TensorFlow for AI: Neural Network Representation,https://www.coursera.org/learn/tensorflow-for-ai-neural-network-representation,Data Science,Machine Learning,Mo Rebaie,"This guided project course is part of the ""Tensorflow for AI"" series, and this series presents material that builds on the first course of DeepLearning.AI TensorFlow Developer Professional Certificate, which will help learners reinforce their skills and build more projects with Tensorflow.

In this 1.5-hour long project-based course, you will learn practically how to work on a deep learning task in the real world and create, train, and test a neural network with Tensorflow using real-world images, and you will get a bonus deep learning exercise implemented with Tensorflow. By the end of this project, you will have created a deep neural network with TensorFlow on a real-world dataset.

This class is for learners who want to use Python for building neural networks with TensorFlow, and for learners who are currently taking a basic deep learning course or have already finished a deep learning course and are searching for a practical deep learning project with TensorFlow project. Also, this project provides learners with further knowledge about creating and training convolutional neural networks and improves their skills in Tensorflow which helps them in fulfilling their career goals by adding this project to their portfolios.",,,4.2,18.0
TensorFlow for CNNs: Learn and Practice CNNs,https://www.coursera.org/learn/tensorflow-for-cnns-learn-and-practice-cnns,Data Science,Machine Learning,Mo Rebaie,"This guided project course is part of the ""Tensorflow for Convolutional Neural Networks"" series, and this series presents material that builds on the second course of DeepLearning.AI TensorFlow Developer Professional Certificate, which will help learners reinforce their skills and build more projects with Tensorflow.

In this 2-hour long project-based course, you will learn the fundamentals of CNNs, structure, components, and how they work, and you will learn practically how to solve an image classification deep learning task in the real world and create, train, and test a neural network with Tensorflow using real-world images, and you will get a bonus deep learning exercise implemented with Tensorflow. By the end of this project, you will have learned the fundamentals of convolutional neural networks and created a deep learning model with TensorFlow on a real-world dataset.

This class is for learners who want to learn how to work with convolutional neural networks and use Python for building convolutional neural networks with TensorFlow, and for learners who are currently taking a basic deep learning course or have already finished a deep learning course and are searching for a practical deep learning project with TensorFlow. Also, this project provides learners with further knowledge about creating and training convolutional neural networks and improves their skills in Tensorflow which helps them in fulfilling their career goals by adding this project to their portfolios.",,,4.3,40.0
TensorFlow on Google Cloud,https://www.coursera.org/learn/intro-tensorflow,Data Science,Machine Learning,Google Cloud Training,"This course covers designing and building a TensorFlow input data pipeline, building ML models with TensorFlow and Keras, improving the accuracy of ML models, writing ML models for scaled use, and writing specialized ML models.",42684.0,21660.0,4.4,2695.0
TensorFlow を使った畳み込みニューラルネットワーク,https://www.coursera.org/learn/convolutional-neural-networks-tensorflow-ja,Data Science,Machine Learning,Laurence Moroney,"ソフトウェア開発者であれば、拡張性のあるAI搭載アルゴリズムを構築したい場合、構築ツールの使い方を理解する必要があります。この講座は今後学んでいく「TensorFlow in Practice 専門講座」の一部であり、機械学習用の人気のオープンソースフレームワークであるTensorFlowのベストプラクティスを学習します。

deeplearning.ai が提供する「TensorFlow in Practice 専門講座」の講座２では、講座１で構築したコンピュータビジョンモデルを改善するための高度な技法を学習します。現実世界の様々な形状とサイズがある画像の扱い方を探求し、畳み込みを通過する画像がたどる行程を視覚化して、コンピューターがどのようにして情報を「見る」かを理解し、損失と精度をプロットし、拡張とDropoutなど、過学習を防ぐための戦略を探求します。最後に、講座２では転移学習を紹介し、学習した特徴をモデルから抽出する方法を学びます。
 
アンドリュー・エンの「 The Machine Learning（機械学習）」と「Deep Learning Specialization（ディープラーニング専門講座）」では、機械学習とディープラーニングの最も重要かつ基本的な原理を学習します。deeplearning.aiが提供する新しい「TensorFlow in Practice 専門講座」では、TensorFlowを使用してそれらの原理を実装し、拡張性のあるモデルを構築して現実世界の問題に適用する方法を学びます。ニューラルネットワークの仕組みについての理解を深めるには、「ディープラーニング専門講座」を受講することをお勧めします。",,,,
Tensorflow : Analyse de Sentiments avec Word Embedding,https://www.coursera.org/learn/tensorflow-analyse-sentiments-cinema,Data Science,Machine Learning,ELINGUI Pascal Uriel,"Dans ce projet guidé, vous créerez un modèle de Machine Learning d’analyse de sentiments par classification de textes  avec Tensorflow, en utilisant le plongement de mots (Word Embedding). Vous allez vous exercer avec des données collectées sur le site www.allocine.fr 

Le word embedding est une méthode d'apprentissage d'une représentation de mots utilisée traitement automatique des langues. Il donne d’excellents résultats comme vous pourrez le constater dans ce projet guidé.

Ce cours est destiné aux ingénieurs en Machine Learning, au Data Scientists et tous les curieux désireux d’apprendre à faire de la classification de textes facilement.",,,,
Tesla Stock Price Prediction using Facebook Prophet,https://www.coursera.org/learn/tesla-stock-price-prediction-facebook-prophet,Data Science,Machine Learning,Abhishek Jha,"In this 1.5-hour long project-based course, you will learn how to build a Facebook Prophet Machine learning model in order to forecast the price of Tesla 30 days into the future. We will also visualize the historical performance of Tesla through graphs and charts using Plotly express and evaluate the performance of the model against real data using Google Finance in Google Sheets. We will also dive into a brief stock analysis of Tesla and we will discuss PE ratio, EPS, Beta, Market cap, Volume and price range of Tesla.  We will end the project by automating the forecasting process in such a way that you will get the forecast of any of your favourite stock with all necessary visualization within a few seconds of uploading the data. By the end of this project, you will be confident in analyzing, visualizing and forecasting the price of any stock of your choice.

Disclaimer: This project is intended for educational purpose only and is by no means a piece of Financial advice. Please consult your financial advisor before investing in stocks. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3227.0,,4.5,70.0
Text Mining and Analytics,https://www.coursera.org/learn/text-mining,Data Science,Data Analysis,ChengXiang Zhai,"This course will cover the major techniques for mining and analyzing text data to discover interesting patterns, extract useful knowledge, and support decision making, with an emphasis on statistical approaches that can be generally applied to arbitrary text data in any natural language with no or minimum human effort. 

Detailed analysis of text data requires understanding of natural language text, which is known to be a difficult task for computers. However, a number of statistical approaches have been shown to work well for the ""shallow"" but robust analysis of text data for pattern finding and knowledge discovery. You will learn the basic concepts, principles, and major algorithms in text mining and their potential applications.",66056.0,27531.0,4.5,694.0
Text Retrieval and Search Engines,https://www.coursera.org/learn/text-retrieval,Data Science,Data Analysis,ChengXiang Zhai,"Recent years have seen a dramatic growth of natural language text data, including web pages, news articles, scientific literature, emails, enterprise documents, and social media such as blog articles, forum posts, product reviews, and tweets. Text data are unique in that they are usually generated directly by humans rather than a computer system or sensors, and are thus especially valuable for discovering knowledge about people’s opinions and preferences, in addition to many other kinds of knowledge that we encode in text. 

This course will cover search engine technologies, which play an important role in any data mining applications involving text data for two reasons. First, while the raw data may be large for any particular problem, it is often a relatively small subset of the data that are relevant, and a search engine is an essential tool for quickly discovering a small subset of relevant text data in a large text collection. Second, search engines are needed to help analysts interpret any patterns discovered in the data by allowing them to examine the relevant original text data to make sense of any discovered pattern. You will learn the basic concepts, principles, and the major techniques in text retrieval, which is the underlying science of search engines.",53494.0,40364.0,4.5,919.0
The Data Scientist’s Toolbox,https://www.coursera.org/learn/data-scientists-tools,Data Science,Data Analysis,"Jeff Leek, PhD, Roger D. Peng, PhD, Brian Caffo, PhD","In this course you will get an introduction to the main tools and ideas in the data scientist's toolbox. The course gives an overview of the data, questions, and tools that data analysts and data scientists work with. There are two components to this course. The first is a conceptual introduction to the ideas behind turning data into actionable knowledge. The second is a practical introduction to the tools that will be used in the program like version control, markdown, git, GitHub, R, and RStudio.",699310.0,200730.0,4.6,33424.0
The Fundamental of Data-Driven Investment,https://www.coursera.org/learn/the-fundamental-of-data-driven-investment,Data Science,Data Analysis,Youngju Nielsen,"In this course, the instructor will discuss the fundamental analysis of investment using R programming. The course will cover investment analysis topics, but at the same time, make you practice it using R programming. This course's focus is to train you to do the elemental analysis for investment management that you might need to do in your job every day. 

Additionally, the study note to do using Python programming will be provided. 

The course is designed with the assumption that most students already have a little bit of knowledge in financial economics. Students are expected to have heard about stocks and bonds and balance sheets, earnings, etc., and know the introductory statistics level, such as mean, median, distribution, regression, etc. 

The instructor will explain the detail of R programming for beginners. It will be an excellent course for you to improve your programming skills. If you are very good at R programming, it will provide you an excellent opportunity to practice again with finance and investment examples. 

Professor Youngju Nielsen creates the course with the assistants of Keonwoo Lim and Jeeun Yuen.
===========================================================================================
Coursera Course recommendations before this course for those who are not familiar with basic R programming:
<Getting Started with R>  
https://www.coursera.org/projects/getting-started-with-r
<Introduction to Business Analytics with R> 
https://www.coursera.org/learn/business-analytics-r
<Statistics with Python >
https://www.coursera.org/specializations/statistics-with-python",,1558.0,,
"The Power of Machine Learning: Boost Business, Accumulate Clicks, Fight Fraud, and Deny Deadbeats",https://www.coursera.org/learn/the-power-of-machine-learning,Data Science,Machine Learning,Eric Siegel,"It's the age of machine learning. Companies are seizing upon the power of this technology to combat risk, boost sales, cut costs, block fraud, streamline manufacturing, conquer spam, toughen crime fighting, and win elections.

Want to tap that potential? It's best to start with a holistic, business-oriented course on machine learning – no matter whether you’re more on the tech or the business side. After all, successfully deploying machine learning relies on savvy business leadership just as much as it relies on technical skill. And for that reason, data scientists aren't the only ones who need to learn the fundamentals. Executives, decision makers, and line of business managers must also ramp up on how machine learning works and how it delivers business value.

And the reverse is true as well: Techies need to look beyond the number crunching itself and become deeply familiar with the business demands of machine learning. This way, both sides speak the same language and can collaborate effectively.

This course will prepare you to participate in the deployment of machine learning – whether you'll do so in the role of enterprise leader or quant. In order to serve both types, this course goes further than typical machine learning courses, which cover only the technical foundations and core quantitative techniques. This curriculum uniquely integrates both sides – both the business and tech know-how – that are essential for deploying machine learning. It covers:

– How launching machine learning – aka predictive analytics – improves marketing, financial services, fraud detection, and many other business operations

– A concrete yet accessible guide to predictive modeling methods, delving most deeply into decision trees

– Reporting on the predictive performance of machine learning and the profit it generates

– What your data needs to look like before applying machine learning

– Avoiding the hype and false promises of “artificial intelligence”

– AI ethics: social justice concerns, such as when predictive models blatantly discriminate by protected class

NO HANDS-ON AND NO HEAVY MATH. This concentrated entry-level program is totally accessible to business leaders – and yet totally vital to data scientists who want to secure their business relevance. It's for anyone who wishes to participate in the commercial deployment of machine learning, no matter whether you'll play a role on the business side or the technical side. This includes business professionals and decision makers of all kinds, such as executives, directors, line of business managers, and consultants – as well as data scientists.

BUT TECHNICAL LEARNERS SHOULD TAKE ANOTHER LOOK. Before jumping straight into the hands-on, as quants are inclined to do, consider one thing: This curriculum provides complementary know-how that all great techies also need to master. It contextualizes the core technology, guiding you on the end-to-end process required to successfully deploy a predictive model so that it delivers a business impact.

LIKE A UNIVERSITY COURSE. This course is also a good fit for college students, or for those planning for or currently enrolled in an MBA program. The breadth and depth of the overall three-course specialization is equivalent to one full-semester MBA or graduate-level course.

IN-DEPTH YET ACCESSIBLE. Brought to you by industry leader Eric Siegel – a winner of teaching awards when he was a professor at Columbia University – this curriculum stands out as one of the most thorough, engaging, and surprisingly accessible on the subject of machine learning.

VENDOR-NEUTRAL. This course includes illuminating software demos of machine learning in action using SAS products. However, the curriculum is vendor-neutral and universally-applicable. The contents and learning objectives apply, regardless of which machine learning software tools you end up choosing to work with.",9637.0,4572.0,4.8,130.0
The Pytorch basics you need to start your ML projects,https://www.coursera.org/learn/the-pytorch-basics-you-need-to-start-your-ml-projects,Data Science,Machine Learning,Baye Gaspard,"In this 1-hour long project-based course, you will learn how to use simple commands to create and manipulate files and folders, perform multiple complex tasks using one simple command, use the superuser to perform high privilege operations.",,,3.5,25.0
The R Programming Environment,https://www.coursera.org/learn/r-programming-environment,Data Science,Data Analysis,"Roger D. Peng, PhD, Brooke Anderson","This course provides a rigorous introduction to the R programming language, with a  particular focus on using R for software development in a data science setting. Whether you are part of a data science team or working individually within a community of developers, this course will give you the knowledge of R needed to make useful contributions in those settings. As the first course in the Specialization, the course provides the essential foundation of R needed for the following courses. We cover basic R concepts and language fundamentals, key concepts like tidy data and related ""tidyverse"" tools, processing and manipulation of complex and large datasets, handling textual data, and basic data science tasks. Upon completing this course, learners will have fluency at the R console and will be able to create tidy datasets from a wide range of possible data sources.",49624.0,25740.0,4.3,1147.0
The Structured Query Language (SQL),https://www.coursera.org/learn/the-structured-query-language-sql,Data Science,Data Analysis,Alan Paradise,"In this course you will learn all about the Structured Query Language (""SQL"".)   We will review the origins of the language and its conceptual foundations.   But primarily, we will focus on learning all the standard SQL commands, their syntax, and how to use these commands to conduct analysis of the data within a relational database.  Our scope includes not only the SELECT statement for retrieving data and creating analytical reports, but also includes the DDL (""Data Definition Language"") and DML (""Data Manipulation Language"") commands necessary to create and maintain database objects.

The Structured Query Language (SQL) can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",16342.0,208856.0,4.7,264.0
The Total Data Quality Framework,https://www.coursera.org/learn/the-total-data-quality-framework,Data Science,Data Analysis,"Brady T. West, James Wagner, Jinseok Kim, Trent D Buskirk","By the end of this first course in the Total Data Quality specialization, learners will be able to: 

1. Identify the essential differences between designed and gathered data and summarize the key dimensions of the Total Data Quality (TDQ) Framework; 
2. Define the three measurement dimensions of the Total Data Quality framework, and describe potential threats to data quality along each of these dimensions for both gathered and designed data; 
3. Define the three representation dimensions of the Total Data Quality framework, and describe potential threats to data quality along each of these dimensions for both gathered and designed data; and 
4. Describe why data analysis defines an important dimension of the Total Data Quality framework, and summarize potential threats to the overall quality of an analysis plan for designed and/or gathered data.

This specialization as a whole aims to explore the Total Data Quality framework in depth and provide learners with more information about the detailed evaluation of total data quality that needs to happen prior to data analysis. The goal is for learners to incorporate evaluations of data quality into their process as a critical component for all projects. We sincerely hope to disseminate knowledge about total data quality to all learners, such as data scientists and quantitative analysts, who have not had sufficient training in the initial steps of the data science process that focus on data collection and evaluation of data quality. We feel that extensive knowledge of data science techniques and statistical analysis procedures will not help a quantitative research study if the data collected/gathered are not of sufficiently high quality.

This specialization will focus on the essential first steps in any type of scientific investigation using data: either generating or gathering data, understanding where the data come from, evaluating the quality of the data, and taking steps to maximize the quality of the data prior to performing any kind of statistical analysis or applying data science techniques to answer research questions. Given this focus, there will be little material on the analysis of data, which is covered in myriad existing Coursera specializations. The primary focus of this specialization will be on understanding and maximizing data quality prior to analysis.",,3618.0,,
The Unix Workbench,https://www.coursera.org/learn/unix,Data Science,Machine Learning,"Sean Kross, Jeff Leek, PhD, Brian Caffo, PhD, Roger D. Peng, PhD","Unix forms a foundation that is often very helpful for accomplishing other goals you might have for you and your computer, whether that goal is running a business, writing a book, curing disease, or creating the next great app. The means to these goals are sometimes carried out by writing software. Software can’t be mined out of the ground, nor can software seeds be planted in spring to harvest by autumn. Software isn’t produced in factories on an assembly line. Software is a hand-made, often bespoke good. If a software developer is an artisan, then Unix is their workbench. Unix provides an essential and simple set of tools in a distraction-free environment. Even if you’re not a software developer learning Unix can open you up to new methods of thinking and novel ways to scale your ideas. 

This course is intended for folks who are new to programming and new to Unix-like operating systems like macOS and Linux distributions like Ubuntu. Most of the technologies discussed in this course will be accessed via a command line interface. Command line interfaces can seem alien at first, so this course attempts to draw parallels between using the command line and actions that you would normally take while using your mouse and keyboard. You’ll also learn how to write little pieces of software in a programming language called Bash, which allows you to connect together the tools we’ll discuss. My hope is that by the end of this course you be able to use different Unix tools as if they’re interconnecting Lego bricks.",51747.0,44477.0,4.7,1296.0
Tidy Messy Data using tidyr in R,https://www.coursera.org/learn/tidy-messy-data-using-tidyr-in-r,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"As data enthusiasts and professionals, our work often requires dealing with data in different forms. In particular, messy data can be a big challenge because the quality of your analysis largely depends on the quality of the data. This project-based course, ""Tidy Messy Data using tidyr in R,"" is intended for beginner and intermediate R users with related experiences who are willing to advance their knowledge and skills. 
In this course, you will learn practical ways for data cleaning, reshaping, and transformation using R. You will learn how to use different tidyr functions like pivot_longer(), pivot_wider(), separate_rows(), separate(), and others to achieve the tidy data principles. By the end of this 2-hour-long project, you will get hands-on massaging data to put in the proper format. By extension, you will learn to create plots using ggplot().
This project-based course is a beginner to an intermediate-level course in R. Therefore, to get the most out of this project, it is essential to have a basic understanding of using R. Specifically, you should be able to load data into R and understand how the pipe function works. It will be helpful to complete my previous project titled ""Data Manipulation with dplyr in R.""",,,,
Time Series Data Visualization And Analysis Techniques,https://www.coursera.org/learn/time-series-data-visualization-techniques,Data Science,Data Analysis,Ahmad Varasteh,"By the end of this project we will learn how to analyze time series data. We are going to talk about different visualization techniques for time series datasets and we are going to compare them in terms of the tasks that we can solve using each of them. Tasks such as outlier detection, Key moments detection and overall trend analysis. During this project, we will learn how and when to use Line charts, Bar charts, and Boxplot. We will also learn some techniques about color mapping and we will understand how it can help us for a better analysis and understanding of our data.",,,,
Titanic Survival Prediction Using Machine Learning,https://www.coursera.org/learn/titanic-survival-prediction-using-machine-learning,Data Science,Machine Learning,Ryan Ahmed,"In this 1-hour long project-based course, we will predict titanic survivors’ using logistic regression and naïve bayes classifiers. The sinking of the Titanic is one of the key sad tragedies in history and it took place on April 15th, 1912. The numbers of survivors were low due to lack of lifeboats for all passengers. This practical guided project, we will analyze what sorts of people were likely to survive this tragedy with the power of machine learning.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Tools and Practices for Addressing Pandemic Challenges,https://www.coursera.org/learn/tools-and-practices-for-addressing-pandemic-challenges,Data Science,Data Analysis,Marco Brambilla,"An overview of the tools, techniques, and practices that can be enacted by policy makers, countries, and organizations to monitor, manage, and react to pandemics and mitigate and govern their impacts. 

An introductory, multidisciplinary course covering data science, social science, healthcare, and management, paving the way to various courses on specific matters.

This course is part of the research project 'Pan-European Response to the Impacts of the COVID-19 and future Pandemics and Epidemics' (PERISCOPE, https://www.periscopeproject.eu/). Funded by the European Commission Research Funding programme Horizon 2020 under the Grant Agreement number 101016233, PERISCOPE investigates the broad socio-economic and behavioural impacts of the COVID-19 pandemic, to make Europe more resilient and prepared for future large-scale risks.",,,,
Tools for Data Science,https://www.coursera.org/learn/open-source-tools-for-data-science,Data Science,Data Analysis,"Aije Egwaikhide, Svetlana Levitan, Romeo Kienzler","In order to be successful in Data Science, you need to be skilled with using tools that Data Science professionals employ as part of their jobs. This course teaches you about the popular tools in Data Science and how to use them. 

You will become familiar with the Data Scientist’s tool kit which includes: Libraries & Packages, Data Sets, Machine Learning Models, Kernels, as well as the various Open source, commercial, Big Data and Cloud-based tools. 

Work with Jupyter Notebooks, JupyterLab, RStudio IDE, Git, GitHub, and Watson Studio. You will understand what each tool is used for, what programming languages they can execute, their features and limitations.  

This course gives plenty of hands-on experience in order to develop skills for working with these Data Science Tools. With the tools hosted in the cloud on Skills Network Labs, you will be able to test each tool and follow instructions to run simple code in Python, R, or Scala.  

Towards the end the course, you will create a final project with a Jupyter Notebook. You will demonstrate your proficiency preparing a notebook, writing Markdown, and sharing your work with your peers.",320414.0,913111.0,4.5,25276.0
Tools for Exploratory Data Analysis in Business,https://www.coursera.org/learn/tools-exploratory-data-analysis-business,Data Science,Data Analysis,"Jessen Hobson, Ronald Guymon","This course introduces several tools for processing business data to obtain actionable insight. The most important tool is the mind of the data analyst. Accordingly, in this course, you will explore what it means to have an analytic mindset. You will also practice identifying business problems that can be answered using data analytics. You will then be introduced to various software platforms to extract, transform, and load (ETL) data into tools for conducting exploratory data analytics (EDA). Specifically, you will practice using PowerBI, Alteryx, and RStudio to conduct the ETL and EDA processes. 

The learning outcomes for this course include:
1.	Development of an analytic mindset for approaching business problems.
2.	The ability to appraise the value of datasets for addressing business problems using summary statistics and data visualizations.
3.	The ability to competently operate business analytic software applications for exploratory data analysis.",5355.0,76149.0,4.9,22.0
Topic Modeling using PyCaret,https://www.coursera.org/learn/topic-modeling-using-pycaret,Data Science,Machine Learning,Mohamed Jendoubi,"In this 1-hour long project-based course, you will create an end-to-end Topic model using PyCaret a low-code Python open-source Machine Learning library.
You will learn how to automate the major steps for preprocessing, building, evaluating and deploying Machine Learning Models for Topic . 
Here are the main steps you will go through: frame the problem, get and prepare the data, discover and visualize the data, create the transformation pipeline, build, evaluate, interpret and deploy the model.
This guided project is for seasoned Data Scientists who want to build a accelerate the efficiency in building POC and experiments by using a low-code library. It is also for Citizen data Scientists (professionals working with data) by using the low-code library PyCaret to add machine learning models to the analytics toolkit
In order to be successful in this project, you should be familiar with Python and the basic concepts on Machine Learning


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Tout Pour Démarrer avec RStudio,https://www.coursera.org/learn/demarrer-avec-rstudio,Data Science,Data Analysis,Emmanuel Segui,"Dans ce cours d'une heure, basé sur un projet, vous apprendrez comment démarrer avec RStudio IDE, sur votre ordinateur ou sur la solution en ligne de RStudio, comment créer des projets, installer des librairies R, ainsi qu'apprendre comment afficher des cartes interactives, des graphiques et des tableaux avec 1 ligne de code.

Remarque : ce cours fonctionne le mieux pour les étudiants basés en Amérique du Nord. Nous nous efforçons actuellement d'apporter la même expérience dans d'autres régions.",,,,
Trabajando con Dask,https://www.coursera.org/learn/trabajando-dask,Data Science,Data Analysis,Nestor Nicolas Campos Rojas,"En este curso basado en un proyecto y de 1 hora de duración, aprenderás sobre Dask y la importancia de usarlo en proyectos de Big Data para grandes análisis de datos en procesamiento paralelo.",,,,
Trabalho de conclusão de Ciência de Dados Aplicada,https://www.coursera.org/learn/applied-data-science-capstone-pt,Data Science,Data Analysis,Alex Aklson,"Este curso do projeto de conclusão mostrará um pouco do que os cientistas de dados passam na vida real ao trabalhar com dados.

Você aprenderá sobre dados de localização e diferentes provedores de dados de localização, como o Foursquare. Você aprenderá como fazer chamadas de API RESTful para a API do Foursquare a fim de recuperar dados sobre locais em diferentes bairros do mundo. Você também aprenderá como usar a criatividade quando os dados não estiverem disponíveis na hora, coletando dados da Web e analisando o código HTML. Você utilizará Python e sua biblioteca do Pandas para manipular dados, o que ajudará você a refinar suas habilidades para explorar e analisar dados.

Por fim, você deverá usar a biblioteca Folium para obter excelentes mapas de dados geoespaciais e para comunicar seus resultados e descobertas.

Se optar por fazer este curso e obter o certificado de conclusão de curso do Coursera, você também poderá ganhar um selo digital da IBM.

OFERTA LIMITADA: a assinatura custa apenas US$ 39,00 por mês para acesso a materiais classificados e a um certificado.",,,,
Tracking Cryptocurrency Exchange Trades with Google Cloud Platform in Real-Time,https://www.coursera.org/learn/googlecloud-tracking-cryptocurrency-exchange-trades-with-google-cloud-plat-eneyt,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Traffic Sign Classification Using Deep Learning in Python/Keras,https://www.coursera.org/learn/traffic-sign-classification-deep-learning,Data Science,Machine Learning,Ryan Ahmed,"In this 1-hour long project-based course, you will be able to:
- Understand the theory and intuition behind Convolutional Neural Networks (CNNs).
- Import Key libraries, dataset and visualize images.
- Perform image normalization and convert from color-scaled to gray-scaled images.
- Build a Convolutional Neural Network using Keras with Tensorflow 2.0 as a backend.
- Compile and fit Deep Learning model to training data. 
- Assess the performance of trained CNN and ensure its generalization using various KPIs.
- Improve network performance using regularization techniques such as dropout.",10407.0,,4.6,359.0
Train Machine Learning Models,https://www.coursera.org/learn/train-machine-learning-models,Data Science,Machine Learning,"Stacey McBrine, Megan Smith Branch, Sarah Haq","This course is designed for business professionals that wish to identify basic concepts that make up machine learning, test model hypothesis using a design of experiments and train, tune and evaluate models using algorithms that solve classification, regression and forecasting, and clustering problems.

To be successful in this course a learner should have a background in computing technology, including some aptitude in computer programming.",,2135.0,,
"Training & Visualizing a Decision Tree ,predicting and checking sensitivity",https://www.coursera.org/learn/training-and-visualizing-a-decision-tree,Data Science,Machine Learning,Ashish Dikshit,"Training & Visualizing a Decision Tree ,predicting and checking sensitivity",,,,
Transfer Learning for Food Classification,https://www.coursera.org/learn/transfer-learning-food-classification,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train a deep learning model to predict the type of food and then fine tune the model to improve its performance. This project could be practically applied in food industry to detect the type and quality of food. In this 2-hours long project-based course, you will be able to:
- Understand the theory and intuition behind Convolutional Neural Networks (CNNs).
- Understand the theory and intuition behind transfer learning.
- Import Key libraries, dataset and visualize images.
- Perform data augmentation.
- Build a Deep Learning Model using Pre-Trained InceptionResnetV2.
- Compile and fit Deep Learning model to training data. 
- Assess the performance of trained CNN and ensure its generalization using various KPIs.",3951.0,,4.6,64.0
Transfer Learning for NLP with TensorFlow Hub,https://www.coursera.org/learn/transfer-learning-nlp-tensorflow-hub,Data Science,Machine Learning,Snehan Kekre,"This is a hands-on project on transfer learning for natural language processing with TensorFlow and TF Hub.  By the time you complete this project, you will be able to use pre-trained NLP text embedding models from TensorFlow Hub, perform transfer learning to fine-tune models on real-world data, build and evaluate multiple models for text classification with TensorFlow, and visualize model performance metrics with Tensorboard.

Prerequisites:
In order to successfully complete this project, you should be competent in the Python programming language, be familiar with deep learning for Natural Language Processing (NLP), and have trained models with TensorFlow or and its Keras API.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6770.0,,4.8,147.0
Transformer les Données avec R,https://www.coursera.org/learn/transformer-donnees-avec-r,Data Science,Data Analysis,Emmanuel Segui,"Dans ce cours d'une heure, basé sur un projet, vous apprendrez comment faire pivoter des données dans un format large et long, diviser et combiner des cellules et des colonnes, gérer les valeurs manquantes, sélectionner des groupes d'observations et de variables et joindre des données de différentes tables.

Remarque : ce cours fonctionne le mieux pour les étudiants basés en Amérique du Nord. Nous nous efforçons actuellement d'apporter la même expérience dans d'autres régions.",,,,
Transforming Data in R,https://www.coursera.org/learn/transforming-data-in-r,Data Science,Data Analysis,Emmanuel Segui,"In this 1-hour long project-based course, you will learn how to pivot data into wide and long format, split and combine cells and columns, handling missing values, select groups of observations and variables, and join data from different tables.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,14.0
Translate Text with the Cloud Translation API,https://www.coursera.org/learn/googlecloud-translate-text-with-the-cloud-translation-api-l1tmv,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Tri et filtrage dans SQL,https://www.coursera.org/learn/tri-et-filtrage-dans-sql,Data Science,Data Analysis,Hodroj Jamal,"Dans ce projet guidé d'une heure, vous apprendrez à faire une requête SQL pour filtrer des enregistrements, et aussi à trier les données par ordre croissant ou décroissant.
À la fin de ce projet, nous aurons appris à créer et exploiter les requêtes de recherche dans SQL.",,,,
Trier et filtrer les données en SQL,https://www.coursera.org/learn/trier-et-filtrer-les-donnes-en-sql,Data Science,Data Analysis,Mohamed Jendoubi,Trier et filtrer les données en SQL,,,,
Troubleshooting Common SQL Errors with BigQuery,https://www.coursera.org/learn/googlecloud-troubleshooting-common-sql-errors-with-bigquery-q3baf,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Troubleshooting and Solving Data Join Pitfalls,https://www.coursera.org/learn/googlecloud-troubleshooting-and-solving-data-join-pitfalls-ukiqz,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Turn Ethical Frameworks into Actionable Steps,https://www.coursera.org/learn/ethical-frameworks-action,Data Science,Machine Learning,"Eleanor 'Nell' Watson, Aaron Hui, Abhishek Gupta, Megan Smith Branch","Ethical principles build a strong foundation for driving ethical technologies. Principles alone can be elusive and impractical for application. Ethical frameworks based upon these principles provide a structure to guide technologists when implementing data-driven solutions. However, ethical frameworks, along with standards and regulations, can make compliance tasks more complex, and they can also raise the tension between ethical duties and business practicalities. An approach is needed to reconcile these issues. This second course within the Certified Ethical Emerging Technologist (CEET) professional certificate is designed for learners seeking to analyze ethical frameworks, regulations, standards, and best practices and integrate them into data-driven solutions.

Students will become familiar with frameworks and the common ethical principles they are based upon and how they can be applied across a variety of ethically driven dilemmas. You will learn applicable regulations and best practices established across global organizations and governments and how to navigate the integration of these standards in the context of business needs.

This course is the second of five courses within the Certified Ethical Emerging Technologist (CEET) professional certificate. The preceding course is titled Promote the Ethical Use of Data-Driven Technologies.",7946.0,41980.0,4.7,94.0
Tweet Emotion Recognition with TensorFlow,https://www.coursera.org/learn/tweet-emotion-tensorflow,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long guided project, we are going to create a recurrent neural network and train it on a tweet emotion dataset to learn to recognize emotions in tweets. The dataset has thousands of tweets each classified in one of 6 emotions. This is a multi class classification problem in the natural language processing domain. We will be using TensorFlow as our machine learning framework.

You will need prior programming experience in Python. This is a practical, hands on guided project for learners who already have theoretical understanding of Neural Networks, recurrent neural networks, and optimization algorithms like gradient descent but want to understand how to use the Tensorflow to start performing natural language processing tasks like text classification. You should also have some basic familiarity with TensorFlow.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",7509.0,,4.7,125.0
Twitter API: Mining Data using Orange Data Mining Platform,https://www.coursera.org/learn/twitter-api-mining-data-using-orange-data-mining-platform,Data Science,Data Analysis,Abhishek Jha,"In this one hour long project, you will mine, analyze and visualize various trending tweets using Word Cloud, Heat map, Document Map and perform sentiment analysis using Orange. Orange is an open-source data visualization, machine learning and data mining toolkit. Without any prior programming experience, Orange allows you to mine Twitter. If you are a corporate employee, marketer, or even a student who wants to explore how to mine tweets, Orange is the best platform for it.

We will begin this guided project by creating a Twitter developer account and applying for elevated access. We will create an app within the Twitter developer portal and get its API keys and then use these API keys to connect to Orange data mining software. We will fetch tweets about trending topics and create a Word-cloud for text visualization and Documents map to get Geo-location data about trending tweets. In the final tasks, we will perform sentiment analysis and explore the emotions behind each tweet using the Tweet Profiler widget. We will also create a Heat-map to understand the overall sentiment of a trending topic. 

In order to complete this project successfully, you need a Twitter account.",,,,
"Understanding China, 1700-2000: A Data Analytic Approach, Part 1",https://www.coursera.org/learn/understanding-china-history-part-1,Data Science,Data Analysis,James Z. Lee,"The purpose of this course is to summarize new directions in Chinese history and social science produced by the creation and analysis of big historical datasets based on newly opened Chinese archival holdings, and to organize this knowledge in a framework that encourages learning about China in comparative perspective.

Our course demonstrates how a new scholarship of discovery is redefining what is singular about modern China and modern Chinese history. Current understandings of human history and social theory are based largely on Western experience or on non-Western experience seen through a Western lens. This course offers alternative perspectives derived from Chinese experience over the last three centuries. We present specific case studies of this new scholarship of discovery divided into two stand-alone parts, which means that students can take any part without prior or subsequent attendance of the other part.

Part 1 (this course) focuses on comparative inequality and opportunity and addresses two related questions ‘Who rises to the top?’ and ‘Who gets what?’.

Part 2 (https://www.coursera.org/learn/understanding-china-history-part-2) turns to an arguably even more important question ‘Who are we?’ as seen through the framework of comparative population behavior - mortality, marriage, and reproduction – and their interaction with economic conditions and human values. We do so because mortality and reproduction are fundamental and universal, because they differ historically just as radically between China and the West as patterns of inequality and opportunity, and because these differences demonstrate the mutability of human behavior and values.

Course Overview video: https://youtu.be/dzUPRyJ4ETk",9105.0,2814.0,4.7,112.0
"Understanding China, 1700-2000: A Data Analytic Approach, Part 2",https://www.coursera.org/learn/understanding-china-history-part-2,Data Science,Data Analysis,James Z. Lee,"The purpose of this course is to summarize new directions in Chinese history and social science produced by the creation and analysis of big historical datasets based on newly opened Chinese archival holdings, and to organize this knowledge in a framework that encourages learning about China in comparative perspective.

Our course demonstrates how a new scholarship of discovery is redefining what is singular about modern China and modern Chinese history. Current understandings of human history and social theory are based largely on Western experience or on non-Western experience seen through a Western lens. This course offers alternative perspectives derived from Chinese experience over the last three centuries. We present specific case studies of this new scholarship of discovery divided into two stand-alone parts, which means that students can take any part without prior or subsequent attendance of the other part.

Part 1 (https://www.coursera.org/learn/understanding-china-history-part-1) focuses on comparative inequality and opportunity and addresses two related questions ‘Who rises to the top?’ and ‘Who gets what?’. 

Part 2 (this course) turns to an arguably even more important question ‘Who are we?’ as seen through the framework of comparative population behavior - mortality, marriage, and reproduction – and their interaction with economic conditions and human values. We do so because mortality and reproduction are fundamental and universal, because they differ historically just as radically between China and the West as patterns of inequality and opportunity, and because these differences demonstrate the mutability of human behavior and values.

Course Overview video: https://youtu.be/dzUPRyJ4ETk",3971.0,1667.0,4.5,53.0
Understanding Deepfakes with Keras,https://www.coursera.org/learn/deepfakes-keras,Data Science,Machine Learning,Amit Yadav,"In this 2-hour long project-based course, you will learn to implement DCGAN or Deep Convolutional Generative Adversarial Network, and you will train the network to generate realistic looking synthesized images. The term Deepfake is typically associated with synthetic data generated by Neural Networks which is similar to real-world, observed data - often with synthesized images, videos or audio. Through this hands-on project, we will go through the details of how such a network is structured, trained, and will ultimately generate synthetic images similar to hand-written digit 0 from the MNIST dataset.

Since this is a practical, project-based course, you will need to have a theoretical understanding of Neural Networks, Convolutional Neural Networks, and optimization algorithms like Gradient Descent. We will focus on the practical aspect of implementing and training DCGAN, but not too much on the theoretical aspect. You will also need some prior experience with Python programming.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, and Tensorflow pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6974.0,,4.4,154.0
Understanding and Visualizing Data with Python,https://www.coursera.org/learn/understanding-visualization-data,Data Science,Data Analysis,"Brenda Gunderson, Brady T. West, Kerby Shedden","In this course, learners will be introduced to the field of statistics, including where data come from, study design, data management, and exploring and visualizing data. Learners will identify different types of data, and learn how to visualize, analyze, and interpret summaries for both univariate and multivariate data. Learners will also be introduced to the differences between probability and non-probability sampling from larger populations, the idea of how sample estimates vary, and how inferences can be made about larger populations based on probability sampling.

At the end of each week, learners will apply the statistical concepts they’ve learned using Python within the course environment. During these lab-based sessions, learners will discover the different uses of Python as a tool, including the Numpy, Pandas, Statsmodels, Matplotlib, and Seaborn libraries. Tutorial videos are provided to walk learners through the creation of visualizations and data management, all within Python. This course utilizes the Jupyter Notebook environment within Coursera.",109641.0,129998.0,4.7,2384.0
University Admission Prediction Using Multiple Linear Regression,https://www.coursera.org/learn/machine-learning-university-admission,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on guided project, we will train regression models to find the probability of a student getting accepted into a particular university based on their profile. This project could be practically used to get the university acceptance rate for individual students using web application. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6090.0,,4.6,177.0
Unsupervised Algorithms in Machine Learning,https://www.coursera.org/learn/unsupervised-algorithms-in-machine-learning,Data Science,Machine Learning,Geena Kim ,"One of the most useful areas in machine learning is discovering hidden patterns from unlabeled data. Add the fundamentals of this in-demand skill to your Data Science toolkit. In this course, we will learn selected unsupervised learning methods for dimensionality reduction, clustering, and learning latent features. We will also focus on real-world applications such as recommender systems with hands-on examples of product recommendation algorithms.

Prior coding or scripting knowledge is required. We will be utilizing Python extensively throughout the course. College-level math skills, including Calculus and Linear Algebra, are needed. It is recommended, but not required, to take the first course in the specialization, Introduction to Machine Learning: Supervised Learning. 

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.


Course logo image by Ryan Wallace on Unsplash.",,17325.0,,
"Unsupervised Learning, Recommenders, Reinforcement Learning",https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning,Data Science,Machine Learning,"Andrew Ng, Eddy Shyu, Aarti Bagul, Geoff Ladwig","In the third course of the Machine Learning Specialization, you will:

• Use unsupervised learning techniques for unsupervised learning: including clustering and anomaly detection.
• Build recommender systems with a collaborative filtering approach and a content-based deep learning method.
• Build a deep reinforcement learning model.

The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. In this beginner-friendly program, you will learn the fundamentals of machine learning and how to use these techniques to build real-world AI applications. 

This Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.

This 3-course Specialization is an updated and expanded version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012. 

It provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)

By the end of this Specialization, you will have mastered key concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.",37772.0,539658.0,4.9,462.0
Unsupervised Machine Learning,https://www.coursera.org/learn/ibm-unsupervised-machine-learning,Data Science,Machine Learning,"Mark J Grover, Miguel Maldonado","This course introduces you to one of the main types of Machine Learning: Unsupervised Learning. You will learn how to find insights from data sets that do not have a target or labeled variable. You will learn several clustering and dimension reduction algorithms for unsupervised learning as well as how to select the algorithm that best suits your data. The hands-on section of this course focuses on using best practices for unsupervised learning.

By the end of this course you should be able to:
Explain the kinds of problems suitable for Unsupervised Learning approaches
Explain the curse of dimensionality, and how it makes clustering difficult with many features
Describe and use common clustering and dimensionality-reduction algorithms
Try clustering points where appropriate, compare the performance of per-cluster models
Understand metrics relevant for characterizing clusters

Who should take this course?
This course targets aspiring data scientists interested in acquiring hands-on experience with Unsupervised Machine Learning techniques in a business setting.
 
What skills should you have?
To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Data Cleaning, Exploratory Data Analysis, Calculus, Linear Algebra, Probability, and Statistics.",10787.0,42940.0,4.7,157.0
Unsupervised Machine Learning for Customer Market Segmentation,https://www.coursera.org/learn/machine-learning-for-customer-segmentation,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on guided project, we will train unsupervised machine learning algorithms to perform customer market segmentation. Market segmentation is crucial for marketers since it enables them to launch targeted ad marketing campaigns that are tailored to customer's specific needs. 

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",10376.0,,4.7,310.0
Unsupervised Text Classification for Marketing Analytics,https://www.coursera.org/learn/unsupervised-text-classification-for-marketing-analytics,Data Science,Data Analysis,"Chris J. Vargo, Scott Bradley","Marketing data is often so big that humans cannot read or analyze a representative sample of it to understand what insights might lie within. In this course, learners use unsupervised deep learning to train algorithms to extract topics and insights from text data. Learners walk through a conceptual overview of unsupervised machine learning and dive into real-world datasets through instructor-led tutorials in Python. The course concludes with a major project.

This course uses Jupyter Notebooks and the coding environment Google Colab, a browser-based Jupyter notebook environment. Files are stored in Google Drive.

This course can be taken for academic credit as part of CU Boulder’s Master of Science in Data Science (MS-DS) degree offered on the Coursera platform. The MS-DS is an interdisciplinary degree that brings together faculty from CU Boulder’s departments of Applied Mathematics, Computer Science, Information Science, and others. With performance-based admissions and no application process, the MS-DS is ideal for individuals with a broad range of undergraduate education and/or professional experience in computer science, information science, mathematics, and statistics. Learn more about the MS-DS program at https://www.coursera.org/degrees/master-of-science-data-science-boulder.",,4165.0,,
Use Python for Non-Data Role,https://www.coursera.org/learn/use-python-non-data-role,Data Science,Data Analysis,Carmen Rojas,"Even if you are not a person with a data specific role, knowing how to work with data is becoming a highly in-demand skill. More and more companies are collecting data, storing data, and making data-based decisions. From marketing to human resources, to finance and operations, knowing the basics of how to use a data language such as Python will make you even more desirable, valuable, and useful to your company. In this project, learners will learn how to get started with Python. They will learn how to upload Excel sets into Python; how to create lists, dictionaries, and tables; and even how to create Gantt charts with Python. This will arm people in all kinds of roles to use Python to perform data tasks.",,,,
Using Advanced Formulas and Functions in Excel,https://www.coursera.org/learn/using-advanced-formulas-and-functions-in-excel,Data Science,Data Analysis,Wendy S Barker,"In this project, you will learn the advanced formulas and functions in Excel to perform analysis on several different topics. First, we will review basic formulas and functions and take a tour through the many choices in the Excel Formulas tab. Then we will explore the advanced financial formulas and functions followed by logic and text. Last, we will learn many ways to perform lookup and reference type queries. Throughout the project, you will work through some examples that will show you how to apply the formulas and functions you have learned.",,,3.5,17.0
Using BigQuery in the Google Cloud Console,https://www.coursera.org/learn/googlecloud-using-bigquery-in-the-google-cloud-console-th5it,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Using Cloud Error Reporting to Remediate Workload Issues on GKE,https://www.coursera.org/learn/googlecloud-using-cloud-error-reporting-to-remediate-workload-issues-on-gk-kuthl,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Using Custom Fields in Looker Explores,https://www.coursera.org/learn/googlecloud-using-custom-fields-in-looker-explores-nrr2j,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Using DAX throughout PowerBI to create robust data scenarios,https://www.coursera.org/learn/using-dax-throughout-powerbi-to-create-robust-data-scenarios,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"If you don't use Data Analysis Expressions (DAX) Language, you will miss out on 95% of Power BI's potential as a fantastic analytical tool, and the journey to becoming a DAX master starts with the right step. This project-based course, ""Using DAX throughout Power BI to create robust data scenarios,"" is intended for novice data analysts willing to advance their knowledge and skills.

This 2-hour project-based course will teach you how to create columns, measures, and tables using DAX codes while understanding the importance of context in DAX formulas. Finally, we'll round off the course by introducing time-intelligence functions and show you how to use Quick Measures to create complex DAX code. This course is structured in a systematic way and very practical, where you get an option to practice as you progress. 

This project-based course is a beginner-level course in Power BI. Therefore, you should be familiar with the Power BI interface to get the most out of this project. Please join me on this beautiful ride! Let's take the first step in your DAX mastery journey!",,,,
Using Data for Geographic Mapping and Forecasting in SAS Visual Analytics,https://www.coursera.org/learn/using-data-geographic-mapping-sas-va,Data Science,Data Analysis,Nicole Ball,"In this course, you learn about the data structure needed for geographic mapping and forecasting, how to use SAS Data Studio to restructure data for analysis, and how to create geo maps and forecasts in SAS Visual Analytics.",8208.0,7240.0,4.7,203.0
Using Descriptive Statistics to Analyze Data in R,https://www.coursera.org/learn/descriptive-statistics-analyze-data-r,Data Science,Data Analysis,Dr. Nikunj Maheshwari,"By the end of this project, you will create a data quality report file (exported to Excel in CSV format) from a dataset loaded in R, a free, open-source program that you can download. You will learn how to use the following descriptive statistical metrics in order to describe a dataset and how to calculate them in basic R with no additional libraries. 
- minimum value
- maximum value
- average value
- standard deviation
- total number of values
- missing values
- unique values
- data types


You will then learn how to record the statistical metrics for each column of a dataset using a custom function created by you in R. The output of the function will be a ready-to-use data quality report.  Finally, you will learn how to export this report to an external file.

A data quality report can be used to identify outliers, missing values, data types, anomalies, etc. that are present in your dataset. This is the first step to understand your dataset and let you plan what pre-processing steps are required to make your dataset ready for analysis.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2808.0,,4.6,84.0
Using Machine Learning in Trading and Finance,https://www.coursera.org/learn/machine-learning-trading-finance,Data Science,Machine Learning,Jack Farmer,"This course provides the foundation for developing advanced trading strategies using machine learning techniques. In this course, you’ll review the key components that are common to every trading strategy, no matter how complex. You’ll be introduced to multiple trading strategies including quantitative trading, pairs trading, and momentum trading. By the end of the course, you will be able to design basic quantitative trading strategies, build machine learning models using Keras and TensorFlow, build a pair trading strategy prediction model and back test it, and build a momentum-based trading model and back test it.

To be successful in this course, you should have advanced competency in Python programming and familiarity with pertinent libraries for machine learning, such as Scikit-Learn, StatsModels, and Pandas. Experience with SQL is recommended. You should have a background in statistics (expected values and standard deviation, Gaussian distributions, higher moments, probability, linear regressions) and foundational knowledge of financial markets (equities, bonds, derivatives, market structure, hedging).",18717.0,20256.0,4.0,314.0
Using SAS Viya REST APIs with Python and R,https://www.coursera.org/learn/sas-viya-rest-api-python-r,Data Science,Data Analysis,"Jordan Bakerman, Ari Zitin","SAS Viya is an in-memory distributed environment used to analyze big data quickly and efficiently. In this course, you’ll learn how to use the SAS Viya APIs to take control of SAS Cloud Analytic Services from a Jupyter Notebook using R or Python. You’ll learn to upload data into the cloud, analyze data, and create predictive models with SAS Viya using familiar open source functionality via the SWAT package -- the SAS Scripting Wrapper for Analytics Transfer. You’ll learn how to create both machine learning and deep learning models to tackle a variety of data sets and complex problems. And once SAS Viya has done the heavy lifting, you’ll be able to download data to the client and use native open source syntax to compare results and create graphics.",3347.0,2680.0,4.6,14.0
Using SQL String Functions to Clean Data,https://www.coursera.org/learn/using-sql-string-functions-to-clean-data,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Welcome to this project-based course on Using SQL String Functions to Clean Data. In this project, you will learn how to perform data cleaning and manipulation using SQL string functions like LENGTH, UPPER & LOWER, REPLACE, TRIM, SUBSTRING, CONCAT, STRING_AGG, and COALESCE.

By the end of this 2-hour long project, you will understand why you need to learn about string functions and use them to get the desired result you want from tables in a database. Also, for this hands-on project, we will use PostgreSQL as our preferred database management system (DBMS). Therefore, to complete this project, it is required that you have prior experience with using PostgreSQL. Similarly, this project is an advanced SQL concept; so, a good foundation for writing SQL queries is vital to complete this project.

If you are not familiar with SQL and want to learn the basics, start with my previous guided projects titled “Performing Data definition and Manipulation in SQL"" and “Querying Databases using SQL SELECT statement.” I taught these guided projects using PostgreSQL. Taking these projects will give the needed requisite to complete this project Using SQL String Functions to Clean Data. However, if you are comfortable writing queries in PostgreSQL, please join me on this wonderful ride! Let’s get our hands dirty!",,,4.3,15.0
Using Shiny to Plot Differential Gene Expression,https://www.coursera.org/learn/shiny-to-plot-differential-gene-expression,Data Science,Data Analysis,Usama A. F. Khalil,"In this project-based course, you will create a Shiny app to plot gene expression data (Real-Time PCR) from a published manuscript. You will build the Shiny app from scratch and handle every component of Shiny. The project covers data processing and collecting feedback from the user to build and finetune the output.
In this course, we will be concerned with the optimal use of inputs and outputs. Instead of building a lot of inputs and outputs, we will use a limited number of components and recycle some even seven times for different purposes.",1772.0,,4.4,42.0
Using TensorFlow with Amazon Sagemaker,https://www.coursera.org/learn/sagemaker-tensorflow,Data Science,Machine Learning,Amit Yadav,"Please note: You will need an AWS account to complete this course. Your AWS account will be charged as per your usage. Please make sure that you are able to access Sagemaker within your AWS account. If your AWS account is new, you may need to ask AWS support for access to certain resources. You should be familiar with python programming, and AWS before starting this hands on project. We use a Sagemaker P type instance in this project, and if you don't have access to this instance type, please contact AWS support and request access.

In this 2-hour long project-based course, you will learn how to train and deploy an image classifier created and trained with the TensorFlow framework within the Amazon Sagemaker ecosystem. Sagemaker provides a number of machine learning algorithms ready to be used for solving a number of tasks. However, it is possible to use Sagemaker for custom training scripts as well. We will use TensorFlow and Sagemaker's TensorFlow Estimator to create, train and deploy a model that will be able to classify images of dogs and cats from the popular Oxford IIIT Pet Dataset.

Since this is a practical, project-based course, we will not dive in the theory behind deep learning based image classification, but will focus purely on training and deploying a model with Sagemaker and TensorFlow. You will also need to have some experience with Amazon Web Services (AWS).

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",6313.0,,4.6,94.0
Using Tensorflow for Image Style Transfer,https://www.coursera.org/learn/using-tensorflow-image-style-transfer,Data Science,Machine Learning,Charles Ivan Niswander II,"Have you ever wished you could paint like Van Gogh, Monet or even Picasso? Better yet, have you wished for an easy way to convert your own images into new ones incorporating the style of these famous artists? With Neural Style Transfer, Convolutional Neural Networks (CNNs) distill the essence of the style of any famous artist it is fed, and are able to transfer that style to any other image. In this project-based course, you will learn how to utilize Python and Tensorflow to build a Neural Style Transfer (NST) model using a VGG19 CNN.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Using ggplot,https://www.coursera.org/learn/using-ggplot,Data Science,Data Analysis,Dr. Karl Michel,"In this project, you will learn about using ggplot, specifically ggplot2 (the latest version of ggplot). This program is a plotting package for the programming language R. R is a computer programming language, and it is also an open-source software often used among data scientists, statisticians, and data miners in their everyday work with data sets. The gg in ggplot2 means Grammar of Graphics, a graphic concept which describes plots by using a “grammar.”

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Using probability distributions for real world problems in R,https://www.coursera.org/learn/probability-distributions-real-world-problems-r,Data Science,Probability and Statistics,Dr. Nikunj Maheshwari,"By the end of this project, you will learn how to apply probability distributions to solve real world problems in R, a free, open-source program that you can download. You will learn how to answer real world problems using the following probability distributions – Binomial, Poisson, Normal, Exponential and Chi-square. You will also learn the various ways of visualizing these distributions of real world problems. By the end of this project, you will become confident in understanding commonly used probability distributions through solving practical problems and you will strengthen your core concepts of data distributions using R programming language.

These distributions are widely used in day-to-day life of statisticians for hypothesis testing and drawing conclusions on a population from a small sample. Additionally, in the field of data science, statistical inferences use probability distribution of data to analyze or predict trend from data.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.8,22.0
Using the Natural Language API from Google Docs,https://www.coursera.org/learn/googlecloud-using-the-natural-language-api-from-google-docs-03efz,Data Science,Data Analysis,Google Cloud Training ,"We help millions of organizations empower their employees, serve their customers, and build what’s next for their businesses with innovative technology created in—and for—the cloud. Our products are engineered for security, reliability, and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping customers apply our technologies to create success.",,,,
Utilisation de RegexExtract et RegexMatch pour analyser les données avec Google Feuilles et RE2,https://www.coursera.org/learn/utilisation-de-regexextract-et-regexmatch-pour-analyser-les-donnees-avec-google,Data Science,Data Analysis,Hodroj Jamal,"Dans ce projet guidé d’une heure, vous apprendrez ce qu'est une expression régulière. Quelles sont les syntaxes à utiliser et comment les utiliser avec Google Sheets. A la fin de ce projet, vous allez être capable de rechercher et découper une chaîne de caractères de différentes façons.",,,,
Utilisation des méthodes de Deep Learning avec Python pour la prédiction boursière.,https://www.coursera.org/learn/prediction-bourse-python-lstm-streamlit,Data Science,Machine Learning,Azza Hamed,"#### ***A la fin de ce projet, vous serez en mesure de :***

*   Créer une application Web connectée à ***Yahoo Finance*** pour prédire la tendance de plusieurs actions boursières. 
*   Déployer une Application Web de Deep Learning à l’aide de ***Streamlit***.
*   Implémenter un réseau de neurones récurrents (***LSTM***).",,,,
Visual Analytics with Tableau,https://www.coursera.org/learn/dataviz-visual-analytics,Data Science,Data Analysis,"Suk S. Brar, M.B.A.","In this third course of the specialization, we’ll drill deeper into the tools Tableau offers in the areas of charting, dates, table calculations and mapping. We’ll explore the best choices for charts, based on the type of data you are using. We’ll look at specific types of charts including scatter plots, Gantt charts, histograms, bullet charts and several others, and we’ll address charting guidelines. We’ll define discrete and continuous dates, and examine when to use each one to explain your data.  You’ll learn how to create custom and quick table calculations and how to create parameters. We’ll also introduce mapping and explore how Tableau can use different types of geographic data, how to connect to multiple data sources and how to create custom maps.",49970.0,61928.0,4.6,1706.0
Visual Machine Learning with Yellowbrick,https://www.coursera.org/learn/machine-learning-visualization,Data Science,Machine Learning,Snehan Kekre,"Welcome to this project-based course on Visual Machine Learning with Yellowbrick. In this course, we will explore how to evaluate the performance of a random forest classifier on the Poker Hand data set using visual diagnostic tools from Yellowbrick. With an emphasis on visual steering of our analysis, we will cover the following topics in our machine learning workflow: feature analysis, feature importance, algorithm selection, model evaluation using regression, cross-validation, and hyperparameter tuning.

This course runs on Coursera's hands-on project platform called Rhyme. On Rhyme, you do projects in a hands-on manner in your browser. You will get instant access to pre-configured cloud desktops containing all of the software and data you need for the project. Everything is already set up directly in your internet browser so you can just focus on learning. For this project, you’ll get instant access to a cloud desktop with Python, Jupyter, Yellowbrick, and scikit-learn pre-installed.

Notes:
-  You will be able to access the cloud desktop 5 times. However, you will be able to access instructions videos as many times as you want.
- This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",3589.0,,4.7,71.0
Visualizaciones de Datos con Python utilizando Matplotlib,https://www.coursera.org/learn/visualizaciones-de-datos-con-python,Data Science,Data Analysis,Layla Scheli,"Python es un lenguaje fabuloso de programación, que nos ofrece muchas ventajas a la hora de utilizarlo como herramienta de Data Viz. En la actualidad, cada vez se requiere mas que los profesionales adquieran un nivel significativo en materia de visualizaciones de datos, para la creación de gráficos, dashboards, reportes, que ayuden a un negocio a tomar mejores decisiones con sus datos. 

Resulta importante mencionar, que este proyecto guiado tiene una dificultad “intermedia” para su desarrollo. Como objetivo principal al finalizar todas las capsulas de conocimiento y entregas de prácticas asociadas, se busca que los estudiantes puedan aprender los conceptos más relevantes e importantes para crear visualizaciones de datos en Python, utilizando las 3 librerías más utilizadas: Matplotlib, Seaborn y Plotly. 

También veremos cómo es el proceso de instalación de librerías utilizando el Anaconda Prompt.

Con los conocimientos adquiridos en este proyecto guiado, los estudiantes podrán crear sus propias visualizaciones de datos, de forma eficiente, efectiva y visualmente atractiva para la audiencia.",,,,
Visualización Avanzada de datos con Python,https://www.coursera.org/learn/visualizacion-avanzada-datos-python,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a visualizar los datos en Python. Para ello utilizarás librerías de visualización como Seaborn, Altair, Bokeh, Matplotlib, etc. Crearas múltiples tipos de gráficas, desde gráficos de líneas hasta heatmaps de correlación, y aprenderás a cuando utilizar cada tipo de gráfico
Gracias a ello, aprenderás las librerías más populares de visualización de datos y podrás crear tus propios proyectos de visualización.",,,,
Visualización de Datos con Python,https://www.coursera.org/learn/visualizacion-de-datos-con-python,Data Science,Data Analysis,Alex Aklson,"""Una imagen vale mas que mil palabras"". Todos estamos familiarizados con esta expresión. Se aplica especialmente cuando se trata de explicar la información obtenida del análisis de conjuntos de datos cada vez más grandes. La visualización de datos juega un papel esencial en la representación de datos tanto a pequeña como a gran escala.

Una de las habilidades clave de un científico de datos es la capacidad de contar una historia convincente, visualizando datos y hallazgos de una manera accesible y estimulante. Aprender a aprovechar una herramienta de software para visualizar datos también le permitirá extraer información, comprender mejor los datos y tomar decisiones más eficaces.

El objetivo principal de este curso de Visualización de datos con Python es enseñarle cómo tomar datos que a primera vista tienen poco significado y presentarlos en una forma que tenga sentido para las personas. Se han desarrollado varias técnicas para presentar datos visualmente, pero en este curso utilizaremos varias bibliotecas de visualización de datos en Python, a saber, Matplotlib, Seaborn y Folium.

OFERTA POR TIEMPO LIMITADO: La suscripción cuesta solo $ 39 USD por mes para acceder a materiales calificados y un certificado.",1579.0,12976.0,4.5,31.0
Visualización de Datos y Tableros con Excel y Cognos,https://www.coursera.org/learn/visualizacion-de-datos-y-tableros-con-excel-y-cognos,Data Science,Data Analysis,"Sandip Saha Joy, Steve Ryan, Kevin McFaul","Este curso cubre algunos de los primeros pasos en el desarrollo de visualizaciones de datos utilizando hojas de cálculo y tableros. Comienza el proceso de contar una historia con tus datos creando los muchos tipos de gráficos que están disponibles en hojas de cálculo como Excel. Explore las diferentes herramientas de una hoja de cálculo, como la importante función de pivote y la capacidad de crear cuadros de mando, y aprenda cómo cada uno tiene su propia propiedad única para transformar sus datos. Continúe adquiriendo una valiosa experiencia familiarizándose con la popular herramienta analítica - IBM Cognos Analytics - para crear cuadros de mando interactivos.

Al completar este curso, tendrá una comprensión básica del uso de las hojas de cálculo como herramienta de visualización de datos. Adquirirá la capacidad de crear eficazmente visualizaciones de datos, como gráficos o tablas, y comenzará a ver cómo desempeñan un papel fundamental en la comunicación de sus resultados de análisis de datos. Todo esto se puede lograr aprendiendo los fundamentos del análisis de datos con Excel y IBM Cognos Analytics, sin tener que escribir ningún código. Al final de este curso será capaz de describir las herramientas de cuadros de mando comunes utilizadas por un analista de datos, diseñar y crear un cuadro de mando en una plataforma de nube, y comenzar a elevar su nivel de confianza en la creación de visualizaciones de datos de nivel intermedio. 

A lo largo de este curso encontrará numerosos laboratorios prácticos y un proyecto final. Con cada laboratorio, gane experiencia práctica en la creación de gráficos básicos y avanzados, y luego continúe a través del curso y comience a crear cuadros de mando con hojas de cálculo y IBM Cognos Analytics. A continuación, terminará este curso creando un conjunto de visualizaciones de datos con IBM Cognos Analytics y creando un cuadro de mando interactivo que podrá compartir con sus compañeros, comunidades profesionales o posibles empleadores.

Este curso no requiere ningún análisis de datos previo, ni experiencia en informática. Todo lo que necesita para empezar es un conocimiento básico de informática, matemáticas de nivel secundario, acceso a un navegador web moderno como Chrome o Firefox, la capacidad de crear una cuenta de Microsoft para acceder a Excel para la Web, y una comprensión básica de las hojas de cálculo de Excel.",1544.0,6356.0,4.4,41.0
Visualización de datos con Seaborn,https://www.coursera.org/learn/visualizacion-datos-seaborn,Data Science,Data Analysis,Leire Ahedo,"Este proyecto es un curso práctico y efectivo para aprender a visualizar los datos con Python y la librería de Seaborn. Seaborn es una de las herramientas de visualización de datos más populares de Python y en este curso se aprenderá de forma práctica a utilizarla.
Crearas múltiples tipos de gráficas, desde gráficos de líneas hasta heatmaps de correlación, y aprenderás a cuando utilizar cada tipo de gráfico",,,,
Visualization for Data Journalism,https://www.coursera.org/learn/visualization-for-data-journalism,Data Science,Data Analysis,Margaret Ng,"While telling stories with data has been part of the news practice since its earliest days, it is in the midst of a renaissance. Graphics desks which used to be deemed as “the art department,” a subfield outside the work of newsrooms, are becoming a core part of newsrooms’ operation. Those people (they often have various titles: data journalists, news artists, graphic reporters, developers, etc.) who design news graphics are expected to be full-fledged journalists and work closely with reporters and editors. The purpose of this class is to learn how to think about the visual presentation of data, how and why it works, and how to doit the right way. We will learn how to make graphs like The New York Times, Vox, Pew, and FiveThirtyEight. In the end, you can share–embed your beautiful charts in publications, blog posts, and websites.

This course assumes you understand basic coding skills, preferably Python. However, we also provide a brief review on Python in Module 1, in case you want to refresh yourself on the basics and perform simple data analysis.",7456.0,7285.0,4.5,62.0
Visualization for Statistical Analysis,https://www.coursera.org/learn/visualization-for-statistical-analysis,Data Science,Data Analysis,Barsha Saha,"In this project you will learn about several visualization techniques and their importance for Statistical Analysis. The project demonstrates different plotting techniques, for example, histograms, scatter plots, box and whiskers plot, violin plot, bar plot, addition of regression line to scatter plot, and creating matrix of multiple plots. It also discusses the suitability of each plots according to the data type of the variables and illustrates multiple ways to achieve the desired plots efficiently. The project refers to 'Palmer Penguins' data set for the illustrative purpose.",,,,
Visualization of UK accidents using Plotly Express,https://www.coursera.org/learn/visualization-of-uk-accidents-using-plotly-express,Data Science,Data Analysis,Priya Jha,"In this 1.5-hour long project-based course, you will learn to Visualize the data of UK accidents using Plotly Express. This project gives detailed insights into United Kingdom (UK) long-term road accident trends between 2005 - 2014. We are going to visualize:
1. What is the rate of road accidents (i.e. the number of casualties) in the UK between 2005 - 2014?    
2. What is the rate of road accidents based on weekdays?                                                                                                                                                                                             
3. How is the distribution of accident severity in the UK, from 2005 - 2014?                                                                                                                                                                       5. Which speed limit is closely associated with road accidents in the UK, from 2005 - 2014?                                                                                                    6. Which road type has the highest rate of road accidents between 2005 - 2014?

By the end of this project, you will learn to set up Google Colab. You'll be able to download the UK accidents dataset directly from the Kaggle Platform on the Colab using Kaggle API. You'll visualize potential casualties due to road accidents, distribution of accident severity that may be either a serious accident, fatal accident, or a slight accident type. You will also visualize how speed limit is associated with the road accidents and see which road type has the highest rate of road accidents.

You must have a basic knowledge of Python Programming Language. You'll need a free Gmail account to complete this project.


Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Visualização de dados com o Python,https://www.coursera.org/learn/python-for-data-visualization-pt,Data Science,Data Analysis,Alex Aklson,"""Uma imagem vale mais que mil palavras"". Todos conhecemos essa expressão. Ela é válida principalmente quando se tenta explicar algum insight obtido através de análises de conjuntos de dados cada vez maiores. A visualização de dados tem um papel essencial na representação de dados pequenos e de larga escala.

Uma das principais habilidades de um cientista de dados é conseguir contar uma história envolvente, exibindo dados e resultados de uma maneira acessível e estimulante. Aprender como alavancar uma ferramenta de software para visualizar dados também permite que você extraia informações, entenda melhor os dados e tome decisões mais eficazes.

O principal objetivo deste curso de Visualização de Dados com o Python é ensinar a você como pegar dados que à primeira vista têm pouco significado e apresentá-los de um jeito que faça sentido para as pessoas. Várias técnicas foram desenvolvidas para a apresentação de dados visualmente, mas neste curso usaremos algumas bibliotecas de visualização de dados no Python, como a Matplotlib, a Seaborn e a Folium.

OFERTA POR TEMPO LIMITADO: a inscrição custa apenas US$ 39 por mês para ter acesso a materiais avaliados e a um certificado.",,,,
Visualizing & Communicating Results in Python with Jupyter,https://www.coursera.org/learn/codio-visualizing-and-communicating-results-in-python-with-jupyter,Data Science,Data Analysis,"Kevin Noelsaint, Anh Le","Code and run your first Python program in minutes without installing anything!

This course is designed for learners with limited coding experience, providing a foundation for presenting data using visualization tools in Jupyter Notebook. This course helps learners describe and make inferences from data, and better communicate and present data.

The modules in this course will cover a wide range of visualizations which allow you to illustrate and compare the composition of the dataset, determine the distribution of the dataset, and visualize complex data such as geographically-based data. Completion of Data Analysis in Python with pandas & matplotlib in Spyder before taking this course is recommended. 

To allow for a truly hands-on, self-paced learning experience, this course is video-free.

Assignments contain short explanations with images and runnable code examples with suggested edits to explore code examples further, building a deeper understanding by doing. You’ll benefit from instant feedback from a variety of assessment items along the way, gently progressing from quick understanding checks (multiple choice, fill in the blank, and un-scrambling code blocks) to small, approachable coding exercises that take minutes instead of hours. Finally, an accumulative lab at the end of the course will provide you an opportunity to apply all learned concepts within a real-world context.",3140.0,4671.0,,
Visualizing Data & Communicating Results in R with RStudio,https://www.coursera.org/learn/codio-visualizing-data-and-communicating-results-in-r-with-rstudio,Data Science,Data Analysis,Anh Le,"Code and run your first R program in minutes without installing anything!

This course is designed for learners with limited coding experience, providing foundational knowledge of data visualizations and R Markdown. The modules in this course cover different types of visualization models such as bar charts, histograms, and heat maps as well as R Markdown. Completion of the previous course (Data Analysis in R with RStudio & Tidyverse) in this specialization or similar experience is recommended.

To allow for a truly hands-on, self-paced learning experience, this course is video-free.

Assignments contain short explanations with images and runnable code examples with suggested edits to explore code examples further, building a deeper understanding by doing. You’ll benefit from instant feedback from a variety of assessment items along the way, gently progressing from quick understanding checks (multiple choice, fill in the blank, and un-scrambling code blocks) to small, approachable coding exercises that take minutes instead of hours. Finally, a cumulative lab at the end of the course will provide you an opportunity to apply all learned concepts within a real-world context.",,,,
Visualizing Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-visualize-data,Data Science,Data Analysis,"Carrie Wright, PhD, Shannon Ellis, PhD, Stephanie Hicks, PhD, Roger D. Peng, PhD","Data visualization is a critical part of any data science project. Once data have been imported and wrangled into place, visualizing your data can help you get a handle on what’s going on in the data set. Similarly, once you’ve completed your analysis and are ready to present your findings, data visualizations are a highly effective way to communicate your results to others. In this course we will cover what data visualization is and define some of the basic types of data visualizations.

In this course you will learn about the ggplot2 R package, a powerful set of tools for making stunning data graphics that has become the industry standard. You will learn about different types of plots, how to construct effect plots, and what makes for a successful or unsuccessful visualization.

In this specialization we assume familiarity with the R programming language. If you are not yet familiar with R, we suggest you first complete R Programming before returning to complete this course.",,2966.0,4.6,12.0
Visualizing Filters of a CNN using TensorFlow,https://www.coursera.org/learn/visualizing-filters-cnn-tensorflow,Data Science,Machine Learning,Amit Yadav,"In this short, 1 hour long guided project, we will use a Convolutional Neural Network - the popular VGG16 model, and we will visualize various filters from different layers of the CNN. We will do this by using gradient ascent to visualize images that maximally activate specific filters from different layers of the model.

We will be using TensorFlow as our machine learning framework. The project uses the Google Colab environment which is a fantastic tool for creating and running Jupyter Notebooks in the cloud, and Colab even provides free GPUs for your notebooks.

You will need prior programming experience in Python. This is a practical, hands on guided project for learners who already have theoretical understanding of Neural Networks, Convolutional Neural Networks, and optimization algorithms like gradient descent but want to understand how to use the TensorFlow to visualize various filters of a CNN.

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",2961.0,,4.5,53.0
Visualizing static networks with R,https://www.coursera.org/learn/visualizing-static-networks-r,Data Science,Data Analysis,You (Lilian) Cheng,"In daily life, our connections with family and friends form our social networks. Across the country, roads between different places form transportation networks. In research areas, collaborations among different researchers form research collaboration networks. Visible or invisible, networks exist in many aspects of our life. Being able to visualize networks will help us understand relationships embedded in complicated network information. 

In this project, learners will visualize various types of static networks of marvel heroes using the igraph package and base R plot functions. We can easily use static networks in reports and presentations. A good handle of this method will help learners, from both academia and industry, quickly express informative relationships and connections among different variables.",,,,
Wearable Technologies and Sports Analytics,https://www.coursera.org/learn/wearable-technologies,Data Science,Data Analysis,Peter F. Bodary,"Sports analytics now include massive datasets from athletes and teams that quantify both training and competition efforts.  Wearable technology devices are being worn by athletes everyday and provide considerable opportunities for an in-depth look at the stress and recovery of athletes across entire seasons.  The capturing of these large datasets has led to new hypotheses and strategies regarding injury prevention as well as detailed feedback for athletes to try and optimize training and recovery.

This course is an introduction to wearable technology devices and their use in training and competition as part of the larger field of sport sciences.  It includes an introduction to the physiological principles that are relevant to exercise training and sport performance and how wearable devices can be used to help characterize both training and performance.  It includes access to some large sport team datasets and uses programming in python to explore concepts related to training, recovery and performance.",1705.0,6175.0,4.8,19.0
Web of Data,https://www.coursera.org/learn/web-data,Data Science,Data Analysis,"Catherine Faron Zucker, Fabien Gandon, Olivier Corby","This MOOC – a joint initiative between EIT Digital, Université de Nice Sophia-Antipolis / Université Côte d'Azur, and INRIA - introduces the Linked Data standards and principles that provide the foundation of the Semantic web. You will learn how to publish, obtain and use structured data directly from the Web. Learning the principles, languages, and standards to exchange data on the Web will enable you to design and produce new applications, products, and services that leverage the volume and variety of data the Web holds.

We divided this course into four parts that cover the core technical skills and competencies you need to master to be able to use the Web as a space for giant structure data exchange:
•    in the first part, “Principals of a Web of Linked Data”: you will learn and practice the principles to publish and obtain data directly on the Web instead of Web pages; 
•    in the second part, “The RDF Data Model”: you will learn the standard data model for the Web and its syntaxes to publish and link data on the Web in your applications and services;
•    in the third part, “SPARQL Query Language”: you will learn how to directly query and access data sources on the Web and obtain structured data relevant to your activity and domain;
•    in the fourth and final part, “Integration of other Data Formats and Sources”: you will learn how the Web standards interact and interoperate with other data formats to allow the integration of a variety of data sources.

Each week alternates short videos and quizzes, as well as supplementary resources and forums to gradually progress through the different principles and standards.

After following this course successfully, you will have the skills to obtain focused and structured datasets from the Web that you can then use to augment your own datasets, enrich their dimensions, feed your applications, perform data mining, machine learning, and training, data analysis, AI processing and reasoning and other data management.",4996.0,6816.0,4.1,81.0
What is Data Science?,https://www.coursera.org/learn/what-is-datascience,Data Science,Data Analysis,"Rav Ahuja, Alex Aklson","Do you want to know why Data Science has been labelled as the sexiest profession of the 21st century? After taking this course you will be able to answer this question, and get a thorough understanding of what is Data Science, what data scientists do, and learn about career paths in the field. 

The art of uncovering the insights and trends in data has been around since ancient times. The ancient Egyptians used census data to increase efficiency in tax collection and they accurately predicted the flooding of the Nile river every year. Since then, people using data to derive insights and predict outcomes have carved out a unique and distinct field for the work they do. This field is data science.  

In today's world, we use Data Science to find patterns in data, and make meaningful, data driven conclusions and predictions.  

This course is for everyone, and teaches concepts like Machine Learning, Deep Learning, and Neural Networks  and how companies apply data science in business.  

You will meet several data scientists, who will share their insights and experiences in Data Science. By taking this introductory course, you will begin your journey into the thriving field that is Data Science!",676936.0,1186755.0,4.7,59351.0
"Where, Why, and How of Lambda Functions in Python",https://www.coursera.org/learn/where-why-and-how-of-lambda-functions-in-python,Data Science,Data Analysis,Ahmad Varasteh,"In this project we are going to learn about lambda expressions and it's application in python. We are going to start with what is Lambda expression and how we can define it, comparing lambda functions with regular functions in python and at the end we will learn how to use lambda functions for data manipulation and exploration in pandas. this guided-project is completely beginner friendly. you only need to have basic knowledge of python programming and some experience coding in Jupyter notebook environment.",,,,
Working with BigQuery,https://www.coursera.org/learn/working-with-bigquery,Data Science,Data Analysis,Ikechukwu Nigel Ogbuchi,"In this guided project, you will learn about working with Google's BigQuery which is allows easily work with and query massive datasets without worrying about time wasting or having the right infrastructure to analyze that data quickly. You will learn how to use big query to collect your data, query it with SQL and even do quick visualizations on it.",4838.0,,4.4,105.0
Working with SQL Stored Procedures using MySQL Workbench,https://www.coursera.org/learn/working-with-sql-stored-procedures-using-mysql-workbench,Data Science,Data Analysis,Arimoro Olayinka Imisioluwa,"Have you thought about creating a query that can be called several times to perform a routine task? Stored procedures offer this with a great advantage of efficiency. This project-based course, ""Working with SQL Stored Procedures using MySQL Workbench"" is intended for intermediate SQL users with some related experiences with SQL and who are willing to advance their knowledge and skills.

In this 2-hour project-based course, you will learn how to create stored procedures for different tasks including stored procedures with one input parameter, multiple input parameters, and an output parameter(s). This course is structured in a systematic way and very practical, where you get an option to practice as you progress. 

This project-based course is an intermediate-level course in SQL. Therefore, to get the most out of this project, it is essential to understand using SQL. Specifically, you should be able to write SQL JOIN statements and work with aggregate functions. If you are not familiar with these concepts, it will be helpful to complete my previous project titled ""Performing Data Aggregation using SQL Aggregate Functions"" and “Mastering SQL Joins.”

However, if you are comfortable with these SQL concepts, please join me on this wonderful ride! Let’s get our hands dirty!",,,,
Wrangling Data for Data Analysts with Python,https://www.coursera.org/learn/wrangling-data-for-data-analysts-with-python,Data Science,Probability and Statistics,Omnya Khaled,"By the end of this project, you will be able to analyze and data and answer three different questions by Data wrangling which is the process of gathering, selecting, and transforming data to answer an analytical question using Python. In this project, you will be able to gather the data for the whole year of 2020 and query it from the Quandl website using its API. It’s a free website for dummy data. You will be able to convert the returned JSON data into a Python dictionary. And you will be able to analyze this data to calculate the highest and lowest prices in this period, the biggest change based on High and Low price during this year, And finally, the average makeover during this year.

This guided project is for people in the field of business and data analysis. people who want to wrangle data and answer business questions and Clarify the use case and predict the relations between the source data. It provides you with important steps to be a data analyst. Moreover, it equips you with the knowledge in python's native data structures

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,,
Wrangling Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-data-wrangling,Data Science,Data Analysis,"Carrie Wright, PhD, Shannon Ellis, PhD, Stephanie Hicks, PhD, Roger D. Peng, PhD","Data never arrive in the condition that you need them in order to do effective data analysis. Data need to be re-shaped, re-arranged, and re-formatted, so that they can be visualized or be inputted into a machine learning algorithm. This course addresses the problem of wrangling your data so that you can bring them under control and analyze them effectively. The key goal in data wrangling is transforming non-tidy data into tidy data.

This course covers many of the critical details about handling tidy and non-tidy data in R such as converting from wide to long formats, manipulating tables with the dplyr package, understanding different R data types, processing text data with regular expressions, and conducting basic exploratory data analyses. Investing the time to learn these data wrangling techniques will make your analyses more efficient, more reproducible, and more understandable to your data science team.

In this specialization we assume familiarity with the R programming language. If you are not yet familiar with R, we suggest you first complete R Programming before returning to complete this course.",,3935.0,4.5,27.0
XG-Boost 101: Used Cars Price Prediction,https://www.coursera.org/learn/used-car-price-prediction-using-machine-learning-models,Data Science,Machine Learning,Ryan Ahmed,"In this hands-on project, we will train 3 Machine Learning algorithms namely Multiple Linear Regression, Random Forest Regression, and XG-Boost to predict used cars prices. This project can be used by car dealerships to predict used car prices and understand the key factors that contribute to used car prices.

By the end of this project, you will be able to: 

- Understand the applications of Artificial Intelligence and Machine Learning techniques in the banking industry
- Understand the theory and intuition behind XG-Boost Algorithm
- Import key Python libraries, dataset, and perform Exploratory Data Analysis.
- Perform data visualization using Seaborn, Plotly and Word Cloud.
- Standardize the data and split them into train and test datasets.   
- Build, train and evaluate XG-Boost, Random Forest, Decision Tree, and Multiple Linear Regression Models Using Scikit-Learn.
- Assess the performance of regression models using various Key Performance Indicators (KPIs).

Note: This course works best for learners who are based in the North America region. We’re currently working on providing the same experience in other regions.",,,4.6,34.0
¿Qué es la ciencia de datos?,https://www.coursera.org/learn/que-es-la-ciencia-de-datos,Data Science,Data Analysis,"Alex Aklson, Polong Lin","El arte de descubrir los conocimientos y las tendencias de los datos ha existido desde la antigüedad. Los antiguos egipcios usaron datos del censo para aumentar la eficiencia en la recaudación de impuestos y predijeron con precisión la inundación del río Nilo cada año. Desde entonces, las personas que trabajan en ciencia de datos han creado un campo único y distinto para el trabajo que realizan. Este campo es ciencia de datos. En este curso, conoceremos a algunos profesionales de la ciencia de datos y obtendremos una visión general de lo que es hoy la ciencia de datos.",5496.0,84789.0,4.7,259.0
Анализ данных с использованием Python,https://www.coursera.org/learn/data-analysis-with-python-ru,Data Science,Data Analysis,Joseph Santarcangelo,"Научитесь применять Python для анализа данных. На этом курсе вы перейдете от основ Python к изучению различных типов данных. Вы узнаете, как подготовить данные к анализу, выполнить простой статистический анализ, визуализировать данные, cпрогнозировать тенденции на основе данных и многое другое!

Рассматриваемые темы:

1) Импорт наборов данных
2) Очистка данных
3) Работа с кадрами данных
4) Обобщение данных
5) Построение регрессионных моделей машинного обучения
6) Создание конвейеров данных

Курс «Анализ данных на Python» включает лекции, лабораторные работы и практические задания. Курс состоит из нескольких частей:

Библиотеки для анализа данных: вы научитесь использовать библиотеки Pandas, Numpy и Scipy на тестовом наборе данных. Вы познакомитесь с Pandas, библиотекой с открытым исходным кодом, и научитесь использовать ее для загрузки, обработки, анализа и визуализации интересных наборов данных. Затем мы рассмотрим еще одну библиотеку с открытым исходным кодом, scikit-learn, используем некоторые из входящих в нее алгоритмов машинного обучения для создания интеллектуальных моделей и построения интересных прогнозов.

Пройдя этот курс и получив сертификат Coursera, вы также можете получить цифровой значок IBM.

ОГРАНИЧЕННОЕ ПРЕДЛОЖЕНИЕ: приобретите подписку всего за 39 долл. США в месяц и получите доступ к упорядоченным по уровням материалам и сертификат по окончании курса.",2984.0,9235.0,,
Базы данных и SQL в обработке и анализе данных,https://www.coursera.org/learn/sql-data-science-ru,Data Science,Data Analysis,"Hima Vasudevan, Rav Ahuja","Огромное количество данных в мире хранится в базах данных. Для управления данными, в том числе для извлечения данных, чаще всего используют язык структурированных запросов SQL (Structured Query Language). Если вы хотите стать аналитиком данных, то вам необходимы практические знания в области баз данных и SQL.

Цель этого курса — познакомиться с концепциями реляционных баз данных, изучить основы языка SQL и научиться применять эти знания на практике. Также вы научитесь применять язык SQL для обработки и анализа данных.

Этот курс ориентирован на практическое применение. Поэтому вы будете работать с реальными базами и наборами данных, использовать реальные инструменты обработки и анализа данных Вы создадите экземпляр базы данных в облаке. Выполняя лабораторные работы, вы попрактикуетесь в создании и выполнении SQL-запросов. Вы также узнаете, как получить доступ к базам данных из среды Jupyter с помощью языков SQL и Python.

Первоначальные знания о базах данных, SQL, Python и программировании не требуются.

Любой желающий может пройти этот курс бесплатно. Если вы пройдете этот курс и получите сертификат Coursera, вы также можете получить цифровой значок IBM.

ОГРАНИЧЕННОЕ ПРЕДЛОЖЕНИЕ: приобретите подписку всего за 39 долл. США в месяц и получите доступ к упорядоченным по уровням материалам и сертификат по окончании курса.",16033.0,20984.0,3.9,68.0
Введение в анализ данных с помощью Excel,https://www.coursera.org/learn/excel-data-analysis-ru,Data Science,Data Analysis,Sharad Borle,"Использование Excel широко распространено в отрасли. Это очень мощный инструмент анализа данных, и почти все крупные и малые предприятия используют Excel в своей повседневной работе. Это вводный курс по использованию Excel, который предоставляет знания о работе в Excel с целью ее использования для более продвинутых тем деловой статистики позже. Курс разработан с учетом двух типов учащихся — тех, у кого очень мало функциональных знаний о Excel, и тех, кто регулярно использует Excel, но на периферийном уровне и хочет развить свои навыки. Курс включает в себя базовые операции, такие как импорт данных в Excel с использованием различных форматов данных, организацию и управление данными, а также некоторые более продвинутые функции Excel. В целом, знакомство с функциями Excel проходит на базе простых для понимания примеров, которые демонстрируются таким образом, чтобы учащимся не составило труда понять и применить их.

Для успешного прохождения курсов учащиеся должны иметь доступ к Microsoft Excel 2010 или более поздней версии для Windows. 
________________________________________
НЕДЕЛЯ 1
Модуль 1: Введение в электронные таблицы
В этом модуле вы познакомитесь с использованием электронных таблиц Excel и различными базовыми функциями данных Excel.

Рассматриваемые темы включают:
•	Импорт данных в Excel с использованием различных форматов
•	Основные функции в Excel, арифметические и различные логические функции
•	Форматирование строк и столбцов
•	Использование формул в Excel и их копирование с использованием абсолютных и относительных ссылок
________________________________________
НЕДЕЛЯ 2
Модуль 2: Функции электронной таблицы для организации данных
В этом модуле представлены различные функции Excel для организации и запроса данных. Участники знакомятся с функциями ЕСЛИ, ВПР и ГПР и вложенной функцией ЕСЛИ в Excel. 

Рассматриваемые темы включают:
•	Функция ЕСЛИ и вложенная функция ЕСЛИ
•	ВПР и ГПР
•	Функция СЛУЧМЕЖДУ
________________________________________
НЕДЕЛЯ 3
Модуль 3: Введение в фильтры, сводные таблицы и диаграммы
В этом модуле представлены различные возможности фильтрации данных в Excel. Вы узнаете, как настраивать фильтры для избирательного доступа к данным. Также объясняется очень мощный инструмент обобщения данных, сводная таблица, и мы начинаем вводить функцию построения диаграмм в Excel.

Рассматриваемые темы включают:
•	ВПР и рабочие листы
•	Фильтрация данных в Excel
•	Использование сводных таблиц с категориальными и числовыми данными
•	Введение в возможности построения диаграмм в Excel
________________________________________
НЕДЕЛЯ 4
Модуль 4: Расширенные возможности построения графиков и диаграмм
В этом модуле рассматриваются различные продвинутые методы построения графиков и диаграмм, доступные в Excel. Начиная с различных линейных, столбчатых и круговых диаграмм, мы представляем сводные диаграммы, точечные графики и гистограммы. Вы научитесь понимать эти различные диаграммы и начнете строить их самостоятельно.

Рассматриваемые темы включают:
•	Линейные, столбчатые и круговые диаграммы
•	Сводные диаграммы
•	Точечные графики
•	Гистограммы",1596.0,5630.0,,
Визуализация данных с помощью Python,https://www.coursera.org/learn/python-for-data-visualization-ru,Data Science,Data Analysis,Alex Aklson,"«Лучше один раз увидеть, чем сто раз услышать». Всем нам знакомо это выражение. Оно справедливо и в случае, когда нужно объяснить выводы, полученные при анализе огромных наборов данных. Визуализация данных играет важную роль в представлении как мелких, так и крупных данных.

Один из важнейших навыков аналитика данных — способность убедительно преподносить выводы, визуализируя данные и результаты в доступном и позитивном виде. Научитесь использовать программные инструменты для визуализации данных, и это поможет извлекать информацию, лучше понимать данные и принимать более разумные решения.

Основная задача этого курса «Визуализация данных с помощью Python» — научить выбирать данные, которые на первый взгляд кажутся малозначимыми, и представлять их в том виде, в котором они будут иметь смысл. Для презентации данных существует множество методик, но в этом курсе мы будем использовать несколько библиотек визуализации на Python, в частности, Matplotlib, Seaborn и Folium.

ОГРАНИЧЕННОЕ ПРЕДЛОЖЕНИЕ: приобретите подписку всего за 39 долл. США в месяц и получите доступ к упорядоченным по уровням материалам и сертификат по окончании курса.",,,,
Заключительный курс по теме «Прикладная наука о данных»,https://www.coursera.org/learn/applied-data-science-capstone-ru,Data Science,Data Analysis,Alex Aklson,"Этот заключительный курс позволит получить представление о том, как аналитики данных работают с данными в реальных условиях. 

Вы узнаете о данных о местоположении и различных поставщиках данных о местоположении, таких как Foursquare. Изучите принцип обращения REST API к Foursquare API для получения данных о местах проведения мероприятий в различных районах в любой стране мира. Также вы узнаете о творческом подходе, применяемом в случае недоступности данных и позволяющем выполнить извлечение данных из Интернета и посредством анализа HTML-кода. Вы будете применять Python и библиотеку Pandas для работы с данными, что поможет вам усовершенствовать навыки изучения и анализа данных. 

В конце вы сможете пользоваться библиотекой Folium для улучшения карт геопространственных данных и для предоставления своих результатов и выводов.

Если вы пройдете этот курс и получите сертификат Coursera, вы также можете получить цифровой значок IBM. 

ОГРАНИЧЕННОЕ ПРЕДЛОЖЕНИЕ: приобретите подписку всего за 39 долл. США в месяц и получите доступ к упорядоченным по уровням материалам и сертификат по окончании курса.",,,,
Машинное обучение с использованием Python,https://www.coursera.org/learn/machine-learning-with-python-ru,Data Science,Machine Learning,"SAEED AGHABOZORGI, Joseph Santarcangelo","Этот курс посвящен основам машинного обучения с использованием распространенного языка программирования — Python. \Курс включает два основных раздела.

Во-первых, вы узнаете о целях и задачах машинного обучения и способах применения этой технологии для решения реальных задач.
Во-вторых, вы получите общее представление об отличиях между свободным и контролируемым машинным обучением, оценке моделей и алгоритмах машинного обучения.

В рамках этого курса вы рассмотрите возможности применения технологий машинного обучения на практике и убедитесь в том, что они влияют на окружающий мир больше, чем вы могли себе представить!

Для этого вам понадобится посвятить курсу всего несколько часов в неделю на протяжении нескольких недель.
1) Новые навыки для резюме: регрессия, систематизация, кластеризация, Scikit-learn и SciPy
2) Новые проекты для вашего портфолио, в том числе в сферах диагностики рака, прогнозирования экономических тенденций, прогнозирования оттока клиентов, рекомендательных систем и многое другое.
3) Сертификат о прохождении курса «Машинное обучение», подтверждающий вашу квалификацию который можно предъявлять физически и виртуально, например добавить к профилю в LinkedIn и других социальных сетях.

Если вы пройдете этот курс и получите сертификат Coursera, то также получите цифровой значок IBM.",,3903.0,,
Методология обработки и анализа данных,https://www.coursera.org/learn/data-science-methodology-ru,Data Science,Data Analysis,"Alex Aklson, Polong Lin","Несмотря на то, что в последние десятилетия существенно выросли вычислительные возможности и доступ к данным, наша способность использовать эти данные для принятия решений либо снижается, либо не используется с максимальной эффективностью. Чаще всего у нас отсутствует глубокие знания о задаваемых вопросах и том, как правильно применять данные для решения определенной проблемы.

У этого курса всего одна задача, и она заключается в том, чтобы познакомить вас с методами, которые можно использовать при обработке и анализе данных, чтобы убедиться в том, что используемые для решения проблемы данные правильно подобраны и обработаны для поиска ответа на конкретный вопрос.

Соответственно, из этого курса вы узнаете о:
- основных этапах решения проблемы, связанной с обработкой и анализом данных;
- основных этапах обработки и анализа данных: от формулирования проблемы конкретной компании или исследования до сбора и анализа данных, построения модели и обработки обратной связи после внедрения модели;
- том, как размышляют аналитики данных.

ВРЕМЕННАЯ АКЦИЯ: приобретите подписку всего за 39 долл. США в месяц и получите доступ к отсортированным материалам и сертификат.",,2090.0,,
Нейронные сети и глубокое обучение,https://www.coursera.org/learn/neural-networks-deep-learning-ru,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Этот курс поможет вам ознакомиться с новейшими технологиями искусственного интеллекта. Инженеры по глубокому обучению сейчас широко востребованы, освойте методы глубокого обучения и перед вами откроются многочисленные карьерные возможности. Глубокое обучение также можно считать новой «сверхспособностью», с помощью которой вы будете строить такие ИИ-системы, которые невозможно было создать еще пару лет назад.

В этом курсе вы познакомитесь с основами глубокого обучения. После завершения курса вы: 
- будете иметь представление об основных технологических тенденциях, движущих вперед область глубокого обучения;  
- сможете строить, обучать и применять полносвязные глубокие нейронные сети;  
- будете знать, как реализуются эффективные (векторизованные) нейросети;  
- получите представление о ключевых параметрах архитектуры нейронной сети 

Данный курс также позволяет разобраться, как в реальности действует глубокое обучение, а не просто дает его поверхностное описание. Поэтому после завершения курса вы сможете применять глубокое обучение в собственных приложениях. Если вы ищете работу в области ИИ, то после прохождения данного курса вы также сможете ответить на простые вопросы в ходе собеседования.

Это первый курс специализации «Глубокое обучение».",1855.0,5067.0,,
Повышение эффективности глубоких нейросетей,https://www.coursera.org/learn/deep-neural-network-ru,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Этот курс научит вас «магии» повышения эффективности глубокого обучения. Вы изучите сложный механизм работы глубокого обучения, узнаете, какие параметры влияют на его эффективность и сможете систематически получать хорошие результаты. Также вы изучите TensorFlow. 

По прошествии трех недель вы:  
— освоите передовые методы создания  приложений для глубокого обучения;
— научитесь эффективно использовать распространенные «хитрости» работы с нейросетями, включая инициализацию, L2-регуляризацию и регуляризацию методом исключения, пакетную нормализацию и проверку градиента;
— научитесь выполнять и применять различные алгоритмы оптимизации, такие как мини-пакетный градиентный спуск, моменты, RMSprop и Adam, а также проверять их сходимость;
— освоите передовые методы составления наборов данных для обучения, разработки и тестирования, а также анализа предвзятости и отклонений;
— сможете реализовывать нейронную сеть в TensorFlow.

 Это второй курс специализации «Глубокое обучение».",,,,
Последовательные модели,https://www.coursera.org/learn/nlp-sequence-models-ru,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Данный курс научит вас строить модели естественных языков, звуков и других последовательных данных. Благодаря глубокому обучению последовательные алгоритмы сегодня работают в разы лучше, чем ещё два года назад. Это открывает широчайший спектр возможностей применения алгоритмов в распознавании речи, синтезе музыки, чат-ботах, машинном переводе, понимании естественных языков и во многом другом.

Вы научитесь:
— строить и обучать рекуррентные нейронные сети (РНС, RNN), а также широко используемые управляемые рекуррентные блоки (УРБ, GRU) и долгую краткосрочную память (ДКП, LSTM);
— применять последовательные модели в задачах по обработке естественного языка, включая синтез текста;
— применять модели последовательностей к звуковой информации, например для распознавания речи или синтеза музыки.

Это пятый и заключительный курс специализации «Глубокое обучение».

 Задача по программированию машинного перевода с глубоким обучением, содержащаяся в этом курсе, разработана deeplearning.ai совместно с партнером — Институтом глубокого обучения NVIDIA (DLI). У вас будет возможность создать проект по глубокому обучению с современным, актуальным для индустрии содержанием.",,,,
Сверточные нейронные сети,https://www.coursera.org/learn/convolutional-neural-networks-ru,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","Этот курс научит вас строить сверточные нейронные сети и использовать их для обработки изображений. Благодаря глубокому обучению машинное зрение сегодня работает намного лучше, чем всего лишь два года назад, и это позволяет использовать его в самых разных отраслях, начиная от безопасного автономного вождения и точного распознавания лиц и заканчивая автоматической интерпретацией рентгеновских снимков. 

В рамках курса вы:

— научитесь строить сверточные нейронные сети, включая их самые современные виды, такие как остаточные сети;
— узнаете, как применять сверточные сети в задачах визуального обнаружения объектов и распознавания изображений;
— узнаете, как использовать нейронную передачу стиля для создания изображений;
— научитесь применять алгоритмы к изображениям, видео и другим 2D- и 3D-данным.

Это четвертый курс специализации «Глубокое обучение».",,1975.0,,
Структурирование проектов по машинному обучению,https://www.coursera.org/learn/machine-learning-projects-ru,Data Science,Data Analysis,"Andrew Ng, Younes Bensouda Mourri, Kian Katanforoosh","Из этого курса вы узнаете, как создавать успешные проекты по машинному обучению. Вы — лидер команды по внедрению ИИ или хотите им стать? Этот курс научит вас ставить правильные цели для своей команды.

Многое из содержимого этого курса никогда не предлагалось в других образовательных проектах и наработано на основе моего опыта построения и внедрения многочисленных проектов. В настоящий курс также включены два тренажера, которые позволят вам отработать принятие решений в ходе организации проектов по машинному обучению. Тренажеры дадут вам опыт, на получение которого иначе могло бы потребоваться несколько лет работы в машинном обучении.

После двух недель занятий вы: 
— поймете, как диагностировать ошибки в системах машинного обучения;
— научитесь выделять наиболее перспективные направления для снижения количества ошибок;
— получите знания о сложных настройках машинного обучения, таких как несоответствие наборов для обучения тестовым наборам, и сравнении показателей машины с показателями человеческого уровня;
— узнаете, как применять сквозное обучение (end-to-end learning), перенос обучения (transfer learning) и многозадачное обучение (multi-task learning).

Я видел, как команды специалистов впустую тратили месяцы и даже годы работы потому, что не понимали принципы, излагаемые в этом курсе. Я надеюсь, что этот двухнедельный курс сэкономит месяцы вашего времени.

Он независим от других, и для его прохождения нужны только базовые знания в области машинного обучения. Это третий курс специализации «Глубокое обучение».",,5952.0,,
Что такое обработка и анализ данных?,https://www.coursera.org/learn/what-is-datascience-ru,Data Science,Data Analysis,"Rav Ahuja, Alex Aklson","Люди с древних времен занимаются поиском закономерностей и тенденций в данных. Древние египтяне использовали данные переписи для более эффективного сбора налогов, а также из года в год точно предсказывали разлив Нила. С тех времен люди, занимающиеся анализом данных, сделали эту сферу деятельности отдельной уникальной наукой. И эта наука называется «обработка и анализ данных». В этом курсе мы познакомимся с несколькими специалистами по обработке и анализу данных и разберемся, что представляет собой эта наука в современном мире.",,,,
أساسيات تحليل البيانات باستخدام بايثون وباندا,https://www.coursera.org/learn/data-analysis-python-pandas-ar,Data Science,Data Analysis,Amani Abbas,"في هذه الدورة التدريبية القائمة على المشروع والتي تستغرق ساعة ونصف تقريباً ستتعلم كيفية تحليل البيانات باستخدام لغة البرمجة بايثون. ستتعرف على مكتبات تحليل البيانات والتعامل مع الأرقام في بايثون، كما ستتعلم كيفية تنظيف البيانات وترتيبها لتهيئتها للتحليل وكيفية الحصول على إجابات للأسئلة المتعلقة بالبيانات التي لديك.

سنقوم باستخدام جوبيتر نوتبوك لكتابة الأكواد وتنفيذها والحصول على رسومات بيانية تمثل البيانات.

لا يوجد متطلبات سابقة للبدء بالمشروع حيث أن هذا المشروع هو للمبتدئين تماما في تحليل البيانات باستخدام بايثون وسيكون هناك شرح مفصل لكل خطوة من الخطوات التي ستقوم بها لإتمامه.",,,,
أساسيات تحليل البيانات باستخدام جداول بيانات جوجل,https://www.coursera.org/learn/data-analysis-google-sheets-ar,Data Science,Data Analysis,Amani Abbas,"في هذه الدورة التدريبية القائمة على المشروع والتي تستغرق ساعة واحدة، ستتعلم أساسيات تحليل البيانات باستخدام جداول بيانات جوجل - Google sheets.

سنتعرف على معنى تحليل البيانات كما سنتعرف على كيفية التعامل مع جداول بيانات جوجل، سنقوم بالتطبيق العملي لبعض أنواع تحليل البيانات كالتحليل الإحصائي والتحليل الاستكشافي، سنقوم باستخدام الأدوات والدوال التي توفرها جداول بيانات جوجل، ثم سنقوم بتمثيل البيانات من خلال استخدام الرسوم البيانية.

هذه الدورة للمبتدئين تماماً في مجال تحليل البيانات ولا يتطلب وجود خبرة سابقة في استخدام جداول بيانات جوجل.",1758.0,,4.7,62.0
أساسيات مايكروسوفت آوتلوك | Microsoft Outlook Fundamentals,https://www.coursera.org/learn/microsoft-outlook-fundamentals,Data Science,Machine Learning,"Alfaisal.KLD, Raed Sughayyar","مايكروسوفت آوتلوك (Microsoft Outlook) هو برنامج لإدارة المعلومات الشخصية والتي تتضمن البريد الإلكتروني، وإدارة المهام، والتقويم، وتدوين الملاحظات، وإدارة جهات الاتصال وغيرها، وهو جزء من مجموعة (Microsoft Office)  التي تضم برامج أخرى مثل وورد (Word) و إكسل (Excel) وبوربوينت (PowerPoint) وغيرها، ولكل برنامج وظائفه ومهامه المختلفة.

تهدف هذه الدورة إلى رفع المستوى المعرفي للمتدربين لمواكبة سوق العمل فيما يتعلق باستخدام برنامج (Outlook) من خلال تعريفهم بالأدوات الأساسية في البرنامج وكيفية استخدامها، بحيث تمكنهم من إدارة حياتهم الشخصية بشكلٍ عام والمهنية بشكلٍ خاص بطريقة أكثر احترافية وتنظيم.

هذه الدورة هي دورة تمهيدية؛ فهي تلقي الضوء على أساسيات الموضوع بشكل عام بهدف التعريف به وبمحاوره الأساسية التي يجب الإلمام بها.

إذا كنت من المهتمين بإتقان أساسيات مايكروسوفت آوتلوك أو كان مجال عملك يتطلب إتقان تلك المهارات وتوظيفها في سياق عملك، فهذه الدورة ستكون مثالية لإغناء خبرتك وتطوير مهاراتك في فهم وتحليل وذلك بشكل فعال ومؤثر.

حيث ستزودك هذه الدورة باطلاع واسع ودقيق على مجموعة من المحاور المتعلقة بهذا الموضوع، مثل: التعرف على إدارة جهات الاتصال وإضافة جهات اتصال جديدة مع بيانات الاتصال كاملة لكل جهة، تعلم إضافة المهام والملاحظات وتعديلها، شرح استخدامات التقويم وكيفية إنشاء اجتماع أو دعوة، التعرف على إرسال الرسائل الإلكترونية والرد عليها وإعادة توجيهها بنجاح، شرح الفرق بين كل إصدار من إصدارات آوتلوك المختلفة، تحديد أجزاء برنامج آوتلوك ووظيفة كل جزء.",,3389.0,,
إنشاء جداول قاعدة البيانات باستخدام SQL,https://www.coursera.org/learn/iinsha-jadawil-qaeidat-albayanat-sql,Data Science,Data Analysis,Yasmine Elfares,"في نهاية هذا المشروع ، سوف تكون قادرًا على تطبيق ""SQL Basic Syntax"" لإنشاء database tables. بصفتك مبرمج databases مبتدئ ، ستتمكن من إنشاء files SQL وإنشاء databases وأخيراً إنشاء tables لتمثيل علاقات database.

من خلال هذا المشروع ، سننشئ قاعدة بيانات كاملة لشركة 'Nike' بما في ذلك موظفيها.


سيساعدك فهم قواعد البيانات على التقدم  في العمل لأن قواعد البيانات ضرورية لأي منظمة لأنها تعمل على توصيل المعلومات بسهولة وكفاءة.",,,,
اساسيات قواعد البيانات باستخدام Airtable,https://www.coursera.org/learn/database-fundamentals-airtable,Data Science,Data Analysis,Mohammed Al M.,في هذا المشروع التفاعلي، ستقوم بانشاء حساب ايرتيبل وتخلق جداول مكونة من أنواع حقول مختلفة وتنشئ علاقات لربط الجداول ببعضها، وتتابع التحديثات في قاعدة بياناتك، وتخصص مظهرها باستخدام التصفية والتجميع والتلوين وأدوات أخرى، كما ستضاعف امكانيات قاعدة بياناتك باستخدام التطبيقات والوظائف التلقائية، وتخلق مشاهد مختلفة لقاعدة بياناتك لمشاركتها مع مستخدمين اخرين!,,,,
الأسس: البيانات، البيانات في كل مكان,https://www.coursera.org/learn/foundations-data-data-everywhere-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة التدريبية الأولى في شهادة تحليلات البيانات من Google. ستزودك هذه الدورات بالمهارات التي تحتاجها للتقدم لوظائف محلل البيانات على المستوى التمهيدي. تحتاج المؤسسات من جميع الأنواع إلى محللي بيانات لمساعدتها على تحسين عملياتها، وتحديد الفرص والاتجاهات، وإطلاق منتجات جديدة، واتخاذ قرارات مدروسة. في هذه الدورة التدريبية، ستتعرف على عالم تحليلات البيانات من خلال المناهج العملية التي طورتها Google. تغطي المواد التي تمت مشاركتها الكثير من موضوعات تحليلات البيانات الرئيسية، وهي مصممة لتوفر لك نظرة عامة على ما سيأتي في شهادة تحليلات البيانات من Google. سيقوم محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، سوف:
- تكتسب فهم للممارسات والعمليات التي يستخدمها محلل بيانات مبتدئ أو مشارك في وظيفتهم اليومية. 
- تتعرّف على المهارات التحليلية الأساسية (تنظيف البيانات، وتحليل البيانات، ومؤثرات عرض البيانات) والأدوات (جداول البيانات، SQL، برمجة R، Tableau) التي يمكنك إضافتها إلى صندوق أدواتك الاحترافي. 
- تكتشف مجموعة متنوعة من المصطلحات والمفاهيم ذات الصلة بدور محلل البيانات المبتدئ، مثل دورة حياة البيانات وعملية تحليل البيانات. 
- تقيمّ دور التحليلات في النظام الشامل للبيانات. 
- تقوم بإجراء تقييم ذاتي للتفكير التحليلي. 
- تكتشف فرص العمل المتاحة لك عند الانتهاء من البرنامج، وتتعرّف على أفضل الممارسات في البحث عن وظيفة.",,23573.0,4.7,16.0
التعلّم الآلي باستخدام لغة بايثون,https://www.coursera.org/learn/machine-learning-with-python-ar,Data Science,Machine Learning,"SAEED AGHABOZORGI, Joseph Santarcangelo","تتعمق هذه الدورة في تناول أساسيات التعلم الآلي باستخدام لغة برمجة سهلة التعلم ومعروفة، ألا وهي لغة بايثون. 

وسنتطرق في هذه الدورة إلى عنصرين رئيسيين:
الأول، ستتعرف على الغرض من التعلم الآلي وأماكن تطبيقه في الواقع. 
وثانيًا، سوف نلقِ نظرة عامة على موضوعات التعلم الآلي، مثل التعلم المُوجّه والتعلم غير المُوجّه وتقييم النماذج وخوارزميات التعلم الآلي. 

سنتتدرب في هذه الدورة على أمثلة واقعية للتعلم الآلي ونتعرف على كيفية تأثير ذلك على المجتمع بطرق ربما لم تخطر على بالك!\n\nلتخصص فقط بضع ساعات أسبوعيًا خلال الأسابيع القليلة المقبلة، وإليك ما سوف تتعلمه.
1)مهارات جديدة تُضاف إلى سيرتك الذاتية، مثل الانحدار والتصنيف والتجميع العنقودي ومكتبة ساي كيت ليرن
 ومكتبة سي باي
2) مشاريع جديدة يمكنك إضافتها إلى ملفك الشخصي، ومنها الكشف عن السرطان والتنبؤ بالاتجاهات الاقتصادية والتنبؤ بانسحاب العملاء ومحركات التوصية وغير ذلك الكثير.
3) وشهادة في التعلم الآلي لإثبات كفاءتك وتقديمها إلى أي مكان ترغب في التقدم إليه عبر الإنترنت أو خلافه، مثل الملفات الشخصية على لينكد إن ووسائل التواصل الاجتماعي.

فإذا اخترت المشاركة في هذه الدورة والحصول على شهادة دورة كورسيرا، فستحصل أيضًا على شارة رقمية من IBM عند إتمامك للدورة بنجاح.",,,,
الحصول على البيانات وتنظيفها,https://www.coursera.org/learn/data-cleaning-ar,Data Science,Data Analysis,"Jeff Leek, PhD, Roger D. Peng, PhD, Brian Caffo, PhD","قبل أن تتمكن من العمل مع البيانات، يجب أن تحصل على بعضها. ستتناول هذه الدورة التدريبية الطرق الأساسية التي يمكن من خلالها الحصول على البيانات. ستتناول الدورة التدريبية كيفية الحصول على بيانات من الويب ومن واجهات برمجة التطبيقات ومن قواعد البيانات ومن الزملاء بتنسيقات مختلفة. كما أنها ستتناول أساسيات تنظيف البيانات وكيفية جعل البيانات ""مُرتبة"". فالبيانات المرتبة تزيد من سرعة مهام تحليل البيانات النهائية. وكذلك، ستتناول الدورة مكونات مجموعة بيانات كاملة بما في ذلك البيانات الأولية وتعليمات المعالجة وكتب التعليمات البرمجية والبيانات التي تمت معالجتها. ستتناول الدورة التدريبية الأساسيات اللازمة لجمع البيانات وتنظيفها ومشاركتها.",,,,
الشبكات العصبونية الالتفافية,https://www.coursera.org/learn/convolutional-neural-networks-ar,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri",سيُعلمك هذا المساق طريقة إعداد الشبكات العصبونية الالتفافية وتطبيقها على بيانات الصورة. وبفضل التعلم المتعمق، تعمل الرؤية الحاسوبية على نحوٍ أفضل كثيرًا مما كانت عليه في العامين السابقين وأتاح هذا الكثير من التطبيقات الحالية التي تمتد بدءًا من التحكم الذاتي الآمن حتى التعرف على الوجه بصورةٍ دقيقة وحتى القراءة الأوتوماتيكية للصور الإشعاعية. ستُصبح مُلِم بطريقة إعداد شبكة عصبونية التفافية، بما في ذلك التغييرات التي طرأت في الآونة الأخيرة من قبيل الشبكات المتبقية. وستتعرف على طريقة تطبيق الشبكات الالتفافية على وظائف الكشف والتعرف المرئيين. وستتعرف على طريقة استعمال خاصية نقل النمط العصبي لإنتاج الأعمال الفنية. وسيُصبح بوسعك تطبيق هذه الخوارزميات على مجموعة مختلفة من الصور ومقاطع الفيديو وغيرها من المعطيات ثنائية الأبعاد وثلاثية الأبعاد. ويُمثل هذا المساق الرابع من نوعه في تخصص التعلم المتعمق.,,,,
الشبكات العصبية والتعلم العميق,https://www.coursera.org/learn/neural-networks-deep-learning-ar,Data Science,Machine Learning,"Andrew Ng, Younes Bensouda Mourri","إذا كنت ترغب في اختراق عالم الذكاء الاصطناعي شديد التطور، فسوف تساعدك هذه الدورة التدريبية على تحقيق ذلك. إن مهندسي التعلم العميق مطلوبون بشدة، كما أن إتقان التعلم العميق يمنحك العديد من فرص المستقبل المهني الجديدة. إن التعلم العميق يعد بمثابة ""قوة عظمى"" جديدة كذلك تساعدك على بناء أنظمة الذكاء الاصطناعي التي لم يكن بالإمكان الوصول إليها منذ عدة سنوات قليلة مضت. 

في هذه الدورة التدريبية، سوف تتعرف على أسس التعلم العميق. عندما تنتهي من هذا الفصل الدراسي، سيكون بإمكانك ما يلي:
- فهم اتجاهات التقنيات الرئيسية التي تدفع التفكير العميق قدمًا
- التمكن من بناء شبكات عصبية متصلة بشكل كامل وتتسم بالعمق وتدريب تلك الشبكات وتطبيقها 
- إدراك كيفية تنفيذ الشبكات العصبية الفعالة (الموجهة) 
- إدراك المعاملات الرئيسية في بنية الشبكة العصبية 

كما تعلمك هذه الدورة التدريبية كذلك كيف يعمل التعلم العميق بشكل فعلي كذلك، بدلاً من تقديم وصف سريع أو سطحي فقط. لذا، بعد إكمال هذه الدورة التدريبية، سوف تكون قادرًا على تطبيق التعلم العميق على التطبيقات الخاصة بك. إذا كنت تبحث عن وظيفة في مجال الذكاء الاصطناعي، بعد إتمام هذه الدورة التدريبية، سوف تكون قادرًا كذلك على الإجابة على أسئلة المقابلات الشخصية الأساسية. 

هذه الدورة التدريبية هي الأولى في تخصص التعلم العميق.",4352.0,2699.0,,
النماذج المتعاقبة,https://www.coursera.org/learn/nlp-sequence-models-ar,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","ستتعلم في هذا المساق كيفية إنشاء نماذج للغة الطبيعية والصوت وغيرها من البيانات المتعاقبة. بفضل التعلم العميق، تعمل خوارزميات التسلسل والتعاقب بشكل أفضل بكثير مما كانت عليه قبل عامين فقط مما يتيح العديد من التطبيقات المثيرة في التعرف على الكلام والتركيبات الموسيقية وروبوتات الدردشة والترجمة الآلية وفهم اللغة الطبيعية وغيرها من التطبيقات الأخرى. 

سوف تتعلم كيفية:
- فهم كيفية بناء وتدريب الشبكات العصبونية المتكررة (RNN) والمتغيرات الشائعة الاستخدام مثل GRUs والذاكرة طويلة المدى.
- تطبيق نماذج التسلسل على المشاكل الطبيعية للغة بما في ذلك تركيب النص. 
- تطبيق نماذج التسلسل على التطبيقات الصوتية، بما في ذلك التعرف على الكلام والتركيبات الموسيقية.

هذا هو المساق الخامس والأخير من تخصص التعلم العميق.

تشاركdeeplearning.ai أيضًا مع مؤسسة نيفيديا للتعلم العميق في المساق الخامس، نماذج التسلسل، لتوفير مهمة برمجة على الترجمة الآلية مع التعلم العميق. سوف تتاح لك فرصة إنشاء مشروع تعلم عميق بمحتوى متطور وذو صلة بالعملية الصناعية.",,,,
بايثون لعلوم البيانات والذكاء الصناعي,https://www.coursera.org/learn/python-for-applied-data-science-ai-ar,Data Science,Data Analysis,Joseph Santarcangelo,"ابدأ تعلم لغة بايثون لعلوم البيانات، بالإضافة إلى البرمجة بوجه عام مع هذه المقدمة البسيطة للمبتدئين في تعلم لغة بايثون. تعتبر بايثون واحدة من أشهر لغات البرمجة في العالم، وهي تشهد إقبالاً غير مسبوق عليها من جانب المحترفين، حيث تمنحهم القدرة على تطبيق المبادئ الأساسية للغة بايثون لتطوير حلول الأعمال في مختلف الصناعات. 

ستنقلك هذه الدورة من مستوى المبتدئين إلى البرمجة في بايثون خلال ساعات، وليس من الضروري أن تكون لديك خبرات سابقة في البرمجة! ستتعلم المبادئ الأساسية للغة بايثون، بما في ذلك هياكل البيانات وتحليل البيانات، وتستكمل التدريبات التطبيقية في وحدات الدورة، وتمتلك القدرة على إنشاء مشروع نهائي يبرز مهاراتك الجديدة. 

مع نهاية هذه الدورة، ستجد سهولة في إنشاء البرامج الأساسية، والعمل باستخدام البيانات، إلى جانب حل المشكلات الواقعية في بايثون. وستكتسب قاعدة معرفية قوية تؤهلك لمستويات تعلم أعلى في هذا المجال، وتُطور مهاراتك لمساعدتك في الارتقاء بحياتك المهنية. 

يمكن تطبيق هذه الدورة على العديد من البرامج المتخصصة أو برامج الشهادات المهنية. إن استكمال هذه الدورة سيعزز معلوماتك في أيٍ من البرامج التالية: 

الشهادة المتخصصة في الذكاء الصناعي التطبيقي من IBM 

التخصص في علوم البيانات التطبيقية 

الشهادة المتخصصة في علوم البيانات من IBM 

فور استكمال أيٍ من البرامج السابقة، إلى جانب الحصول على شهادة الإنجاز في التخصص من كورسيرا، ستتلقى أيضًا شارة رقمية من IBM تقديرًا لخبراتك في المجال.",,2311.0,,
بناء نموذج تعلم الآلة باستخدام Power BI,https://www.coursera.org/learn/bn-nmwdhj-t-lm-lal-bstkhdm-power-bi-luluk,Data Science,Machine Learning,Nermin Elgrawany,"بنهاية هذا المشروع ، ستكون خبير بكيفية عمل نموذج تعلم الآلة لاستخدامها في اي مجال باستخدام Power BI
Power BI هو تطبيق من Microsoft يتميز بالاحترافية في تحليل البيانات وعرضها وايضا لانشاء نموذج تعلم الآلة من خلال العمل على منصة Automated ML في Power BI، وخلال هذا المشروع ستتعلم كيفية انشاء تعلم الآلة نموذج التي تفيد في الاجابة على الاسئلة الخاصة بالعمل وايضا عمل تنبؤات وتوصيات وبالتالي المساعدة في اتخاذ القرار.
هذا المشروع مخصص للأشخاص المهتمين بمجال تحليل البيانات وال تعلم الآلة باستخدام Power BI ، ولذلك فان هذا المشروع ليس للمبتدئين، فطبعا المعرفة الأساسية بتعلم الآلة مهمة جدا للاستفادة من هذا المشروع مثل ما هو ال تعلم الآلة وانواعه والخوارزميات المختلفة المستخدمة وأيضا خطوات بناء النموذج.",,,,
تجميع البيانات باستخدام لغة الاستعلام البنيوية إسكيوإل,https://www.coursera.org/learn/tajmie-albayanat-bestekhdam-loghat-sql,Data Science,Data Analysis,Nour Nasser,"في هذه الدورة التدريبية القائمة على المشروع والتي تستغرق ساعة واحدة، ستتعرف على كيفيّة تجميع البيانات من خلال دوال التجميع باستخدام لغة الاستعلام البنيوية إسكيوإل.
في نهاية الدورة، ستصبح قادرًا على كتابة دوال التجميع مع إستعلامات إسكيوإل كالمعدّل، الإحصاء، أعلى قيمة،أدنى قيمة، والمجموع.",,,,
تجهيز البيانات للاستكشاف,https://www.coursera.org/learn/prepare-data-for-exploration-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة الثالثة في شهادة تحليلات البيانات من Google. ستزودك هذه الدورات بالمهارات اللازمة للتقدم لوظائف محلل البيانات على المستوى التمهيدي. بينما تستمر في البناء على فهمك للموضوعات من أول دورتين، ستتعرف أيضًا على موضوعات جديدة ستساعدك على اكتساب مهارات عملية في تحليل البيانات. ستتعلم كيفية استخدام أدوات مثل جداول البيانات وSQL لاستخراج البيانات الصحيحة والاستفادة منها لأهدافك وكيفية تنظيم بياناتك وحمايتها. سيستمر محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، ستكون قادرًا على:
 - اكتشاف كيف يقرر المحللون البيانات التي يجب جمعها للتحليل.
 - التعرف على البيانات المهيكلة وغير المهيكلة وأنواع البيانات وتنسيقات البيانات.
 - اكتشاف كيفية تحديد أنواع مختلفة من التحيز في البيانات للمساعدة في ضمان مصداقية البيانات. 
 - اكتشاف كيف يستخدم المحللون جداول البيانات وSQL مع قواعد البيانات ومجموعات البيانات.
 - استكشاف البيانات المفتوحة وأهمية أخلاقيات البيانات وخصوصية البيانات والعلاقة بينهما.
 - اكتساب فهم لكيفية الوصول إلى قواعد البيانات واستخراج البيانات التي تحتوي عليها وتصفيتها وفرزها.
 - التعرف على أفضل الممارسات لتنظيم البيانات والحفاظ عليها آمنة.",,3044.0,,
تحليل البيانات الاستكشافية,https://www.coursera.org/learn/exploratory-data-analysis-ar,Data Science,Data Analysis,"Roger D. Peng, PhD, Jeff Leek, PhD, Brian Caffo, PhD",يغطي هذا المقرر التقنيات الاستكشافية الأساسية لتلخيص البيانات. يتم تطبيق هذه الأساليب عادة قبل أن تبدأ النمذجة الرسمية ويمكن أن تساعد في تطوير نماذج إحصائية أكثر تعقيدًا. تعد التقنيات الاستكشافية مهمة أيضًا لإزالة أو شحذ الفرضيات المحتملة حول العالم التي يمكن معالجتها بواسطة البيانات. سنغطي بالتفصيل أنظمة التخطيط في R بالإضافة إلى بعض المبادئ الأساسية لإنشاء رسومات البيانات. سنغطي أيضًا بعض الأساليب الإحصائية الشائعة متعددة المتغيرات المستخدمة لتصور البيانات عالية الأبعاد.,,,,
تحليل البيانات باستخدام البرمجة R,https://www.coursera.org/learn/data-analysis-with-r-programming-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة التدريبية السابعة في شهادة تحليلات البيانات من Google. ستزودك هذه الدورات بالمهارات اللازمة للتقدم لوظائف محلل البيانات على المستوى التمهيدي. في هذه الدورة، ستتعرف على لغة البرمجة المعروفة باسم R. حيث ستتعرف على كيفية استخدام RStudio، وهي البيئة التي تتيح لك استخدام R. كما ستتناول هذه الدورة أيضًا تطبيقات البرامج والأدوات التي تنفرد بها R، مثل حزم R. ستكتشف كيف تتيح لك لغة R تنظيف البيانات وتنظيمها وتحليلها وتصورها والإبلاغ عنها بطرق جديدة وأكثر فاعلية.  سيستمر محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، ستكون قادرًا على:
 - فحص فوائد استخدام لغة البرمجة R.
 - اكتشاف كيفية استخدام RStudio لتطبيق R على تحليلك. 
 - استكشاف المفاهيم الأساسية المرتبطة بالبرمجة في R. 
 - استكشاف محتويات ومكونات حزم R بما في ذلك حزمة Tidyverse.
 - اكتساب فهم لأطر البيانات واستخدامها في R.
 - اكتشاف خيارات إنشاء التصورات في R.
 - التعرف على R Markdown لتوثيق برمجة R.",,,,
تحليل البيانات باستخدام بايثون,https://www.coursera.org/learn/data-analysis-with-python-ar,Data Science,Data Analysis,Joseph Santarcangelo,"تعرف على كيفية تحليل البيانات باستخدام بايثون. تنتقل بك هذه الدورة بدءًا من أساسيات بايثون إلى استكشاف العديد من أنواع البيانات المختلفة. سوف تتعرف على كيفية إعداد البيانات للتحليل وإجراء تحليل إحصائي بسيط وإنشاء مؤثرات عرض بيانات ذات مغزى والتنبؤ بالاتجاهات المستقبلية التي يتم استنتاجها من البيانات، وغير ذلك المزيد!

الموضوعات المتناولة:

1) استيراد مجموعات البيانات
2) تنظيف البيانات
3) معالجة أُطر البيانات
4) تلخيص البيانات
5) تصميم نماذج انحدار التعلم الآلي
6) تصميم مسارات البيانات

 سوف يتم عرض وتقديم تحليل البيانات باستخدام بايثون عبر عدة وسائل تشمل: المحاضرة والتمرين المعملي والمهام. وتتضمن الدورة الأجزاء التالية:

مكتبات تحليل البيانات: ستتعلم كيفية استخدام مكتبة بانداس ومكتبة نامبي ومكتبة سي باي للتعامل مع عينة من مجموعة البيانات. سنقدم لك مكتبة بانداس، وهي مكتبة مفتوحة المصدر سنستعين بها في تحميل مجموعات بيانات جاذبة للاهتمام ومعالجتها وتحليلها وعرض مؤثراتها. ثم سنقدم لك مكتبة أخرى مفتوحة المصدر، ألا وهي ساي كيت ليرن، وسنستخدم بعض خوارزميات التعلم الآلي الخاصة بها لتصميم نماذج ذكية وإبداء تنبؤات رائعة.

إذا اخترت المشاركة في هذه الدورة والحصول على شهادة دورة Coursera، فستحصل أيضًا على شارة رقمية من شركة IBM. 

عرض لوقت محدود: تكلفة الاشتراك 39 دولارًا أمريكيًا فقط للشهر الواحد لتتمكن من الحصول على المواد المصنفة والشهادة.",,4069.0,,
تحليل البيانات للإجابة عن الأسئلة,https://www.coursera.org/learn/analyze-data-to-answer-questions-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة التدريبية الخامسة في شهادة تحليلات البيانات من Google. ستزودك هذه الدورات بالمهارات اللازمة للتقدم لوظائف محلل البيانات على المستوى التمهيدي. في هذه الدورة، سوف تستكشف مرحلة ""التحليل"" في عملية تحليل البيانات. ستستعين بما تعلمته حتى هذه النقطة وتطبقه على تحليلك لفهم البيانات التي جمعتها. وستتعلم كيفية تنظيم بياناتك وتنسيقها باستخدام جداول البيانات وSQL لمساعدتك في إلقاء نظرة على بياناتك والتفكير فيها بطرق مختلفة. ستتعرف أيضًا على كيفية إجراء عمليات حسابية معقدة على بياناتك لإكمال أهداف العمل. ستتعلم كيفية استخدام المعادلات والدوال واستعلامات SQL أثناء إجراء التحليل. سيستمر محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، ستكون قادرًا على:
 - معرفة كيفية تنظيم البيانات من أجل التحليل.
 - اكتشاف عمليات تنسيق البيانات وضبطها. 
 - اكتساب فهم لكيفية تجميع البيانات في جداول البيانات وباستخدام SQL.
 - استخدام المعادلات والدوال في جداول البيانات لحساب البيانات.
 - معرفة كيفية إتمام العمليات الحسابية باستخدام استعلامات SQL.",,4570.0,,
تحليل المجموعات الهرمية باستخدام المسافات الإقليدية,https://www.coursera.org/learn/genome-analysis-hierarchical-clustering-ar,Data Science,Data Analysis,Usama A. F. Khalil,"بنهاية هذا المشروع ، ستنشئ برنامج Python باستخدام واجهة jupyter لتحليل مجموعة من الفيروسات وترسم مخططًا شجرياً أو دندوجرام بناءً على أوجه التشابه فيما بينها. سيعتمد الدندوجرام الذي ستقوم بإنشائه على ملف تعريف الانحراف التراكمي، والذي يعتمد بدوره على تركيبة النوكليوتيدات. ستستخدم تسلسل الجينوم الكامل للعديد من الفيروسات بما في ذلك، كورونا، وفيروس السارس، وفيروس نقص المناعة البشرية، وزيكا، وحمى الضنك، والفيروس المعوي، وفيروسات غرب النيل.

ملاحظة: تعمل هذه الدورة التدريبية بشكل أفضل للمتعلمين المقيمين في منطقة أمريكا الشمالية. نعمل حاليًا على توفير نفس التجربة في مناطق أخرى.",,,,
تصفية و ترتيب المعلومات باستخدام SQL,https://www.coursera.org/learn/tasfiat-w-tartib-almaelumat-biastikhdam-sql,Data Science,Data Analysis,Wassim Joseph,"في نهاية هذا المشروع هتكون قادر تنشئ قاعدة بيانات وتحط جواه جداول وتدخل فيه بيانات  و كمان هتكون قادرتستخدم الـ السي كيو ال في تصفية ال البيانات العندك و كمان هتقدر تعرض ال البيانات بتاعتك بترتيب معين و بالشكل الي انت محتاجه بسهولة و هنغطي معظم ال  اوامر السي كيو ال الي انت ممكن تحتاجها في التعامل مع ال البيانات بتاعتك و تتأكد ان مفيش أي اخطاء في الكتابة.

هذا المشروع للمهتمين بمجال تحليل البيانات باستخدام لغة ال سي كيو ال ، و هذا المشروع للمبتدئين لأننا هنبدأ نتعلم لغة الـ سي كيو ال و نفهم طريقة الكتابة بتاعتها. بعد المشروع هتقدر انك تتعامل مع أي dataset هتقابلك و هتقدر انك تقراء و تكتب لغة الـ سي كيو ال و تنشئ قاعدة البيانات الخاصة بك و ده هيساعدك لو اشتغلت ك محلل للبيانات انك تبقي عارف ازاى تتعامل مع ال قاعدة البيانات الفي الشركة بتاعتك.
في هذا المشروع ، سنستخدم Microsoft SQL server و هنستخدم لغة الـ SQL علشان لغة الاستعلامات البنائية هي لغة للتعامل والتحكم مع قواعد البيانات المترابطة من خلال التعامل مع تراكيب البيانات وإجراء عمليات إدخال البيانات والحذف والفرز والبحث والتصفية والتعديل وخلافه",,,,
تعزيز الشبكات العصبية : ضبط وتحسين مقياس فرط المعلمات,https://www.coursera.org/learn/deep-neural-network-ar,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","يعلمك هذا البرنامج ""سحر"" الحصول على التعلم المتعمق للعمل بشكل جيد. وعوضًا عن كون عملية التعلم المتعمق عبارة عن صندوق أسود، ستدرك الأمر الذي يدفع إلى الأداء، ومن ثم ستتمكن من الحصول على نتائج جيدة بشكل أكثر منهجية. كما ستعرف عن برنامج تنسرفلو. 

بعد 3 أسابيع،: 
- ستفهم أفضل الممارسات في المجال بشأن إنشاء تطبيقات التعلم المتعمق. 
- وأيضًا القدرة على استخدام ""الحيل"" الشائعة للشبكة العصبية بشكل فعال، بما في ذلك التهيئة، المستوى الثاني وتصحيح وضع التسرب، تطبيع الدفعة، فحص التدرج،, 
- القدرة على تنفيذ وتطبيق مجموعة متنوعة من خوارزميات التحسين، مثل هبوط تدرج الدفعات الصغيرة وزخم الحركة وطرق المعدل المقترحة وآدم والتحقق من التطابق فيما بينهما. 
- بالإضافة إلى فهم أفضل الممارسات الجديدة لعصر التعلم المتعمق حول كيفية إعداد مجموعات التدريب/التطوير/الاختبار وتحليل الانحياز/التباين
- القدرة على تطبيق شبكة عصبية في برنامج تنسرفلو. 

هذا هو المساق الثاني من اختصاص التعلم المتعمق.",,,,
تمثيل البيانات رسومياً باستخدام بايثون - Data Visualization,https://www.coursera.org/learn/data-visualization-python-ar,Data Science,Data Analysis,Amani Abbas,"Data Visualization with Python
تمثيل البيانات باستخدام بايثون",,,,
توقع حضور المواعيد الطبية باستخدام Python,https://www.coursera.org/learn/tuaqie-hudur-almawaeid-altibiyat-biastikhdam-python,Data Science,Machine Learning,Mazen Mobtasem,في نهاية المشروع ده هتقدر تصمم model ذكاء صناعي عشان يتوقع المريض هيجي المعاد إلي كان محدد ولا لاباستخدام Python و Jupyter Notebook. خلال المشروع هنمشى مع بعض خطوة بخطوة عشان نقدر نحلل البيانات إلي هتكون معنا من website Kaggle.com الdata  دي هتكون عن مرضى في البرازيل.و هنقدر نحدد  ازاي الmachine learning engineer  بيختار الmachine learning model بتاعو. و ازاي إقدر إستعمل ال-machine learning model بتاعي ده عشان اتوقع هل المريض ده هيجي ولا لا. المشروع ده هيفيد الناس المهتمة بمجال الdata science. و هنخد في الخطوات إلي المفروض الdata scientist يتبعها في المشروع بتاع عشان يقدر يوصل لمطلوب من بدايةً من ال-data preprocessing مروراً بال-data analytics و ال-exploratoray data analysis و في الأخر هنتبء machine learning model على ال-data بتاعتنا. المشروع ده هيكون في مستوى متوسط. طبعن python هي من أشهر لغات البرمجة و jupyter notebook هو application مشهور جداً باستعملو في مشاريع ال-data science و ال-machine learning.,,,,
طرح الأسئلة لاتخاذ قرارات قائمة على البيانات,https://www.coursera.org/learn/ask-questions-to-make-data-driven-decisions-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة الثانية في شهادة تحليلات البيانات من Google. ستزودك هذه الدورات بالمهارات اللازمة للتقدم لوظائف محلل البيانات على المستوى التمهيدي. ستبنى على فهمك للموضوعات التي تم تقديمها في الدورة الأولى لشهادة تحليلات البيانات من Google. ستساعدك المواد على تعلم كيفية طرح أسئلة فعالة لاتخاذ قرارات قائمة على البيانات، مع التواصل لتلبية احتياجات الأطراف المعنية. سيستمر محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، ستكون قادرًا على:
- التعرف على تقنيات طرح الأسئلة الفعالة التي يمكن أن تساعد في توجيه التحليل. 
- اكتساب فهم لعملية اتخاذ القرار القائم على البيانات وكيف يقدم محللو البيانات النتائج.
- اكتشاف مجموعة متنوعة من سيناريوهات الأعمال في العالم الحقيقي لدعم فهم طرح الأسئلة واتخاذ القرار.
- اكتشاف كيف ولماذا تعد جداول البيانات أداة مهمة لمحللي البيانات.
- فحص الأفكار الرئيسية المرتبطة بالتفكير المنظم وكيف يمكن أن تساعد المحللين على فهم المشكلات بشكل أفضل ووضع الحلول.
- تعلم استراتيجيات لإدارة توقعات الأطراف المعنية أثناء إنشاء اتصال واضح مع فريق تحليل البيانات لتحقيق أهداف العمل.",,6430.0,,
عكس وتكامل تسلسل الحمض النووي (DNA ، RNA) باستخدام R,https://www.coursera.org/learn/reverse-and-complement-nucleic-acid-sequences-using-r-ar,Data Science,Data Analysis,Usama A. F. Khalil,في هذه الدورة التدريبية القائمة على المشروع والتي تستغرق ساعة واحدة ، ستتعلم اللبنات الأساسية في لغة R وكيفية تطوير برنامج R الذي يبني متواليات الحمض النووي  (DNA ، RNA) العكسية والمكملة والعكسية-المكملة. أيضًا، ستجعل برنامجك يقرأ ملفًا يحتوي على تسلسل DNA  وتتعامل مع أحد الجينومات الكاملة لفيروس كورونا.,,,,
قواعد البيانات وSQL (لغة الاستعلام البنيوية) لعلم البيانات,https://www.coursera.org/learn/sql-data-science-ar,Data Science,Data Analysis,"Hima Vasudevan, Rav Ahuja","ي عالمنا اليوم، نرى كثيرًا من البيانات مسجَّلة في قواعد بيانات.  تعد لغة SQL (لغة الاستعلام البنيوية) لغة قوية، تستخدم للتواصل مع قواعد البيانات واستخراج البيانات منها. ولا بد من المعرفة العملية بقواعد البيانات وبلغة SQL (لغة الاستعلام البنيوية) إذا كنت تريد أن تصبح عالمًا من علماء البيانات.

الغرض من هذه الدورة هو تقديم مفاهيم قواعد البيانات العلائقية ومساعدتك على تعلُّم المعرفة الأساسية بلغة SQL (لغة الاستعلام البنيوية) وتطبيق هذه المعارف عمليًا. الغرض من هذه الدورة أيضًا مساعدتك على الشروع في البدء باستخدام وصول SQL (لغة الاستعلام البنيوية) في بيئة علم البيانات.
  

ينصب تركيز هذه الدورة على التدريب الفعلي والتعلم العملي. وبالتالي، سوف تتعامل مع قواعد بيانات حقيقية وأدوات علوم بيانات حقيقية ومجموعات بيانات واقعية. ستقوم بإنشاء مثيل قاعدة بيانات في السحابة. من خلال سلسلة من التمرينات المعملية العملية، سوف تتدرب على إنشاء استعلامات SQL (لغة الاستعلام البنيوية) وتشغيلها. كما ستتعلم أيضًا الوصول إلى قواعد البيانات من دفاتر جوبيتر باستخدام SQL (لغة الاستعلام البنيوية) وبايثون.

لا تتطلب هذه الدورة معرفة مُسْبقة بقواعد البيانات أو بلغة SQL (لغة الاستعلام البنيوية) أو بايثون أو البرمجة.

؛ إذ يمكن لأي شخص تدقيق (مراجعة) هذه الدورة مجانًا. إذا اخترت الالتحاق بهذه الدورة والحصول على شهادة الدورة من Coursera، فيمكنك أيضًا الحصول على شارة رقمية من IBM عند إكمال الدورة بنجاح.

عرض لفترة محدودة: للتمكن من الوصول إلى المواد المُقيَّمة والحصول على شهادة، فإن قيمة الاشتراك الشهري هي 39 دولارًا أمريكيًا فقط.",,,,
كابستون علوم البيانات التطبيقية,https://www.coursera.org/learn/applied-data-science-capstone-ar,Data Science,Data Analysis,Alex Aklson,"ستمنحك دورة مشروع الكابستون هذه لمحة عما يمرّ به علماء البيانات في الحياة الواقعية عند التعامل مع البيانات.  

ستتعرف على بيانات الموقع ومقدمي بيانات الموقع المختلفين، مثل فورسكوير. ستتعرف على طريقة إجراء اتصالات واجهة برمجة تطبيقات RESTful لواجهة برمجة تطبيقات فورسكوير لاسترداد البيانات حول أماكن في أحياء مختلفة حول العالم. ستتعلم أيضًا كيف تكون مبدعًا في المواقف التي لا تكون فيها البيانات متاحة بسهولة من خلال استخلاص بيانات الويب وتحليل كود HTML. ستستخدم بايثون ومكتبة الباندا الخاصة بها لمعالجة البيانات، وهو ما سيساعدك في صقل مهاراتك الخاصة باستكشاف البيانات وتحليلها. 

وأخيرًا، سيُطلب منك استخدام مكتبة فوليوم للحصول على خرائط رائعة للبيانات الجيوفضائية والإبلاغ عن النتائج والاستنتاجات الخاصة بك.

وإذا اخترت المشاركة في هذه الدورة والحصول على شهادة دورة كورسيرا، فستحصل أيضًا على شارة رقمية من IBM عند إتمامك للدورة بنجاح. 

عرض لوقت محدود: تكلفة الاشتراك 39 دولارًا أمريكيًا فقط للشهر الواحد لتتمكن من الحصول على المواد المصنفة والشهادة.",,,,
كيفية استخدام ال SQL مع قواعد البيانات الكبيرة,https://www.coursera.org/learn/kayfiat-aistikhdam-al-sql-mae-qawaeid-albayanat-alkabira,Data Science,Data Analysis,Abdelrahman Tarek Hafez,"فى نهاية هذا المشروع ، ستكون قادرًا على كتابة queries بشكل احترافي بأداء أفضل باستخدام أساليب SQL لتحسين أداء queries وتسريع وقت التنفيذ.خلال المشروع، هتقدر تنفذ  الخطوات المهمة لضبط queries. يعتبر تحسين  قاعدة البيانات أمرًا ضروريًا لتنظيم بيانات قاعدة البيانات والوصول إليها بسهولة عن طريق إنشاء أنواع من indexes لتحسين الأداء. , و هتقدر أيضًا تنشئ ملخص الجداول وتدخال البيانات بعد عمل وظائف حسابية عليها. واخيرا هتقدر تنفذ queries باستخدام  Explain and Explain Analyze.
هذا المشروع الارشادى مخصص للأشخاص الذين لديهم خبرة متوسطة  في مجال هندسة البيانات والبيانات. الأشخاص الذين يرغبون في معرفة كيفية تحسين أداء queries وتسريع وقت التنفيذ. يعتبر تحسين كتابة ال queries مع التعامل مع قواعد بيانات كبيرة هى من اهم الخطوات فى ال SQL. فالهدف من تحسين كتابة ال QUERY هو تقليل موارد النظام اللى بنستعملها فى تنفيذ ال QUERY, و  تقليل ال COST. و اخيرا نوصل للنتائج بطريقة اسرع.",,,,
مؤثرات عرض البيانات باستخدام لغة بايثون,https://www.coursera.org/learn/python-for-data-visualization-ar,Data Science,Data Analysis,Alex Aklson,"""الصورة تساوي ألف كلمة"". كلنا يعرف هذا التعبير. إنه ينطبق بشكل خاص عند محاولة شرح نتائج التحليلات التي تم الحصول عليها من تحليل مجموعات البيانات الكبيرة المتزايدة. تؤدي مؤثرات عرض البيانات دورًا أساسيًا في تمثيل البيانات الصغيرة والكبيرة على حد سواء. 

وتتمثل إحدى المهارات الأساسية لعالِم البيانات في قدرته على سرد قصة مقنعة، تعرِض البيانات والنتائج مصحوبة بمؤثرات عرض بطريقة ودّيّة ومحفِّزة. إن تعلم كيفية الاستفادة من أداة برمجية لمؤثرات عرض البيانات في صورة مؤثرات عرض سيمكنك أيضًا من استخراج المعلومات وفهم البيانات بشكل أفضل، واتخاذ قرارات أكثر فاعلية. 

 والهدف الرئيسي من هذه الدورة التدريبية لمؤثرات عرض البيانات باستخدام لغة بايثون هو تعليمك كيفية أخذ البيانات التي تبدو لأول وهلة عديمة المعنى وتقديم تلك البيانات في شكل منطقي للجمهور. تم تطوير تقنيات مختلفة لعرض البيانات بشكل مرئي ولكن في هذه الدورة التدريبية، سنستخدم العديد من مكتبات مؤثرات عرض البيانات في لغة بايثون، وهي مكتبة مات بلوت ليب ومكتبة سيبورن ومكتبة فوليوم. 

 عرض لفترة محدودة: سعر الاشتراك 39 دولارًا أمريكيًا فقط شهريًا للحصول على المواد المتدرّجة والشهادة.",,,,
ما علم البيانات؟,https://www.coursera.org/learn/what-is-datascience-ar,Data Science,Data Analysis,"Rav Ahuja, Alex Aklson",فن الكشف عن الرؤى والاتجاهات في البيانات موجود منذ القِدم. استخدم قدماء المصريين بيانات الإحصاء لزيادة الكفاءة في عملية تحصيل الضرائب وكانوا يتنبؤون بفيضان نهر النيل كل عام بدقة. ومنذ ذلك الحين، اختط العاملون في علم البيانات مجالاً فريدًا ومتميزًا للعمل الذي يؤدونه. هذا المجال هو علم البيانات. في هذه الدورة، سنلتقي بعض الممارسين في مجال علم البيانات وسنحصل على لمحة عامة حول ماهية علم البيانات اليوم.,,,,
مجموعة أدوات عالم البيانات,https://www.coursera.org/learn/data-scientists-tools-ar,Data Science,Data Analysis,"Jeff Leek, PhD, Roger D. Peng, PhD, Brian Caffo, PhD",ستتلقى في هذه الدورة التدريبية مقدمة عن الأدوات الرئيسية والأفكار الخاصة بمجموعة أدوات عالم البيانات. تقدم الدورة التدريبية نظرة عامة عن البيانات والاستفسارات والأدوات التي يعمل عليها علماء البيانات ومحللو البيانات. هناك عنصران لهذه الدورة التدريبية. الأول هو مقدمة نظرية عن الأفكار الكامنة وراء تحويل البيانات إلى معلومات قابلة للتطبيق. والثاني هو مقدمة عملية عن الأدوات التي سيتم استخدامها في البرنامج مثل التحكم في النُسَخ ولغة Markdown وGit وGitHub وR وRStudio.,2210.0,2001.0,4.7,107.0
مشاركة البيانات من خلال فن مؤثرات عرض التصور,https://www.coursera.org/learn/share-data-through-the-art-of-visualization-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة التدريبية السادسة في شهادة تحليلات البيانات من Google. ستزودك هذه الدورات بالمهارات اللازمة للتقدم لوظائف محلل البيانات على المستوى التمهيدي. سوف تتعلم كيفية تصور وتقديم نتائج البيانات الخاصة بك عندما تكمل عملية تحليل البيانات. ستوضح لك هذه الدورة التدريبية كيف يمكن أن تساعد تصورات البيانات، مثل لوحات المعلومات المرئية، في إحياء بياناتك. ستستكشف أيضًا Tableau، وهو منصة لتصور البيانات سيساعدك على إنشاء تصورات فعالة لعروضك التقديمية. سيستمر محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، ستكون قادرًا على:
 - فحص أهمية تصور البيانات.
 - تعلم كيفية تكوين سرد مقنع من خلال قصص البيانات.
 - اكتساب فهم لكيفية استخدام Tableau لإنشاء لوحات معلومات وعوامل تصفية للوحة المعلومات.
 - اكتشف كيفية استخدام Tableau لإنشاء تصورات فعالة. 
 - اكتشف المبادئ والممارسات المتضمنة في العروض التقديمية الفعالة.
 - تعرف على كيفية مراعاة القيود المحتملة المرتبطة بالبيانات في عروضك التقديمية.
 - فهم كيفية تطبيق أفضل الممارسات على الأسئلة والأجوبة مع جمهورك.",,1850.0,,
مشروع كابستون لشهادة تحليلات البيانات من Google: الانتهاء من دراسة الحالة,https://www.coursera.org/learn/google-data-analytics-capstone-complete-a-case-study-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة التدريبية الثامنة في شهادة تحليلات البيانات من Google. ستتاح لك الفرصة لإكمال دراسة حالة اختيارية، مما سيساعد في إعدادك للبحث عن وظيفة في مجال تحليل البيانات. يشيع استخدام دراسات الحالة من قبل أصحاب العمل لتقييم المهارات التحليلية. بالنسبة لدراسة حالتك، ستختار سيناريو قائم على التحليلات. ستطرح بعد ذلك أسئلة وتحضر وتعالج وتحلل وتتصور وتتصرف بناءً على البيانات من السيناريو. ستتعلم أيضًا مهارات أخرى مفيدة للبحث عن عمل من خلال مقاطع الفيديو التي تحتوي على أسئلة وإجابات شائعة للمقابلة، ومواد مفيدة لبناء محفظة عبر الإنترنت، والمزيد. سيستمر محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، ستكون قادرًا على:
 - التعرف على فوائد واستخدامات دراسات الحالة والمحافظ في البحث عن وظيفة.
 - اكتشاف سيناريوهات مقابلة العمل في العالم الحقيقي وأسئلة المقابلة الشائعة.
 - اكتشاف كيف يمكن أن تكون دراسات الحالة جزءًا من عملية مقابلة العمل. 
 - فحص ودراسة سيناريوهات دراسة الحالة المختلفة. 
 - لديك فرصة لإكمال دراسة الحالة لمحفظتك.",,,,
معالجة البيانات من غير نظيفة إلى نظيفة,https://www.coursera.org/learn/process-data-from-dirty-to-clean-arabic,Data Science,Data Analysis,Google Career Certificates,"هذه هي الدورة التدريبية الرابعة في شهادة تحليلات البيانات من Google. ستزودك هذه الدورات بالمهارات اللازمة للتقدم لوظائف محلل البيانات على المستوى التمهيدي. في هذه الدورة التدريبية، ستستمر في بناء فهمك لتحليلات البيانات والمفاهيم والأدوات التي يستخدمها محللو البيانات في عملهم. ستتعلم كيفية التحقق من بياناتك وتنظيفها باستخدام جداول البيانات وSQL وكذلك كيفية التحقق من نتائج تنظيف البيانات وإبلاغها. سيستمر محللو بيانات Google الحاليون بإرشادك وتزويدك بالطرق العملية لإنجاز مهام محلل البيانات الشائعة باستخدام أفضل الأدوات والموارد.

سيتم تجهيز المتعلمين الذين يكملون برنامج الشهادة هذا للتقدم لوظائف المستوى التمهيدي كمحللين بيانات. لا تلزم خبرة سابقة.

بنهاية هذه الدورة، ستكون قادرًا على:
 - تعلم كيفية التحقق من سلامة البيانات.
 - اكتشاف تقنيات تنظيف البيانات باستخدام جداول البيانات. 
 - إنشاء استعلامات SQL الأساسية للاستخدام مع قواعد البيانات.
 - تطبيق دوال SQL الأساسية لتنظيف البيانات وتحويلها.
 - اكتساب فهم لكيفية التحقق من نتائج تنظيف البيانات.
 - استكشاف عناصر تقارير تنظيف البيانات وأهميتها.",,3040.0,,
معالجة البيانات وتحليل الأعمال باستخدام برنامج جدول البيانات,https://www.coursera.org/learn/data-manipulation-business-analysis-arabic,Data Science,Data Analysis,Omnya Khaled,"في نهاية هذا المشروع ، ستكون قادرًا على معالجة البيانات بالدوال، وتطبيق المعادلات لاستخراج الكلمات من النص. علاوة على ذلك ، سوف تكون قادرًا على تحديد وإدارة البيانات الخاصة بك. أخيرًا ، ستتمكن من إنشاء جداول الاحصائيات ومعادلات البحث لتلخيص  بياناتك وتحليلها. سيوضح لك هذا المشروع كيفية التعامل مع النص وكيفية تحليله لتقديمه بشكل احترافي بطرق مختلفة.

هذا المشروع مخصص للأشخاص في مجال الأعمال وتحليل البيانات. يوفر لكم الخطوات المهمة لتكون محلل بيانات. علاوة على ذلك ، فإنه يزودك بالمعرفة الموجودة في جداول البيانات المتعلقة بتحليل الأعمال وكيفية التعامل مع البيانات حسب المعادلات.",,,4.8,16.0
مقاييس الأعمال للشركات التي تعتمد على البيانات,https://www.coursera.org/learn/analytics-business-metrics-ar,Data Science,Data Analysis,"Daniel Egger, Jana Schaich Borg","في هذه الدورة التدريبية، ستتعلم أفضل الممارسات لكيفية استخدام تحليلات البيانات لتجعل أي شركة لها قدرة أكبر على التنافس والربح. سيمكنك التعرف على أهم مقاييس الأعمال وتمييزها عن البيانات العادية.

وستكون لديك صورة واضحة عن الأدوار الحيوية المختلفة التي يضطلع بها كل من محللي الأعمال، ومحللي بيانات الأعمال، وعلماء البيانات في مختلف أنواع الشركات. وستعرف بالضبط أي المهارات مطلوبة للتوظيف في هذه الأعمال التي يرتفع الطلب عليها والنجاح فيها.
 
وفي النهاية، سيمكنك الاستعانة بالقائمة المرجعية التي توفرها الدورة التدريبية؛ لتقييم أي شركة بناءً على كيفية تبنّيها لثقافة البيانات الضخمة بفعاليّة. تُحدث الشركات الرقمية مثل Amazon، وUber، وAirbnb تحوّلًا في الصناعات بالكامل من خلال استخدامها الإبداعي للبيانات الضخمة.. وستدرك لِمَ تكون هذه الشركات معرقلة للغاية، وكيفية استخدامها لتقنيات تحليل البيانات؛ لكي تتفوق في قدرتها التنافسية على الشركات التقليدية.",1752.0,1555.0,4.7,76.0
مقدمة عن البيانات الضخمة,https://www.coursera.org/learn/big-data-introduction-ar,Data Science,Data Analysis,"Ilkay Altintas, Amarnath Gupta","مقدمة عن البيانات الضخمة

هل أنت مهتم بزيادة معرفتك بأبرز سمات البيانات الضخمة؟ هذه الدورة التدريبية مخصصة للمستجدين في علوم البيانات والمهتمين بفهم أسباب ظهور عصر البيانات الضخمة. فهي مخصصة لمن يريدون الإلمام بالمصطلحات والمفاهيم الأساسية الخاصة بمشكلات البيانات الضخمة وتطبيقاتها وأنظمتها. إنها لمن يريدون البدء في التفكير بشأن الطريقة التي يمكن أن تفيدهم البيانات الضخمة بها في عملهم أو مسيرتهم المهنية. حيث تتعرض مقدمة عن أحد أكثر أطر العمل الشائعة ألا وهو Hadoop، والذي زاد من سهولة تحليل البيانات الضخمة وإمكانية الوصول إليها، فقد زاد من احتمالية تطوير البيانات الضخمة لعالمنا!

وفي نهاية الدورة التدريبية، ستتمكن مما يلي:

*  وصف أبرز سمات البيانات الضخمة بما في ذلك الأمثلة على مشكلات البيانات الضخمة على أرض الواقع التي تتضمن ثلاثة مصادر أساسية للبيانات الضخمة وهي الأفراد والمؤسسات وأدوات الاستشعار.

* شرح خصائص البيانات الضخمة التي تبدأ بالحرف V مثل (volume (الحجم)، وvelocity (السرعة)، وvariety (التنوع)، وveracity (الصحة)، وvalence (التكافؤ)، وvalue (القيمة)) ولماذا تؤثر كل خاصية من تلك الخصائص في جمع البيانات ومتابعتها وتخزينها وتحليلها والإبلاغ عنها

* الاستفادة بقيمة البيانات الضخمة عن طريق استخدام عملية مكونة من 5 خطوات لهيكلة تحليلك. 

* تحديد المشكلات التي تندرج تحت البيانات الضخمة والتي لا تندرج تحتها، والقدرة على إعادة تشكيل مشكلات البيانات الضخمة مثل مسائل علوم البيانات.

* تقديم تفسير للمكونات الهندسية والنماذج البرمجية التي تستخدم في التحليل القابل للتوسيع للبيانات الضخمة.

* تلخيص ميزات المكونات الأساسية لمكدس Hadoop وقيمتها بما في ذلك مورد YARN ونظام إدارة الوظائف، ونظام ملفات HDFS، ونموذج برمجة MapReduce.

* تثبيت البرامج وتشغيلها باستخدام إطار عمل Hadoop!

هذه الدورة التدريبية موجهة للمستجدين في علوم البيانات.  لا يلزم توافر خبرة برمجية مسبقة، على الرغم من ضرورة توافر القدرة على تثبيت التطبيقات واستخدام الأجهزة الظاهرية لإنجاز الواجبات العملية.  

متطلبات الأجهزة:
(أ) معالج رباعي النواة (يوصى بمعالج يدعم ميزة VT-x أو AMD-V)، 64 بت؛ (ب) ذاكرة وصول عشوائي بحجم 8 جيجابايت؛ (ج) مساحة خالية بحجم 20 جيجابايت. 
طريقة العثور على معلومات الأجهزة: (نظام Windows): افتح النظام عن طريق الضغط على زر Start (بدء التشغيل)، وانقر بزر الفأرة الأيمن على أيقونة Computer (جهاز الكمبيوتر)، ثم انقر على Properties (خصائص)؛ (نظام Mac): افتح Overview (نظرة عامة) عن طريق الضغط على قائمة Apple والنقر على ""About This Mac."" سيتوفر الحد الأدنى من المتطلبات في معظم أجهزة الكمبيوتر ذات الذاكرة العشوائية سعة 8 جيجابايت والتي تم شراؤها في آخر 3 أعوام. وستحتاج إلى سرعة اتصال عالية بالإنترنت لأنك ستقوم بتنزيل ملفات يصل حجمها إلى 4 جيجابايت.

المتطلبات البرمجية: تعتمد هذه الدورة التدريبية على العديد من الأدوات البرمجية مفتوحة المصدر، ومنها Apache Hadoop. ويمكن تنزيل جميع البرامج المطلوبة وتثبيتها مجانًا.
تتضمن المتطلبات البرمجية ما يلي: Windows 7+ أو Mac OS X 10.10+ أو Ubuntu 14.04+ أو CentOS 6+ VirtualBox 5+.",2949.0,2907.0,4.5,100.0
مقدمة لتحليل البيانات باستخدام جدول البيانات,https://www.coursera.org/learn/introduction-to-business-analysis-by-sheets,Data Science,Data Analysis,Omnya Khaled,"في هذه الدورة، سنركز على هدفين تعلمين:
1. هتتعلم اساسيات اوراق جوجل و كيفية استخدام الدوال و المعادلات الشرطيةو المنطقية و التجميعية.

 2.هتتعلم كيفية تنظيف البيانات و إنشاء تصور البيانات والبيانات الفئوية باستخدام: المخططات الدائرية والشريطية والخطية أو 
العمودية.
في نهاية هذه الدورة التدريبية، هتتعلم الهدف و الدور لتحليل البيانات.",,,4.9,16.0
منهجية علم البيانات,https://www.coursera.org/learn/data-science-methodology-ar,Data Science,Data Analysis,"Alex Aklson, Polong Lin","على الرغم من الزيادة الأخيرة في قوة الحوسبة والوصول إلى البيانات على مدى العقدين الماضيين، فإن قدرتنا على استخدام البيانات في عملية صنع القرار إما فُقدت أو لم يتم تعزيزها على الإطلاق في كثير من الأحيان، فليس لدينا فهم قوي للأسئلة التي يتم طرحها وكيفية تطبيق البيانات بشكل صحيح على المشكلة المطروحة.

إن هذه الدورة التدريبية لها غرض واحد، وهو مشاركة المنهجية التي يمكن استخدامها في علم البيانات، للتأكد من أن البيانات المستخدمة في حل المشكلات ذات صلة وتم معالجتها بشكل صحيح لمعالجة السؤال المطروح.

وبناءً عليه، ستتعلم في هذه الدورة التدريبية ما يلي:
 - الخطوات الرئيسية المتضمنة في معالجة مشكلة علم البيانات.
 - الخطوات الرئيسية المتضمنة في ممارسة علم البيانات، من تشكيل مشكلة عمل أو بحث ملموسة، إلى جمع البيانات وتحليلها، إلى بناء نموذج، وفهم التعقيبات بعد نشر النموذج.
 - كيف يفكر علماء البيانات!

عرض لفترة محدودة: الاشتراك تكلفته 39 دولارًا أمريكيًا فقط كل شهر للوصول إلى مواد ذات درجات وشهادة.",,,,
نظرة عامة على تحليل بيانات العملاء باستخدام  Excel,https://www.coursera.org/learn/nazrat-eamat-ealaa-tahlilat-aleumala-biastikhdam-barnamaj-excel,Data Science,Data Analysis,Nermin Elgrawany,"أهلا بيكم في مشروع تحليل بيانات العملاء باستخدام  Excel معكم باشمهندس / احمد ماهر انا مهندس اتصالات والكترونيات وعندي خبيرة بتتجاوز ال 4 سنين في مجال الشبكات وتحليل البيانات واستخدامها في التطبيقات المختلفه لمساعدة العملاء في مجال عملهم، بنهاية هذا المشروع ، ستكون خبير في طرق وإستراتيجيات تحليل بيانات العملاء باستخدام Excel. تحليل بيانات العملاء هي عملية يتم من خلالها استخدام البيانات من سلوك العميل للمساعدة في اتخاذ قرارات العمل الرئيسية ويتم استخدام هذه المعلومات من قبل الشركات للتسويق المباشر واختيار الموقع وإدارة علاقات العملاء من خلال تطبيق بعض الاستراتيجيات لتحليل بيانات العملاء مثل استراتيجية تقسيم العملاء الى شرائح او Segmentation ، استراتيجية انسحاب العملاء او Customer churn ، استراتيجية القيمة الدائمة للعميل Customer Lifetime ، استراتيجية اكتساب العملاء او Customer Acquisition، و استراتيجية رضا العملاء Customer Satisfaction ، وبالتالي يؤهلكم للحصول على فرص أفضل في سوق العمل.
هذا المشروع مخصص للمبتدئين في مجال تحليل بيانات العملاء سواء كنت جديد تماما وتريد معرفة المفاهيم الاساسية او تريد توسيع فهمك في هذا المجال، اذا هذا المشروع مثالي بالنسبة لك، حيث يعتمد هذا المشروع على برنامج Excel الذي يستخدم جداول البيانات لتنظيم الأرقام والبيانات بالصيغ والوظائف، وتحليل Excel منتشر في كل مكان حول العالم وتستخدمه الشركات من جميع الأحجام لإجراء التحليلات المختلفة.",,,,
نظره عامة عن البيانات المصورة باستخدام Tableau,https://www.coursera.org/learn/nazaruh-eamatan-ean-albayanat-almusawarat-biastikhdam-tableau,Data Science,Data Analysis,Nermin Elgrawany,"بنهاية هذا المشروع ، ستكون خبير بكيفية استعمال Tableau لعمل بيانات مصورة لاستخدامها في العروض التقديمية  او التقارير وبالتالي يأهلك للحصول على فرص أفضل في العمل.
. Tableau هو عبارة عن تطبيق لتحليل وعرض البيانات بصورة مرئية من خلال الاشكال البيانية المختلفة والمناسبة لنوع البيانات المستخدمة، وخلال هذا المشروع ستتعلم كيفية انشاء الاشكال البيانية و لوحة عرض البيانات و قصة مع الاخذ في الاعتبار اسس اختيار الاشكال البيانية المناسبة لعرض المعلومات وترجمة النتائج التي تفيد في الاجابة على الاسئلة الخاصة بالعمل وبالتالي المساعدة في اتخاذ القرار.
هذا المشروع مخصص للمبتدئين في مجال البيانات المرئية من خلال التطبيق على برنامج Tableau، سواء كنت جديد تماما وتريد معرفة المفاهيم الاساسية للبيانات المرئية أو تريد توسيع فهمك في هذا المجال، اذا هذا المشروع مثالي بالنسبة لك.",,,,
نهج هندسي لتحليل الجينوم: الانحراف ومنحنى زد,https://www.coursera.org/learn/genome-analysis-z-curve-arabic,Data Science,Data Analysis,Usama A. F. Khalil,في هذه الدورة التدريبية القائمة على المشروع والتي تستغرق ساعة واحدة، ستتعلم كيفية تحليل جينوم فيروسي كامل باستخدام طرق هندسية (الانحراف ومنحنى زد)، والتخطيط ثنائي وثلاثي الأبعاد في بايثون، وكيفية استخدام بعض مكتبات Python المهمة ( مثل Tkinter و Matplotlib و NumPy) لمساعدتك على تحقيق ذلك. سوف تتعرف أيضًا على جينومات بعض الفيروسات بما في ذلك فيروسات كورونا، والسارس، وفيروسات نقص المناعة البشرية، وزيكا، والفيروس العُشي (نيدوفيروس)، والحصبة الألمانية وفيروسات الألتهاب الكبدي.,,,,
هيكلة مشاريع التعلم الآلي,https://www.coursera.org/learn/machine-learning-projects-ar,Data Science,Data Analysis,"Andrew Ng, Younes Bensouda Mourri, Kian Katanforoosh","ستتعلم كيفية بناء مشروع تعلم آلي ناجح. إذا كنت تطمح في أن تكون قائدًا تقنيًا في مجال الذكاء الاصطناعي، وتعرف كيفية تحديد اتجاه عمل فريقك فسيوضح لك هذا المساق كيفية القيام بذلك.

لم يتم تدريس الكثير من هذا المحتوى في أي مكان آخر، وهو مستمد من تجربتي في بناء وتشكيل العديد من منتجات التعلم المتعمق. يحتوي هذا المساق كذلك على ""محاكي طيران"" مما تتيح لك ممارسة عملية صنع القرار كقائد لمشروع التعلم الآلي. مما يمنحك ""خبرة صناعية"" قد تحصل عليها بخلاف ذلك بعد سنوات من الخبرة العملية.

فبعد أسبوعين ستتمكن من: 
- فهم كيفية تشخيص الأخطاء في نظام التعلم الآلي،  
- ستصبح قادرًا على إعطاء الأولوية للاتجاهات الواعدة لتقليل الخطأ،
- فهم إعدادات التعليم الآلي المعقدة مثل مجموعات التدريب/الاختبار غير المتطابقة ومقارنة و/أو تجاوز الأداء على مستوى البشري،
- معرفة كيفية تطبيق التعلم الشامل والنقل التعلم متعدد المهام

فقد شاهدت فرقًا تضيع شهورًا أو سنوات بسبب عدم فهم المبادئ التي يتم تدريسها في هذا المساق. وأتمنى ان يوفر عليك هذا المساق العديد من الأشهر.

فهذا مساق قائم بذاته، يمكنك حضوره طالما ان لديك أساسيات معرفة التعلم الآلي. هذا هو المساق الثالث في تخصص التعلم المتعمق.",,,,
و تحميل البيانات و إخراجهاPandas شرح أساسيات استخدام,https://www.coursera.org/learn/explain-pandas-load-and-export-data,Data Science,Data Analysis,Omnya Khaled,"فى نهاية هذا المشروع ، ستكون قادرًا على تحميل البيانات من ملفات CSV ، وتحديد شكل ال data frame ، وتطبيق بعض العمليات للتحقق من صحة البيانات ، ومعالجة البيانات وتصفيتها. ايضا  ، ستتمكن من إعادة تسمية وحذف الأعمدة وتنظيف البيانات لتطبيق بعض الوظائف  ، وأخيراً تصديرها إلى ملفات CSV باستخدام Pandas library وهي  library  مفتوحة المصدر توفر العديد من الأدوات لتحليل البيانات. يوجد بها العديد من هياكل البيانات التي يمكن استخدامها للعديد من مهام معالجة البيانات المختلفة. كما أن لديها مجموعة متنوعة من الأساليب التي يمكن استخدامها لتحليل البيانات ، والتي تكون مفيدة عند العمل على علوم البيانات و مشاكل الmachine learning  في python.

هذا المشروع  موجه للأشخاص في مجال الأعمال وتحليل البيانات. وأيضًا الأشخاص الذين يرغبون في معرفة المزيد عن library  Python و Pandas. يوفر لك الخطوات المهمة لتكون محلل بيانات. ايضا ، فإنه يزودك بمعرفة هياكل البيانات الأصلية ل Python",,,,
‏SQL لعلوم البيانات,https://www.coursera.org/learn/sql-for-data-science-ar,Data Science,Data Analysis,Sadie St. Lawrence,"مع زيادة جمع البيانات بشكل كبير، تزداد الحاجة إلى الأشخاص المهرة في استخدام البيانات والتفاعل معها؛ لتكون قادرة على التفكير بشكل نقدي، وتقديم رؤى لاتخاذ قرارات أفضل وتحسين أعمالهم. هذا هو عالم بيانات، ""عالم رياضيات جزئي، وعالم كمبيوتر جزئي، ومراقب اتجاهات جزئي"" (SAS Institute، Inc.). وفقًا لـ Glassdoor، كونك عالم بيانات هي أفضل وظيفة في أمريكا؛ براتب أساسي متوسط ​​قدره 110000 دولار، وآلاف من فرص العمل الشاغرة في وقت واحد. تشمل المهارات اللازمة لتكون عالم بيانات جيدًا القدرة على استرداد البيانات والعمل معها، وللقيام بذلك، يجب أن تكون على دراية جيدة بـ SQL، وهي اللغة القياسية للتواصل مع أنظمة قواعد البيانات.

وقد تم تصميم هذه الدورة لتمنحك الدليل التمهيدي في أساسيات SQL والعمل مع البيانات حتى يمكنك البدء في تحليلها لأغراض علوم البيانات. ستبدأ في طرح الأسئلة الصحيحة والتوصل إلى إجابات جيدة لتقديم رؤى قيمة لمؤسستك. تبدأ هذه الدورة بالأساسيات وتفترض أنك لا تملك أي معرفة أو مهارات في SQL. سيعتمد على هذا الأساس وسيطلب منك تدريجيًا كتابة استعلامات بسيطة ومعقدة لمساعدتك في تحديد البيانات من الجداول.  ستبدأ في العمل مع أنواع مختلفة من البيانات مثل السلاسل والأرقام ومناقشة طرق تصفية النتائج وتقليلها. 

ستنشئ جداول جديدة وستكون قادرًا على نقل البيانات إليها. سوف تتعلم العوامل المشتركة وكيفية دمج البيانات. سوف تستخدم بيانات الحالة والمفاهيم مثل إدارة البيانات والتنميط. سوف تناقش موضوعات حول البيانات، وتتدرب على استخدام مهام البرمجة في العالم الحقيقي. ستقوم بتفسير البنية والمعنى والعلاقات في بيانات المصدر واستخدام SQL كمحترف لتشكيل بياناتك لأغراض التحليل المستهدفة. 

على الرغم من أنه ليست لدينا أي متطلبات مسبقة محددة أو متطلبات برامج لأخذ هذه الدورة، إلا إنه يوصى باستخدام محرر نصوص بسيط للمشروع النهائي. فما تنتظرون؟ هذه هي خطوتكم الأولى في الحصول على وظيفة في أفضل مهنة في الولايات المتحدة وقريبًا في العالم!",1649.0,,,
人工智慧：機器學習與理論基礎 (Artificial Intelligence - Learning & Theory),https://www.coursera.org/learn/ai2,Data Science,Machine Learning,于天立,"本課程第二部分著重在和人工智慧密不可分的機器學習。課程內容包含了機器學習基礎理論（包含 1990 年代發展的VC理論）、分類器（包含決策樹及支援向量機）、神經網路（包含深度學習）及增強式學習（包含深度增強式學習。

此部份技術包含最早追溯至 1950 年代直到最近 2016 年附近的最新發展。此課程從基礎理論開始，簡介了各機器學習主流技法以及從淺層學習架構演變到最近深度架構的轉換。

本課程之核心目標為：
（一）使同學對人工智慧相關的機器學習技術有基礎概念
（二）同學能夠理解機器學習基礎理論、分類器、神經網路、增強式學習
（三）同學能將相關技術應用到自己的問題上

修課前，基礎背景知識：
需要的先備知識：計算機概論
建議的先備知識：資料結構與演算法",8463.0,4183.0,4.6,48.0
大數據分析：商業應用與策略管理 (Big Data Analytics: Business Applications and Strategic Decisions),https://www.coursera.org/learn/bigdataanalysis,Data Science,Data Analysis,"魏志平, 李正國, 楊立偉, 陳建錦","本課程是為非資料科學專業者設計的大數據領域入門課程，偏商管應用，非資訊技術教學。透過修習本課程，學員將能對資料科學商管領域的範疇與分類建立基本的觀念，並且瞭解其在商管領域的各種應用。在學的學生可藉此為職涯做準備，在職的社會人士則可拓展自己對資料科學的想像，進一步思考在自身工作場域應用資料科學的可能性。

本課程共計六週，第一週為學界與業界對談，透過直播企劃呈現大數據應用的議題，作為課程的開端，二到五週由臺灣大學教授進行授課，分別就金融、行銷、社群媒體、輿情分析、行銷智慧等議題，介紹大數據在領域的應用，課程以闡述應用為主，但不會花很多時間在演算法的技術細節。第六週則由玉山金控李正國數位金融長主講，帶入玉山金控積極應用大數據於銀行業的策略，產學合作課程確實結合學界與業界的專家，就資料科學的商管應用做不同面向的介紹。

課程設計中安排一位主持人的課前提問、單元介紹引言、延伸提問等等，引導學生學習與思考，各週授課教師與課程主題概述如下：

第一週：臺灣大學資訊管理學系魏志平教授、玉山金控李正國數位金融長 -- 課程簡介、與大數據的午餐約會直播活動
第二週：臺灣大學工商管理學系與資訊管理學系合聘楊立偉教授 -- 資料分析在金融及財務上的應用
第三週：臺灣大學工商管理學系與資訊管理學系合聘楊立偉教授 -- 資料分析在零售及行銷上的應用
第四週：臺灣大學資訊管理學系陳建錦教授 -- 社群媒體之輿情分析
第五週：臺灣大學資訊管理學系魏志平教授 -- 社群媒體分析與行銷智慧
第六週：玉山金控李正國數位金融長 -- 大數據的商業應用策略",17952.0,23076.0,4.7,299.0
機器學習基石上 (Machine Learning Foundations)---Mathematical Foundations,https://www.coursera.org/learn/ntumlone-mathematicalfoundations,Data Science,Machine Learning,林軒田,"Machine learning is the study that allows computers to adaptively improve their performance with experience accumulated from the data observed. Our two sister courses teach the most fundamental algorithmic, theoretical and practical tools that any user of machine learning needs to know. This first course of the two would focus more on mathematical tools, and the other course would focus more on algorithmic tools. [機器學習旨在讓電腦能由資料中累積的經驗來自我進步。我們的兩項姊妹課程將介紹各領域中的機器學習使用者都應該知道的基礎演算法、理論及實務工具。本課程將較為著重數學類的工具，而另一課程將較為著重方法類的工具。]",42558.0,15743.0,4.9,891.0
機器學習基石下 (Machine Learning Foundations)---Algorithmic Foundations,https://www.coursera.org/learn/ntumlone-algorithmicfoundations,Data Science,Machine Learning,林軒田,"Machine learning is the study that allows computers to adaptively improve their performance with experience accumulated from the data observed. Our two sister courses teach the most fundamental algorithmic, theoretical and practical tools that any user of machine learning needs to know. This second course of the two would focus more on algorithmic tools, and the other course would focus more on mathematical tools. [機器學習旨在讓電腦能由資料中累積的經驗來自我進步。我們的兩項姊妹課程將介紹各領域中的機器學習使用者都應該知道的基礎演算法、理論及實務工具。本課程將較為著重方法類的工具，而另一課程將較為著重數學類的工具。]",15052.0,4024.0,4.9,313.0
機器學習技法 (Machine Learning Techniques),https://www.coursera.org/learn/machine-learning-techniques,Data Science,Machine Learning,林軒田,"The course extends the fundamental tools in ""Machine Learning Foundations"" to powerful and practical models by three directions, which includes embedding numerous features, combining predictive features, and distilling hidden features. [這門課將先前「機器學習基石」課程中所學的基礎工具往三個方向延伸為強大而實用的工具。這三個方向包括嵌入大量的特徵、融合預測性的特徵、與萃取潛藏的特徵。]",4634.0,6445.0,4.9,27.0
데이터 과학이란 무엇인가?,https://www.coursera.org/learn/what-is-datascience-ko,Data Science,Data Analysis,"Rav Ahuja, Alex Aklson","The art of uncovering the insights and trends in data has been around since ancient times. The ancient Egyptians used census data to increase efficiency in tax collection and they accurately predicted the flooding of the Nile river every year. Since then, people working in data science have carved out a unique and distinct field for the work they do. This field is data science. In this course, we will meet some data science practitioners and we will get an overview of what data science is today.",,2196.0,4.6,17.0
데이터 과학자의 도구 상자,https://www.coursera.org/learn/data-scientists-tools-ko,Data Science,Data Analysis,"Jeff Leek, PhD, Brian Caffo, PhD, Roger D. Peng, PhD","이 과정에서는 데이터 과학자의 도구 상자에 있는 메인 도구와 아이디어를 소개합니다. 본 과정은 데이터 분석가와 데이터 과학자가 작업하는 데이터, 질문 및 도구의 개요에 대해 설명합니다. 이 과정에는 두 가지 구성 요소가 있습니다. 첫 번째는 데이터를 실행 가능한 지식으로 바꾸는 아이디어에 대한 개념적 소개입니다. 두 번째는 버전 관리, 마크다운, git, GitHub, R 및 RStudio와 같은 프로그램에서 사용할 도구에 대한 실용적인 소개입니다.",,,,
데이터 중심 기업을 위한 비즈니스 지표,https://www.coursera.org/learn/analytics-business-metrics-ko,Data Science,Data Analysis,Jana Schaich Borg,"이 과정에서는 데이터 분석을 사용하여 회사의 경쟁력과 수익성을 높이는 방법에 대한 모범 사례를 배웁니다. 가장 중요한 비즈니스 지표를 인식하고 단순한 데이터와 구별할 수 있습니다.

다양한 유형의 회사에서 수행하는 비즈니스 분석가, 비즈니스 데이터 분석가 및 데이터 과학자의 중요하면서도 다른 역할을 명확하게 이해할 수 있습니다. 그리고 수요가 높은 이러한 직종에 취업하고 성공하기 위해 필요한 기술을 정확히 파악하게 됩니다.

마지막으로 이 과정에서 제공되는 체크리스트를 사용하여 기업이 빅 데이터 문화를 얼마나 효과적으로 수용하고 있는지 점수를 매길 수 있습니다. 아마존, 우버 및 에어비앤비와 같은 디지털 회사는 빅 데이터를 창의적으로 사용하여 전체 산업을 변화시키고 있습니다. 이러한 회사가 와해적인 이유와 어떻게 데이터 분석 기술을 사용하여 기존 회사를 앞서가는지를 알 수 있습니다.",,1832.0,,
머신 러닝 기초: 사례 연구 접근 방식,https://www.coursera.org/learn/ml-foundations-ko,Data Science,Machine Learning,Carlos Guestrin,"데이터가 있고 그 데이터로 무엇을 알 수 있는지 궁금하신가요? 머신 러닝으로 비즈니스를 개선할 수 있는 핵심 방법을 더 깊이 이해해야 하나요? 회귀 및 분류에서 딥 러닝 및 추천 시스템까지 어떤 내용으로든 전문가와 대화할 수 있기를 원하시나요?

이 과정에서는 일련의 실제 사례 연구를 통해 머신 러닝에 대한 실무 경험을 얻을 수 있습니다. 첫 번째 과정이 끝나면 주택 수준 특성을 기반으로 주택 가격을 예측하고, 사용자 리뷰에서 감정을 분석하고, 관심 문서를 검색하고, 제품을 추천하고, 이미지를 검색하는 방법을 배우게 됩니다. 이러한 사용 사례에 대한 실습을 통해 광범위한 영역에서 머신 러닝 방법을 적용할 수 있습니다.

이 첫 번째 과정은 머신 러닝 방법을 블랙박스로 취급합니다. 이 추상화를 통해 관심 있는 작업을 이해하고, 이러한 작업을 머신 러닝 도구와 일치시키고, 출력 품질을 평가하는 데 집중할 것입니다. 후속 과정에서는 모델과 알고리즘을 검토하여 이 블랙박스의 구성 요소를 자세히 알아볼 것입니다. 이 조각들은 결합하여 지능형 애플리케이션 개발에 사용할 머신 러닝 파이프라인을 형성합니다.

학습 결과: 이 과정을 마치면 다음을 수행할 수 있습니다.
-실제로 머신 러닝의 잠재적 애플리케이션을 식별합니다. 
-회귀, 분류 및 클러스터링을 통해 가능해진 분석의 핵심 차이를 설명합니다.
-잠재적 애플리케이션에 적합한 머신 러닝 작업을 선택합니다.
-회귀, 분류, 클러스터링, 검색, 추천 시스템 및 딥 러닝을 적용합니다.
-머신 러닝 모델에 대한 입력 정보 역할을 하는 특성으로 데이터를 제시합니다. 
-각 작업에 대한 관련 오류 지표 측면에서 모델 품질을 평가합니다.
-새로운 데이터를 분석하기 위해 모델에 맞는 데이터 세트를 활용합니다.
-머신 러닝을 핵심으로 사용하는 엔드 투 엔드 애플리케이션을 구축합니다.
-Python에서 이러한 기술을 구현합니다.",,2469.0,,
머신 러닝 프로젝트 구조화,https://www.coursera.org/learn/machine-learning-projects-ko,Data Science,Data Analysis,Andrew Ng,"딥 러닝 전문화 과정의 세 번째 과정에서는 성공적인 머신 러닝 프로젝트를 구축하고 머신 러닝 프로젝트 리더로서 의사 결정을 연습하는 방법을 배우게 됩니다. 

이 과정을 마치면 머신 러닝 시스템의 오류를 진단할 수 있고, 오류를 줄이기 위한 전략의 우선 순위를 지정하고, 일치하지 않는 training/test set와 같은 복합적인 ML 설정을 이해하며 휴먼 레벨의 성능에 필적 및/또는 능가하는 ML 설정을 이해하고, 종단 간 학습, 전이 학습, 멀티 태스크 러닝을 적용할 수 있게 됩니다.

이는 또한 기본적인 머신 러닝 지식이 있는 학습자를 위한 독립형 과정입니다. 이 과정에서는 많은 딥 러닝 제품을 구축하고 출시한 Andrew Ng의 경험을 활용합니다. AI 팀의 방향을 제시할 수 있는 기술 리더가 되고 싶다면 이 과정은 수년간의 ML 업무 경험을 거친 후에 얻을 수 있는 ‘산업 경험’을 제공해드립니다.

딥 러닝 전문화 과정은 딥 러닝의 기능, 도전 과제 및 결과를 이해하고 첨단 AI 기술 개발에 참여할 수 있도록 준비하는 데 도움이 되는 기본 프로그램입니다. 머신 러닝을 업무에 적용하고, 기술 경력의 수준을 높이고, AI 세계의 최종적인 단계를 밟을 수 있는 지식과 기술을 쌓을 수 있는 경로를 제공합니다.",,1627.0,,
시퀀스 모델,https://www.coursera.org/learn/nlp-sequence-models-ko,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh","딥 러닝 전문화의 다섯 번째 과정에서는 시퀀스 모델과 음성 인식, 음악 합성, 챗봇, 기계 번역, 자연어 처리(NLP) 등과 같은 흥미로운 애플리케이션에 익숙해질 것입니다. 

이 과정을 이수하면 순환 신경망(RNN)과 GRU 및 LSTM과 같이 일반적으로 사용되는 변형을 구축 및 훈련하고, RNN을 문자 수준의 언어 모델링에 적용하며, 자연어 처리 및 단어 임베딩에 대한 경험을 얻을 수 있으며, HuggingFace 토크나이저 및 트랜스포머 모델을 사용하여 NER 및 질문에 답하기 같은 다양한 NLP 작업을 해결합니다.

딥 러닝 전문화 과정은 딥 러닝의 기능, 과제 및 결과를 이해하고 최첨단 AI 기술의 개발에 참여할 준비를 하는 데 도움이 되는 기본 프로그램입니다. 경력을 쌓기 위한 지식과 기술을 습득할 수 있도록 도와줌으로써 AI 세계에서 최종적인 단계를 맡을 수 있는 길을 제공합니다.",,1623.0,,
신경망 및 딥 러닝,https://www.coursera.org/learn/neural-networks-deep-learning-ko,Data Science,Machine Learning,Younes Bensouda Mourri,"딥 러닝 전문화의 첫 번째 과정에서는 신경망과 딥 러닝의 기본 개념을 학습합니다. 

마지막에는 완전히 연결된 심층 신경망의 구축, 훈련 및 적용, 효율적인(벡터화된) 신경망 구현, 신경망 아키텍처의 주요 파라미터 식별, 딥 러닝을 자체 애플리케이션에 적용 등 딥 러닝의 부상을 주도하는 중요한 기술 동향에 익숙해질 것입니다.

딥 러닝 전문화는 딥 러닝의 기능, 과제 및 결과를 이해하고 첨단 AI 기술 개발에 참여할 수 있도록 준비하는 데 도움이 되는 기본 프로그램입니다. 머신 러닝을 업무에 적용하고, 기술 경력의 수준을 높이고, AI 세계에서 결정적인 단계를 밟을 수 있는 지식과 기술을 얻을 수 있는 경로를 제공합니다.",,1946.0,,
"심층 신경망 개선: 하이퍼파라미터 튜닝, 정규화 및 최적화",https://www.coursera.org/learn/deep-neural-network-ko,Data Science,Machine Learning,Andrew Ng,"딥 러닝 전문화 두 번째 과정에서는 딥 러닝 블랙박스를 열어 성과를 이끌어내고 체계적으로 좋은 결과를 만들어내는 과정을 이해하게 됩니다. 

최종적으로, 테스트 세트를 훈련 및 개발하고 딥 러닝 애플리케이션 구축을 위한 바이어스/분산을 분석하는 모범 사례를 배우게 됩니다. 초기화, L2 및 드롭아웃 정규화, 하이퍼파라미터 튜닝, 배치 정규화 및 기울기 검사와 같은 표준 신경망 기술을 사용할 수 있어야 합니다. 미니 배치 기울기 하강법, 모멘텀, RMSprop 및 Adam과 같은 다양한 최적화 알고리즘을 구현 및 적용하고 수렴을 확인하고 TensorFlow에서 신경망을 구현합니다.

딥 러닝 전문화는 딥 러닝의 기능, 과제 및 결과를 이해하고 최첨단 AI 기술 개발에 참여할 수 있도록 준비하는 데 도움이 되는 기본 프로그램입니다. 머신 러닝을 업무에 적용하고, 기술 경력 수준을 높이고, AI 세계에서 결정적인 단계를 완료할 수 있는 지식과 기술을 얻을 수 있는 경로를 제공합니다.",,1632.0,,
의사 결정을 위한 비즈니스 분석,https://www.coursera.org/learn/business-analytics-decision-making-ko,Data Science,Data Analysis,Manuel Laguna,이 과정에서는 의사 결정을 위한 모델을 만드는 방법을 알아봅니다. 시장 세분화에 매우 유용한 데이터 축소 기법인 클러스터 분석부터 시작하겠습니다. 그런 다음 많은 비즈니스 결정에 만연한 불확실성을 모델링하는 데 유용한 몬테카를로 시뮬레이션의 기본 사항을 배우게 됩니다. 의사 결정의 핵심 요소는 최선의 조치를 식별하는 것입니다. 비즈니스 문제에는 대안적 해결책이 너무 많은 경우가 있으므로 최적화가 최상의 옵션을 식별하는 데 어떻게 도움이 되는지 배우게 됩니다. 이 과정에서 정말 흥미로운 점은 이러한 예측 및 규범적 분석 모델에 대해 배우기 위해 컴퓨터 언어나 고급 통계를 알아야 할 필요가 없다는 것입니다. Analytic Solver Platform과 Excel에 대한 기본 지식만 있으면 됩니다. 과제에 참여하는 학습자는 Analytic Solver Platform에 무료로 액세스할 수 있습니다.,,,,
컨볼루션 신경망,https://www.coursera.org/learn/convolutional-neural-networks-ko,Data Science,Machine Learning,"Andrew Ng, Kian Katanforoosh, Younes Bensouda Mourri","딥 러닝 전문화의 네 번째 과정에서는 컴퓨터 비전이 어떻게 발전해 왔는지 이해하고 자율 주행, 얼굴 인식, 방사선 이미지 읽기 등과 같은 흥미로운 애플리케이션에 익숙해질 것입니다.

마지막에는 Residual Networks와 같은 최근 파생을 포함하여 컨볼루션 신경망을 구축할 수 있습니다. 시각적 감지 및 인식 작업에 컨볼루션 네트워크를 적용합니다. Neural Style Transfer를 사용하여 아트 작품을 생성하고 이러한 알고리즘을 다양한 이미지, 비디오 및 기타 2D 또는 3D 데이터에 적용합니다. 

딥 러닝 전문화는 딥 러닝의 기능, 도전 과제 및 결과를 이해하고 첨단 AI 기술 개발에 참여할 수 있도록 준비하는 데 유용한 기본 프로그램입니다. 기계 학습을 업무에 적용하고, 기술 경력의 수준을 높이고, AI 세계에서 결정적인 단계를 밟을 수 있는 지식과 기술을 얻을 수 있는 경로를 제공합니다.",,2929.0,,
파이썬의 데이터 과학 소개,https://www.coursera.org/learn/python-data-analysis-ko,Data Science,Data Analysis,Christopher Brooks,"이 과정에서는 학습자에게 람다, csv 파일 읽기 및 조작, numpy 라이브러리와 같은 기본적인 파이썬 프로그래밍 기술을 포함하여 파이썬 프로그래밍 환경의 기본 사항을 소개합니다. 이 과정에서는 인기 있는 python pandas 데이터 과학 라이브러리를 사용하여 데이터 조작 및 정리 기술을 소개하고 데이터 분석을 위한 중심 데이터 구조로 Series 및 DataFrame의 추상화를 소개하고 groupby, merge 및 pivot 테이블 같은 함수를 효과적으로 사용하는 방법에 대한 튜토리얼을 제공합니다. 이 과정이 끝나면 학생들은 표 형식의 데이터를 가져와 정리하고 조작하고 기본 추론 통계 분석을 실행할 수 있습니다. 

이 과정은 다른 ‘파이썬을 사용한 응용 데이터 과학’ 과정보다 먼저 수강해야 합니다. 파이썬의 응용 플로팅, 차트 및 데이터 표현, 파이썬의 응용 머신 러닝, 파이썬의 응용 텍스트 마이닝, 파이썬의 응용 소셜 네트워크 분석.",,2538.0,,
파이썬의 응용 소셜 네트워크 분석,https://www.coursera.org/learn/python-social-network-analysis-ko,Data Science,Data Analysis,Daniel Romero,"이 과정은 NetworkX 라이브러리를 사용한 튜토리얼을 통해 학습자에게 네트워크 분석을 소개합니다. 과정 처음에는 네트워크 분석이란 무엇인지, 왜 현상을 네트워크로 모델링할 수 있는지를 파악합니다. 두 번째 주에는 연결성과 네트워크 견고성의 개념을 소개합니다. 세 번째 주에는 네트워크에서 노드의 중요성 또는 중심성을 측정하는 방법을 탐구합니다. 마지막 주에는 시간 경과에 따른 네트워크의 진화를 탐구하고 네트워크 생성 모델과 링크 예측 문제를 다룹니다.

이 과정을 시작하려면 먼저 다음을 수강해야 합니다. 파이썬의 데이터 과학 입문, 파이썬의 응용 플로팅, 차트 및 데이터 표현, 파이썬의 응용 머신 러닝.",,,,
